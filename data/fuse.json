{"keys":[{"path":["title"],"id":"title","weight":1,"src":"title","getFn":null},{"path":["body"],"id":"body","weight":1,"src":"body","getFn":null}],"records":[{"i":0,"$":{"0":{"v":"This page has not yet sprouted","n":0.408},"1":{"v":"[Dendron](https://dendron.so/) (the tool used to generate this site) lets authors selective publish content. You will see this page whenever you click on a link to an unpublished page\n\n![](https://foundation-prod-assetspublic53c57cce-8cpvgjldwysl.s3-us-west-2.amazonaws.com/assets/images/not-sprouted.png)","n":0.189}}},{"i":1,"$":{"0":{"v":"root","n":1},"1":{"v":"\nThe hyperfixated rabbit hole diving knowledge base that is my brain looking at technology.\n","n":0.267}}},{"i":2,"$":{"0":{"v":"Theory","n":1}}},{"i":3,"$":{"0":{"v":"Pseudo Code Sketching","n":0.577},"1":{"v":"\n\n- [This One Technique Is How I Build Projects Without Getting Stuck][1]\n  - Write comments (pseudo-code) for everything that should happen then write the code for it\n  - Writing out comments for the logic of the code/functions to flesh out\n\n[1]: https://youtu.be/Qvmp4F-hOKA\n","n":0.156}}},{"i":4,"$":{"0":{"v":"Mental Models","n":0.707},"1":{"v":"\n\n| Acronym | Definition              |\n| ------- | ----------------------- |\n| KISS    | Keep It Super Simple    |\n| YAGNI   | You Ain't Gonna Need It |\n| MVP     | Minimum Viable Product  |\n","n":0.183}}},{"i":5,"$":{"0":{"v":"Strangler Fig","n":0.707},"1":{"v":"\n<https://martinfowler.com/bliki/StranglerFigApplication.html>\n","n":1}}},{"i":6,"$":{"0":{"v":"Guard Clauses","n":0.707},"1":{"v":"\n\nThe idea behind returning early is that you write functions that return the expected positive result at the end of the function.\n\nThe rest of the code, in the function, should trigger the termination as soon as possible in case of divergence with the function‚Äôs purpose.\n\nAn early return does exactly as its name implies. This is what an early return looks like:\n\n```js\nfunction someFunction() {\n    if (!someCondition) {\n        return;\n    }    \n    // Do something\n}\n```\n\n- Reference:\n  - <https://levelup.gitconnected.com/how-you-can-avoid-using-else-in-your-code-871197a1adbc>\n\n","n":0.115}}},{"i":7,"$":{"0":{"v":"Design Patterns","n":0.707},"1":{"v":"\n## Creational\n\n> How objects are created\n\n### Singleton\n\n- a type of object that can only be instantiated once\n\n### Prototype\n\n- cloning and inheritance. \n\n### Builder\n\n- Method chaining and instead of passing all arguments at instantiation it can be used to have setter methods that are called with method chaining so the object that gets returned after each method is progressively built up into its final form\n\n### Factory\n\n- instead of using `new` keywords to instantiate an object you use a function to do it for you\n\n## Structural\n\n> How objects relate to each other\n\n### Facade\n\n- a simplified API to hide other low level details in your code while still implementing them\n\n![facade pattern](/assets/images/2022-07-05-18-23-04.png)\n\n### Proxy\n\n- using a stand in object in place of the original that can also contain side effects and additional behavior\n\n## Behavioral\n\n> How objects behave with each other\n\n### Iterator\n\n![iterator](/assets/images/2022-07-05-18-28-20.png)\n\n### Observer\n\n- allows many objects to intercept events broadcasted by other objects.\n- It's a one to many relationship (like a radio tower and several receivers)\n\n![Observer](/assets/images/2022-07-05-18-30-52.png)\n\n### Mediator\n\n- middle man or broker\n- like runways and airplanes (is the runway clear for the airplane to land)\n  - Instead of having all the objects talking to each other via a many to many relationship\n- mediator is like an air traffic controller coordinating between airplanes and runways\n\n### State\n\n- where an object behaves a specific way based on a finite number of states\n\n![bad, switch hell](/assets/images/2022-07-05-18-34-52.png)\n\n![state machine implementation](/assets/images/2022-07-05-18-35-17.png)\n\n![implemented methods](/assets/images/2022-07-05-18-35-41.png)\n\n![when state changes. object will behave in a completely different way](/assets/images/2022-07-05-18-36-02.png)","n":0.065}}},{"i":8,"$":{"0":{"v":"Data Warehousing","n":0.707}}},{"i":9,"$":{"0":{"v":"Component Object Model","n":0.577},"1":{"v":"\n\n#üå±Ô∏è\n","n":1}}},{"i":10,"$":{"0":{"v":"Anti Patterns","n":0.707}}},{"i":11,"$":{"0":{"v":"Itm","n":1},"1":{"v":"\n\n**I**nitialize **T**hen **M**odify\n\n- [[r.+.2021.10.20.beautiful-python-refactoring]]\n  - ![alt](assets/images/Pasted_image_20211020110715.png)\n  - ![alt](assets/images/Pasted_image_20211020110728.png)\n\n---\n\n- Reference:\n  - [[r.+.2021.10.20.beautiful-python-refactoring]]\n- Related:\n  - [[DRY|terms.dry]]\n\n","n":0.267}}},{"i":12,"$":{"0":{"v":"Agile","n":1},"1":{"v":"\n\n## Risk & Release Frequency\n\n![alt](assets/images/Pasted_image_20211130105154.png)\n\n## Iterations\n\n![alt](assets/images/Pasted_image_20211130105226.png)\n\n## Backlogs & Story Sizing\n\n![alt](assets/images/Pasted_image_20211130105241.png)\n\n- Reference:\n  - <https://medium.com/swlh/three-drawings-i-use-to-explain-agile-9c0ef15b64b8>\n","n":0.277}}},{"i":13,"$":{"0":{"v":"Terms","n":1}}},{"i":14,"$":{"0":{"v":"Zettabyte file system","n":0.577},"1":{"v":"\nThe go-to file system of servers\n\n<https://en.wikipedia.org/wiki/ZFS>\n","n":0.408}}},{"i":15,"$":{"0":{"v":"ZIL","n":1},"1":{"v":"\n<https://www.truenas.com/blog/zfs-zil-and-slog-demystified/>\n","n":1}}},{"i":16,"$":{"0":{"v":"Yagni","n":1},"1":{"v":"\n`Y`ou `A`aint `G`onna `N`eed `I`t\n","n":0.447}}},{"i":17,"$":{"0":{"v":"Vpn","n":1},"1":{"v":"\n\n`V`irtual `P`rivate `N`etwork\n","n":0.577}}},{"i":18,"$":{"0":{"v":"VLAN","n":1},"1":{"v":"\n\n`V`irtual `L`ocal `A`rea `N`etwork\n\n- VLAN's for various utility purposes\n  - `\"...it is common practice to isolate server-to-server traffic from client-server traffic and to isolate administration/management traffic (channels used for inbound management of appliances and servers). Another standard configuration option is to create a \"null\" VLAN that is non-routable to the rest of the network. This VLAN is used for any physical ports that do not have authorized connected equipment.\"`\n  - ![vlans](assets/images/2022-01-07-20-19-15.png)\n  - ![vlans2](assets/images/2022-01-07-20-22-44.png)","n":0.117}}},{"i":19,"$":{"0":{"v":"uuid","n":1}}},{"i":20,"$":{"0":{"v":"TTL","n":1},"1":{"v":"\n\n`T`ime `T`o `L`ive\n\nThe amount of hops through a router. when the number hits 0 the packet is discarded.\n","n":0.236}}},{"i":21,"$":{"0":{"v":"Tld","n":1},"1":{"v":"\n\n`T`op `L`evel `D`omain\n\nLike `.com` | `.org` | `.mil` | `.gov`\n","n":0.316}}},{"i":22,"$":{"0":{"v":"Syn","n":1},"1":{"v":"\n\n`Syn`chronize\n","n":1}}},{"i":23,"$":{"0":{"v":"Slc","n":1},"1":{"v":"\n\n`S`oftware `L`icense `C`ompliance\n","n":0.577}}},{"i":24,"$":{"0":{"v":"Sla","n":1},"1":{"v":"\n\n`S`ervice `L`evel `A`greement\n","n":0.577}}},{"i":25,"$":{"0":{"v":"Rst","n":1},"1":{"v":"\n\n`R`e`s`e`t` segment\n\nUsed to abruptly end a [[n.protocol.tcp]] connection\n\nNot standard behavior\n","n":0.316}}},{"i":26,"$":{"0":{"v":"Rfc","n":1},"1":{"v":"\n\n`R`equest `F`or `C`hange\n\nor\n\n`R`equest `F`or `C`omment\n","n":0.447}}},{"i":27,"$":{"0":{"v":"Protected Management Frames","n":0.577},"1":{"v":"\n\n> prevents a malicious third party from sending deauth frames and kicking clients off the network and forcing them to reauth, or from otherwise screwing with the network.\n>\n> By default with 802.11 wifi, even if your traffic is encrypted, so called management frames are not, the setting you listed enables crypto for management frames.\n>\n> <https://www.reddit.com/r/HomeNetworking/comments/6u336f/comment/dlpig45/?utm_source=share&utm_medium=web2x&context=3>\n","n":0.135}}},{"i":28,"$":{"0":{"v":"Network File System","n":0.577}}},{"i":29,"$":{"0":{"v":"Nack","n":1},"1":{"v":"\n\n`N`egative `Ack`nowledgement Packet\n","n":0.577}}},{"i":30,"$":{"0":{"v":"MTU","n":1},"1":{"v":"\n\n`M`aximum `T`ransmission `U`nit \n\npHow large a packet can be sent without the need for fragmentation.\n","n":0.258}}},{"i":31,"$":{"0":{"v":"Mitm","n":1},"1":{"v":"\n\n`M`an `I`n `T`he `M`iddle\n","n":0.5}}},{"i":32,"$":{"0":{"v":"MIB","n":1},"1":{"v":"\n\n`M`anagement `I`nformation `B`ase\n\nHolds statistics relating to the activity of the device, such as the number of frames per second handled by a switch. \nEach parameter stored in a MIB is referred to by a numeric Object Identifier (OID).\nOIDs are stored within a tree structure. \nPart of the tree is generic to SNMP, while part can be defined by the device vendor.\n","n":0.128}}},{"i":33,"$":{"0":{"v":"Lan","n":1},"1":{"v":"\n\n`L`ocal `A`rea `N`etwork\n","n":0.577}}},{"i":34,"$":{"0":{"v":"iommu","n":1},"1":{"v":"\n\n- <https://en.wikipedia.org/wiki/Input%E2%80%93output_memory_management_unit>\n\n> \"In virtualization, guest operating systems can use hardware that is not specifically made for virtualization. Higher performance hardware such as graphics cards use DMA to access memory directly; in a virtual environment all memory addresses are re-mapped by the virtual machine software, which causes DMA devices to fail. The IOMMU handles this re-mapping, allowing the native device drivers to be used in a guest operating system.\"\n","n":0.121}}},{"i":35,"$":{"0":{"v":"Idempotent","n":1},"1":{"v":"\n> \"denoting an element of a set which is unchanged in value when multiplied or otherwise operated on by itself.\"\n\nIn [[terms.api]]'s this is the outcome of only 1 executed action despite potentially multiple attempts to perpetrate an action.\n\n> \"an Idempotent Operation is when a request can be retransmitted or retried with no additional side effects\"\n","n":0.135}}},{"i":36,"$":{"0":{"v":"Infrastructure As Code","n":0.577},"1":{"v":"\n\n[[s.iac.ansible]]\n","n":1}}},{"i":37,"$":{"0":{"v":"Fqdn","n":1},"1":{"v":"\n\n`F`ully `Q`ualified `D`omain `N`ame\n\n## example\n\n> nut.widget.com\n\n## Details\n\nAn FQDN is made up of the host name and a domain suffix. \n\nIn the example, the host name is `nut` and the domain suffix is `widget.com`. \n\nThis domain suffix consists of the domain name widget within the top-level domain ([[terms.tld]]) `.com`.\nA domain suffix could also contain subdomains between the host and domain name. \nThe trailing dot or period represents the root of the hierarchy.\n\n## Rules\n\n- The host name must be unique within the domain.\n- The total length of an FQDN cannot exceed 253 characters, \n    - with each label (part of the name defined by a period) no more than 63 characters (excluding the periods).\n- A DNS label should use letter, digit, and hyphen characters only. \n    - A label should not start with a hyphen. Punctuation characters such as the period (.) or forward slash (/) should not be used.\n- DNS labels are not case sensitive.\n\n## Find your FQDN\n\n### Windows\n\n```shell\nipconfig /all\n```\n\n### Linux\n\n```bash\nhostname -fqdn\n```\n","n":0.079}}},{"i":38,"$":{"0":{"v":"Fin","n":1},"1":{"v":"\n\n`Fin`ish\n\nConcludes the 4 step handshake to a graceful exit to a [[n.protocol.tcp]] connection\n","n":0.277}}},{"i":39,"$":{"0":{"v":"Etl","n":1},"1":{"v":"\n\n`E`xtract `T`ransform `L`oad\n","n":0.577}}},{"i":40,"$":{"0":{"v":"ESP","n":1},"1":{"v":"\n\n`E`ncapsulating `S`ecurity `P`ayload\n","n":0.577}}},{"i":41,"$":{"0":{"v":"Data Source Name","n":0.577},"1":{"v":"\nTODO put info here that i used to setup DSN python file watching service","n":0.267}}},{"i":42,"$":{"0":{"v":"Dry","n":1},"1":{"v":"\n\n`D`on't `R`epeat `Y`ourself\n","n":0.577}}},{"i":43,"$":{"0":{"v":"Drp","n":1},"1":{"v":"\n\n`D`isaster `R`ecovery `P`lan\n","n":0.577}}},{"i":44,"$":{"0":{"v":"Cidr","n":1},"1":{"v":"\n\n`C`lassless `I`nter-`D`omain `R`outing\n","n":0.577}}},{"i":45,"$":{"0":{"v":"CI CD","n":0.707},"1":{"v":"\n\n`C`ontinuous `I`ntegration - `C`ontinuous `D`evelopment\n\n![[r.+.2022.02.22.the-ideal-ci-cd-pipeline-concepts-overview]]\n","n":0.447}}},{"i":46,"$":{"0":{"v":"Content Delivery Network","n":0.577},"1":{"v":"\n> A content delivery network (CDN) is a group of geographically distributed servers that speed up the delivery of web content by bringing it closer to where users are. \n>\n> -- <https://www.akamai.com/our-thinking/cdn/what-is-a-cdn#:~:text=A%20content%20delivery%20network%20(CDN,closer%20to%20where%20users%20are.>\n\n","n":0.177}}},{"i":47,"$":{"0":{"v":"Cab","n":1},"1":{"v":"\n\n`C`hange `A`dvisory `B`oard\n","n":0.577}}},{"i":48,"$":{"0":{"v":"API","n":1},"1":{"v":"\n\n`A`pplication `P`rogramming `I`nterface\n\n![[r.+.2022.02.24.what_is_api_idempotency_and_why_is_it_important#notes]]\n","n":0.577}}},{"i":49,"$":{"0":{"v":"ACL","n":1},"1":{"v":"\n\n`A`ccess `C`ontrol `L`ist\n","n":0.577}}},{"i":50,"$":{"0":{"v":"Ack","n":1},"1":{"v":"\n\n`Ack`nowledgement Packet\n","n":0.707}}},{"i":51,"$":{"0":{"v":"ACID","n":1},"1":{"v":"\n> **Atomicity**\n> A transaction must be an atomic unit of work; either all of its data modifications are performed, or none of them are performed.\n>\n> **Consistency**\n> When completed, a transaction must leave all data in a consistent state.\n> In a relational database, all rules must be applied to the transaction's modifications to maintain all data integrity.\n> All internal data structures, such as B-tree indexes or doubly-linked lists, must be correct at the end of the transaction.\n>\n> **Isolation**\n> Modifications made by concurrent transactions must be isolated from the modifications made by any other concurrent transactions.\n> A transaction either recognizes data in the state it was in before another concurrent transaction modified it, or it recognizes the data after the second transaction has completed, but it does not recognize an intermediate state.\n> This is referred to as serializability because it results in the ability to reload the starting data and replay a series of transactions to end up with the data in the same state it was in after the original transactions were performed.\n>\n> **Durability**\n> After a fully durable transaction has completed, its effects are permanently in place in the system.\n> The modifications persist even in the event of a system failure.\n> SQL Server 2014 (12.x) and later enable delayed durable transactions.\n> Delayed durable transactions commit before the transaction log record is persisted to disk.\n> For more information on delayed transaction durability, see the article Transaction Durability.\n>\n> -- <https://docs.microsoft.com/en-us/sql/relational-databases/sql-server-transaction-locking-and-row-versioning-guide?view=sql-server-ver15>\n","n":0.065}}},{"i":52,"$":{"0":{"v":"Templates","n":1}}},{"i":53,"$":{"0":{"v":"R","n":1}}},{"i":54,"$":{"0":{"v":"Video","n":1},"1":{"v":"\n\n\n---\n\n- $0\n","n":0.707}}},{"i":55,"$":{"0":{"v":"Article","n":1},"1":{"v":"\n- Author:\n  - ${2:[[p.}\n- Anatomy:\n  - ${3:[[a.}\n- Activity:\n  - ${4:[[n.}\n- Category:\n  - ${5:[[n.}\n- Related:\n  - \n- Reference:\n  - \n\n---\n\n- ${0}\n","n":0.224}}},{"i":56,"$":{"0":{"v":"S","n":1}}},{"i":57,"$":{"0":{"v":"Funcs","n":1},"1":{"v":"\n## Details\n\n$0\n\n## Usage\n\n```$1\n\n```\n","n":0.577}}},{"i":58,"$":{"0":{"v":"Log","n":1}}},{"i":59,"$":{"0":{"v":"Monthly","n":1},"1":{"v":"\n\n## Notes Worked On This Month\n","n":0.408}}},{"i":60,"$":{"0":{"v":"Daily","n":1},"1":{"v":"\n\n## Inputs\n\n---\n\n---\n\n## Notes\n\n---\n\n---\n","n":0.577}}},{"i":61,"$":{"0":{"v":"Annually","n":1},"1":{"v":"\n\nannual\n","n":1}}},{"i":62,"$":{"0":{"v":"Task","n":1}}},{"i":63,"$":{"0":{"v":"Tags","n":1}}},{"i":64,"$":{"0":{"v":"√∞√Ç¬ü√Ç¬å¬øÔ∏è","n":1}}},{"i":65,"$":{"0":{"v":"√∞√Ç¬ü√Ç¬å¬≤Ô∏è","n":1}}},{"i":66,"$":{"0":{"v":"√∞√Ç¬ü√Ç¬å¬±Ô∏è","n":1}}},{"i":67,"$":{"0":{"v":"√∞√Ç¬ü√Ç¬å√Ç¬ûÔ∏è","n":1}}},{"i":68,"$":{"0":{"v":"Scratch","n":1}}},{"i":69,"$":{"0":{"v":"2022","n":1}}},{"i":70,"$":{"0":{"v":"01","n":1}}},{"i":71,"$":{"0":{"v":"01","n":1}}},{"i":72,"$":{"0":{"v":"Monthly Review Task Code Execution","n":0.447},"1":{"v":"\n\n```bash {cmd=true}\ncd \"${workspaceFolder}\" && lsd -lA *.md | awk '{print $7,$10,$NF}' | grep \"$(date +\"%b %Y\")\" | awk '{print \"[[\"$NF\"]]\"}'\n```\n","n":0.224}}},{"i":73,"$":{"0":{"v":"Software","n":1}}},{"i":74,"$":{"0":{"v":"Query","n":1}}},{"i":75,"$":{"0":{"v":"T-SQL","n":1}}},{"i":76,"$":{"0":{"v":"Process","n":1}}},{"i":77,"$":{"0":{"v":"ETL","n":1}}},{"i":78,"$":{"0":{"v":"Bulk Insert","n":0.707},"1":{"v":"\n<https://docs.microsoft.com/en-us/sql/t-sql/statements/bulk-insert-transact-sql?view=sql-server-ver15>\n\n```sql\nBULK INSERT\n   { database_name.schema_name.table_or_view_name | schema_name.table_or_view_name | table_or_view_name }\n    FROM 'data_file'\n    [ WITH (\n        [ [ , ] BATCHSIZE = batch_size ]\n        [ [ , ] CHECK_CONSTRAINTS ]\n        [ [ , ] CODEPAGE = { 'ACP' | 'OEM' | 'RAW' | 'code_page' } ]\n        [ [ , ] DATAFILETYPE = { 'char' | 'native'| 'widechar' | 'widenative' } ]\n        [ [ , ] DATA_SOURCE = 'data_source_name' ]\n        [ [ , ] ERRORFILE = 'file_name' ]\n        [ [ , ] ERRORFILE_DATA_SOURCE = 'errorfile_data_source_name' ]\n        [ [ , ] FIRSTROW = first_row ]\n        [ [ , ] FIRE_TRIGGERS ]\n        [ [ , ] FORMATFILE_DATA_SOURCE = 'data_source_name' ]\n        [ [ , ] KEEPIDENTITY ]\n        [ [ , ] KEEPNULLS ]\n        [ [ , ] KILOBYTES_PER_BATCH = kilobytes_per_batch ]\n        [ [ , ] LASTROW = last_row ]\n        [ [ , ] MAXERRORS = max_errors ]\n        [ [ , ] ORDER ( { column [ ASC | DESC ] } [ ,...n ] ) ]\n        [ [ , ] ROWS_PER_BATCH = rows_per_batch ]\n        [ [ , ] ROWTERMINATOR = 'row_terminator' ]\n        [ [ , ] TABLOCK ]\n\n        -- input file format options\n        [ [ , ] FORMAT = 'CSV' ]\n        [ [ , ] FIELDQUOTE = 'quote_characters']\n        [ [ , ] FORMATFILE = 'format_file_path' ]\n        [ [ , ] FIELDTERMINATOR = 'field_terminator' ]\n        [ [ , ] ROWTERMINATOR = 'row_terminator' ]\n    )]\n```\n","n":0.066}}},{"i":79,"$":{"0":{"v":"Tools","n":1}}},{"i":80,"$":{"0":{"v":"Tsql Test","n":0.707},"1":{"v":"\n<!-- REVISIT TSQL Test -->\n\n- <https://www.red-gate.com/products/sql-development/sql-test/>\n- <https://www.mssqltips.com/sqlservertip/5195/free-database-unittesting-framework-for-sql-server/>\n- <https://www.mssqltips.com/sqlservertip/5195/free-database-unittesting-framework-for-sql-server/>\n- <https://tsqlt.org/user-guide/>\n- <https://tsqlt.org/user-guide/quick-start/>\n- <https://tsqlt.org/use-tsqlt-framework/>\n- <https://www.red-gate.com/simple-talk/databases/sql-server/t-sql-programming-sql-server/getting-started-testing-databases-with-tsqlt/>\n","n":0.289}}},{"i":81,"$":{"0":{"v":"SSRS","n":1},"1":{"v":"\n- <https://docs.microsoft.com/en-us/sql/reporting-services/create-a-basic-table-report-ssrs-tutorial?view=sql-server-2017>","n":0.707}}},{"i":82,"$":{"0":{"v":"Ssms","n":1}}},{"i":83,"$":{"0":{"v":"Tips Tricks","n":0.707}}},{"i":84,"$":{"0":{"v":"Database Diagrams Can Build Your Tables and Relationships","n":0.354},"1":{"v":"\nIn the diagrams pane if you make a new diagram you can make your tables and their relationships in a GUI all at once\n","n":0.204}}},{"i":85,"$":{"0":{"v":"Custom Color Theme Settings Import Export","n":0.408},"1":{"v":"\n<https://www.sentryone.com/blog/aaronbertrand/making-ssms-pretty-my-dark-theme>\n","n":1}}},{"i":86,"$":{"0":{"v":"Ssis","n":1},"1":{"v":"\n## Resources\n\n- <https://www.mssqltips.com/sqlservertip/6409/extract-import-and-migrate-ssis-project/>\n- <https://www.mssqltips.com/sqlservertip/3676/sql-server-integration-services-2016-incremental-package-deployment/>\n- <https://www.timmitchell.net/post/2017/05/31/deleting-a-package-from-the-ssis-catalog/>\n","n":0.447}}},{"i":87,"$":{"0":{"v":"Sql Smash","n":0.707}}},{"i":88,"$":{"0":{"v":"Sql Agent","n":0.707}}},{"i":89,"$":{"0":{"v":"Toggle All Sql Server Agent Jobs","n":0.408},"1":{"v":"\n## Disable\n\n### Blanket Disable\n\n```sql\nUSE MSDB;\nGO\n\nDECLARE @job_id uniqueidentifier\n\nDECLARE job_cursor CURSOR READ_ONLY FOR\nSELECT job_id FROM msdb.dbo.sysjobs WHERE enabled = 1\n\nOPEN job_cursor\nFETCH NEXT FROM job_cursor INTO @job_id\n\nWHILE @@FETCH_STATUS = 0\nBEGIN\n   EXEC msdb.dbo.sp_update_job @job_id = @job_id, @enabled = 0\n   FETCH NEXT FROM job_cursor INTO @job_id\nEND\n\nCLOSE job_cursor\nDEALLOCATE job_cursor\n```\n\n### Disable by name\n\n```sql\nUSE MSDB;\nGO\n\nDECLARE @job_id uniqueidentifier\n\nDECLARE job_cursor CURSOR READ_ONLY FOR\nSELECT job_id FROM msdb.dbo.sysjobs WHERE enabled = 1 AND [name] like N'Admin%'\n\nOPEN job_cursor\nFETCH NEXT FROM job_cursor INTO @job_id\n\nWHILE @@FETCH_STATUS = 0\nBEGIN\n   EXEC msdb.dbo.sp_update_job @job_id = @job_id, @enabled = 0\n   FETCH NEXT FROM job_cursor INTO @job_id\nEND\n\nCLOSE job_cursor\nDEALLOCATE job_cursor\n```\n\n### Disable Jobs By Job Category\n\n```sql\nUSE MSDB;\nGO\n\nDECLARE @job_id uniqueidentifier\n\nDECLARE job_cursor CURSOR READ_ONLY FOR\nSELECT SJ.job_id\nFROM msdb.dbo.sysjobs SJ\n   INNER JOIN msdb.dbo.syscategories AS SC\n      ON SJ.category_id = SC.category_id\nWHERE SJ.enabled = 1\n   AND SC.[name] = N'Database Maintenance'\n\nOPEN job_cursor\nFETCH NEXT FROM job_cursor INTO @job_id\n\nWHILE @@FETCH_STATUS = 0\nBEGIN\n   EXEC msdb.dbo.sp_update_job @job_id = @job_id, @enabled = 0\n   FETCH NEXT FROM job_cursor INTO @job_id\nEND\n\nCLOSE job_cursor\nDEALLOCATE job_cursor\n```\n\n## Enable\n\n```sql\nUSE MSDB;\nGO\n\nDECLARE @job_id uniqueidentifier\n\nDECLARE job_cursor CURSOR READ_ONLY FOR\nSELECT job_id FROM msdb.dbo.sysjobs WHERE enabled = 0\n\nOPEN job_cursor\nFETCH NEXT FROM job_cursor INTO @job_id\n\nWHILE @@FETCH_STATUS = 0\nBEGIN\n   EXEC msdb.dbo.sp_update_job @job_id = @job_id, @enabled = 1\n   FETCH NEXT FROM job_cursor INTO @job_id\nEND\n\nCLOSE job_cursor\nDEALLOCATE job_cursor\n```\n","n":0.073}}},{"i":90,"$":{"0":{"v":"Resources","n":1},"1":{"v":"\n<!-- REVISIT SQL Agent job information -->\n\n- <https://www.mssqltips.com/sqlservertip/6111/query-sql-server-agent-jobs-job-steps-history-and-schedule-system-tables/>\n- <https://www.mssqltips.com/sqlservertip/5969/manage-sql-server-agent-history-more-effectively/>\n- <https://www.mssqltips.com/sqlservertip/5731/how-to-pass-data-between-sql-server-agent-job-steps/>\n- <https://www.mssqltips.com/sqlservertip/5911/run-python-scripts-in-sql-server-agent/>\n- <https://www.mssqltips.com/sqlservertip/1394/how-to-store-longer-sql-agent-job-step-output-messages/>\n","n":0.289}}},{"i":91,"$":{"0":{"v":"Check Current Staus of Sql Agent Jobs","n":0.378},"1":{"v":"\n```sql\nSELECT job_id, name, enabled FROM msdb.dbo.sysjobs\n\n-- or this version\n\nSELECT SJ.job_id\n     , SJ.name\n     , SJ.enabled\n     , SC.name AS category\nFROM msdb.dbo.sysjobs AS SJ\nINNER JOIN msdb.dbo.syscategories AS SC\n    ON SJ.category_id = SC.category_id\n```\n","n":0.186}}},{"i":92,"$":{"0":{"v":"Redgate","n":1},"1":{"v":"\n- **The Tools:** <https://www.red-gate.com/products/sql-development/sql-source-control/>\n- **About it:** <https://www.youtube.com/watch?v=aR5IHfHvh98>\n- [Version Control Demo With Git](https://youtu.be/mNXipSFbV0s)\n","n":0.289}}},{"i":93,"$":{"0":{"v":"Workflow","n":1},"1":{"v":"\n## Deploying New DB from TEST to PROD\n\n1. Create same name copy of DB onto PROD\n2. Link that DB with the working folder you've been working out of\n3. `Get Latest`\n4. Apply changes\n   - If there are changes on the remote Repository you can pull those too to apply those changes as well\n\n## Every Day Workflow\n\n- This assumes all setup and connection work has been done for redgate work\n- The following examples assume you're performing all this work on 1 SQL Server: `TEST` and that downstream, migration scripts will be applied to push those changes automatically onto the `PROD` server without human intervention.\n\n### Getting Started and Setup\n\n- Main repository is Repo @ `PROD`\n  - They pull the repo and branch down to local machine\n  - People make their own branch off of `PROD` that will contains the changes they want for specific work\n  - they are now up to date and ready to work\n- Cloning the database you want to work in\n  <!-- - Right click the database you want to change\n  - `Tasks > Copy Database` -->\n- Open [[s.q.tsql.tools.redgate.products.sql-compare]]\n  - Select Source Server and Database\n  - Select Target Server and in the database selection dropdown type the name of your new DEV copy of the database\n    - The new empty database naming convention being DATABASE_BSJ_DEV\n    - the database name in all caps, followed by the developers initials, and ended with DEV so people know its someones development copy\n    - When the name is ready click the `Create` link below the dropdown\n  - Continue through the Sql Compare menus and no need to save or backup the migration scripts\n  - After copying of the database is complete you're ready to begin work if changes are only schema related\n    - Right click that new DB and `Link with source control`\n    - `Link with my source control system`\n    - Select the folder location of the database from within the repository\n    - `Get Latest` if applicable\n    - `Apply Changes` if applicable\n    - Developer is now free to make changes to schema, objects, etc inside their test database\n- If data is also required within the dev copy from the source database then open [[s.q.tsql.tools.redgate.products.data-compare]]\n  - Select Source Server and Database\n  - Select Target Server and in the database selection dropdown type the name of your new DEV copy of the database you made prior\n  - No need to save the migration scripts and run everything within the Data Compare tool for deployment\n  - Select the data to copy across databases\n  - `Deploy`\n  - Now your schema and data all match across the servers and databases\n    - Right click that new DB and `Link with source control`\n    - `Link with my source control system`\n    - Select the folder location of the database from within the repository\n    - Select the folder location of the database from within the repository\n    - `Get Latest` if applicable\n    - `Apply Changes` if applicable\n    - Developer is now free to make changes to schema, objects, etc inside their test database\n\n### Getting your change into the Pull Request process\n\n- Make your changes, New UDF, new USP, modify existing items, make new tables, alter other tables, etc.\n- When ready, or incrementally throughout the process add your changes to your branch via commits\n- when you are ready to enter the PR process push your branch to the remote repository\n- open pull request of your branch into the master branch\n- Normal PR process occurs here\n- Once PR is merged then at that point CI/CD pipelines should take over to build, test, and deploy the changes to the `PROD` server with no human intervention.\n  - **IF NO AUTOMATED PROCESS YET PROCEED TO SECTION BELOW**\n\n#### Manual implementation of new changes in the absence of a CI/CD pipeline\n\n<!-- - Back in [[s.db.ms-sql-server.tools.ssms]] select your target database (the one you wanted to make changes to not your DEV copy of it)\n- Got to the SQL Source Control Interface and `Get Latest`\n- Apply Changes -->\n- Open [[r.+.redgate-training.sql-change-automation]]\n- Pick your source and target for changes\n  - Based on this proposed workflow your source would be the \"master\" copy of the Database on the `TEST` server\n  - Based on this proposed workflow your target would be the same Database on the `PROD` server\n- Select desired changes to be implemented\n- Click `Deploy` to generate a migration script to implement changes without modification to the repository code\n  - If the individual cannot run the code then pass it to someone who can as a final deliverable artifact to be executed and discarded\n","n":0.037}}},{"i":94,"$":{"0":{"v":"Products","n":1}}},{"i":95,"$":{"0":{"v":"Sql Search","n":0.707},"1":{"v":"\n## Setup\n\n1. Close [[s.db.ms-sql-server.tools.ssms]] and Visual Studio\n2. Run Installers\n","n":0.333}}},{"i":96,"$":{"0":{"v":"Sql Scripts Manager","n":0.577},"1":{"v":"\n## Setup\n\n1. Close [[s.db.ms-sql-server.tools.ssms]] and Visual Studio\n2. Run Installers\n3. Make sure you have an up to date copy of the SQL Server Repo installed for the shared scripts folder\n4. `File > Application Options > ...`\n5. change scripts folder location to the location of the teams shared scripts\n","n":0.146}}},{"i":97,"$":{"0":{"v":"Sql Compare","n":0.707},"1":{"v":"\n## Setup\n\n1. Close [[s.db.ms-sql-server.tools.ssms]] and Visual Studio\n2. Run Installers\n","n":0.333}}},{"i":98,"$":{"0":{"v":"Sql Change Automation","n":0.577},"1":{"v":"\n## Setup\n\n1. Close [[s.db.ms-sql-server.tools.ssms]] and Visual Studio\n2. Run Installers\n","n":0.333}}},{"i":99,"$":{"0":{"v":"Flyway Desktop","n":0.707},"1":{"v":"\n## Setup\n\n1. Close [[s.db.ms-sql-server.tools.ssms]] and Visual Studio\n2. Run Installers\n","n":0.333}}},{"i":100,"$":{"0":{"v":"Deploy","n":1},"1":{"v":"\n## Setup\n\n1. Close [[s.db.ms-sql-server.tools.ssms]] and Visual Studio\n2. Run Installers\n3. Enter [[s.db.ms-sql-server.tools.ssms]] and enter license key\n","n":0.258}}},{"i":101,"$":{"0":{"v":"Data Compare","n":0.707},"1":{"v":"\n## Setup\n\n1. Close [[s.db.ms-sql-server.tools.ssms]] and Visual Studio\n2. Run Installers\n","n":0.333}}},{"i":102,"$":{"0":{"v":"Implementation Notes","n":0.707},"1":{"v":"\n1. Make Empty Git repository on Azure DevOps\n2. Make sure git repo has a master branch on the remote\n   - If you cannot make this happen, it can be fixed later and might just have to be\n3. Setup [[s.q.tsql.tools.redgate.implementation.changelog-database]]\n   - Or at least make sure all users have followed steps to get added to changelog DB\n4. if no remote master branch then errors will occur in the local repository\n   - To correct errors of missing `origin/master` run `git branch --unset-upstream` since an upstream `master` branch doesn't yet exist\n   - This will arise when you add a DB to the source control and try to enter the commit screen\n5. Make a new folder for each Version Controlled DB in your Repo\n   - Convention being used is to name each folder the same as the DB's name but in all CAPS\n6. Setup Source control filters so you essentially have gitignore functionality in the repository\n7. [[s.q.tsql.tools.redgate.implementation.link-a-development-database-to-your-source-control-system]]\n   - If applicable [[s.q.tsql.tools.redgate.implementation.linking-static-data]]\n","n":0.08}}},{"i":103,"$":{"0":{"v":"Linking Static Data","n":0.577},"1":{"v":"\n## Linking static data tables\n\n1. Right click a database in [[s.q.tsql.tools.ssms]]\n2. `Other SQL Source Control tasks`\n3. `Link or unlink static data`\n4. `save and close`\n5. Right click a database in [[s.q.tsql.tools.ssms]]\n6. `Commit changes to source control`\n7. In source control pane you will now see a commit with the data link change type that shows the diff as a bunch of insert statements\n8. Commit message and commit\n   - Result is that in your source control repository there is now a `Data/` directory with a SQL file in it consisting of the insert statements.\n\n- **To source control the data on your tables they need a PK**\n","n":0.099}}},{"i":104,"$":{"0":{"v":"Link a Development Database to Your Source Control System","n":0.333},"1":{"v":"\n## [Linking a development database to your source control system][2]\n\n- Can link your database to a repository solution\n  - Right click on database\n  - link database with source control\n  - link to my source control system\n  - Select your source control **which for ADO? git?**\n    - Browse for target folder\n    - Click on it\n    - Add commit Message\n    - OK\n    - select either (See [[#shared-vs-dedicated-development-model]])\n      - dedicated database\n      - shared database\n  - When link is complete the DB icon will turn green\n  - You need to start by committing all your objects\n  - Click on \"Commit\" in Redgate source control\n  - add commit message\n  - Commit\n    - this will export all your objects as create scripts to your source control\n\n[2]: https://www.red-gate.com/hub/university/courses/sql-source-control/sql-source-control/getting-started/linking-development-database-source-control-system\n","n":0.091}}},{"i":105,"$":{"0":{"v":"Changelog Database","n":0.707},"1":{"v":"\n## Process\n\nTo track WHO is changing things (basically the source control `Last Changed By` column) We needed a change log database\n\n[Guide](https://documentation.red-gate.com/soc7/configuring/log-changes-to-shared-databases)\n\n1. Running the following code to create the database\n\n    ```sql\n    USE master EXECUTE ('CREATE DATABASE ChangeLog')\n    ALTER DATABASE ChangeLog SET ANSI_NULL_DEFAULT OFF\n    ALTER DATABASE ChangeLog SET ANSI_NULLS OFF\n    ALTER DATABASE ChangeLog SET ANSI_PADDING OFF\n    ALTER DATABASE ChangeLog SET ANSI_WARNINGS OFF\n    ALTER DATABASE ChangeLog SET ARITHABORT OFF\n    ALTER DATABASE ChangeLog SET AUTO_CLOSE OFF\n    ALTER DATABASE ChangeLog SET AUTO_CREATE_STATISTICS ON\n    ALTER DATABASE ChangeLog SET AUTO_SHRINK OFF\n    ALTER DATABASE ChangeLog SET AUTO_UPDATE_STATISTICS ON\n    ALTER DATABASE ChangeLog SET READ_WRITE\n    ALTER DATABASE ChangeLog SET RECOVERY SIMPLE\n    ALTER DATABASE ChangeLog SET MULTI_USER\n    ALTER DATABASE ChangeLog SET PAGE_VERIFY CHECKSUM\n    ALTER DATABASE ChangeLog SET DB_CHAINING ON\n    EXECUTE ('USE ChangeLog IF NOT EXISTS (SELECT * FROM sys.sysusers WHERE name=''guest'') EXECUTE sp_grantdbaccess guest')\n    ```\n\n2. - Close [[s.db.ms-sql-server.tools.ssms]]\n3. - Navigate to `%localappdata%\\Red Gate\\SQL Source Control 7`\n4. - Open `RedGate_SQLSourceControl_Engine_EngineOptions.xml` in a text editor\n5. - Below the `EngineOptions version` line, add:\n    1. - `<TraceCacheDatabase>ChangeLog</TraceCacheDatabase>`\n    2. - **The above is case sensative**\n6. - Save and close the file.\n\n## Important Points\n\n- Each developer **must** have `dbo_owner` permissions for the change log database.\n- You can delete the change log database, **but history about changes will be permanently deleted**.\n- SQL Source Control **will only use the change log database to save information about changes to linked databases**. It won't be used for any other purpose.\n","n":0.066}}},{"i":106,"$":{"0":{"v":"MSSQL","n":1},"1":{"v":"\nThere is a cli client that can access SQL Server from the cli and it works on all platforms allowing for queries to be ran and for output to be sent to the cli.\n\n## Potential use cases\n\n- Cronjobs to routinely run scripts that insert data at regular intervals or on certain system events\n- join with other scripts and tools like [[cli.cmd.ledger-cli]], [[s.l.bash]], [[cli.cmd.fzf]], etc to make for a robust workflow to manage finances\n\n## Installation\n\n```bash\npip install mssql-cli\n```\n","n":0.115}}},{"i":107,"$":{"0":{"v":"Tips Tricks","n":0.707}}},{"i":108,"$":{"0":{"v":"Yyyymm Date Part Calculation","n":0.5},"1":{"v":"\n\n```sql\nSELECT DATEPART(YEAR, GETDATE()) * 100 + DATEPART(MONTH, GETDATE()) AS 'YearMo'\n```\n","n":0.316}}},{"i":109,"$":{"0":{"v":"Wildcard Search Use Index","n":0.5},"1":{"v":"\n![sql-hack](/assets/images/2022-01-24-13-36-52.png)\n\nYou want to know the coolest SQL hack I learned this week?\n\nIn SQL, we often need to search character fields using the percentage (`%`) wildcard. When I put the wildcard at the end of the search string (`String%`) it uses the index, but if I put it at the front (`%String`) it does a scan of the index.\n\nThis significantly increases your run time!\n\n```sql\n-- Example:\nSELECT *\nFROM table\nWHERE column1 LIKE 'Some_string%'\n\n-- vs.\n\nSELECT *\nFROM table\nWHERE column1 LIKE '%Some_string'\n```\n\nWe say that option 1 is Sargable (Search ARGument ABLE), and option 2 is not Sargable, meaning option 2 could not leverage the index on the column.\n\nTo ensure all your wildcard queries are Sargable and to significantly decrease your run time, do the following:\n\n```sql\nSELECT *\nFROM table\nWHERE REVERSE(column1) LIKE REVERSE('Some_string') + '%'\n```\n\nAnd boom, your query runs much, much faster!\n","n":0.087}}},{"i":110,"$":{"0":{"v":"Using Hashbytes to Compare Character Strings","n":0.408},"1":{"v":"\n> If you have to compare string values on a regular basis, and especially if you have to compare more than one column at a time, instead of comparing the columns directly, hash the columns first. Hashing creates a string based on the encryption algorithm you select. You can pass in concatenated string values. The ultimate benefit is that all the algorithms generate a value that is a set number of characters. This comes in handy for storing this value when it comes time for loading junk dimensions into data warehouses.\n> You cannot use `HASHBYTES()` on `NVARCHAR(MAX)` in SQL Server. `HASHBYTES` has a 4,000-character limit for `NVARCHAR`. Technically, you can get around this programmatically, but if your data is longer than 4,000 characters, I‚Äôd suggest looking for another way to identify the record.\n>\n> -- <https://tutorials.massstreet.net/v/transact-sql/solutions-to-real-world-problems/lesson-63.-using-hashbytes-to-compare-character-strings>\n\n\n```sql\nDECLARE @Statement1 NVARCHAR(255)\nDECLARE @Statement2 NVARCHAR(255)\n\nSET @Statement1 = 'Army And Navy Play For Second'\nSET @Statement2 = 'Rock Chalk Jayhawk'\n\nPRINT LEN(@Statement1)\nPRINT LEN(@Statement2)\n\nPRINT HASHBYTES('MD5', @Statement1)\nPRINT HASHBYTES('MD5', @Statement2)\n\nPRINT LEN(HASHBYTES('MD5', @Statement1))\nPRINT LEN(HASHBYTES('MD5', @Statement2))\n\n-- 29\n-- 18\n-- 0x9A6A731EB1D5FE8F3B93A576A9740E3E\n-- 0xFDEFE8D5B2FF212060E733A0A01A1A7F\n-- 16\n-- 16\n```\n\n```sql\nDECLARE @Statement1 NVARCHAR(255)\nDECLARE @Statement2 NVARCHAR(255)\n\nSET @Statement1 = 'WalMart'\nSET @Statement2 = 'walmart'\n\n\nPRINT HASHBYTES('MD5', @Statement1) --0xDE2E98EE55B1B249B711300DE7047C75\nPRINT HASHBYTES('MD5', @Statement2) --0xC48604C9A656E09D87E99B820499D430\n```\n\n## Using Pipe To Hash Multiple Columns For Matching\n\n<https://tutorials.massstreet.net/v/transact-sql/solutions-to-real-world-problems/lesson-64.-using-pipe-to-hash-multiple-columns-for-matching>\n\n> When using the `HASHBYTES()` function in SQL Server to hash multiple columns for matching, use `CONCAT()` and separate values with a pipe.\n> Usually, the values in columns are disparate enough that you really do not have to worry. For example, it was years before I actually discovered an edge case. However, I did discover at least one scenario where concatenating the columns was not enough to develop a unique record. This occurred in a table with few columns and small amounts of data.\n> A better approach is to just `CONCAT()` columns with a pipe between values. Since this character is rarely used, it lowers the probability of having different values hash the same.\n\n```sql\nDECLARE @SampleStageTable AS TABLE(ID INT, VALUE1 NVARCHAR(10), VALUE2 NVARCHAR(10))\n\nINSERT INTO @SampleStageTable(ID, VALUE1, VALUE2)\nSELECT 1, '012','345'\nUNION\nSELECT 2, '01','2345'\n\nSELECT * FROM @SampleStageTable\n-------------------------------------------------------------------------------------\nDECLARE @SampleStageTable AS TABLE(ID INT, VALUE1 NVARCHAR(10), VALUE2 NVARCHAR(10))\n\nINSERT INTO @SampleStageTable(ID, VALUE1, VALUE2)\nSELECT 1, '012','345'\nUNION\nSELECT 2, '01','2345'\n\n\nSELECT ID, VALUE1, VALUE2, HASHBYTES('MD5', CONCAT(VALUE1, VALUE2)) AS ROWHASH\nFROM @SampleStageTable\n```\n\nSo separate columns with a `|`\n\n```sql\nDECLARE @SampleStageTable AS TABLE(ID INT, VALUE1 NVARCHAR(10), VALUE2 NVARCHAR(10))\n\nINSERT INTO @SampleStageTable(ID, VALUE1, VALUE2)\nSELECT 1, '012','345'\nUNION\nSELECT 2, '01','2345'\n\n\nSELECT ID, VALUE1, VALUE2, HASHBYTES('MD5', CONCAT(VALUE1,'|', VALUE2)) AS ROWHASH\nFROM @SampleStageTable\n```\n","n":0.051}}},{"i":111,"$":{"0":{"v":"Sql Server Script to Rebuild All Indexes for All Tables and All Databases","n":0.277},"1":{"v":"\n![[r.(.2022.03.03.sql-server-script-to-rebuild-all-indexes-for-all-tables-and-all-databases]]\n","n":1}}},{"i":112,"$":{"0":{"v":"Setting up Queries for Ablation Testing","n":0.408},"1":{"v":"\n> Sometimes you write a complex SQL statement that doesn‚Äôt work, and you do not know why. The best way to figure out what is wrong is by ablation testing.\n> Ablation testing is where you turn things off until you isolate the problem. In the case of SQL queries, this involves commenting out lines of a complex WHERE clause (or JOIN) until you find the thing that is not working as designed.\n> However, if your WHERE clause starts with a filter, you have to move it so you can comment it out. If you start your WHERE clause with 1 = 1, which is always true, then you preserve syntax and can easily comment out your filters without having to rewrite your code.\n> No matter how simple your SQL statement is, I recommend that you get in the habit of creating ablation testing ready SQL statements.\n>\n> -- <https://tutorials.massstreet.net/v/transact-sql/solutions-to-real-world-problems/lesson-50.-setting-up-queries-for-ablation-testing>\n\n```sql\nUSE AdventureWorks2016\n\nSELECT *\nFROM Sales.SalesOrderHeader soh\nJOIN Sales.SalesOrderDetail sod ON soh.SalesOrderID = sod.SalesOrderID\nWHERE 1 = 1\n```\n\n## An Example Of Ablation Testing\n\nHere we suspect that two lines in the WHERE clause are causing our query to act up.\n\n```sql\nUSE AdventureWorks2016\n\nSELECT\n    CONCAT(p.FirstName, ' ',p.LastName) AS SalesPerson,\n    DATEPART(month,soh.OrderDate) AS MonthOfSale,\n    SUM(sod.LineTotal) AS TotalSales\nFROM Person.Person p\n    JOIN Sales.SalesPerson sp ON p.BusinessEntityID = sp.BusinessEntityID\n    JOIN Sales.SalesOrderHeader soh ON sp.BusinessEntityID = soh.SalesPersonID\n    JOIN Sales.SalesOrderDetail sod ON soh.SalesOrderID = sod.SalesOrderDetailID\nWHERE 1 = 1\n    AND sp.Bonus BETWEEN 3000.00 AND 6000.00\n    --AND sp.SalesYTD >= 2000000.00\n    --AND sod.UnitPrice < 2000\n    AND (YEAR(soh.OrderDate) BETWEEN 2014 AND 2013 OR YEAR(soh.OrderDate) = 2011)\nGROUP BY p.LastName, p.FirstName, DATEPART(month,soh.OrderDate)\nORDER BY p.LastName, p.FirstName, DATEPART(month,soh.OrderDate)\n```\n","n":0.063}}},{"i":113,"$":{"0":{"v":"Sending Notification Emails with T Sql without Using Hardcoded Email Addresses","n":0.302},"1":{"v":"\n```sql\nUSE demo\n\nDECLARE @OperatorName sysname = N'YourOperatorName';\n\nDECLARE @OperatorEmailAddress nvarchar(100) = (SELECT email_address FROM msdb.dbo.sysoperators WHERE [name] = @OperatorName);\n\nPRINT @OperatorEmailAddress\n```\n","n":0.236}}},{"i":114,"$":{"0":{"v":"Select Data into Xml","n":0.5},"1":{"v":"\n\n- <https://www.sqlshack.com/working-with-xml-data-in-sql-server/>\n\n```sql\nSELECT CAST('<Name><FName>Carol</FName><LName>Elliot</LName></Name>' AS XML)\n\nUSE AdventureWorks2012\nGO\n\nSELECT Cust.CustomerID,\n       OrderHeader.CustomerID,\n       OrderHeader.SalesOrderID,\n       OrderHeader.Status\nFROM Sales.Customer Cust \n\tINNER JOIN Sales.SalesOrderHeader OrderHeader\n\t\tON Cust.CustomerID = OrderHeader.CustomerID\nFOR XML AUTO;\n\n\nSELECT * FROM ticketer.sp.ticket \nfor xml path ('Ticket'), root('Tickets')\n```\n","n":0.186}}},{"i":115,"$":{"0":{"v":"Rename Objects","n":0.707},"1":{"v":"\n\n```sql\nALTER DATABASE [Test1] MODIFY NAME = [Test2]\n--or\nsp_renamedb 'Test1' , 'Test2\n--or\nsp_rename 'Test1', 'Test2', 'DATABASE';\n```\n","n":0.277}}},{"i":116,"$":{"0":{"v":"Reduce Code and save Time with Default Column Values","n":0.333},"1":{"v":"\n> If you have a column that represents the datetime of when a record was loaded, there is no reason for you to write CURRENT_TIMESTAMP over and over when you insert data into that table.\n> Instead, when you create the table, specify that column‚Äôs default value of GETDATE. You can do it programmatically or in the table designer.\n> Below is an example of a data warehouse staging table template containing a primary key and standard audit columns. As you can see, each audit column has been assigned a default value there by reducing your insert statement by six lines.\n> Considering you will be writing thousands of procs over your career, the time saved from not having to write six lines is significant.\n>\n> -- <https://tutorials.massstreet.net/v/transact-sql/solutions-to-real-world-problems/lesson-51.-reduce-code-and-save-time-with-default-column-values>\n\n```sql\nUSE demo\n\nCREATE TABLE YourSchemaName.YourStageTableName(\n[ETLKey] [uniqueidentifier] NOT NULL,\n[UniqueDims] [varbinary](35) NULL,\n[UniqueRows] [varbinary](16) NULL,\n[SourceSystem] [nvarchar](255) NULL,\n[Cleansed] [bit] NULL,\n[ErrorRecord] [bit] NULL,\n[ErrorReason] [nvarchar](255) NULL,\n[Processed] [bit] NULL,\n[RunDate] [datetime] NULL,\n CONSTRAINT [PK_YourStageTableName] PRIMARY KEY CLUSTERED \n(\n       [ETLKey] ASC\n) WITH (PAD_INDEX = OFF, STATISTICS_NORECOMPUTE = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS = ON, ALLOW_PAGE_LOCKS = ON) ON [PRIMARY]\n) ON [PRIMARY]\n\nGO\n\nALTER TABLE [YourSchemaName].[YourStageTableName] ADD  CONSTRAINT [DF_YourStageTableName_ETLKey]  DEFAULT (newid()) FOR [ETLKey]\nGO\nALTER TABLE [YourSchemaName].[YourStageTableName] ADD  CONSTRAINT [DF_YourStageTableName_SourceSystem]  DEFAULT (N'Copia') FOR [SourceSystem]\nGO\nALTER TABLE [YourSchemaName].[YourStageTableName] ADD  CONSTRAINT [DF_YourStageTableName_Cleansed]  DEFAULT ((0)) FOR [Cleansed]\nGO\nALTER TABLE [YourSchemaName].[YourStageTableName] ADD  CONSTRAINT [DF_YourStageTableName_ErrorRecord]  DEFAULT ((0)) FOR [ErrorRecord]\nGO\nALTER TABLE [YourSchemaName].[YourStageTableName] ADD  CONSTRAINT [DF_YourStageTableName_Processed]  DEFAULT ((0)) FOR [Processed]\nGO\nALTER TABLE [YourSchemaName].[YourStageTableName] ADD  CONSTRAINT [DF_YourStageTableName_RunDate]  DEFAULT (getdate()) FOR [RunDate]\nGO\n```\n","n":0.066}}},{"i":117,"$":{"0":{"v":"Generate a Parameter List for All Sql Server Stored Procedures and Functions","n":0.289},"1":{"v":"\n![[r.(.2022.03.03.generate-a-parameter-list-for-all-sql-server-stored-procedures-and-functions]]\n","n":1}}},{"i":118,"$":{"0":{"v":"Edit All Rows in a Gui","n":0.408},"1":{"v":"\n> By right-clicking on the table name I select the command \"`Edit Top 200 Rows`\". By the way, the number of rows loaded with this command can be changed by the option \"`Tools > Options > SQL Server Object Explorer > Commands > Value for Edit top <n> Rows command`\". If `0` is entered, all rows or options are loaded.\n>\n> -- <https://smartstore.com/en/edit-database-values-using-sql-server-management-studio#:~:text=By%20right%2Dclicking%20on%20the,rows%20or%20options%20are%20loaded.>\n\n![settings](/assets/images/2022-03-15-14-30-50.png)\n\n![edit setting](/assets/images/2022-03-15-14-31-14.png)","n":0.126}}},{"i":119,"$":{"0":{"v":"Deleting a Large Table Iteratively","n":0.447},"1":{"v":"\n\nNeat way to use TOP to delete / truncate\n\nDeleting a large table takes a lot of resources and causes a lot of locks\n\nLooping query that deletes 100k rows per iteration until 0 rows remain\n\nWhen using TOP with a DELETE statement, you have to use the new syntax - using \"( )\" parenthesis\n\nAllows us to delete a very large table without using a lot of peak resources\n\nDeletes in chunks, allows parts to be deleted, very handy technique\n\n```sql\n-- do delete in chunks to minimize max lock/resources\nupdateMore:\nDELETE TOP(100000) DB.dbo.big_table\nIF @@rowcount !=0\ngoto updateMore;\n```\n","n":0.106}}},{"i":120,"$":{"0":{"v":"Date Stamping Inserts","n":0.577},"1":{"v":"\n```sql\nALTER TABLE dbo.Table\nADD CONSTRAINT Constraint_Name DEFAULT GETDATE() FOR UploadedToSQL\n```\n\nif just adding this in the initial table definition you can just define a table as:\n\n```sql\nUploadedToSQL DATETIME NOT NULL DEFAULT GETDATE(),\n```\n\nand on inserts for that column just pass the value `DEFAULT`\n","n":0.16}}},{"i":121,"$":{"0":{"v":"Datawarehouse Calendar Table","n":0.577},"1":{"v":"\n\n## Date Dimension Table\n\n```sql\n/**************************************************************************************************************************\\\n|===========================================================================================================================|\n|                                                                                                                           |\n|                                                                                                                           |\n| Reference Article: https://www.mssqltips.com/sqlservertip/4054/creating-a-date-dimension-or-calendar-table-in-sql-server/ |\n|                                                                                                                           |\n|                                                                                                                           |\n|===========================================================================================================================|\n***************************************************************************************************************************/\n\n-- FIXME Change all instances of `Ticketer` to the database chosen to house these DBO's\nUSE Ticketer\n\nIF OBJECT_ID('Ticketer.dbo.HolidayDimension') IS NOT NULL DROP TABLE HolidayDimension\nIF OBJECT_ID('Ticketer.dbo.DateDimension') IS NOT NULL DROP TABLE DateDimension\nIF OBJECT_ID('Ticketer.dbo.TheCalendar') IS NOT NULL DROP VIEW TheCalendar\n\n-- prevent set or regional settings from interfering with\n-- interpretation of dates / literals\nSET DATEFIRST  7 -- 1 = Monday, 7 = Sunday\n    , DATEFORMAT mdy\n    , LANGUAGE   US_ENGLISH;\n\n-- Start and End points\nDECLARE @StartDate  DATE = '20100101';\nDECLARE @CutoffDate DATE = DATEADD(DAY, -1, DATEADD(YEAR, 30, @StartDate));\n\n-- First CTE generating the list of numbers from the Start and End points\n;WITH seq(n) AS\n(\n\tSELECT 0 UNION ALL SELECT n + 1 FROM seq\n\tWHERE n < DATEDIFF(DAY, @StartDate, @CutoffDate)\n),\nd(d) AS\n( -- Second CTE generating an ISO 8601 Date from the numbers\n\tSELECT DATEADD(DAY, n, @StartDate) FROM seq\n),\nsrc AS\n( -- Third CTE taking the generated dates and parsing them into the pertinent information\n\tSELECT\n\t\t  TheDate         = CONVERT(DATE,\t\td)\n\t\t, TheDay          = DATEPART(DAY,       d)\n\t\t, TheDayName      = DATENAME(WEEKDAY,   d)\n\t\t, TheWeek         = DATEPART(WEEK,      d)\n\t\t, TheISOWeek      = DATEPART(ISO_WEEK,  d)\n\t\t, TheDayOfWeek    = DATEPART(WEEKDAY,   d)\n\t\t, TheMonth        = DATEPART(MONTH,     d)\n\t\t, TheMonthName    = DATENAME(MONTH,     d)\n\t\t, TheQuarter      = DATEPART(Quarter,   d)\n\t\t, TheYear         = DATEPART(YEAR,      d)\n\t\t, TheFirstOfMonth = DATEFROMPARTS(YEAR(d), MONTH(d), 1)\n\t\t, TheLastOfYear   = DATEFROMPARTS(YEAR(d), 12, 31)\n\t\t, TheDayOfYear    = DATEPART(DAYOFYEAR, d)\n\tFROM d\n),\ndim AS\n( -- Fourth CTE adding additional information of value\n\tSELECT\n\t\t  TheDate\n\t\t, TheDay\n\t\t, TheDaySuffix       = CONVERT(CHAR(2), CASE\n\t\t\t\t\t\t\t\t\t\t\t\tWHEN TheDay / 10 = 1 THEN 'th'\n\t\t\t\t\t\t\t\t\t\t\t\tELSE \n\t\t\t\t\t\t\t\t\t\t\t\t\tCASE RIGHT(TheDay, 1)\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tWHEN '1' THEN 'st'\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tWHEN '2' THEN 'nd'\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tWHEN '3' THEN 'rd'\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tELSE 'th' END\n\t\t\t\t\t\t\t\t\t\t\t\tEND)\n\t\t, TheDayName\n\t\t, TheDayOfWeek\n\t\t, TheDayOfWeekInMonth = CONVERT(TINYINT, ROW_NUMBER() OVER (PARTITION BY TheFirstOfMonth, TheDayOfWeek ORDER BY TheDate))\n\t\t, TheDayOfYear\n\t\t, IsWeekend           = CASE WHEN TheDayOfWeek IN (\n\t\t\t\t\t\t\t\t\tCASE @@DATEFIRST\n\t\t\t\t\t\t\t\t\tWHEN 1 THEN 6\n\t\t\t\t\t\t\t\t\tWHEN 7 THEN 1\n\t\t\t\t\t\t\t\t\tEND, 7\n\t\t\t\t\t\t\t\t) \n\t\t\t\t\t\t\t\tTHEN 1 ELSE 0 END\n\t\t, TheWeek\n\t\t, TheISOweek\n\t\t, TheFirstOfWeek      = DATEADD(DAY, 1 - TheDayOfWeek, TheDate)\n\t\t, TheLastOfWeek       = DATEADD(DAY, 6, DATEADD(DAY, 1 - TheDayOfWeek, TheDate))\n\t\t, TheWeekOfMonth      = CONVERT(TINYINT, DENSE_RANK() OVER (PARTITION BY TheYear, TheMonth ORDER BY TheWeek))\n\t\t, TheMonth\n\t\t, TheMonthName\n\t\t, TheFirstOfMonth\n\t\t, TheLastOfMonth      = MAX(TheDate) OVER (PARTITION BY TheYear, TheMonth)\n\t\t, TheFirstOfNextMonth = DATEADD(MONTH, 1, TheFirstOfMonth)\n\t\t, TheLastOfNextMonth  = DATEADD(DAY, -1, DATEADD(MONTH, 2, TheFirstOfMonth))\n\t\t, TheQuarter\n\t\t, TheFirstOfQuarter   = MIN(TheDate) OVER (PARTITION BY TheYear, TheQuarter)\n\t\t, TheLastOfQuarter    = MAX(TheDate) OVER (PARTITION BY TheYear, TheQuarter)\n\t\t, TheYear\n\t\t, TheISOYear          = TheYear - CASE WHEN TheMonth = 1 AND TheISOWeek > 51 THEN 1\n\t\t\t\t\t\t\t\t\t\t\t   WHEN TheMonth = 12 AND TheISOWeek = 1  THEN -1\n\t\t\t\t\t\t\t\t\t\t\t   ELSE 0 END\n\t\t, TheFirstOfYear      = DATEFROMPARTS(TheYear, 1,  1)\n\t\t, TheLastOfYear\n\t\t, IsLeapYear          = CONVERT(BIT, CASE WHEN TheYear % 400 = 0 OR (TheYear % 4 = 0 AND TheYear % 100 <> 0) THEN 1 ELSE 0 END)\n\t\t, Has53Weeks          = CASE WHEN DATEPART(WEEK, TheLastOfYear) = 53 THEN 1 ELSE 0 END\n\t\t, Has53ISOWeeks       = CASE WHEN DATEPART(ISO_WEEK, TheLastOfYear) = 53 THEN 1 ELSE 0 END\n\t\t, YYYYMM\t\t\t  = CONCAT(TheYear, CASE WHEN LEN(TheMonth) = 1 THEN CONCAT('0', TheMonth) ELSE TheMonth END) \n\t\t, MMYYYY              = CONVERT(CHAR(2), CONVERT(CHAR(8), TheDate, 101)) + CONVERT(CHAR(4), TheYear)\n\t\t, Style101            = CONVERT(CHAR(10), TheDate, 101)\n\t\t, Style103            = CONVERT(CHAR(10), TheDate, 103)\n\t\t, Style112            = CONVERT(CHAR(8),  TheDate, 112)\n\t\t, Style120            = CONVERT(CHAR(10), TheDate, 120)\n\tFROM src\n)\n-- CREATE THE DATE DIMENSION TABLE\nSELECT *\nINTO dbo.DateDimension\nFROM dim\nORDER BY TheDate\nOPTION (MAXRECURSION 0);\n\nCREATE UNIQUE CLUSTERED INDEX CIX_DateDimension ON dbo.DateDimension(TheDate);\n\n-- CREATE THE HOLIDAY DIMENSION TABLE\nCREATE TABLE dbo.HolidayDimension\n(\n\tTheDate DATE NOT NULL,\n\tHolidayText NVARCHAR(255) NOT NULL,\n\tCONSTRAINT FK_DateDimension FOREIGN KEY(TheDate) REFERENCES dbo.DateDimension(TheDate)\n);\n\nCREATE CLUSTERED INDEX CIX_HolidayDimension ON dbo.HolidayDimension(TheDate);\n\n;WITH x AS\n(\n\tSELECT\n\t\t  TheDate\n\t\t, TheFirstOfYear\n\t\t, TheDayOfWeekInMonth\n\t\t, TheMonth\n\t\t, TheDayName\n\t\t, TheDay\n\t\t, TheLastDayOfWeekInMonth = ROW_NUMBER() OVER\n\t\t  (\n\t\t\tPARTITION BY TheFirstOfMonth, TheDayOfWeek\n\t\t\tORDER BY TheDate DESC\n\t\t  )\n\tFROM dbo.DateDimension\n),\ns AS\n(\n\tSELECT\n\t\t  TheDate\n\t\t, HolidayText = CASE\n\t\tWHEN (TheDate = TheFirstOfYear)\n\t\t\tTHEN 'New Year''s Day'\n\t\tWHEN (TheDayOfWeekInMonth = 3 AND TheMonth = 1 AND TheDayName = 'Monday')\n\t\t\tTHEN 'Martin Luther King Day'\t\t-- (3rd Monday in January)\n\t\tWHEN (TheDayOfWeekInMonth = 3 AND TheMonth = 2 AND TheDayName = 'Monday')\n\t\t\tTHEN 'President''s Day'\t\t\t\t-- (3rd Monday in February)\n\t\tWHEN (TheMonth = 3 AND TheDay = 31)\n\t\t\tTHEN 'Cesar Chavez Day'\n\t\tWHEN (TheLastDayOfWeekInMonth = 1 AND TheMonth = 5 AND TheDayName = 'Monday')\n\t\t\tTHEN 'Memorial Day'\t\t\t\t\t-- (last Monday in May)\n\t\tWHEN (TheMonth = 7 AND TheDay = 4)\n\t\t\tTHEN 'Independence Day'\t\t\t\t-- (July 4th)\n\t\tWHEN (TheDayOfWeekInMonth = 1 AND TheMonth = 9 AND TheDayName = 'Monday')\n\t\t\tTHEN 'Labour Day'\t\t\t\t\t-- (first Monday in September)\n\t\tWHEN (TheMonth = 11 AND TheDay = 11)\n\t\t\tTHEN 'Veterans'' Day'\t\t\t\t-- (November 11th)\n\t\tWHEN (TheDayOfWeekInMonth = 4 AND TheMonth = 11 AND TheDayName = 'Thursday')\n\t\t\tTHEN 'Thanksgiving Day'             -- (Thanksgiving Day ()fourth Thursday in November)\n\t\tWHEN (TheMonth = 12 AND TheDay = 25)\n\t\t\tTHEN 'Christmas Day'\n\t\tEND\n\tFROM x\n\tWHERE (TheDate = TheFirstOfYear)\t\t\t\t\t\t\t\t\t\t\t\t\t-- New Years\n\t\tOR (TheDayOfWeekInMonth = 3     AND TheMonth = 1  AND TheDayName = 'Monday')\t-- MLK Day\n\t\tOR (TheDayOfWeekInMonth = 3     AND TheMonth = 2  AND TheDayName = 'Monday')\t-- Presidents Day\n\t\tOR (TheMonth = 3\t\t\t\tAND TheDay = 31)\t\t\t\t\t\t\t\t-- Cesar Chavez Day\n\t\tOR (TheLastDayOfWeekInMonth = 1 AND TheMonth = 5  AND TheDayName = 'Monday')\t-- Memorial Day\n\t\tOR (TheMonth = 7\t\t\t\tAND TheDay = 4)\t\t\t\t\t\t\t\t\t-- Independence Day\n\t\tOR (TheDayOfWeekInMonth = 1     AND TheMonth = 9  AND TheDayName = 'Monday')\t-- Labor Day\n\t\tOR (TheMonth = 11\t\t\t\tAND TheDay = 11)\t\t\t\t\t\t\t\t-- Veterans Day\n\t\tOR (TheDayOfWeekInMonth = 4     AND TheMonth = 11 AND TheDayName = 'Thursday')\t-- Thanksgiving Day\n\t\tOR (TheMonth = 12\t\t\t\tAND TheDay = 25)\t\t\t\t\t\t\t\t-- Christmas Day\n)\nINSERT dbo.HolidayDimension(TheDate, HolidayText)\n\nSELECT TheDate, HolidayText FROM s\nUNION ALL\nSELECT DATEADD(DAY, 1, TheDate), 'Black Friday' -- Special Case\nFROM s WHERE HolidayText = 'Thanksgiving Day'\nORDER BY TheDate;\nGO\n\nCREATE VIEW dbo.TheCalendar\nAS\n\tSELECT\n\t\t  d.*\n\t\t, IsHoliday = CASE WHEN h.TheDate IS NOT NULL THEN 1 ELSE 0 END\n\t\t, h.HolidayText\n\tFROM dbo.DateDimension AS d\n\t\tLEFT OUTER JOIN dbo.HolidayDimension AS h\n\t\t\tON d.TheDate = h.TheDate;\n```\n","n":0.035}}},{"i":122,"$":{"0":{"v":"Cleaner Code in the Where Clause","n":0.408},"1":{"v":"\nIn your code start your WHERE clause with a `WHERE TRUE` so that all logical statements are in `AND` statement on subsequent lines and therefore more easily commented out.\n\n```sql\nSELECT *\nFROM dbo.my_table\nWHERE TRUE\nAND person_id > 5\nAND age BETWEEN 18 AND 65\nAND first_name LIKE '%Paul%'\n```\n","n":0.152}}},{"i":123,"$":{"0":{"v":"Calculate Age","n":0.707},"1":{"v":"\n\n\n```sql\n-- The '365.25' uses .25 to account for leap year\nFLOOR(DATEDIFF(DAY, <birthdate>, GETDATE())/365.25) AS Age\n```\n","n":0.267}}},{"i":124,"$":{"0":{"v":"Boost Performance When Calling a Stored Proc from Ssis","n":0.333},"1":{"v":"\n> If you are calling a proc from an SSIS package, there is no need to get the row count of the records impacted by your query. By setting NOCOUNT to ON, you can significantly boost performance due to the drop in network traffic.\n>\n> -- <https://tutorials.massstreet.net/v/transact-sql/solutions-to-real-world-problems/lesson-49.-boost-performance-when-calling-a-stored-proc-from-ssis>\n\n```sql\nUSE AdventureWorks2016\n\nDROP PROCEDURE IF EXISTS dbo.usp_NoCountExample\nGO\n\nCREATE PROCEDURE dbo.usp_NoCountExample\n\nAS\nBEGIN\n\nSET NOCOUNT ON;\n\nSELECT *\nFROM Sales.SalesOrderHeader soh\nJOIN Sales.SalesOrderDetail sod\nON soh.SalesOrderID = sod.SalesOrderID\n\nSET NOCOUNT OFF;\n\nEND\nGO\n```\n","n":0.124}}},{"i":125,"$":{"0":{"v":"T Sql Show Index Statistics","n":0.447},"1":{"v":"\n\n```sql\nDBCC SHOW_STATISTICS('ticketer.app.metric', 'CIX_Created_Date');\nGO\n```\n\n---\n\n- Reference:\n  - [[r.(.2021.12.20.how-to-think-like-the-sql-server-engine]]\n\n","n":0.408}}},{"i":126,"$":{"0":{"v":"System Resources","n":0.707}}},{"i":127,"$":{"0":{"v":"Stored Procedure","n":0.707}}},{"i":128,"$":{"0":{"v":"Master","n":1}}},{"i":129,"$":{"0":{"v":"Sys","n":1}}},{"i":130,"$":{"0":{"v":"Sp_executesql","n":1},"1":{"v":"\n![[r.(.2022.03.03.introduction-to-the-sp_executesql-stored-procedure-with-examples]]\n","n":1}}},{"i":131,"$":{"0":{"v":"Msdb","n":1}}},{"i":132,"$":{"0":{"v":"sp_send_dbmail","n":1},"1":{"v":"\n## Reference\n\n<https://docs.microsoft.com/en-us/sql/relational-databases/system-stored-procedures/sp-send-dbmail-transact-sql?view=sql-server-ver15>\n\n> \"The parameters `@recipients`, `@copy_recipients`, and `@blind_copy_recipients` are semicolon-delimited lists of e-mail addresses. At least one of these parameters must be provided, or `sp_send_dbmail` returns an error.\"\n\n## Setup\n\n1. in [[s.db.ms-sql-server.tools.ssms]] expand the `Management` folder in the Object Explorer\n2. Right click on `Database Mail` > `Configure Database Mail` > `Next`\n3. `Manage Database Mail accounts and profiles` in the radio button selection list\n4. `Next`\n5. `Create a new account` this is the email account that will actually be sending the emails for you\n   - Gmail is great here because it can be used as a pass through thought you might need to enable additional access in the settings menu of gmail\n   - The outcome of this is that you receive emails from that Gmail account but in an automated fashion\n6. New account details\n   - Account name and description are just for your reference but use them in tandem with the Display name to use an account for each of your Services\n   - Email address is the service account email address\n   - Display name is what it looks like the email is actually from\n   - reply email is who the replies go to\n   - server name for gmail would be `smtp.gmail.com` with port number [[n.port.587]]\n   - The [[n.protocol.ssl]] checkbox should be ticked\n   - Use basic authentication (radio button)\n   - username is the service account email address\n   - password is the password for the service account email address\n7. `Create a new profile`, this is what will be holding the account(s) that send email\n8. Give it a name and description\n9. add your email account you made to it\n10. finish\n11. test `sp_send_dbmail`\n\n## Examples\n\n### Simple Message\n\n```sql\nEXEC msdb.dbo.sp_send_dbmail\n    @profile_name = 'Adventure Works Administrator',\n    @recipients = 'yourfriend@Adventure-Works.com',\n    @body = 'The stored procedure finished successfully.',\n    @subject = 'Automated Success Message' ;\n```\n\n### Email message with the results of a query\n\n```sql\nEXEC msdb.dbo.sp_send_dbmail\n    @profile_name = 'Adventure Works Administrator',\n    @recipients = 'yourfriend@Adventure-Works.com',\n    @query = 'SELECT COUNT(1)\n              FROM AdventureWorks2012.Production.WorkOrder\n              WHERE 1 = 1\n              AND DueDate > ''2004-04-30''\n              AND  DATEDIFF(dd, ''2004-04-30'', DueDate) < 2' ,\n    @subject = 'Work Order Count',\n    @attach_query_result_as_file = 1 ;\n```\n\n### Sending HTML Email\n\n```sql\nDECLARE @tableHTML  NVARCHAR(MAX) ;\n\nSET @tableHTML =\n    N'<H1>Work Order Report</H1>' +\n    N'<table border=\"1\">' +\n    N'<tr><th>Work Order ID</th><th>Product ID</th>' +\n    N'<th>Name</th><th>Order Qty</th><th>Due Date</th>' +\n    N'<th>Expected Revenue</th></tr>' +\n    CAST ( ( SELECT\n             td = wo.WorkOrderID, '',\n             td = p.ProductID, '',\n             td = p.Name, '',\n             td = wo.OrderQty, '',\n             td = wo.DueDate, '',\n             td = (p.ListPrice - p.StandardCost) * wo.OrderQty\n             FROM AdventureWorks.Production.WorkOrder AS wo\n             JOIN AdventureWorks.Production.Product AS p ON wo.ProductID = p.ProductID\n             WHERE 1 = 1\n             AND DueDate > '2004-04-30'\n             AND DATEDIFF(dd, '2004-04-30', DueDate) < 2\n             ORDER BY\n             DueDate ASC,\n             (p.ListPrice - p.StandardCost) * wo.OrderQty DESC\n             FOR XML PATH('tr'), TYPE\n    ) AS NVARCHAR(MAX) ) +\n    N'</table>' ;\n\nEXEC msdb.dbo.sp_send_dbmail @recipients='yourfriend@Adventure-Works.com',\n    @subject = 'Work Order List',\n    @body = @tableHTML,\n    @body_format = 'HTML' ;\n```\n","n":0.047}}},{"i":133,"$":{"0":{"v":"Extended Stored Procedure","n":0.577}}},{"i":134,"$":{"0":{"v":"Master","n":1}}},{"i":135,"$":{"0":{"v":"Xp_readerrorlog","n":1},"1":{"v":"\n![[r.(.2022.03.03.how-to-read-log-file-in-sql-server-using-tsql]]\n","n":1}}},{"i":136,"$":{"0":{"v":"Syntax","n":1}}},{"i":137,"$":{"0":{"v":"Window Functions","n":0.707}}},{"i":138,"$":{"0":{"v":"Rank over Partition","n":0.577},"1":{"v":"\n\n```sql\nRANK ( ) OVER ( [ partition_by_clause ] order_by_clause )\n```\n\nFrom <https://docs.microsoft.com/en-us/sql/t-sql/functions/rank-transact-sql?view=sql-server-ver15> \n\n**Example:**\n\n```sql\nRANK() OVER (PARTITION BY PersonID ORDER BY createdDate DESC) AS 'Rank'\n```\n\nPartition records based on `personID` this means for each `personID` each record set will be grouped by that then operated on as groupings.\n\nOrder by `createdDate` date means that for each `personID` group starting at 1 each record will be ranked in descending order based on the `createdDate`\n","n":0.121}}},{"i":139,"$":{"0":{"v":"Last Value","n":0.707},"1":{"v":"\nSame usage as `FIRST_VALUE`\n\nsee ![[s.q.tsql.syntax.window-functions.first-value]]\n","n":0.447}}},{"i":140,"$":{"0":{"v":"First Value","n":0.707},"1":{"v":"\nFrom\n\n```sql\nWITH\norders AS (\n    SELECT \n        name, \n        model,\n        year, \n        date_at_lot\n        row_number() over(partition by model, year order by date_at_lot asc) AS order\n    FROM cars \n)\nSELECT\n    name AS oldest_car_name,\n    model, \n    year\nFROM orders\nwhere order = 1 \n```\n\nTo\n\n```sql\nSELECT \n    FIRST_VALUE(name) OVER(PARTITION BY model, year ORDER BY date_at_lot ASC) AS oldest_car_name\n    model,\n    year\nFROM cars\n```\n","n":0.14}}},{"i":141,"$":{"0":{"v":"Wild Cards","n":0.707},"1":{"v":"\n\n> A wildcard character is used to substitute one or more characters in a string\n>\n> <div class=\"signature\"><a src=\"https://www.w3schools.com/sql/sql_wildcards.asp\">w3schools</a></div>\n\n---\n\n| Symbol | Description                                         | Example                                  |\n| :----- | :-------------------------------------------------- | :--------------------------------------- |\n| `*`    | Represents zero or more characters                  | `bl*` finds bl, black, blue, and blob    |\n| `?`    | Represents a single character                       | `h?t` finds hot, hat, and hit            |\n| `[]`   | Represents any single character within the brackets | `h[oa]t` finds hot and hat, but not hit  |\n| `^`    | Represents any character not in the brackets        | `h[^oa]t` finds hit, but not hot and hat |\n| `-`    | Represents a range of characters                    | `c[a-b]t` finds cat and cbt              |\n| `%`    | Represents zero or more characters                  | `bl%` finds bl, black, blue, and blob    |\n| `_`    | Represents a single character                       | `h_t` finds hot, hat, and hit            |\n\n---\n\nHas to be used in conjunction with the `LIKE`  keyword as this is the trigger to run a search using these [[Regular Expressions|regular-expression]] \"wild card\" serrches.\n\n---\n\n- Reference:\n  - [w3Schools](https://www.w3schools.com/sql/sql_wildcards.asp)\n\n","n":0.077}}},{"i":142,"$":{"0":{"v":"Variables","n":1}}},{"i":143,"$":{"0":{"v":"Local","n":1},"1":{"v":"\nTo declare a variable in T-SQL for reuse throughout a query, the syntax is simple:\n\n```sql\nDECLARE @VariableName AS datatype\nSET @VariableName = value\n\n-- OR\nDECLARE @VariableName AS datatype = value\n```\n\nYou can also use a single declare to create multiple variable in one go:\n\n```sql\nDECLARE @VariableName AS datatype\n\t\t,@VariableName2 AS datatype\n```\n","n":0.149}}},{"i":144,"$":{"0":{"v":"Global","n":1}}},{"i":145,"$":{"0":{"v":"Rowcount","n":1},"1":{"v":"\n## Usage\n\n`SELECT @@ROWCOUNT` in the same execution block to get the result back\n\n```sql\nSELECT TOP 1000 * FROM dbo.Customer;\nSELECT @@ROWCOUNT;\n```\n\nThis returns the query results and the count of how many rows from that result set\n\n```sql\nSELECT @@ROWCOUNT;\n```\n\nexecuted by itself only returns a count of 1 record (itself).\n\n## Error Handling and Business Rules\n\n> Using SQL Server `@@ROWCOUNT` for Error Handling and Checking a Business Rule\n\n```sql\nBEGIN TRAN\n\nUPDATE [Sales].[SalesOrderHeader]\nSET [SubTotal] = [SubTotal] * 1.1; -- 10% increase\n\nIF @@ROWCOUNT = 0\n    PRINT 'Something went wrong!'\nELSE PRINT 'Rows were updated...'\n\n--COMMIT\nROLLBACK\n```\n\n## Instances of Large ROWCOUNT\n\nSQL Server `ROWCOUNT_BIG` function\n\nThe data type of `@@ROWCOUNT` is integer. In the cases where a higher number of rows are affected than an integer can handle (meaning more than 2,147,483,647 rows!), you need to use the ROWCOUNT_BIG function. This function returns the data type `bigint`.\n\n```sql\nSELECT TOP 1000 * FROM dbo.Customer;\nSELECT ROWCOUNT_BIG();\n```\n\n## Utilizing ROWCOUNT with Try Catch Statements\n\n```sql\nBEGIN TRY\n    SELECT TOP 100 * FROM [AdventureWorks2017].[Person].[Person];\nEND TRY\nBEGIN CATCH\n    SELECT TOP 50 * FROM [AdventureWorks2017].[Person].[Person];\nEND CATCH\nSELECT @@ROWCOUNT;\n\n/*\n\n@@ROWCOUNT returns zero! This is because the last statement is not the SELECT statement from the TRY block (which has been executed), it‚Äôs also not the one from the TRY block as it‚Äôs the last SELECT in the script. It‚Äôs the TRY/CATCH block itself! @@ROWCOUNT returns the affected rows from any statement, even if it‚Äôs not DML or a SELECT query.\n\nTo avoid this kind of scenario, you can store the row count in a local variable. The script would then look like this:\n\n*/\n\nDECLARE @rowcount INT;\nBEGIN TRY\n    SELECT TOP 100 * FROM [AdventureWorks2017].[Person].[Person];\n    SET @rowcount = @@ROWCOUNT;\nEND TRY\nBEGIN CATCH\n    SELECT TOP 50 * FROM [AdventureWorks2017].[Person].[Person];\n    SET @rowcount = @@ROWCOUNT;\nEND CATCH\nSELECT @rowcount;\n```\n","n":0.061}}},{"i":146,"$":{"0":{"v":"Union","n":1},"1":{"v":"\n\nThe `UNION` Operator us useful for combining the records from one table to another.\n\nThere must be:\n\n- Same number of columns in both tables\n- columns must align with each other and be the same data type\n\nthe operator basically does this:\n\n```sql\nSELECT ID, Value\nFROM My_First_Table\nUNION\nSELECT ID, Value\nFROM My_Second_Table\n```\n","n":0.149}}},{"i":147,"$":{"0":{"v":"Example","n":1},"1":{"v":"\n\n## Example\n\n### Before\n\n| ID | Val |\n| -- | --- |\n| 1  | A   |\n| 2  | B   |\n\n| ID | Val |\n| -- | --- |\n| 3  | C   |\n| 4  | D   |\n\n### After\n\n| ID | Val |\n| -- | --- |\n| 1  | A   |\n| 2  | B   |\n| 3  | C   |\n| 4  | D   |\n","n":0.129}}},{"i":148,"$":{"0":{"v":"Top","n":1},"1":{"v":"\n\n```sql\nSELECT TOP 100 <COLUMN>\nFROM <TABLE>\n```\n\nSelects the first `100` records from `<TABLE>` that meet all the criteria but starting from the top of the table scan. it's the first encountered valid records\n","n":0.18}}},{"i":149,"$":{"0":{"v":"The Use Statement","n":0.577},"1":{"v":"\n\nThe `USE` statement indicates what database to use in something like a [[s.q.tsql.syntax.stored-procedures]]\n\n```sql\nUSE My_Database\n<Query Code...>\nGO\n```\n","n":0.258}}},{"i":150,"$":{"0":{"v":"The in Predicate","n":0.577},"1":{"v":"\n\nSimilar to [[s.q.tsql.syntax.between-predicate]], the `IN` predicate denotes not a range between value A and B but any value in a list that doesnt lend itself to ranging like specific text values or disjointed numerical values:\n\n```sql\nSELECT Age\nFROM Person\nWHERE Age IN (55, 65, 80) -- This matches only to those 3 listed numbers\n\n-- OR\n\nSELECT Name\nFROM Person\nWHERE Name IN ('Bob', 'Joe', 'Mary', 'Sue') -- matching on strings\n```\n","n":0.125}}},{"i":151,"$":{"0":{"v":"The Go Statement","n":0.577},"1":{"v":"\n\nThe `GO` Statement signals the end of a batch of Transact-SQL statements to the SQL Server utilities.\n\n```sql\nUSE My_Database\nSELECT *\nFROM My_Table\nGO\n```\n","n":0.224}}},{"i":152,"$":{"0":{"v":"Transaction Control Language","n":0.577},"1":{"v":"\n\n## Transaction Control Language\n\n- `BEING TRANSACTION`\n  - [[s.q.tsql.syntax.tcl.begin-transaction]]\n- `COMMIT`\n  - [[s.q.tsql.syntax.tcl.commit]]\n- `ROLLBACK`\n  - [[s.q.tsql.syntax.tcl.rollback]]\n","n":0.267}}},{"i":153,"$":{"0":{"v":"Rollback","n":1},"1":{"v":"\n\n`ROLLBACK` is used with [[T-SQL Begin Transaction|s.q.tsql.syntax.tcl.begin-transaction]] to revert changes. If you wanted to keep changes made you would [[T-SQL Commit|s.q.tsql.syntax.tcl.commit]] them.\n","n":0.213}}},{"i":154,"$":{"0":{"v":"Commit","n":1},"1":{"v":"\n\n`COMMIT` Commits to the [[s.q.tsql.syntax.tcl.begin-transaction]] being made. Where as [[T-SQL Rollback|s.q.tsql.syntax.tcl.rollback]] reverts the changes back to the original state before modification in the [[s.q.tsql.syntax.tcl.begin-transaction]].\n","n":0.204}}},{"i":155,"$":{"0":{"v":"Begin Transaction","n":0.707},"1":{"v":"\n\n**Best Practice**\n\n`BEGIN TRAN` marks the beginning of a local transaction and is not recorded until [[T-SQL Commit|committed]]. This allows us to [[T-SQL Rollback|s.q.tsql.syntax.tcl.rollback]] any unwanted transactions. \n\nBest practice is to use [[T-SQL Begin Transaction|begin-tran]] to start especially when using the following [[T-SQL Data Manipulation Language|dml]] commands: `INSERT`, `DELETE`, & `UPDATE`\n\n```sql\nBEGIN TRAN\n\tINSERT INTO Database.Schema.Table (<field>)\n\tVALUES('<INSERTED VALUE>')\n\t\n\tSELECT *\n\tFROM Database.Schema.Table\nROLLBACK\nCOMMIT\n```\n","n":0.132}}},{"i":156,"$":{"0":{"v":"Table Variables","n":0.707},"1":{"v":"\n```sql\n-- Table variable\nDECLARE @tablevariable TABLE (customerid [int] NOT NULL PRIMARY KEY, lastorderdate [datetime] NULL);\n\nINSERT INTO @tablevariable\nSELECT customerid, max(orderdate) AS lastorderdate\nFROM sales.SalesOrderHeader\nGROUP BY customerid;\n\nSELECT *\nFROM sales.salesorderheader AS soh\nINNER JOIN @tablevariable AS t\n    ON soh.customerid = t.customerid\n        AND soh.orderdate = t.lastorderdate\nGO\n```\n","n":0.16}}},{"i":157,"$":{"0":{"v":"Table Aliasing","n":0.707},"1":{"v":"\n\nAliasing a table is to reduce the amount of typing needed for a query. This allows for something like `A_REALLY_LONG_TABLE_NAME` to be reduced to `T` by using an alias:\n\n```sql\nSELECT T.Age\nFROM A_REALLY_LONG_TABLE_NAME AS T\nWHERE T.Age > 55\n```\n\nAliasing allows you to include fields with the same name but different tables:\n\n```sql\nSELECT M.Age, F.Age -- 2 Columns called 'Age' are returned because of the alias prefix\nFROM MENS_AGES AS M\n\tJOIN WOMENS_AGES AS F\n\t\tON F.Marriage_ID = M.Marriage_ID\nWHERE M.Age > 55 AND F.Age > 55\n```\n","n":0.113}}},{"i":158,"$":{"0":{"v":"Sub Queries","n":0.707},"1":{"v":"\n\nA sub-query is a nested `SELECT` statement inside of another parent `SELECT` statement.\n\nA usage of this is to select a record set from which you then want to manipulate and operate on after that initial pool is generated:\n\n```sql\nSELECT P.Age\nFROM (\n\tSELECT P1.*\n\tFROM PERSON P1\n\tWHERE P1.Name = 'Paul'\n)\n```\n\nIn this example the first operation performed is the gathering of all records from the `P1` table where the `Name` field contains the string value _Paul_. Then from that result set we are selecting the `Age` field from that initial result set.\n\nWith sub-queries:\n\nA Required `SELECT` statement list\nA Required `FROM` clause\nAn Optional `WHERE` clause\nAn Optional `GROUP BY` clause\nAn Optional `HAVING` clause\nBut **NO** `ORDER BY` clause this will throw an _error_\n\nSub queries can be used anywhere an expression is allowed. This includes the `SELECT` portion of a query, the `FROM` clause, the `WHERE` clause, `JOIN`'s, `GROUP BY`'s.\n","n":0.085}}},{"i":159,"$":{"0":{"v":"Stored Procedures","n":0.707},"1":{"v":"\n\nA <u>stored procedure</u> is a group of SQL statements that have been created and stored in the database. A stored procedure will accept input parameters like `@dates` or `@Name`.\n\nRun a stored procedure with `exec DB.DBO.tbl`\n\n```sql\n-- ================================================\n-- Template generated from Template Explorer using:\n-- Create Procedure (New Menu).SQL\n--\n-- Use the Specify Values for Template Parameters\n-- command (Ctrl-Shift-M) to fill in the parameter\n-- values below.\n--\n-- This block of comments will not be included in\n-- the definition of the procedure.\n-- ================================================\nSET ANSI_NULLS ON\nGO\nSET QUOTED_IDENTIFIER ON\nGO\n-- =============================================\n-- Author:           <Author,,Name>\n-- Create date: <Create Date,,>\n-- Description:      <Description,,>\n-- =============================================\nCREATE PROCEDURE <Procedure_Name, sysname, ProcedureName>\n       -- Add the parameters for the stored procedure here\n       <@Param1, sysname, @p1> <Datatype_For_Param1, , int> = <Default_Value_For_Param1, , 0>,\n       <@Param2, sysname, @p2> <Datatype_For_Param2, , int> = <Default_Value_For_Param2, , 0>\nAS\nBEGIN\n       -- SET NOCOUNT ON added to prevent extra result sets from\n       -- interfering with SELECT statements.\n       SET NOCOUNT ON;\n \n    -- Insert statements for procedure here\n       SELECT <@Param1, sysname, @p1>, <@Param2, sysname, @p2>\nEND\nGO\n```\n\n---\n\n- Reference:\n  - <https://docs.microsoft.com/en-us/sql/relational-databases/stored-procedures/return-data-from-a-stored-procedure?view=sql-server-ver15>\n\n","n":0.079}}},{"i":160,"$":{"0":{"v":"Returning Data","n":0.707}}},{"i":161,"$":{"0":{"v":"Via a Result Set","n":0.5},"1":{"v":"\n\n### Return via result set\n\n```sql\nUSE AdventureWorks2012;  \nGO  \nIF OBJECT_ID('Sales.uspGetEmployeeSalesYTD', 'P') IS NOT NULL  \n   DROP PROCEDURE Sales.uspGetEmployeeSalesYTD;  \nGO  \nCREATE PROCEDURE Sales.uspGetEmployeeSalesYTD  \nAS    \n \n   SET NOCOUNT ON;  \n   SELECT LastName, SalesYTD  \n   FROM Sales.SalesPerson AS sp  \n   JOIN HumanResources.vEmployee AS e ON e.BusinessEntityID = sp.BusinessEntityID  \n   \nRETURN  \nGO\n```\n","n":0.144}}},{"i":162,"$":{"0":{"v":"Via a Parameter","n":0.577},"1":{"v":"\n\n### Return via parameter\n\n```sql\nUSE AdventureWorks2012;  \nGO  \nIF OBJECT_ID('Sales.uspGetEmployeeSalesYTD', 'P') IS NOT NULL  \n    DROP PROCEDURE Sales.uspGetEmployeeSalesYTD;  \nGO  \nCREATE PROCEDURE Sales.uspGetEmployeeSalesYTD  \n@SalesPerson nvarchar(50),  \n@SalesYTD money OUTPUT  \nAS    \n  \n    SET NOCOUNT ON;  \n    SELECT @SalesYTD = SalesYTD  \n    FROM Sales.SalesPerson AS sp  \n    JOIN HumanResources.vEmployee AS e ON e.BusinessEntityID = sp.BusinessEntityID  \n    WHERE LastName = @SalesPerson;  \nRETURN  \nGO\n```\n\nor\n\n```sql\n-- Declare the variable to receive the output value of the procedure.  \nDECLARE @SalesYTDBySalesPerson money;  \n-- Execute the procedure specifying a last name for the input parameter  \n-- and saving the output value in the variable @SalesYTDBySalesPerson  \nEXECUTE Sales.uspGetEmployeeSalesYTD  \n    N'Blythe', @SalesYTD = @SalesYTDBySalesPerson OUTPUT;  \n-- Display the value returned by the procedure.  \nPRINT 'Year-to-date sales for this employee is ' +   \n    convert(varchar(10),@SalesYTDBySalesPerson);  \nGO\n```\n","n":0.091}}},{"i":163,"$":{"0":{"v":"Set Statements","n":0.707},"1":{"v":"\n[MSDN Documentation][1]\n\n[1]: https://docs.microsoft.com/en-us/sql/t-sql/statements/set-statements-transact-sql?view=sql-server-ver15\n","n":0.577}}},{"i":164,"$":{"0":{"v":"Quoted Identifier","n":0.707},"1":{"v":"\n<https://docs.microsoft.com/en-us/sql/t-sql/statements/set-quoted-identifier-transact-sql?view=sql-server-ver15>\n\n\n## Using the quoted identifier setting and reserved word object names\n\n\n```sql\nSET QUOTED_IDENTIFIER OFF\nGO\n\n-- Create statement fails.\nCREATE TABLE \"select\" (\"identity\" INT IDENTITY NOT NULL, \"order\" INT NOT NULL);\nGO\n\nSET QUOTED_IDENTIFIER ON;\nGO\n\n-- Create statement succeeds.\nCREATE TABLE \"select\" (\"identity\" INT IDENTITY NOT NULL, \"order\" INT NOT NULL);\nGO\n\nSELECT \"identity\",\"order\"\nFROM \"select\"\nORDER BY \"order\";\nGO\n\nDROP TABLE \"SELECT\";\nGO\n\nSET QUOTED_IDENTIFIER OFF;\nGO\n```\n\n## Using the quoted identifier setting with single and double quotation marks\n\n```sql\nSET QUOTED_IDENTIFIER OFF;\nGO\n\nUSE AdventureWorks2012;\nIF EXISTS(SELECT TABLE_NAME FROM INFORMATION_SCHEMA.TABLES\n    WHERE TABLE_NAME = 'Test')\n    DROP TABLE dbo.Test;\nGO\nUSE AdventureWorks2012;\nCREATE TABLE dbo.Test (ID INT, String VARCHAR(30)) ;\nGO\n\n-- Literal strings can be in single or double quotation marks.\nINSERT INTO dbo.Test VALUES (1, \"'Text in single quotes'\");\nINSERT INTO dbo.Test VALUES (2, '''Text in single quotes''');\nINSERT INTO dbo.Test VALUES (3, 'Text with 2 '''' single quotes');\nINSERT INTO dbo.Test VALUES (4, '\"Text in double quotes\"');\nINSERT INTO dbo.Test VALUES (5, \"\"\"Text in double quotes\"\"\");\nINSERT INTO dbo.Test VALUES (6, \"Text with 2 \"\"\"\" double quotes\");\nGO\n\nSET QUOTED_IDENTIFIER ON;\nGO\n\n-- Strings inside double quotation marks are now treated\n-- as object names, so they cannot be used for literals.\nINSERT INTO dbo.\"Test\" VALUES (7, 'Text with a single '' quote');\nGO\n\n-- Object identifiers do not have to be in double quotation marks\n-- if they are not reserved keywords.\nSELECT ID, String\nFROM dbo.Test;\nGO\n\nDROP TABLE dbo.Test;\nGO\n\nSET QUOTED_IDENTIFIER OFF;\nGO\n```\n\n\n","n":0.071}}},{"i":165,"$":{"0":{"v":"Nocount and Rowcount","n":0.577},"1":{"v":"\n## SQL Server SET NOCOUNT AND SET ROWCOUNT\n\n### SET ROWCOUNT\n\nAlthough the name, `SET ROWCOUNT` is very similar, it doesn‚Äôt impact `@@ROWCOUNT` directly. `SET ROWCOUNT` simply tells SQL Server to stop processing a query after the specified number of rows have been returned, which makes it kind of a ‚Äúglobal TOP clause‚Äù.\n\nIn the following example, we‚Äôre limiting the rows to 500. The SELECT query itself should return 1,000 rows, but as you can see `@@ROWCOUNT` tells us only 500 were returned.\n\n![SET ROWCOUNT](/assets/images/2022-03-03-14-02-14.png)\n\n### SET NOCOUNT\n\n`SET NOCOUNT ON` also doesn‚Äôt affect `@@ROWCOUNT`. `SET NOCOUNT` tells SQL Server to stop displaying the message with the number of rows affected by a query. However, `@@ROWCOUNT` is still updated.\n\nLet‚Äôs illustrate with an example. First the default configuration where `NOCOUNT` is off.\n\n![NOCOUNT](/assets/images/2022-03-03-14-03-56.png)\n","n":0.089}}},{"i":166,"$":{"0":{"v":"Pivots","n":1},"1":{"v":"\n## Pivoting\n\nthe Pivot is like a transcribe operator in excel. You take the top left point, anchor it and then flips the axis' and their values.\n\n```sql\nSELECT Name\n\t,pvt.Low\n\t,pvt.Med\n\t,pvt.High\n\t,pvt.Ultra\nFROM Person\nPIVOT\n\t(SUM(Total) FOR Level IN ([Low], [Med], [High], [Ultra])\n\t) AS pvt\n```\n\n## UN-pivoting\n\n```sql\nSELECT Name\n\t,upvt.Level\n\t,upvt.Total\nFROM Person\nUNPIVOT\n\t(Total FOR Level IN ([Low], [Med], [High], [Ultra])\n\t) AS upvt\n```\n\n## Advanced Pivoting\n\n<https://www.mssqltips.com/sqlservertip/7167/sql-pivot-grouping-sets-advanced-reporting/>\n","n":0.14}}},{"i":167,"$":{"0":{"v":"Example","n":1},"1":{"v":"\n\n## Example\n\n### Before\n\n| Name | Level | Total |\n| ---- | ----- | ----- |\n| Joe  | Low   | 34    |\n| Joe  | Med   | 65    |\n| Joe  | High  | 29    |\n| Joe  | Ultra | 99    |\n| Tom  | Low   | 37    |\n| Tom  | Med   | 53    |\n| Tom  | High  | 24    |\n| Tom  | Ultra | 74    |\n\n### After\n\n| Name | Low | Med | High | Ultra |\n| ---- | --- | --- | ---- | ----- |\n| Joe  | 34  | 65  | 29   | 99    |\n| Tom  | 37  | 53  | 24   | 74    |\n","n":0.098}}},{"i":168,"$":{"0":{"v":"Operators","n":1},"1":{"v":"\n\n| Operator                | Purpose                                                                                  | Type               |   |\n|:------------------------|:-----------------------------------------------------------------------------------------|:-------------------|---|\n| `+`                     | Addition                                                                                 | Arithmatic         |   |\n| `-`                     | Subtraction                                                                              | Arithmatic         |   |\n| `*`                     | Multiplaicatio                                                                           | Arithmatic         |   |\n| `/`                     | Divison                                                                                  | Arithmatic         |   |\n| `%`                     | Modulous division                                                                        | Arithmatic         |   |\n| `ALL`                   | TRUE if all of a set of comparisons are TRUE.                                            | Logical            |   |\n| `AND`                   | TRUE if both Boolean expressions are TRUE.                                               | Logical            |   |\n| `ANY`                   | TRUE if any one of a set of comparisons are TRUE.                                        | Logical            |   |\n| `BETWEEN`               | TRUE if the operand is within a range.                                                   | Logical            |   |\n| `EXISTS`                | TRUE if a subquery contains any rows.                                                    | Logical            |   |\n| `IN`                    | TRUE if the operand is equal to one of a list of expressions.                            | Logical            |   |\n| `LIKE`                  | TRUE if the operand matches a pattern.                                                   | Logical            |   |\n| `NOT`                   | Reverses the value of any other Boolean operator.                                        | Logical            |   |\n| `OR`                    | TRUE if either Boolean expression is TRUE.                                               | Logical            |   |\n| `SOME`                  | TRUE if some of a set of comparisons are TRUE.                                           | Logical            |   |\n| `::`                    | like [[s.l.cpp]] and [[s.l.r]] namespace access                                          | Scope Resolution   |   |\n| `=`                     | Assign values to a variable                                                              | Assignment         |   |\n| `=`                     | (Equals)\tEqual to                                                                        | Comparison         |   |\n| `>`                     | (Greater Than)\tGreater than                                                              | Comparison         |   |\n| `<`                     | (Less Than)\tLess than                                                                    | Comparison         |   |\n| `>=`                    | (Greater Than or Equal To)\tGreater than or equal to                                      | Comparison         |   |\n| `<=`                    | (Less Than or Equal To)\tLess than or equal to                                            | Comparison         |   |\n| `<>`                    | (Not Equal To)\tNot equal to                                                              | Comparison         |   |\n| `!=`                    | (Not Equal To)\tNot equal to (not ISO standard)                                           | Comparison         |   |\n| `!<`                    | (Not Less Than)\tNot less than (not ISO standard)                                         | Comparison         |   |\n| `!>`                    | (Not Greater Than)\tNot greater than (not ISO standard)                                   | Comparison         |   |\n| [[s.q.tsql.syntax.wild-cards]] | Wild Card Operators                                                                      | String             |   |\n| `+=`                    | String Concatenation                                                                     | String             |   |\n| `+=`                    | Adds some amount to the original value and sets the original value to the result.        | Compound Operators |   |\n| `-=`                    | Subtracts some amount from the original value and sets the original value to the result. | Compound Operators |   |\n| `*=`                    | Multiplies by an amount and sets the original value to the result.                       | Compound Operators |   |\n| `/=`                    | Divides by an amount and sets the original value to the result.                          | Compound Operators |   |\n| `%=`                    | Divides by an amount and sets the original value to the modulo.                          | Compound Operators |   |\n| `&=`                    | Performs a bitwise AND and sets the original value to the result.                        | Compound Operators |   |\n| `^=`                    | Performs a bitwise exclusive OR and sets the original value to the result.               | Compound Operators |   |\n| \\`                                           | =\\`                                                                                      | Performs a bitwise OR and sets the original value to the result. | Compound Operators |\n","n":0.045}}},{"i":169,"$":{"0":{"v":"Merge","n":1},"1":{"v":"\nThe process of using `MERGE` works like this.\n\n1. Identify the table you will load data into.\n2. Identify the table that you will use as the source of your data.\n3. Identify how records in those two tables are connected.\n4. Give instructions on what to do when records do not match.\n5. Give instructions on what to do when records do match.\n\n## Example\n\n```sql\nUSE demo\n\nDROP TABLE IF EXISTS Person\nDROP TABLE IF EXISTS PersonStageTable\n\nCREATE TABLE Person(\n    PersonID BIGINT NOT NULL,\n    FirstName NVARCHAR(50) NULL,\n    LastName NVARCHAR(50) NULL,\n    SourceSystemKey NVARCHAR(50) NULL,\n)\n\nCREATE TABLE PersonStageTable(\n    PersonID BIGINT NOT NULL,\n    FirstName NVARCHAR(50) NULL,\n    LastName NVARCHAR(50) NULL,\n    SourceSystemKey NVARCHAR(50) NULL,\n)\n\nINSERT INTO Person(PersonID, FirstName, LastName, SourceSystemKey)\nSELECT 1, 'Bob', 'Wakefield',1\n\nINSERT INTO PersonStageTable(PersonID, FirstName, LastName, SourceSystemKey)\nSELECT 1,'Bob','Johnson',1\n    UNION\nSELECT 2,'Sally','Ride',2\n\nSELECT * FROM Person\nSELECT * FROM PersonStageTable\n\n\n--*****Merge example beings here.*****\n\nMERGE Person AS target\nUSING (\n    SELECT\n        PersonID,\n        FirstName,\n        LastName,\n        SourceSystemKey\n    FROM PersonStageTable\n) AS source\nON (target.SourceSystemKey = source.SourceSystemKey)\n\nWHEN NOT MATCHED THEN\nINSERT (\n    PersonID,\n    FirstName,\n    LastName,\n    SourceSystemKey\n)\nVALUES (\n    PersonID,\n    FirstName,\n    LastName,\n    SourceSystemKey\n)\n\nWHEN MATCHED THEN\nUPDATE\nSET\ntarget.PersonID = source.PersonID,\ntarget.FirstName = source.FirstName,\ntarget.LastName = source.LastName,\ntarget.SourceSystemKey = source.SourceSystemKey\n;\n\nSELECT * FROM Person\n\nDROP TABLE Person\nDROP TABLE PersonStageTable\n```\n\nAnother Example of syntax\n\n```sql\nMERGE target AS TARGET\nUSING source AS SOURCE\nON condition\nWHEN MATCHED THEN UPDATE\nWHEN NOT MATCHED BY TARGET THEN INSERT\nWHEN NOT MATCHED BY SOURCE THEN DELETE;\n```\n","n":0.072}}},{"i":170,"$":{"0":{"v":"Joins","n":1},"1":{"v":"\n\n\n```sql\nFROM <TABLE A>\n\t[TYPE] JOIN <Table B>\n\t\tON <A Field> = <B Field>\n```\n\n| [[s.q.tsql.syntax.joins.cross-join]]      | [[s.q.tsql.syntax.joins.inner-join]] | [[s.q.tsql.syntax.joins.left-join]]            |\n|-------------------------------------------|--------------------------------------|------------------------------------------------|\n| [[s.q.tsql.syntax.joins.full-outer-join]] | [[s.q.tsql.syntax.joins.right-join]] | [[s.q.tsql.syntax.joins.left-join-where-null]] |\n","n":0.209}}},{"i":171,"$":{"0":{"v":"Right Join","n":0.707},"1":{"v":"\n\nThe same as a [[T-SQL Left Join|s.q.tsql.syntax.joins.left-join]] just in reverse. \n\nConceptually easier to understand by just re-writing these as [[T-SQL Left Join|left-joins]]\n","n":0.213}}},{"i":172,"$":{"0":{"v":"Left Join","n":0.707},"1":{"v":"\n\nThe `LEFT JOIN` is Like the [[T-SQL Inner Join|s.q.tsql.syntax.joins.inner-join]] except instead of throwing out all the single people, if we `LEFT JOIN` Women to Men on `MARRIAGE_ID` then the only records we're throwing out are _all the single ladies_.\n\nThe `LEFT JOIN` Keeps every record on the left and adds records that match the condition onto the right side for those matching records. Where there is no match, `NULL` is returned.\n\n_Statements in WHERE or ON clauses may override LEFT JOIN_\n","n":0.113}}},{"i":173,"$":{"0":{"v":"Left Join Where Null","n":0.5},"1":{"v":"\n\nThe same as [[T-SQL Left Join|s.q.tsql.syntax.joins.left-join]] except the left side has records removed from is where are are `NULL`'s in the right side.\n\nSo this is saying when joining Women to Men on `MARRIAGE_ID` Where `MARRIAGE_ID IS NULL` means you will only see Married Men Returned. No Single Men and no Women at all.\n","n":0.137}}},{"i":174,"$":{"0":{"v":"Inner Join","n":0.707},"1":{"v":"\n\nAn inner join is the default join in T-SQL. The `INNER` is optional but it is a best practice to use it.\n\n````sql\n```sql\nSELECT M.Age, F.Age -- 2 Columns called 'Age' are returned because of the alias prefix\nFROM MENS_AGES AS M\n\t[INNER] JOIN WOMENS_AGES AS F\n\t\tON F.Marriage_ID = M.Marriage_ID\nWHERE M.Age > 55 AND F.Age > 55\n````\n\nThe `INNER JOIN` returns records where the criteria being joined upon matches on both tables\n\nIf you have a table with Men\nand a table with Women\n\nand want to `INNER JOIN` and return the married couples across both tables\n\nyou'd likely `INNER JOIN` Men to Women on `MARRIAGE_ID` and only the pairs with ID's matching each other will be returned. This means that single people in either table will not be returned at all. _Sorry!_\n","n":0.09}}},{"i":175,"$":{"0":{"v":"Full Outer Join","n":0.577},"1":{"v":"\n\nThis joins preserves both tables and retains all records but where there are matches it links them up\n\n\n| Table | One |\n| ----- | --- |\n| 1     | A   |\n| 2     | B   |\n| 3     | C   |\n| 4     | D   |\n\n| Table | Two  |\n| ----- | ---- |\n| 1     | C    |\n| 2     | D    |\n| 3     | NULL |\n| 4     | NULL |\n| 5     | E    |\n| 6     | F    |\n\n| Result | Table One | Table Two |\n| ------ | --------- | --------- |\n| 1      | A         | C         |\n| 2      | B         | D         |\n| 3      | C         | NULL      |\n| 4      | D         | NULL      |\n| 5      | NULL      | E         |\n| 6      | NULL      | F         |\n","n":0.09}}},{"i":176,"$":{"0":{"v":"Cross Join","n":0.707},"1":{"v":"\n\nA Cartesian Product that matches every unique value from one table to every unique value on another table for the complete list of every unique pairing:\n\n| Table | One |\n| ----- | --- |\n| 1     | A   |\n| 2     | B   |\n\n\n| Table | Two |\n| ----- | --- |\n| 1     | C   |\n| 2     | D   |\n\n\n| Result | Table |\n| ------ | ----- |\n| 1      | AC    |\n| 2      | AD    |\n| 3      | BC    |\n| 4      | BD    |\n","n":0.11}}},{"i":177,"$":{"0":{"v":"If Else Statements","n":0.577},"1":{"v":"\n\nConditional operations. Useful with control [[T-SQL Variables|s.q.tsql.syntax.variables]]:\n\n```sql\nDECLARE @retirement INT = 1 -- Using a binary flag\n\nif @retirement = 1\n\tBEGIN\n\t\tSELECT *\n\t\tFROM My_Table\n\t\tWHERE Retirement = 1\n\tEND\nELSE\n\tBEGIN\n\t\tSELECT *\n\t\tFROM My_Table\n\t\tWHERE Retirement = 0\n\tEND\n```\n","n":0.186}}},{"i":178,"$":{"0":{"v":"HTML Email Query Results","n":0.5},"1":{"v":"\n```sql\nDECLARE @tableHTML NVARCHAR(MAX) =\n    N'<h1>Kells Monthly Invoice</h1>' + \n    N'<table border=\"1\">' + \n        N'<tr>' +\n            N'<th>Date</th>' + \n            N'<th>Source_Account</th>' + \n            N'<th>Category</th>' + \n            N'<th>Cashflow_In</th>' +\n            N'<th>Comment</th>' + \n        N'</tr>'\nSET @tableHTML = @tableHTML + CAST((\n    SELECT\n    td = FORMAT(GETDATE(), 'yyyy-MM'), '',\n    td = Source_Account, '',\n    td = Category, '',\n    td = CAST(Cashflow_In AS NVARCHAR), '',\n    td = Comment, ''\n\tFROM <table>\n    FOR XML PATH('tr'), TYPE \n) AS NVARCHAR(MAX))\n\nDECLARE @total NVARCHAR(10) = CAST((SELECT SUM(Cashflow_In) FROM <table>) AS NVARCHAR)\n\nSET @tableHTML = @tableHTML + '<tr><td colspan=\"3\" style=\"text-align:right;\">TOTAL: </td><td>' + @total + '</td><td></td></tr>'\n\nSET @tableHTML = @tableHTML + '</table>'\n```\n","n":0.104}}},{"i":179,"$":{"0":{"v":"Hint","n":1}}},{"i":180,"$":{"0":{"v":"Nolock","n":1},"1":{"v":"\n![[r.(.2022.03.03.understanding-the-sql-server-nolock-hint]]\n\nBetter way to get dirty reads on tables\n\n```sql\nUSE AdventureWorks2016\n\nSET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED\n\n\nSELECT *\nFROM [Sales].[SalesOrderHeader] soh\nJOIN [Sales].[SalesOrderDetail] sod\nON soh.SalesOrderID = sod.SalesOrderID\n\nSET TRANSACTION ISOLATION LEVEL READ COMMITTED\n```\n","n":0.192}}},{"i":181,"$":{"0":{"v":"Group By","n":0.707}}},{"i":182,"$":{"0":{"v":"With Rollup","n":0.707},"1":{"v":"\n\n### The 'RollUp' Sub-Clause\n\n```sql\nSELECT Age, Name, COUNT(Name)\nFROM Person \nGROUP BY Age WITH ROLLUP\nHAVING Age > 50\n```\n\nAdds an additional record item of the results of the initial aggregation option.\n\nSo: if you had a grouping of `COUNT()`'s for each `Age` already totaled up, the `ROLLUP` looks at all of those totals and aggregates them into a grand total.\n","n":0.134}}},{"i":183,"$":{"0":{"v":"Having","n":1},"1":{"v":"\n\n### The 'HAVING' Clause\n\nThe having clause is like the `WHERE` clause except you can use aggregate functions like `COUNT()` and `SUM()` with it.\n\n```sql\nSELECT Age, Name, COUNT(Name)\nFROM Person \nGROUP BY Age\nHAVING COUNT(Name) > 50\n```\n","n":0.174}}},{"i":184,"$":{"0":{"v":"Functions","n":1}}},{"i":185,"$":{"0":{"v":"Sign","n":1},"1":{"v":"\n![[r.(.2022.03.16.how-to-use-these-six-unusual-sql-functions#sign]]\n","n":1}}},{"i":186,"$":{"0":{"v":"Object_id","n":1},"1":{"v":"\n- <https://docs.microsoft.com/en-us/sql/relational-databases/system-catalog-views/sys-objects-transact-sql?view=sql-server-ver15>\n\n```sql\nUSE AdventureWorks2012;\nGO\nIF EXISTS OBJECT_ID(N'dbo.AWBuildVersion', N'U')\n    DROP TABLE dbo.AWBuildVersion;\nGO\n```\n\nThe additional types at the end can be found at the documentation link above\n","n":0.213}}},{"i":187,"$":{"0":{"v":"Lead","n":1},"1":{"v":"\n![[r.(.2022.03.16.how-to-use-these-six-unusual-sql-functions#lead]]\n","n":1}}},{"i":188,"$":{"0":{"v":"Lag","n":1},"1":{"v":"\n![[r.(.2022.03.16.how-to-use-these-six-unusual-sql-functions#lag]]\n","n":1}}},{"i":189,"$":{"0":{"v":"Iif","n":1},"1":{"v":"\n![[r.(.2022.03.16.how-to-use-these-six-unusual-sql-functions#iif]]\n","n":1}}},{"i":190,"$":{"0":{"v":"Concat_ws","n":1},"1":{"v":"\nInstead of eplicitly adding each separator\n\n```sql\nSELECT CONCAT(first_name, ' ', last_name) FROM person_table;\n```\n\n> `CONCAT_WS(<separator>, <data>)`\n\n```sql\nSELECT CONCAT_WS(' ', first_name, middle_name, last_name) FROM person_table;\n```\n","n":0.218}}},{"i":191,"$":{"0":{"v":"Data Manipulation Language","n":0.577},"1":{"v":"\n## Data Manipulation Language\n\n- `SELECT`\n  -\n- `INSERT`\n  - Allows us to add rows to an existing table\n  - also used in the generation of [[T-SQL Temp Tables|s.q.tsql.dbos.temp-tables]]\n  - [[s.q.tsql.syntax.dml.insert-into]]\n- `UPDATE`\n  - [[s.q.tsql.syntax.dml.update]]\n- `DELETE`\n  - [[s.q.tsql.syntax.dml.delete]]\n- `TRUNCATE`\n  - [[s.q.tsql.syntax.dml.truncate]]\n","n":0.162}}},{"i":192,"$":{"0":{"v":"Update","n":1},"1":{"v":"\n\n`UPDATE` Allows us to update a set of data in a table that can be specified by the `WHERE` criteria.\n\n```sql\nUPDATE My_Table\nSET <Column1> = [updated_value1]\n\t,<Column2> = [updated_value2]\n\t,[...]\nWHERE <filter(s)> (Optional)\n```\n\nSo in essence:\n\n```sql\nBEGIN TRAN\nUPDATE database.schema.table\nSET Misc = 'Fourth'\nOUTPUT Inserted.*\nWHERE ID = 4\n\nSELECT * FROM database.schema.table\nROLLBACK COMMIT\n```\n\n- Uses elements:\n  - [[s.q.tsql.syntax.tcl.begin-transaction]]\n  - [[T-SQL Rollback|s.q.tsql.syntax.tcl.rollback]]\n  - [[T-SQL Commit|s.q.tsql.syntax.tcl.commit]]\n  - [OUTPUT](https://docs.microsoft.com/en-us/sql/t-sql/queries/output-clause-transact-sql?view=sql-server-ver15)\n\n","n":0.135}}},{"i":193,"$":{"0":{"v":"Example","n":1},"1":{"v":"\n\n## Example\n\n### Before\n\n| ID | Name | Misc     |\n| -- | ---- | -------- |\n| 1  | AAA  | First    |\n| 2  | BBB  | Second   |\n| 3  | CCC  | Third    |\n| 4  | DDD  | **NULL** |\n\n### After\n\n| ID | Name | Misc   |\n| -- | ---- | ------ |\n| 1  | AAA  | First  |\n| 2  | BBB  | Second |\n| 3  | CCC  | Third  |\n| 4  | DDD  | Fourth |\n","n":0.115}}},{"i":194,"$":{"0":{"v":"Truncate","n":1},"1":{"v":"\n\n`TRUNCATE` Allows us to delete all rows from a table without removing the table from the database\n\n```sql\nTRUNCATE TABLE My_Table\n```\n\n<em>\\*</em>`TRUNCATE` is minimally logged and will perform far faster than [[T-SQL DELETE|s.q.tsql.syntax.dml.delete]] will.\n","n":0.18}}},{"i":195,"$":{"0":{"v":"Like Predicate","n":0.707},"1":{"v":"\n\nUsed with [[T-SQL Wild Cards|s.q.tsql.syntax.wild-cards]], the `LIKE` predicate looks at a [[s.q.tsql.syntax.wild-cards]] string and runs the [[s.o.regular-expressions]] pattern matching operation.\n\n```sql\nSELECT Name\nFROM Person\nWHERE Name LIKE 'Jo*' -- wild card matching on strings\n/*\n\tResult would be any of these:\n\tJohn\n\tJon\n\tJohnny\n\tJonny\n\tEtc.\n*/\n\n```\n","n":0.167}}},{"i":196,"$":{"0":{"v":"Insert Into","n":0.707},"1":{"v":"\n\n```sql\nINSERT INTO database.schema.table (<col1>, <col2>, <col3>) VALUES\n  (<val1>, <val2>, <val3>)\n, (<val1>, <val2>, <val3>)\n, (<val1>, <val2>, <val3>)r\n-- OR\nINSERT INTO database.schema.table\nSELECT <columns>\nFROM <other_table>\n```\n\n`INSERT INTO` is also used with temp table creation:\n\n![[s.q.tsql.dbos.temp-tables]]\n","n":0.186}}},{"i":197,"$":{"0":{"v":"Group By","n":0.707},"1":{"v":"\n\n```sql\nSELECT Age, Name, COUNT(Name)\nFROM Person \nGROUP BY Age\nHAVING Age > 50\n```\n\nThe `GROUP BY` statement consolidates the records based on the aggregate function used. The aggregate function could be something like `COUNT()` or `SUM()` etc. and it says group by `Age`.\n\nSo it will find each distinct `Age` and then group together a `COUNT()` or `SUM()` of all the records for each of those unique `Age`'s.\n\nThe filtering occurs post-aggregation when `HAVING` is applied to not return the aggregates for any `Age`'s that are _> 50_\n\n\n\n","n":0.11}}},{"i":198,"$":{"0":{"v":"Distinct","n":1},"1":{"v":"\n\n```sql\nSELECT DISTINCT <COLUMN>\nFROM <TABLE>\n```\n\nSelects only unique values from that table. \n\nIf there are multiple columns then its every unique pairing of all values in those 2 columns that occur and the same goes on for every additional column:\n\n```sql\nSELECT DISTINCT <COLUMN 1>, [COLUMN 2], [...]\nFROM <TABLE>\n```\n","n":0.149}}},{"i":199,"$":{"0":{"v":"Delete","n":1},"1":{"v":"\n\n`DELETE` Allows us to delete data from a table based on the filters specified in the `WHERE` clause.\n\n```sql\nDELETE FROM My_Table\nWHERE <Filters>\n```\n\n<em>\\*</em>`DELETE` is fully logged and can be an expensive operation if deleting a lot of data\n","n":0.167}}},{"i":200,"$":{"0":{"v":"Data Definition Language","n":0.577},"1":{"v":"\n\n## Data Definition Language\n\n---\n\n- `CREATE`\n  - [[s.q.tsql.syntax.ddl.create]]\n- `ALTER`\n  - To alter an existing table's structure\n  - [[s.q.tsql.syntax.ddl.alter]]\n- `DROP`\n  - to delete a table\n  - also used to re-use [[T-SQL Temp Tables|s.q.tsql.dbos.temp-tables]] in the same session iteratively\n  - [[s.q.tsql.syntax.ddl.drop]]\n","n":0.162}}},{"i":201,"$":{"0":{"v":"Drop","n":1},"1":{"v":"\n\n`DROP TABLE` lets us Delete a table from a data base not just its data like [[T-SQL TRUNCATE|s.q.tsql.syntax.dml.truncate]] or [[T-SQL DELETE|s.q.tsql.syntax.dml.delete]]. Can add `IF EXISTS` starting from SQL Server 2016. cannot drop a table that is referenced by a foreign key constraint.\n\n```sql\ndrop TABLE My_Table\n-- OR\ndrop TABLE IF EXISTS My_Table\n```\n\nSimilar to [[s.q.tsql.dbos.temp-tables]] dropping where `IF NOT NULL` is similar to `IF EXISTS`:\n\n![[s.q.tsql.dbos.temp-tables]]\n","n":0.128}}},{"i":202,"$":{"0":{"v":"Create","n":1},"1":{"v":"\n\n```sql\nCREATE TABLE Database.schema.table_name\n(\tID INT PRIMARY KEY IDENTITY(1,1),\n\tName VARCHAR(50),\n \tMisc VARCHAR(50)\n)\n```\n\nThe primary key here is using the [Identity()](https://docs.microsoft.com/en-us/sql/t-sql/functions/identity-function-transact-sql?view=sql-server-ver15) function.\n\nThe default setting is that this table will have a Clustered index\n\nwe can override this explicitly with:\n\n```sql\nCREATE TABLE Database.schema.table_name\n(\tID INT NOT NULL IDENTITY(1,1),\n\tName VARCHAR(50),\n \tMisc VARCHAR(50)\n \tPRIMARY KEY NONCLUSTERED\n \t(\n\t\tID ASC\n\t)\n)\n```\n\n[MSDN Docs](https://docs.microsoft.com/en-us/sql/relational-databases/indexes/create-clustered-indexes?view=sql-server-ver15) recommend that most situations unless explicitly defined should just use clustered indexes\n\n### Script new table\n\nIf creating a new table with similar structure to an existing one, right click the existing table in SSMS `SCRIPT TABLE AS` --> `CREATE TO` --> `NEW QUERY EDITOR WINDOW`\n","n":0.104}}},{"i":203,"$":{"0":{"v":"Alter","n":1},"1":{"v":"\n\n`ALTER` allows you to add, delete, or modify columns in an existing table.\n\n```sql\nALTER TABLE Table_Name -- and one of the following\nADD Column_Name Datatype\nDROP COLUMN Column_Name\nALTER COLUMN Column_Name Datatype [NULL | NOT NULL]\n```\n","n":0.177}}},{"i":204,"$":{"0":{"v":"Cursors","n":1},"1":{"v":"\n> Cursors are a really inefficient way to loop, so they should only be used in those cases where your process is so inefficient that a cursor is the only thing less efficient than your process. A good example of this is loading large amounts of data between tables.\n\n```sql\nUSE demo\n\nDECLARE @Year INT\nDECLARE @Month INT\n\nDECLARE BatchingCursor CURSOR FOR\nSELECT DISTINCT YEAR([SomeDateField]),MONTH([SomeDateField])\nFROM [Sometable];\n\n\nOPEN BatchingCursor;\nFETCH NEXT FROM BatchingCursor INTO @Year, @Month;\nWHILE @@FETCH_STATUS = 0\nBEGIN\n\nBEGIN TRANSACTION\n--All logic goes in here\n--Any select statements from [Sometable] need to be suffixed with:\n--WHERE Year([SomeDateField])=@Year AND Month([SomeDateField])=@Month   \nCOMMIT TRANSACTION\n\nFETCH NEXT FROM BatchingCursor INTO @Year, @Month;\nEND;\nCLOSE BatchingCursor;\nDEALLOCATE BatchingCursor;\nGO\n```\n\n\n","n":0.102}}},{"i":205,"$":{"0":{"v":"Comments","n":1},"1":{"v":"\n\nSingle line comments are denoted with double dashes while multi-line comments follow popular convention is C like languages like [[s.l.cpp]] or [[s.l.javascript]].\n\n```sql\n-- a Single line comment\n\n/*\n  A Multi-line comment\n  good for in-file documentation\n*/\n\n```\n","n":0.174}}},{"i":206,"$":{"0":{"v":"Case Statements","n":0.707},"1":{"v":"\n\nWith case statements in T-SQL you can in essence insert a bunch of logic and calculation into a multi-faceted case statement with the output being a single result field\n\n```sql\nSELECT P.Age\n\t\t,CASE\n\t\t\tWHEN P.Age > 55\tTHEN 1\n\t\t\tELSE 0\n\t\tEND AS 'RetirementAge'\nFROM Person AS P\n```\n\nThis case statement examines the `Age` field and asks if each value i `> 55` if it is, the result field is assigned a `1` if `Age` is not `> 55` then the `ELSE` statement is executed and the result field receives the value of `0`. \n\nThe ultimate of this being a boolean flag column indicating if each individual is at `RetirementAge` or not. \n\nYou can also nest several `WHEN ... THEN` statements for a multi faceted Case statement:\n\n```sql\nSELECT P.Age\n\t\t,CASE\n\t\t\tWHEN P.Age > 65\tTHEN 'Senior Citizen'\n\t\t\tWHEN P.Age > 55\tTHEN 'Mature Adult'\n\t\t\tWHEN P.Age > 40\tTHEN 'Mid-Life Crisis'\n\t\t\tELSE 'No Discount'\n\t\tEND AS 'DiscountLevel'\nFROM Person AS P\n```\n","n":0.084}}},{"i":207,"$":{"0":{"v":"Between Predicate","n":0.707},"1":{"v":"\n\nThe `BETWEEN` predicate is used to signify an **inclusive** range of values for a condition. You use `BETWEEN` in conjunction with the `AND` operator to mark the 2 ranges your result values should fall between.\n\n```sql\nSELECT Age\nFROM Person\nWHERE Age BETWEEN 55 AND 65 -- This includes both the ages 55 and 65 as it is inclusive\n```\n","n":0.135}}},{"i":208,"$":{"0":{"v":"Apply Operator","n":0.707},"1":{"v":"\n\n`CROSS APPLY` = [[T-SQL Inner Join|s.q.tsql.syntax.joins.inner-join]]\n\n```sql\nSELECT *\nFROM Department D\nCROSS APPLY (\n    SELECT *\n    FROM Employee E\n    WHERE E.DepartmentID = D.DepartmentID\n) A\n\n-- The result sets from these would have been identical\n\nSELECT *\nFROM Department D\nINNER JOIN Employee E\n  ON D.DepartmentID = E.DepartmentID\n```\n\n`OUTER APPLY` = [[T-SQL Left Join|s.q.tsql.syntax.joins.left-join]]\n\n```sql\nSELECT *\nFROM Department D\nOUTER APPLY (\n    SELECT *\n    FROM Employee E\n    WHERE E.DepartmentID = D.DepartmentID\n) A\n\n\n-- The result sets from these would have been identical\n\nSELECT *\nFROM Department D\nLEFT OUTER JOIN Employee E\n  ON D.DepartmentID = E.DepartmentID\n```\n\nGreat uses for Apply\n\n- [SO Examples for apply](https://stackoverflow.com/questions/9275132/real-life-example-when-to-use-outer-cross-apply-in-sql)\n- [Examples of main use cases](https://riptutorial.com/sql/example/8323/cross-apply-and-outer-apply-basics)\n","n":0.104}}},{"i":209,"$":{"0":{"v":"Sql Agent Jobs","n":0.577}}},{"i":210,"$":{"0":{"v":"Setting up Alerts for All Sql Server Agent Jobs","n":0.333},"1":{"v":"\n> Here is a sample T-SQL script that will create the commands for you. This script actually outputs the commands that can then be copied and pasted into a query windows and executed to make the updates. The script could also be changed to automatically issue the commands, but with this version you have the ability to review the commands before you execute them.\n>\n> -- <https://www.mssqltips.com/sqlservertip/1091/setting-up-alerts-for-all-sql-server-agent-jobs/>\n\n```sql\nUSE msdb\nGO\n\nDECLARE @operator varchar(50)\nSET @operator = 'SQLalerts'\n\nSELECT 'EXEC msdb.dbo.sp_update_job @job_ID = ''' + convert(varchar(50),job_id)\n        + ''' ,@notify_level_email = 2, @notify_email_operator_name = ''' + @operator + ''''\nFROM sysjobs\n```\n\nWhen this gets run the following output is created:\n\n```sql\nEXEC msdb.dbo.sp_update_job @job_ID = '589D2B60-EDBD-45B5-BDE6-4DD974D20D25' ,@notify_level_email = 2, @notify_email_operator_name = 'SQLalerts'\nEXEC msdb.dbo.sp_update_job @job_ID = '6BE4306C-CC37-4D38-BC27-1B099601EF6A' ,@notify_level_email = 2, @notify_email_operator_name = 'SQLalerts'\nEXEC msdb.dbo.sp_update_job @job_ID = 'F7569D9A-641E-4130-90F4-535F0B11FC1E' ,@notify_level_email = 2, @notify_email_operator_name = 'SQLalerts'\nEXEC msdb.dbo.sp_update_job @job_ID = 'CD012AF2-BC96-4D9E-A03E-6ABB2F6048AF' ,@notify_level_email = 2, @notify_email_operator_name = 'SQLalerts'\nEXEC msdb.dbo.sp_update_job @job_ID = '451C94B4-8BA3-48AA-BB66-D184F0C25556' ,@notify_level_email = 2, @notify_email_operator_name = 'SQLalerts'\nEXEC msdb.dbo.sp_update_job @job_ID = '7EA95731-1E19-40F6-A5E3-325647DACDE9' ,@notify_level_email = 2, @notify_email_operator_name = 'SQLalerts'\n```\n\n![notify level](/assets/images/2022-03-03-13-46-46.png)\n","n":0.079}}},{"i":211,"$":{"0":{"v":"Sample Job Code","n":0.577},"1":{"v":"\n## Sample Job Code\n\n- <https://www.mssqltips.com/sqlservertip/3052/simple-way-to-create-a-sql-server-job-using-tsql/?utm_source=feedburner&utm_medium=feed&utm_campaign=Feed%3A+MSSQLTips-LatestSqlServerTips+%28MSSQLTips+-+Latest+SQL+Server+Tips%29>\n\n```sql\nUSE msdb\ngo\nCREATE procedure [dbo].[sp_add_job_quick] \n@job nvarchar(128),\n@mycommand nvarchar(max), \n@servername nvarchar(28),\n@startdate nvarchar(8),\n@starttime nvarchar(8)\nas\n--Add a job\nEXEC dbo.sp_add_job\n    @job_name = @job \n--Add a job step named process step. This step runs the stored procedure\nEXEC sp_add_jobstep\n    @job_name = @job,\n    @step_name = N'process step',\n    @subsystem = N'TSQL',\n    @command = @mycommand\n--Schedule the job at a specified date and time\nexec sp_add_jobschedule @job_name = @job,\n@name = 'MySchedule',\n@freq_type=1,\n@active_start_date = @startdate,\n@active_start_time = @starttime\n-- Add the job to the SQL Server \nEXEC dbo.sp_add_jobserver\n    @job_name =  @job,\n    @server_name = @servername\n```\n\nThis is a stored procedure named `sp_add_job_quick` that calls 4 `msdb` stored procedures:\n\n- `sp_add_job` creates a new job\n- `sp_add_jobstep` adds a new step in the job\n- `sp_add_jobschedule` schedules a job for a specific date and time\n- `sp_add_jobserver` adds the job to a specific server\n\n```sql\nexec dbo.sp_add_job_quick \n@job = 'myjob', -- The job name\n@mycommand = 'sp_who', -- The T-SQL command to run in the step\n@servername = 'serverName', -- SQL Server name. If running locally, you can use @servername=@@Servername\n@startdate = '20130829', -- The date August 29th, 2013\n@starttime = '160000' -- The time, 16:00:00\n```\n","n":0.077}}},{"i":212,"$":{"0":{"v":"Execute Python Script on Sql Server Agent Job","n":0.354},"1":{"v":"\n## Execute Python Script On SQL Server Agent Job\n\n- <https://stackoverflow.com/questions/54680105/how-to-execute-python-script-as-administrator-in-sql-server-agent-job>\n\n```sql\nexecute sp_execute_external_script \n@language = N'Python', \n@script = N'\na = 1\nb = 2\nc = a/b\nd = a*b\nprint(c, d)\n'\n```\n\nOR\n\n> I was able to solve the problem to my question by adding a credential/proxy account, assigning it to the Run as in the step, and then altering the Command to look like this:\n> <br>\n> `C:\\Windows\\System32\\cmd.exe /C python \"C:\\PythonScripts\\myPython.py\"`\n","n":0.125}}},{"i":213,"$":{"0":{"v":"Resources","n":1},"1":{"v":"\n\n- [MSDN Documentation](https://docs.microsoft.com/en-us/sql/t-sql/language-reference?view=sql-server-ver15)\n- [Documentation Outline Idea](https://derekhackett.com/t-sql-documentation)\n- [SQL Red Gate Doc](https://www.red-gate.com/products/sql-development/sql-doc/)\n  - [Elaboration](https://www.red-gate.com/simple-talk/sql/t-sql-programming/documenting-your-sql-server-database/)\n- [getting sql server and databases setup on mac](https://database.guide/install-sql-server-2019-on-a-mac/)\n- [SQL Code Formatter](https://www.freeformatter.com/sql-formatter.html#ad-output)\n- [SQL injection Cheat Sheet](https://www.netsparker.com/blog/web-security/sql-injection-cheat-sheet/)\n- [Data Warehouse ETL Framework](https://etl-framework.massstreetuniversity.com/data-warehouse-etl-framework/)\n- [Data Models](http://www.databaseanswers.org/data_models/)\n","n":0.174}}},{"i":214,"$":{"0":{"v":"Query Execution Order of Operations","n":0.447},"1":{"v":"\n\n```sql\n( 5.1 ) SELECT \n         ( 5.2 ) DISTINCT \n         ( 7 ) TOP \n( 1 ) FROM  <tables>  [JOIN, APPLY, PIVOT, UNPIVOT]\n( 2 ) WHERE\n( 3 ) GROUP BY\n( 4 ) HAVING\n( 6 ) ORDER BY\n```\n\n1. `FROM`:  The query process starts with the FROM clause. Beginning with the specified source tables, it processes table operators (join, apply, etc.) in written order from left to right.  \n2. `WHERE`: This phase filters the rows based on the predicate in the WHERE clause. Only rows for which the predicate evaluates to TRUE are returned.\n3. `GROUP BY`: This phase arranges the filtered rows in groups based on the set of expressions (aka, grouping set) specified in the GROUP BY clause. There will be one result row per qualifying group\n4. `HAVING`: This phase filters the groups on the predicate that appears in the HAVING clause (similar to a WHERE clause but for groups). Only groups for which the predicate evaluates to TRUE are returned.\n5. `SELECT`\n6. `Evaluate Expressions`: This phase evaluates the expressions in the SELECT list.\n7. `DISTINCT`: This phase removes duplicate rows from the SELECT list results.\n8. `ORDER BY `: This phase orders the rows according to the list in the ORDER BY clause.\n9. `TOP`: This phase filters specified number of rows based on the ordering in the ORDER BY clause, or based on arbitrary order if there is no ORDER BY clause specified. \n","n":0.066}}},{"i":215,"$":{"0":{"v":"Flow","n":1}}},{"i":216,"$":{"0":{"v":"Try Catch","n":0.707},"1":{"v":"\n```sql\nBEGIN TRY\n--Process that may create an error\nEND TRY\nBEGIN CATCH\n--Process to handle error\nEND CATCH\n```\n\n| Function Name     | Function Definition                                                   |\n|-------------------|-----------------------------------------------------------------------|\n| `ERROR_LINE`      | The line number the error occurred on.                                |\n| `ERROR_MESSAGE`   | Plain language description of the error.                              |\n| `ERROR_NUMBER`    | The number of the error.                                              |\n| `ERROR_PROCEDURE` | The name of the function or stored procedure that produced the error. |\n| `ERROR_SEVERITY`  | The severity value of the error.                                      |\n| `ERROR_STATE`     | The state number of the error.                                        |\n\n```sql\nUSE demo\n\nBEGIN TRY\nPrint 1/0\nEND TRY\nBEGIN CATCH\nPRINT 'Error '+CAST(ERROR_NUMBER()AS NVARCHAR(6))+' '+ERROR_MESSAGE()\nEND CATCH\n```\n","n":0.106}}},{"i":217,"$":{"0":{"v":"Loops","n":1}}},{"i":218,"$":{"0":{"v":"While","n":1},"1":{"v":"\n## Syntax\n\n```sql\nWHILE CONDITION\nBEGIN\n   CODE\n   BREAK --Optional\n   CONTINUE --Optional\nEND\n```\n\n```sql\nWHILE (SELECT SUM([OrderQty]) FROM #SalesOrderDetail ) < 300000\nBEGIN \n   UPDATE #SalesOrderDetail SET [OrderQty] = [OrderQty] + 1000\n \n   IF (SELECT MAX(OrderQty) FROM #SalesOrderDetail) > 3000\n      BREAK\n   ELSE\n      CONTINUE\nEND\n```\n\n```sql\nDECLARE @counter INT = 0\n\nWHILE ( @counter <= 5 )\nBEGIN\n\tPRINT 'Too much for the market to bear'\n\tPRINT '@counter value is:' + CAST(@counter AS VARCHAR)\n\tSET @counter = @counter + 1\nEND ;\n```\n\n## While Example\n\n```sql\nDECLARE @count smallint = 0\n\nWHILE @count<100\nBEGIN\n  INSERT INTO #email VALUES(@count,CONCAT('user',FLOOR(RAND()*1000),'@outlook.com'))\n  SET @count=@count+1\nEND\n```\n\n`WHILE` is not as efficient as [[s.q.tsql.dbos.common-table-expressions]]\n\n## CTE Example\n\n```sql\nWITH numbergenerator (id, email) AS\n(\n   SELECT 1 AS id, CONCAT('user',floor(1000*RAND(CHECKSUM(NEWID()))),'@outlook.com') as email\n   UNION ALL\n   SELECT ng.id + 1  AS id, CONCAT('user',floor(1000*RAND(CHECKSUM(NEWID()))),'@outlook.com')\n   FROM numbergenerator ng\n   WHERE ng.id < 100\n)\nSELECT  *\nINTO #numbergenerator\nFROM numbergenerator ng;\nGO\n```\n\n\n","n":0.093}}},{"i":219,"$":{"0":{"v":"For","n":1},"1":{"v":"\nFor loops do not exist in SQL Server so here's how to replicate them with a [[s.q.tsql.flow.loops.while]] loop.\n\n```sql\nDECLARE @cnt INT = 0;\n\nWHILE @cnt < cnt_total\nBEGIN\n   {...statements...}\n   SET @cnt = @cnt + 1;\nEND;\n```\n","n":0.177}}},{"i":220,"$":{"0":{"v":"DBO's","n":1}}},{"i":221,"$":{"0":{"v":"Views","n":1},"1":{"v":"\n\nIn SQL, a view is a virtual table based on the result-set of an SQL statement. A view contains rows and columns, just like a real table. The fields in a view are fields from one or more real tables in the database.\n\nViews can be used when we you need a physical table but query a certain table with certain criteria often, you can use a view for this.\n\ncan be queried like most normal tables:\n\n```sql\nSELECT *\nFROM v_view\n```\n\n","n":0.114}}},{"i":222,"$":{"0":{"v":"Triggers","n":1},"1":{"v":"\n\n- <https://www.mssqltips.com/sqlservertip/5909/sql-server-trigger-example/>\n- <https://docs.microsoft.com/en-us/sql/t-sql/statements/create-trigger-transact-sql?view=sql-server-ver15#remarks-for-dml-triggers>\n\n```sql\nUSE AdventureWorks2012;\nGO\nIF OBJECT_ID ('Purchasing.LowCredit','TR') IS NOT NULL\n   DROP TRIGGER Purchasing.LowCredit;\nGO\n-- This trigger prevents a row from being inserted in the Purchasing.PurchaseOrderHeader table\n-- when the credit rating of the specified vendor is set to 5 (below average).  \n  \nCREATE TRIGGER Purchasing.LowCredit ON Purchasing.PurchaseOrderHeader  \nAFTER INSERT  \nAS  \nIF (ROWCOUNT_BIG() = 0)\nRETURN;\nIF EXISTS (SELECT 1  \n           FROM inserted AS i   \n           JOIN Purchasing.Vendor AS v   \n           ON v.BusinessEntityID = i.VendorID  \n           WHERE v.CreditRating = 5  \n          )  \nBEGIN  \nRAISERROR ('A vendor''s credit rating is too low to accept new  \npurchase orders.', 16, 1);  \nROLLBACK TRANSACTION;  \nRETURN   \nEND;  \nGO  \n  \n-- This statement attempts to insert a row into the PurchaseOrderHeader table  \n-- for a vendor that has a below average credit rating.  \n-- The AFTER INSERT trigger is fired and the INSERT transaction is rolled back.  \n  \nINSERT INTO Purchasing.PurchaseOrderHeader (RevisionNumber, Status, EmployeeID,  \nVendorID, ShipMethodID, OrderDate, ShipDate, SubTotal, TaxAmt, Freight)  \nVALUES (  \n2  \n,3  \n,261  \n,1652  \n,4  \n,GETDATE()  \n,GETDATE()  \n,44594.55  \n,3567.564  \n,1114.8638 );  \nGO\n```\n","n":0.078}}},{"i":223,"$":{"0":{"v":"Temp Tables","n":0.707},"1":{"v":"\n\n## Temporary Tables\n\nTemp Tables are result sets that are stored in memory for the live of the connection session. There are two types:\n\n### Local\n\n- Only available for the session that created them.\n- Deleted once the session is terminated.\n- Denoted with a `#` prepended to the table name.\n\n### Global\n\n- Available for all sessions and users.\n- Not deleted until the last session using them is terminated\n- CAN be explicitly deleted\n- Denoted with `##` prepended to the table name\n\n## Benefits\n\n- Stored in memory and are FAST\n- Helps to modularize your code instead of monolithic queries\n\n## Usage\n\nYou CAN simply just create the new table but to use the tables iteratively while testing they need to be explicitly deleted for re-use. The best method for this is the following code:\n\n```sql\nIF OBJECT_ID('Tempdb.dbo.#table') IS NOT NULL DROP TABLE #table\n\nSELECT *\nINTO #table\nFROM other_table\nWHERE Age > 55\n```\n\nTemplate Version\n\n```sql\nIF OBJECT_ID('Tempdb.dbo.#<Temp Table Name, Table,>') IS NOT NULL DROP TABLE #<Temp Table Name, Table,>\n```\n\n","n":0.081}}},{"i":224,"$":{"0":{"v":"Indexes","n":1}}},{"i":225,"$":{"0":{"v":"Show Index Statistics","n":0.577},"1":{"v":"\n\n```sql\nDBCC SHOW_STATISTICS('ticketer.app.metric', 'CIX_Created_Date');\nGO\n```\n\n---\n\n- Reference:\n  - [[r.(.2021.12.20.how-to-think-like-the-sql-server-engine]]\n\n","n":0.408}}},{"i":226,"$":{"0":{"v":"Non Clustered Index","n":0.577},"1":{"v":"\n\n> A non-clustered index doesn‚Äôt sort the physical data inside the table. In fact, a non-clustered index is stored at one place and table data is stored in another place. This is similar to a textbook where the book content is located in one place and the index is located in another. This allows for more than one non-clustered index per table.\n> <br>\n> It is important to mention here that inside the table the data will be sorted by a clustered index. However, inside the non-clustered index data is stored in the specified order. The index contains column values on which the index is created and the address of the record that the column value belongs to.\n> <br>\n> When a query is issued against a column on which the index is created, the database will first go to the index and look for the address of the corresponding row in the table. It will then go to that row address and fetch other column values. **It is due to this additional step that non-clustered indexes are slower than [[TSQL Clustered Index|s.q.tsql.dbos.indexes.clustered-index]].**\n\n```sql\nCREATE DATABASE schooldb\n          \nCREATE TABLE student (\n    id INT PRIMARY KEY, -- <==\n    name VARCHAR(50) NOT NULL,\n    gender VARCHAR(50) NOT NULL,\n    DOB datetime NOT NULL,\n    total_score INT NOT NULL,\n    city VARCHAR(50) NOT NULL\n)\n\n--------------------------------\nUSE schooldb\n          \nEXECUTE sp_helpindex student\n```\n\nThe above query will return this result:\n\n![alt](assets/images/Pasted_image_20211201134834.png)\n\n```sql\nUSE schooldb\n          \nINSERT INTO student\n \nVALUES  \n(6, 'Kate', 'Female', '03-JAN-1985', 500, 'Liverpool'), \n(2, 'Jon', 'Male', '02-FEB-1974', 545, 'Manchester'),\n(9, 'Wise', 'Male', '11-NOV-1987', 499, 'Manchester'), \n(3, 'Sara', 'Female', '07-MAR-1988', 600, 'Leeds'), \n(1, 'Jolly', 'Female', '12-JUN-1989', 500, 'London'),\n(4, 'Laura', 'Female', '22-DEC-1981', 400, 'Liverpool'),\n(7, 'Joseph', 'Male', '09-APR-1982', 643, 'London'),  \n(5, 'Alan', 'Male', '29-JUL-1993', 500, 'London'), \n(8, 'Mice', 'Male', '16-AUG-1974', 543, 'Liverpool'),\n(10, 'Elis', 'Female', '28-OCT-1990', 400, 'Leeds');\n-- NOTE id's in random order upon insertion\n\n--------------------------------\nUSE schooldb\n          \nSELECT * FROM student\n```\n\n![alt](assets/images/Pasted_image_20211201134934.png)\n\n```sql\nuse schooldb\n \nCREATE NONCLUSTERED INDEX IX_tblStudent_Name\nON student(name ASC)\n```\n\n> The above script creates a non-clustered index on the ‚Äúname‚Äù column of the student table. The index sorts by name in ascending order. As we said earlier, the table data and index will be stored in different places. The table records will be sorted by a clustered index if there is one. The index will be sorted according to its definition and will be stored separately from the table.\n\n![alt](assets/images/Pasted_image_20211201135410.png)\n","n":0.052}}},{"i":227,"$":{"0":{"v":"Clustered Index","n":0.707},"1":{"v":"\n\n> A clustered index defines the order in which data is physically stored in a table. Table data can be sorted in only way, therefore, there can be only one clustered index per table. In SQL Server, the primary key constraint automatically creates a clustered index on that particular column.\n\n```sql\nCREATE DATABASE schooldb\n          \nCREATE TABLE student (\n    id INT PRIMARY KEY, -- <==\n    name VARCHAR(50) NOT NULL,\n    gender VARCHAR(50) NOT NULL,\n    DOB datetime NOT NULL,\n    total_score INT NOT NULL,\n    city VARCHAR(50) NOT NULL\n)\n\n--------------------------------\nUSE schooldb\n          \nEXECUTE sp_helpindex student\n```\n\nThe above query will return this result:\n\n![alt](assets/images/Pasted_image_20211201134834.png)\n\n```sql\nUSE schooldb\n          \nINSERT INTO student\n \nVALUES  \n(6, 'Kate', 'Female', '03-JAN-1985', 500, 'Liverpool'), \n(2, 'Jon', 'Male', '02-FEB-1974', 545, 'Manchester'),\n(9, 'Wise', 'Male', '11-NOV-1987', 499, 'Manchester'), \n(3, 'Sara', 'Female', '07-MAR-1988', 600, 'Leeds'), \n(1, 'Jolly', 'Female', '12-JUN-1989', 500, 'London'),\n(4, 'Laura', 'Female', '22-DEC-1981', 400, 'Liverpool'),\n(7, 'Joseph', 'Male', '09-APR-1982', 643, 'London'),  \n(5, 'Alan', 'Male', '29-JUL-1993', 500, 'London'), \n(8, 'Mice', 'Male', '16-AUG-1974', 543, 'Liverpool'),\n(10, 'Elis', 'Female', '28-OCT-1990', 400, 'Leeds');\n-- NOTE id's in random order upon insertion\n\n--------------------------------\nUSE schooldb\n          \nSELECT * FROM student\n```\n\n![alt](assets/images/Pasted_image_20211201134934.png)\n\nCreating a new Clustered index:\n\n```sql\n\n-- Since there can only be 1 per table, you'll need to delete the original one on the Primary Key\n\nuse schooldb\n \nCREATE CLUSTERED INDEX IX_tblStudent_Gender_Score\nON student(gender ASC, total_score DESC)\n```\n\n> The characteristics of the best clustering keys can be summarized in few points that are followed by most of the designers:\n> <br>\n> **Short**: Although SQL Server allows us to add up to 16 columns to the clustered index key, with maximum key size of 900 bytes, the typical clustered index key is much smaller than what is allowed, with as few columns as possible. The wide Clustered index key will also affect all non-clustered indexes built over that clustered index, as the clustered index key will be used as a lookup key for all the non-clustered indexes pointing to it.\n> **Static**: It is recommended to choose the columns that are not changed frequently in the clustered index key. Changing the clustered index key values means that the whole row will be moved to the new proper page to keep the data values in the correct order.\n> **Increasing**: Using an increasing column, such as the IDENTITY column, as a clustered index key will help in improving the INSERT process, that will directly insert the new values at the logical end of the table. This highly recommended choice will help in reducing the amount of memory required for the page buffers, minimize the need to split the page into two pages to fit the newly inserted values and the fragmentation occurrence, that required rebuilding or reorganizing the index again.\n> **Unique**: It is recommended to declare the clustered index key column or combination of columns as unique to improve the queries performance. Otherwise, SQL Server will automatically add a uniqueifier column to enforce the clustered index key uniqueness.\n> **Accessed** frequently: This is due to the fact that the rows will be stored in the clustered index in a sorted order based on that index key that is used to access the data.\n> **Used in the ORDER BY clause**: In this case, no need for the SQL Server Engine to sort the data in order to display it, as the rows are already sorted based on the index key used in the ORDER BY clause.\n\n---\n\n- Reference:\n  - <https://www.sqlshack.com/what-is-the-difference-between-clustered-and-non-clustered-indexes-in-sql-server/>\n  - <https://www.sqlshack.com/designing-effective-sql-server-clustered-indexes/>\n","n":0.043}}},{"i":228,"$":{"0":{"v":"Common Table Expressions","n":0.577},"1":{"v":"\n\nA `CTE` is a temporary result set that you can reference within another `SELECT`, [[s.q.tsql.syntax.dml.insert-into]], [[T-SQL UPDATE|s.q.tsql.syntax.dml.update]], or [[T-SQL DELETE|s.q.tsql.syntax.dml.delete]] statement.\n\nA `CTE` always returns a result set. They are used to simplify queries, like eliminating a derived table from the main query body:\n\n```sql\nWITH My_Table (Age, Counts)\nAS\n(\n\tSELECT Age, COUNT(Name) AS Counts\n\tFROM Source_Table\n\tWHERE Age > 55\n\tGROUP BY Age\n)\nSELECT *\nFROM My_Table\nORDER BY Age\nGO\n```\n\nNo [[s.q.tsql.dbos.temp-tables]] assignment, no need to make an intermediary table. I like to this of `CTE`'s like Rice paddy fields where the data like the water just flows downward into the next query or `CTE`.\n\n","n":0.103}}},{"i":229,"$":{"0":{"v":"Recursive","n":1},"1":{"v":"\n\n### Recursive CTE\n\nUseful when you dont have a defined number of iterations\n\n```sql\nWITH CTE\nAS\n(\n\tSELECT 1 AS n -- Anchor Member\n\tUNION ALL\n\tSELECT n + 1 -- Recursive Member\n\tFROM CTE\n\tWHERE n < 50 -- Terminator\n)\nSELECT n \nFROM CTE;\n```\n","n":0.169}}},{"i":230,"$":{"0":{"v":"Chaining","n":1},"1":{"v":"\n\n### Chaining CTE's:\n\n```sql\nWITH My_Table (Age, Counts)\nAS\n(\n\tSELECT Age, COUNT(Name) AS Counts\n\tFROM Source_Table\n\tWHERE Age > 55\n\tGROUP BY Age\n), -- THE COMMA IS THE IMPORTANT PART OF THIS CHAINING\nMy_Second_CTE\nAS\n(\n\tSELECT Age, Counts, Average(Counts)\n\tFROM My_Table\n\tORDER BY Age\n\tGROUP BY Age, Counts\n)\n\nSELECT * FROM My_Second_CTE\n\n```\n\nCTE's are often faster than [[T-SQL Temp Tables|s.q.tsql.dbos.temp-tables]]\n","n":0.149}}},{"i":231,"$":{"0":{"v":"Data T","n":0.707},"1":{"v":"\n\n|     Data Type     | Range                                                                                                                                                                        | Storage                   |\n|:-----------------:|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:--------------------------|\n|   `varchar(x)`    | string of `x` number of bytes \"variable character\"                                                                                                                           | Variable                  |\n|   `nvarchar(x)`   | string of `x` number of bytes \"non-variable character\"                                                                                                                       | User Defined              |\n|     `char(x)`     | string of `x` number of bytes of characters. Unlike `varchar` if you only use 1/50 chars, the other 49 will be taken up with spaces                                          | User Defined              |\n|     `bigint`      | -2^63 (-9,223,372,036,854,775,808) to 2^63-1 (9,223,372,036,854,775,807)                                                                                                     | 8 Bytes                   |\n|       `int`       | -2^31 (-2,147,483,648) to 2^31-1 (2,147,483,647)                                                                                                                             | 4 Bytes                   |\n|    `smallint`     | -2^15 (-32,768) to 2^15-1 (32,767)                                                                                                                                           | 2 Bytes                   |\n|     `tinyint`     | 0 to 255                                                                                                                                                                     | 1 Byte                    |\n|      `money`      | -922,337,203,685,477.5808 to 922,337,203,685,477.5807 (-922,337,203,685,477.58 to 922,337,203,685,477.58 for Informatica. Informatica only supports two decimals, not four.) | 8 bytes                   |\n|   `smallmoney`    | - 214,748.3648 to 214,748.3647                                                                                                                                               | 4 bytes                   |\n| `date(s)/time(s)` | [see docs](https://docs.microsoft.com/en-us/sql/t-sql/data-types/date-transact-sql?view=sql-server-ver15)                                                                    |                           |\n|      `float`      | - 1.79E+308 to -2.23E-308, 0 and 2.23E-308 to 1.79E+308                                                                                                                      | Depends on the value of n |\n|      `real`       | - 3.40E + 38 to -1.18E - 38, 0 and 1.18E - 38 to 3.40E + 38                                                                                                                  | 4 Bytes                   |\n\n---\n\n- Reference:\n  - [MS Docs](https://docs.microsoft.com/en-us/sql/t-sql/data-types/data-types-transact-sql?view=sql-server-ver15)\n","n":0.072}}},{"i":232,"$":{"0":{"v":"Json","n":1}}},{"i":233,"$":{"0":{"v":"Working with Json","n":0.577},"1":{"v":"\n![[r.(.2022.03.16.a-cheat-sheet-for-working-with-json-in-sql-server]]\n","n":1}}},{"i":234,"$":{"0":{"v":"Select Data into Json","n":0.5},"1":{"v":"\n```sql\nSELECT¬†TOP¬†(1000)¬†*\n¬†¬†FROM¬†[DataBase].[schema].[table]¬†AS¬†t\n¬†¬†FOR¬†JSON¬†PATH,¬†ROOT('RootNode')\n```\n\n---\n\n- Reference:\n  - [Reference Docs](https://docs.microsoft.com/en-us/sql/relational-databases/json/format-query-results-as-json-with-for-json-sql-server?view=sql-server-ver15)\n","n":0.447}}},{"i":235,"$":{"0":{"v":"Database Data to Json for App","n":0.408},"1":{"v":"\nInstead of selecting data into a data frame or dealing with data in that manner,\nJust select the data into [[s.df.json]] straight from the database so that you\ncan use the data in the app as pure json as needed and if you need to push data\nback into the database you could easily read the json into pandas and push that\nto the SQL db or maybe even just send the json string back!\n","n":0.119}}},{"i":236,"$":{"0":{"v":"Dates","n":1},"1":{"v":"\n## Difference Between datetime2 and datetimeoffset\n\n```sql\nCREATE TABLE #DateTests (DateTime_2 DATETIME2(7), DateTime_Offset DATETIMEOFFSET(7));\n\nINSERT INTO #DateTests VALUES (GETDATE(), GETDATE());\n\nSELECT * FROM #DateTests;\n```\n\n![offset](/assets/images/2022-03-14-13-07-29.png)\n\n## How to add a valid time zone to a datetime value\n\n`AT TIME ZONE` will assign a time zone offset to a `datetime`, `smalldatetime`, or `datetime2` value that otherwise would not include one.\nIt works by simply adding the words `AT TIME ZONE` immediately after a `datetime` or `datetime2` value and then listing a valid time zone.\nThis time zone is a `NVARCHAR(256)` type.\nSince this author is writing this tip from the Eastern Time zone in the US, that will be the time zone selected.\n\nThe second option is to use the `GETUTCDATE()` function which will return the UTC date and time rather than the system date and time.\nThis will be recorded with the correct time zone (+00:00) and will thus be accurate.\n\n```sql\nDROP TABLE IF EXISTS #DateTests;\n\nCREATE TABLE #DateTests (DateTime_2 DATETIME2(7), DateTime_Offset DATETIMEOFFSET(7));\n\nINSERT INTO #DateTests VALUES (GETDATE(), GETDATE() AT TIME ZONE N'US Eastern Standard Time');\n\nINSERT INTO #DateTests VALUES (GETDATE(), GETUTCDATE());\n\nSELECT * FROM #DateTests;\n```\n\n![output](/assets/images/2022-03-14-13-10-04.png)\n\n## Get list of valid time zones\n\n```sql\nSELECT * FROM sys.time_zone_info;\n```\n\n## Get list of your values for each timezone\n\n```sql\nSELECT\n    DateTime_Offset\n  , tzi.name\n  , DateTime_Offset AT TIME ZONE tzi.name AS ConvertedDateAndTime\nFROM #DateTests\nCROSS JOIN sys.time_zone_info tzi\nORDER BY tzi.name;\n```\n","n":0.07}}},{"i":237,"$":{"0":{"v":"Date Manipulation","n":0.707},"1":{"v":"\n\n```sql\nDATEPART ( datepart , date )\n```\n\n| datepart    | Abbreviations |\n| ----------- | ------------- |\n| year        | yy, yyyy      |\n| quarter     | qq, q         |\n| month       | mm, m         |\n| dayofyear   | dy, y         |\n| day         | dd, d         |\n| week        | wk, ww        |\n| weekday     | dw            |\n| hour        | hh            |\n| minute      | mi, n         |\n| second      | ss, s         |\n| millisecond | ms            |\n| microsecond | mcs           |\n| nanosecond  | ns            |\n| tzoffset    | tz            |\n| iso_week    | isowk, isoww  |\n\nReturns an INT\n\n```sql\nSELECT DATEPART(datepart,'2007-10-30 12:15:32.1234567 +05:10')\n```\n\n| datepart               | Return value |\n| ---------------------- | ------------ |\n| year, yyyy, yy         | 2007         |\n| quarter, qq, q         | 4            |\n| month, mm, m           | 10           |\n| dayofyear, dy, y       | 303          |\n| day, dd, d             | 30           |\n| week, wk, ww           | 44           |\n| weekday, dw            | 3            |\n| hour, hh               | 12           |\n| minute, n              | 15           |\n| second, ss, s          | 32           |\n| millisecond, ms        | 123          |\n| microsecond, mcs       | 123456       |\n| nanosecond, ns         | 123456700    |\n| tzoffset, tz           | 310          |\n| iso_week, isowk, isoww | 44           |\n","n":0.075}}},{"i":238,"$":{"0":{"v":"Postgres","n":1},"1":{"v":"\n\nsuper user account is `postgres`\n\nWhen first creating a server instance the only database that will be in the server is also `postgres`\n","n":0.213}}},{"i":239,"$":{"0":{"v":"Workflow","n":1}}},{"i":240,"$":{"0":{"v":"Migrating Databases","n":0.707},"1":{"v":"\n\nTo migrate a database:\n\n1. Right click on the database on the source server\n2. Backup\n3. Save the file as *.sql\n4. Create a new database on the target server\n5. Right click the new database and select `restore`\n6. Choose the *.sql file you made to restore from\n","n":0.151}}},{"i":241,"$":{"0":{"v":"Adding Data to a Table","n":0.447},"1":{"v":"\n\n<br></br>\n**When** you select values from a table you can edit the output and add new data\nonce you want to \"commit\" the data you click the icon to save the data to the table:\n\n![save data icon](/assets/images/2022-01-10-14-30-12.png)\n","n":0.169}}},{"i":242,"$":{"0":{"v":"Triggers","n":1},"1":{"v":"\n\n```sql\nCREATE OR REPLACE FUNCTION rpt.FN_Clean_Data() RETURNS trigger LANGUAGE 'plpgsql' AS $$\nBEGIN\n    INSERT INTO rpt.report_data_clean\n    SELECT DATE_PART('year', payment_date) AS Year\n         , address AS Location\n         , CAST(amount AS money) AS Revenue\n    FROM rpt.report_data;\n    RETURN NULL;\nEND;\n$$;\nALTER FUNCTION rpt.FN_Clean_Data() OWNER TO postgres;\nCOMMENT ON FUNCTION rpt.FN_Clean_Data()\nIS 'New data in rpt.report_data gets cleaned and inserted into rpt.report_data_clean';\n\nCREATE TRIGGER TR_ETL AFTER INSERT ON rpt.report_data\n    FOR STATEMENT\n    EXECUTE FUNCTION rpt.FN_Clean_Data();\nCOMMENT ON TRIGGER TR_ETL ON rpt.report_data\nIS 'Update reports when new data is added to the rpt.report_data table';\n/*========================================================================*/\nCREATE OR REPLACE FUNCTION rpt.FN_ETL() RETURNS trigger LANGUAGE 'plpgsql' AS $$\nBEGIN\n    TRUNCATE TABLE rpt.location_trended;\n    INSERT INTO rpt.location_trended\n    SELECT \"Year\", \"Location\", SUM(\"Revenue\")\n    FROM rpt.report_data_clean\n    GROUP BY \"Year\", \"Location\";\n\n    TRUNCATE TABLE rpt.location_top;\n    INSERT INTO rpt.location_top\n    SELECT \"Year\", \"Location\", SUM(\"Revenue\")\n         , RANK() OVER(ORDER BY \"Year\" DESC, SUM(\"Revenue\") DESC) AS \"Rank\"\n    FROM rpt.report_data_clean\n    WHERE \"Year\" IN (\n        --   CAST(DATE_PART('year', NOW()) AS INT)     -- Current Year\n        -- , CAST(DATE_PART('year', NOW()) AS INT) - 1 -- Prior Year\n          (SELECT MAX(\"Year\") FROM rpt.report_data_clean)\n        , (SELECT MAX(\"Year\") - 1 FROM rpt.report_data_clean)\n    )\n    GROUP BY \"Year\", \"Location\";\n    RETURN NULL;\nEND\n$$;\nALTER FUNCTION rpt.FN_ETL() OWNER TO postgres;\nCOMMENT ON FUNCTION rpt.FN_ETL()\nIS 'New data in rpt.report_data_clean so update all reports';\n\nCREATE TRIGGER TR_Update_Reports AFTER INSERT ON rpt.report_data_clean\nFOR STATEMENT\nEXECUTE FUNCTION rpt.FN_ETL();\nCOMMENT ON TRIGGER TR_Update_Reports ON rpt.report_data_clean\nIS 'Update reports when new data is added to the rpt.report_data_clean table';\n```\n\n\n","n":0.069}}},{"i":243,"$":{"0":{"v":"Tools","n":1}}},{"i":244,"$":{"0":{"v":"Pgagent","n":1},"1":{"v":"\n\nReference: <https://severalnines.com/database-blog/overview-job-scheduling-tools-postgresql>\n\nLike [[s.q.tsql.tools.sql-agent]] it is a job scheduling agent available for PostgreSQL that allows the execution of stored procedures, SQL statements, and shell scripts.\n\nThe purpose is to have this agent running as a daemon on Linux systems and periodically does a connection to the database to check if there are any jobs to execute.\n\nThis scheduling is easily managed by PgAdmin 4, but it‚Äôs not installed by default once the pgAdmin installed, it‚Äôs necessary to download and install it on your own.\n","n":0.111}}},{"i":245,"$":{"0":{"v":"Installation","n":1},"1":{"v":"\n\n## Step 1\n\nInstallation of pgAdmin 4\n\n```bash\nsudo apt install pgadmin4 pgadmin4-apache\n```\n\n## Step 2\n\nCreation of plpgsql procedural language if not defined\n\n```sql\nCREATE TRUSTED PROCEDURAL LANGUAGE 'plpgsql'\nHANDLER plpgsql_call_ handler\nHANDLER plpgsql validator;\n```\n\n## Step 3\n\nInstallation of pgAgent\n\n```bash\nsudo apt-get install pgagent\n```\n\n## Step 4\n\nCreation of the pgagent extension\n\n```sql\nCREATE EXTENSION pageant\n```\n\nIn order to define a new job, it's only necessary select \"Create\" using the right\nbutton on \"pgAgent Jobs\", and it'll insert a designation for this job and define the\nsteps to execute it:\n\n![pgagent](/assets/images/2022-01-14-23-43-37.png)\n\n![job](/assets/images/2022-01-14-23-44-04.png)\n\n![schedules](/assets/images/2022-01-14-23-44-19.png)\n\n## Step 5\n\nFinally, to have the agent running in the background it's necessary to launch the\nfollowing process manually:\n\n```bash\n/usr/bin/pgagent host=localhost dbname=postgres user=postgres port=5432 -l 1\n```\n\n","n":0.102}}},{"i":246,"$":{"0":{"v":"Pgadmin","n":1},"1":{"v":"\n\n## Setup\n\nPGAdmin Stores your passwords for all Postgres server instances.\n\nPassword provided for this is not the same as the installation password for Postgres\n","n":0.209}}},{"i":247,"$":{"0":{"v":"Tips Tricks","n":0.707}}},{"i":248,"$":{"0":{"v":"Writeable Cte","n":0.707},"1":{"v":"\n\n![writeable CTE](/assets/images/2022-01-26-10-39-53.png)\n\n```sql\n-- Delete rows while simultaneously\n-- inserting them elsewhere\nWITH moved_rows AS (\n    DELETE FROM products\n    WHERE date >= '2010-10-01' AND date < '2010-11-01'\n    RETURNING *\n)\nINSERT INTO products_log SELECT * FROM moved_rows;\n```\n\n\n","n":0.18}}},{"i":249,"$":{"0":{"v":"Returning Newly Inserted Record","n":0.5},"1":{"v":"\n\n## Return Newly Inserted Record\n\nWhen inserting a new record into a table, if you also want that record immediately\nreturned to the output viewer after insertion just add the `RETURNING` keyword\n\n### Before\n\n```sql\nINSERT INTO products ( col1, col2, col3 ) VALUES ( val1, val2, val3 );\n```\n\n### After\n\n```sql\n-- This returns all fields of the newly inserted record but you can also make\n-- the returned value something like just the new PK ID of the record\nINSERT INTO products ( col1, col2, col3 ) VALUES ( val1, val2, val3 ) RETURNING *;\n```\n","n":0.107}}},{"i":250,"$":{"0":{"v":"Returning Data You Touched","n":0.5},"1":{"v":"\n\n```sql\nINSERT INTO person (name) VALUES ('Groot') RETURNING id;\n/*\n id\n----\n  4\n(1 row)\n*/\n```\n\n\n","n":0.302}}},{"i":251,"$":{"0":{"v":"Query Tuning with Explain","n":0.5},"1":{"v":"\n\n```sql\nEXPLAIN(FORMAT JSON)\nSELECT * \nFROM public.test\nWHERE hello IN (SELECT hello FROM public.test ORDER BY hello DESC LIMIT 1);\n```\n\n![query plan](/assets/images/2022-01-26-10-01-27.png)\n\nUsing `EXPLAIN(ANALYZE)` and then pasting the output of the plan into this tool gives like a flame graph:\n\n<https://explain.depesz.com/>\n\n![flame graph](/assets/images/2022-01-26-10-09-32.png)\n\nThis tool is also amazing for displaying graphics on a plan\n\n<https://explain.dalibo.com/>\n\n![query plan](/assets/images/2022-01-26-10-30-43.png)\n\nSetting EXPLAIN to be done automatically (must be a super user to load the module)\n\n```sql\nLOAD 'auto_explain';\n```\n\n`Explain` will just provide the plan calculations\n\nRunning `Analyze` as well will actually execute the statement so if running on a `DELETE` statement be careful if just testing\n","n":0.107}}},{"i":252,"$":{"0":{"v":"Extract Date Parts","n":0.577},"1":{"v":"\n\n```sql\nSELECT current_date\n     , EXTRACT(dow FROM current_date) AS day_of_week\n     , EXTRACT(week FROM current_date) AS week_of_year\n     , EXTRACT(quarter FROM current_date) AS quarter;\n\n/*\n\ncurrent_date | day_of_week | week | quarter\n-------------+-------------+------+--------\n2019-04-28   |           0 |   17 |       2\n(1 row)\n\n*/\n```\n\n\n","n":0.174}}},{"i":253,"$":{"0":{"v":"Date Intervals","n":0.707},"1":{"v":"\n\n```sql\nSELECT TIMESTAMP '2016-03-01 00:00:00' + INTERVAL '7 days' AS new_date;\n\n/*\n\nnew_date\n-------------------\n2016-03-08 00:00:00\n(1 row)\n\n*/\n```\n\n\n","n":0.289}}},{"i":254,"$":{"0":{"v":"Tables","n":1},"1":{"v":"\n\n```sql\nCREATE TABLE rpt.report_data\n(\n    \"payment_date\" timestamp without time zone NOT NULL,\n    \"address\" character varying (255) NOT NULL,\n    \"amount\" numeric\n);\nALTER TABLE rpt.report_data OWNER to postgres;\n```\n","n":0.209}}},{"i":255,"$":{"0":{"v":"Indexes","n":1},"1":{"v":"\n\n```sql\nCREATE UNIQUE INDEX \"CIX_Year_Loc\"\n    ON rpt.location_trended USING btree\n    (\"Year\" ASC NULLS LAST, \"Location\" COLLATE pg_catalog.\"default\" ASC NULLS LAST)\n    INCLUDE (\"Year\", \"Location\")\n    TABLESPACE pg_default;\n    ALTER TABLE rpt.location_trended CLUSTER ON \"CIX_Year_Loc\";\n```\n\n\n","n":0.186}}},{"i":256,"$":{"0":{"v":"Stored Proc","n":0.707},"1":{"v":"\n\n\n```sql\n\nCREATE OR REPLACE FUNCTION rpt.\"FN_Nuke_From_Orbit\"() RETURNS void LANGUAGE 'plpgsql' AS $$\nBEGIN\n    TRUNCATE TABLE rpt.report_data;\n    TRUNCATE TABLE rpt.report_data_clean;\n    TRUNCATE TABLE rpt.location_trended;\n    TRUNCATE TABLE rpt.location_top;\nEND;\n$$;\nALTER FUNCTION rpt.\"FN_Nuke_From_Orbit\"() OWNER TO postgres;\nCOMMENT ON FUNCTION rpt.\"FN_Nuke_From_Orbit\"()\nIS 'Wipe all data in the rot schema from the Face of the earth';\n\nCREATE OR REPLACE PROCEDURE rpt.\"USP_Refresh\"() LANGUAGE 'plpgsql' AS $$\nBEGIN\n    /*********************************************************\n    USAGE:\n        This stored procedure can be run at any interval desired.\n        Since this performs a full truncate and load of the entire\n            rpt schema and all table data this will be expensive\n            in resources.\n        Recommendation is, depending on geographic factors of\n            store locations affecting end of day accounting totals,\n            to run the stored procedure in the off hours such as \n            at midnight or directly after C.O.B. so the day's\n            results are posted immediately after the conclusion\n            of that day's business.\n    *********************************************************/\n    /*********************************************************\n    Wipe The entire structure of the rpt schema for a clean\n    full rebuild via truncate and load ETL\n    *********************************************************/\n    PERFORM rpt.\"FN_Nuke_From_Orbit\"();\n    /*********************************************************\n    Grab all raw data and kick off the live rebuild process\n    driven by triggers.\n    *********************************************************/\n    INSERT INTO rpt.report_data\n    SELECT p.payment_date\n         , a.address\n         , p.amount\n    FROM public.payment AS p\n        LEFT JOIN public.staff AS S ON s.staff_id = p.staff_id\n        LEFT JOIN public.store AS st ON st.store_id = s.store_id\n        LEFT JOIN public.address AS a ON a.address_id = st.address_id;\n    COMMIT;\nEND;\n$$;\nCOMMENT ON PROCEDURE rpt.\"USP_Refresh\"()\nIS 'Refresh the entire reporting structure';\n```\n","n":0.067}}},{"i":257,"$":{"0":{"v":"Setup","n":1},"1":{"v":"\n\n## Create database\n\nCreate server instance > right click on databases > new database\n\n## Create Tables\n\nExpand your databse > Expand Schemas > Tables > Create > table creation GUI\n\n### Constraints and more\n\nWhen in the column menu of the table GUI you can select the edit icon next to any column\nand it will open a sub-menu with items that allow you to do things like add Constraints\n","n":0.124}}},{"i":258,"$":{"0":{"v":"Schemas","n":1},"1":{"v":"\n\n\n```sql\nCREATE SCHEMA rpt AUTHORIZATION postgres;\nCOMMENT ON SCHEMA rpt IS 'Reporting';\nGRANT ALL PRIVILEGES ON SCHEMA rpt TO postgres;\nALTER USER postgres SET search_path TO rpt, public;\n```\n","n":0.204}}},{"i":259,"$":{"0":{"v":"Resources","n":1},"1":{"v":"\n\n- [Official Documents][1]\n\n[1]: https://www.postgresql.org/docs/current/index.html\n","n":0.5}}},{"i":260,"$":{"0":{"v":"Funcs","n":1}}},{"i":261,"$":{"0":{"v":"Window Functions","n":0.707},"1":{"v":"\n\nExamples of window functions\n\n```sql\nSELECT {columns}\n     , {window_func} OVER (PARTITION BY {partition_key} ORDER BY {order_key})\nFROM table1;\n```\n\nmore realistic example:\n\n```sql\nSELECT customer_id\n     , title\n     , first_name\n     , last_name\n     , gender\n     , COUNT(*) OVER (PARTITION BY gender ORDER BY customer_id) AS total_customers\n     , SUM(CASE WHEN title IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY gender ORDER BY customer_id) AS total_customers_title\nFROM customers\nORDER BY customer_id;\n```\n\nThe window Keyword:\n\n```sql\nSELECT customer_id\n     , title\n     , first_name\n     , last_name\n     , gender\n     , COUNT(*) OVER w AS total_customers,\n     , SUM(CASE WHEN title IS NOT NULL THEN 1 ELSE 0 END) OVER w AS total_customers_title\nFROM customers\n     WINDOW w AS (PARTITION BY gender ORDER BY customer_id) -- Reduces typing and improves legibility\nORDER BY customer_id;\n```\n\n\n\n","n":0.094}}},{"i":262,"$":{"0":{"v":"Now","n":1},"1":{"v":"\n\n## Details\n\n`NOW()` is Like `GETDATE()` in [[s.q.tsql]] returns a `DATETIME` value but also with the\nrelevant timezone info if casted to that.\n\n## Usage\n\n```sql\nSELECT NOW();\n```\n","n":0.209}}},{"i":263,"$":{"0":{"v":"Least Greatest","n":0.707},"1":{"v":"\n\nUnlike aggregate functions such as `MIN` or `MAX` using `LEAST` or `GREATEST` seems to be scalar oriented\n\n> Two functions that come in handy for data preparation are the `LEAST` and `GREATEST` functions. Each function takes any number of values and returns the least or the greatest of the values, respectively.\n>\n> A simple use of this variable would be to replace the value if it's too high or low. For example, the sales team may want to create a sales list where every scooter is $600 or less than that. We can create this using the following query:\n\n```sql\nSELECT product_id\n     , model\n     , year\n     , product_type\n     , LEAST(600.00, base_msrp) AS base_msrp\n     , production_start_date\n     , production_end_date\nFROM products\nWHERE product_type='scooter'\nORDER BY 1;\n```\n\n\n","n":0.092}}},{"i":264,"$":{"0":{"v":"Copy","n":1},"1":{"v":"\n\n> The COPY statement retrieves data from your database and dumps it in the file format of your choosing. For example, take the following statement:\n\n## Data To STDOUT\n\n```sql\nCOPY (SELECT * FROM customers LIMIT 5) TO STDOUT WITH CSV HEADER;\n```\n\n- `COPY` is simply the command used to transfer data to a file format.\n- `(SELECT * FROM customers LIMIT 5)` is the query that we want to copy.\n- `TO STDOUT` indicates that the results should be printed rather than saved to a file on the hard drive. \"Standard Out\" is the common term for displaying output in a command-line terminal environment.\n- `WITH` is an optional keyword used to separate the parameters that we will use in the database-to-file transfer.\n- `CSV` indicates that we will use the CSV file format. We could have also specified `BINARY` or left this out altogether and received the output in text format.\n- `HEADER` indicates that we want the header printed as well.\n\n## Data to a file\n\n```sql\nCOPY (SELECT * FROM customers LIMIT 5) TO '/path/to/my_file.csv' WITH CSV HEADER;\n```\n\n## Use psql CLI to get data into the database\n\n```bash\npsql -h my_host -p 5432 -d my_database -U my_username\n\\copy (SELECT * FROM customers LIMIT 5) TO 'my_file.csv' WITH CSV HEADER:\n```\n\n- `\\copy` is invoking the Postgres `COPY` ... `TO STDOUT`... command to output the data.\n- `(SELECT * FROM customers LIMIT 5)` is the query that we want to copy.\n- `TO 'my_file.csv'` indicates that psql should save the output from standard into my_file.csv.\n- The `WITH CSV HEADER` parameters operate the same as before.\n\n### Configuring the copy command\n\n- `DELIMITER` 'delimiter_character' can be used to specify the delimiter character\nfor CSV or text files (for example for CSV files, or '`|`' for pipe-separated files)\n\n### Loading data into a table\n\n```bash\n\\copy customers FROM 'my_file.csv' CSV HEADER DELIMITER\n```\n\n\n","n":0.059}}},{"i":265,"$":{"0":{"v":"Coalesce","n":1},"1":{"v":"\n\n> To illustrate a simple usage of the COALESCE function, let's return to the customers table. Let's say the marketing team would like a list of the first names, last names, and phone numbers of all male customers. However, for those customers with no phone number, they would like the table to instead write the value 'NO PHONE'. We can accomplish this request with `COALESCE`:\n  \n```sql\nSELECT first_name\n     , last_name\n     , COALESCE(phone, 'NO PHONE') AS phone\nFROM customers\nORDER BY 1;\n```\n\n> When dealing with creating default values and avoiding `NULL`, `COALESCE` will always be helpful.\n\n","n":0.104}}},{"i":266,"$":{"0":{"v":"Flow","n":1}}},{"i":267,"$":{"0":{"v":"Loops","n":1}}},{"i":268,"$":{"0":{"v":"Data T","n":0.707}}},{"i":269,"$":{"0":{"v":"Numeric","n":1}}},{"i":270,"$":{"0":{"v":"Serial","n":1},"1":{"v":"\n\npreferred for auto-incrementing values like primary keys\n","n":0.378}}},{"i":271,"$":{"0":{"v":"Dates","n":1}}},{"i":272,"$":{"0":{"v":"Casting","n":1},"1":{"v":"\n\nunlike [[s.q.tsql]] casting doesnt require the `CAST(column AS TYPE)` function. Instead, within postgres you can cast datatypes like `column::datatype` using the double colon syntax `::`\n\n```sql\nSELECT product_id\n     , model\n     , year::TEXT\n     , product_type\n     , base_msrp\n     , production_start_date\n     , production_end_date\nFROM products;\n```\n","n":0.16}}},{"i":273,"$":{"0":{"v":"Array","n":1},"1":{"v":"\n\n## Array data\n\n```sql\nSELECT ARRAY['Lemon', 'Bat Limited Edition' ] AS example_purchased_products;\n\n/*\n\nexample_purchased_products\n------------------------------\n{Lemon, \"Bat Limited Edition\"}\n\n*/\n```\n\n## Unnest array\n\n```sql\nSELECT UNNEST(ARRAY[123, 456, 789]) AS example_ids;\n```\n\n![unested array](/assets/images/2022-01-26-12-29-12.png)\n\nThis is a great way to add tags to an item in a single column in a better way than using string split on csv values!\n\n## Array aggregate\n\n```sql\nSELECT product_type, ARRAY_AGG(DISTINCT model) AS models FROM products GROUP BY 1;\n```\n\n![array_agg](/assets/images/2022-01-26-12-31-31.png)\n\n## String splitting to array\n\n```sql\nSELECT STRING_TO_ARRAY('hello there how are you?', ' ');\n```\n\n![string to array](/assets/images/2022-01-26-12-32-26.png)\n\n","n":0.119}}},{"i":274,"$":{"0":{"v":"Other","n":1}}},{"i":275,"$":{"0":{"v":"Regular Expressions","n":0.707},"1":{"v":"\n\nUseful site for writing and testing regex\n\n- <https://www.regexpal.com/>\n- <https://regex101.com/>\n- <http://regextutorials.com/index.html>\n- <https://regexper.com/#%5E%28%5Ba-z%5D%2B%5Cd*_%5Ba-z%5Cd_%5D*%7C_%2B%5Ba-z%5Cd%5D%2B%5Ba-z%5Cd_%5D*%29%24>\n\n![image.png](image_1626507098408_0.png)\n\nImage Source: <https://twitter.com/manekinekko/status/1335330878403260419>\n\n|        code         |                                                                                         Purpose                                                                                          |\n| :-----------------: | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: |\n|        `\\d`         |                                                                                 represent any digit 0-9                                                                                  |\n| `[0-9]` or `[abc]`  |                                            matches a range or any specfic item in the brackets could find a,b, or c but will find all of them                                            |\n|        `\\D`         |                                                                              match any NON-digit characters                                                                              |\n| `[^0-9]` or `[^\\d]` |                                                                  says match all BUT these in which case this is digits                                                                   |\n|        `\\w`         |            will match words, `\\D` will match white space, punctuation, hyphens, etc. while `\\w` does not. `\\w` matches only letters and numbers, equivalently: `[a-zA-Z0-9]`             |\n|        `\\W`         |                                           to match a non word character. matches opposite of alphanumeric and is equivalent to `[^_a-zA-Z0-9]`                                           |\n|        `\\s`         |                                                                                 match a space character                                                                                  |\n|        `\\n`         |                                                                                         New line                                                                                         |\n|        `\\t`         |                                                                                          a tab                                                                                           |\n|        `\\r`         |                                                                                     carriage return                                                                                      |\n|         `.`         |                                                                                match any single character                                                                                |\n|        `\\b`         | boundry, so for a word `\\bA.{5}T\\b` the boundries encompass words that start with 'A', end with 'T' and have 5 characters in the middle like ANCYENT or ANCIENT also akin to `\\b\\w{7}\\b` |\n|         `^`         |                                                                                beginning of a line anchor                                                                                |\n|         `$`         |                                                                                   end of a line anchor                                                                                   |\n|                     |                                                     the pipe is an 'or' statement in brackets is saying 't' OR 'T' in a regex search                                                     |\n|    `[0-3[4-5]]`     |                   Union of 2 character sets, this would return 04, 05, 14, 15, 24, 25, 34, 35, this can also work with negation to use a set of 'NOT THESE' characters                   |\n\n---\n\n| Quantifier |                                                             Description                                                             |     |\n| ---------- | :---------------------------------------------------------------------------------------------------------------------------------: | --- |\n| `{8}`      | quantifyer, same as linux CLI `.{8}` would match any 8 characters, this one matches the patter a specific number of times, 8 times. |     |\n| `{8,}`     |                                  the comma means it will match  or more occurances of the pattern                                   |     |\n| `{2,4}`    |                         will match the pattern anytime it ocurs 2-4 times any of those options are captured                         |     |\n\n","n":0.055}}},{"i":276,"$":{"0":{"v":"Make","n":1}}},{"i":277,"$":{"0":{"v":"CLI","n":1}}},{"i":278,"$":{"0":{"v":"Cmd","n":1}}},{"i":279,"$":{"0":{"v":"Variables Aka Macros","n":0.577},"1":{"v":"\n\n## Variable aka Macros\n\n> are like variable replacement in makefiles\n\n```make\n# ==================\n# USING VARIABLES (aka macros)\n# ==================\n# VARIABLENAME = VALUE OF VARIABLE\n# they expand using the syntax $(VARIABLENAME)\n\n\nTMP = tester1.txt\nOUTPUT = tester2.txt\n\n$(OUTPUT): $(TMP)\ncat $(TMP) > $(OUTPUT)\n\n$(TMP):\necho \"this is a test\" > $(TMP)\n```\n","n":0.156}}},{"i":280,"$":{"0":{"v":"Specify Dependency Targets","n":0.577},"1":{"v":"\n\n## Specifying dependency targets\n\n```make\nfinal_target: sub_target final_target.c\n\tRecipe_to_create_final_target\n\nsub_target: sub_target.c\n\tRecipe_to_create_sub_target\n```\n\n```make\nsay_hello:\n\techo \"Hello World\"\n```\n\n- `say_hello:` == _The Target_\n- _prerequisites_ or _dependencies_ follow the target\n- `echo \"Hello World\"` == _The Recipe_\n- The _target_, _prerequisites_, and _recipes_ together make a _rule_.\n- **Suppress command** text and only show output with `@` like `@echo \"hello world\"`\n\n```make\nsay_hello:\n\t  @echo \"Hello World\"\n\ngenerate:\n\t  @echo \"Creating empty text files...\"\n\t  touch file-{1..10}.txt\n\nclean:\n\t  @echo \"Cleaning up...\"\n\t  rm *.txt\n```\n\n- This will only run the `say_hello` function because it's the default target ( the first thing )\n- to hard code the default target, include this at beginning of file: `.DEFAULT_GOAL := generate`\n  - To instead run all targets the target `all` is used to call all other targets\n\n```make\nall: say_hello generate\n\nsay_hello:\n\t  @echo \"Hello World\"\n\ngenerate:\n\t  @echo \"Creating empty text files...\"\n\t  touch file-{1..10}.txt\n\nclean:\n\t  @echo \"Cleaning up...\"\n\t  rm *.txt\n```\n","n":0.089}}},{"i":281,"$":{"0":{"v":"Resources","n":1},"1":{"v":"\n## Resources\n\n- [What is a Makefile and how does it work?](https://opensource.com/article/18/8/what-how-makefile)\n- [C++ Programming Tutorial 75 - Creating a Simple Makefile](https://youtu.be/6Gw1rNyTJWA)\n- [makefiles: the problem](https://calmcode.io/makefiles/the-problem.html)\n- [How To Manage Your Dotfiles With Make](https://youtu.be/aP8eggU2CaU)\n- [How To Write a Makefile](https://youtu.be/TQ7SyYyKXhk)\n- <https://www.gnu.org/software/make/manual/make.html>\n","n":0.167}}},{"i":282,"$":{"0":{"v":"Interface Rules","n":0.707},"1":{"v":"\n\n## Inference rules\n\n```make\n# ==================\n# USING INFERENCE RULES\n# ==================\n\n# $@ = prod.txt (if out of date)\n# $* = prod (its the target with the .extention removed)\n# $< = dep.txt (aka its the first dependancy)\n\n# .SUFFIXES appends these to suffixes used for inference rules\n\n.SUFFIXES: .tmp .txt\n\nall: tester.txt\n\n# make a .txt file using a .tmp file\n# $< for the .tmp file\n# $@ for the .txt file\n\n# .inextension.outextension:\n.tmp.txt:\ncat $< > $*\n```\n","n":0.122}}},{"i":283,"$":{"0":{"v":"Install on Windows","n":0.577},"1":{"v":"\n## Installation on Windows\n\n- Install from [Here](http://gnuwin32.sourceforge.net/packages/make.htm)\n- Run `C:\\MinGW\\bin\\mingw-get.exe` to install the Make tools\n- Add `C:\\MinGW\\bin` to your `$PATH`\n- make [[s.l.powershell]] alias of `mingw32-make.exe` to `make`\n\n```powershell\nNew-Alias -Name make -Value mingw32-make.exe\n```\n","n":0.183}}},{"i":284,"$":{"0":{"v":"Dax","n":1},"1":{"v":"\n\n- Related: [[T-SQL|sql]]\n- Used in: [[Excel|s.apps.excel]]\n- [DAX Formatter](https://www.daxformatter.com/)\n","n":0.354}}},{"i":285,"$":{"0":{"v":"Markup","n":1}}},{"i":286,"$":{"0":{"v":"Restructured Text","n":0.707}}},{"i":287,"$":{"0":{"v":"Tools","n":1}}},{"i":288,"$":{"0":{"v":"Sphinx","n":1},"1":{"v":"\n## Resources\n\n- [Sphinx Tutorial][1]\n- [reStructuredText Primer][2]\n- [Sphinx Markup Constructs][3]\n- [Sphinx Domains][4]\n\n[1]: http://www.sphinx-doc.org/en/stable/tutorial.html\n[2]: http://www.sphinx-doc.org/en/stable/rest.html\n[3]: http://www.sphinx-doc.org/en/stable/markup/index.html\n[4]: http://www.sphinx-doc.org/en/stable/domains.html\n\n## Quick Start\n\n```bash\npip install Sphinx\nmkdir docs\ncd docs\nsphinx-quickstart\n```\n\nThis creates:\n\n![quick start](/assets/images/2022-02-17-12-49-53.png)\n\n## Versioning\n\nInstead of hardcoding version in the quick start wizard, use the python `__version__` dunder to have the version automatically be pulled.\n\n![version](/assets/images/2022-02-17-12-51-56.png)\n\n## Building The docs\n\n```bash\nsphinx-build . _build/html/\nmake html # this is just an alias to the above command\n```\n\nInstead of just detecting changes you might want to rebuild the whole thing:\n\n```bash\nsphinx-build -E . _build/html/\nmake clean; make html\n```\n\n### Code Coverage\n\ncan use a different build tool addon that is activated from the quickstart wizard called `coverage`\n\n```bash\nsphinx-build -b coverage . _build/coverage/`\n```\n\nThis will use `coverage` as the build tool and tell you when you have undocumented functions. Otherwise sphinx will fail quietly because if there's no work to do (functions dont have doc strings) then it fails quietly.\n\nThere is a flag to get it to process and render function documentation even if its blank called `undock members` but coverage gives insight into undocumented things.\n\n## Themes\n\n```bash\npip install sphinx_rtd_theme # this is for read the docs theme\n```\n\nand then inside `conf.py` in the `docs/` directory:\n\n```python\nhtml_theme = 'sphinx_rtd_theme'\n```\n","n":0.074}}},{"i":289,"$":{"0":{"v":"Extensions","n":1},"1":{"v":"\n## Extensions\n\nSphinx is primarily a python toolset for docs but can be used for C and JavaScript sort of but using extensions can extend the support of languages using `.rst`\n\n```bash\npip install sphinxcontrib-httpdomain\n```\n\n![extensions](/assets/images/2022-02-17-13-05-23.png)\n","n":0.177}}},{"i":290,"$":{"0":{"v":"Git Changelog","n":0.707},"1":{"v":"\n<https://github.com/OddBloke/sphinx-git>\n","n":1}}},{"i":291,"$":{"0":{"v":"Develop Your Own","n":0.577},"1":{"v":"\n### Developing your own extensions\n\n- <https://www.sphinx-doc.org/en/master/development/tutorials/helloworld.html>\n- <https://www.sphinx-doc.org/en/master/development/tutorials/todo.html>\n","n":0.378}}},{"i":292,"$":{"0":{"v":"Syntax","n":1}}},{"i":293,"$":{"0":{"v":"Inline Markup","n":0.707},"1":{"v":"\n## Inline Markup\n\nBe aware of some restrictions of this markup:\n\nit may not be nested,\n\ncontent may not start or end with whitespace: `* text*` is wrong,\n\nit must be separated from surrounding text by non-word characters. Use a backslash escaped space to work around that: `thisis\\ *one*\\ word`.\n","n":0.147}}},{"i":294,"$":{"0":{"v":"Italic","n":1},"1":{"v":"\n### Italic\n\n```rst\n*Italic*\n```\n","n":0.707}}},{"i":295,"$":{"0":{"v":"Hyperlinks","n":1},"1":{"v":"\n### Inline Links\n\n`` `Link text <https://domain.invalid/>`_ ``aa\n\n### Separate Link Text and Definition\n\n```rst\nThis is a paragraph that contains `a link`_.\n\n.. _a link: https://domain.invalid/\n```\n\n### Hyperlink Targets\n\n```rst\n.. _Python: https://www.python.org\n\n.. _example:\n\nThe \"_example\" target above points to this paragraph.\n```\n","n":0.171}}},{"i":296,"$":{"0":{"v":"Footnotes","n":1},"1":{"v":"\n```rst\n.. [1] A footnote contains body elements, consistently\n   indented by at least 3 spaces.\n```\n","n":0.267}}},{"i":297,"$":{"0":{"v":"Definition Lists","n":0.707},"1":{"v":"\n```rst\nterm 1\n    Definition 1.\n\nterm 2\n    Definition 2, paragraph 1.\n\n    Definition 2, paragraph 2.\n\nterm 3 : classifier\n    Definition 3.\n\nterm 4 : classifier one : classifier two\n    Definition 4.\n\n\\-term 5\n    Without escaping, this would be an option list item.\n```\n","n":0.164}}},{"i":298,"$":{"0":{"v":"Code","n":1},"1":{"v":"\n### Inline code\n\n```rst\n``inline code``\n```\n","n":0.5}}},{"i":299,"$":{"0":{"v":"Citations","n":1},"1":{"v":"\n```rst\n.. [CIT2002] Just like a footnote, except the label is\n   textual.\n```\n","n":0.302}}},{"i":300,"$":{"0":{"v":"Bold","n":1},"1":{"v":"\n### Bold\n\n```rst\n**bold**\n```\n","n":0.707}}},{"i":301,"$":{"0":{"v":"Info Fields","n":0.707},"1":{"v":"\n## Info Fields\n\nIn python docstrings these might present as items in the docstrings\n\n```rst\n:param str name: optional name\n```\n\n- info is that it is a `parameter`\n- follow by type `str`\n- then the name of the param `name`\n- and finally the description\n\nThis can also be borken out onto 2 different lines for legibility sake\n\n```rst\n:param name: optional name\n:type name: str\n```\n\n```rst\n:returns: 'Hello world!' or 'Hello, {name}!'\n:rtype: str\n```\n\n![return types](/assets/images/2022-02-17-12-40-09.png)\n\n`:attr block_size:` being used to document a class attribute\n\n`:raises ValueError:` To define the exception it may raise and why it will raise that exception\n\n![attributes and exceptions](/assets/images/2022-02-17-12-41-35.png)\n\n`:meth:` for defining methods\n","n":0.105}}},{"i":302,"$":{"0":{"v":"Headers and Sections","n":0.577},"1":{"v":"\n## Headers\n\n```rst\n========\nHeader 1\n========\n\n--------\nHeader 2\n--------\n\nHeader 3\n^^^^^^^^\n```\n\nBut also\n\n```rst\nAlso Header 1\n=============\n\nHeader 2\n********\n\nHeader 3\n--------\n```\n\n| Markup | Meaning                     |\n|--------|-----------------------------|\n| `#`    | with overline, for parts    |\n| `*`    | with overline, for chapters |\n| `=`    | for sections                |\n| `-`    | for subsections             |\n| `^`    | for subsubsections          |\n| `\"`    | for paragraphs              |\n","n":0.144}}},{"i":303,"$":{"0":{"v":"Figures","n":1},"1":{"v":"\n<https://docutils.sourceforge.io/docs/ref/rst/directives.html#figure>\n\n```rst\n.. figure:: picture.png\n   :scale: 50 %\n   :alt: map to buried treasure\n\n   This is the caption of the figure (a simple paragraph).\n\n   The legend consists of all elements after the caption.  In this\n   case, the legend consists of this paragraph and the following\n   table:\n\n   +-----------------------+-----------------------+\n   | Symbol                | Meaning               |\n   +=======================+=======================+\n   | .. image:: tent.png   | Campground            |\n   +-----------------------+-----------------------+\n   | .. image:: waves.png  | Lake                  |\n   +-----------------------+-----------------------+\n   | .. image:: peak.png   | Mountain              |\n   +-----------------------+-----------------------+\n```\n","n":0.116}}},{"i":304,"$":{"0":{"v":"Field Lists","n":0.707},"1":{"v":"\n## Fields Lists\n\n```rst\n:Date: 2001-08-16\n:Version: 1\n:Authors: - Me\n          - Myself\n          - I\n:Indentation: Since the field marker may be quite long, the second\n   and subsequent lines of the field body do not have to line up\n   with the first line, but they must be indented relative to the\n   field name marker, and they must line up with each other.\n:Parameter i: integer\n```\n\n## Bibliographic Fields\n\nThe registered bibliographic field names and their corresponding doctree elements are as follows:\n\n| Field name   | doctree element |\n|--------------|-----------------|\n| Abstract     | topic           |\n| Address      | address         |\n| Author       | author          |\n| Authors      | authors         |\n| Contact      | contact         |\n| Copyright    | copyright       |\n| Date         | date            |\n| Dedication   | topic           |\n| Organization | organization    |\n| Revision     | revision        |\n| Status       | status          |\n| Version      | version         |\n","n":0.089}}},{"i":305,"$":{"0":{"v":"Directives","n":1},"1":{"v":"\n## Directives\n\ndirectives are like in [[s.m.restructured-text.syntax.block-content.code]] where you explicitly say to use python `.. code-block:python`\n\n```rst\n.. image:: mylogo.png\n```\n\n### Substitution Definition\n\n```rst\n.. |symbol here| image:: symbol.png\n```\n","n":0.209}}},{"i":306,"$":{"0":{"v":"Raw","n":1},"1":{"v":"\n## Raw HTML\n\n```rst\n.. raw:: html\n\n    <center><iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/JQ8RQru-Y9Y\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></center>\n\n```\n\nEmbedd raw HTML in the end product documentation\n","n":0.209}}},{"i":307,"$":{"0":{"v":"Container","n":1},"1":{"v":"\n<https://docutils.sourceforge.io/docs/ref/rst/directives.html#container>\n\n```rst\n.. container:: custom\n\n   This paragraph might be rendered in a custom way.\n```\n\nParsing the above results in the following pseudo-XML:\n\n```rst\n<container classes=\"custom\">\n    <paragraph>\n        This paragraph might be rendered in a custom way.\n```\n","n":0.183}}},{"i":308,"$":{"0":{"v":"Admonitions","n":1},"1":{"v":"\n<https://docutils.sourceforge.io/docs/ref/rst/directives.html#admonitions>\n\n- Admonitions\n  - `attention`\n  - `caution`\n  - `danger`\n  - `error`\n  - `hint`\n  - `important`\n  - `note`\n  - `tip`\n  - `warning`\n  - and the generic `admonition.`\n\nMost themes style only `note` and `warning` specially.\n\n## custom\n\nYou can style and define your own custom boxes like `warning` or `note` by using the syntax\n\n```rst\n.. admonition:: custom-name-here\n\n  Text here\n\n```\n","n":0.137}}},{"i":309,"$":{"0":{"v":"Comments","n":1},"1":{"v":"\n```rst\n.. Comments begin with two dots and a space.  Anything may\n   follow, except for the syntax of footnotes/citations,\n   hyperlink targets, directives, or substitution definitions.\n```\n\n```rst\n.. This is a comment.\n```\n\n```rst\n..\n   This whole indented block\n   is a comment.\n\n   Still in the comment.\n```\n","n":0.16}}},{"i":310,"$":{"0":{"v":"Block Content","n":0.707}}},{"i":311,"$":{"0":{"v":"Tables","n":1},"1":{"v":"\n## Normal Tables\n\n<https://docutils.sourceforge.io/docs/ref/rst/directives.html#table>\n\n```rst\n.. table:: Truth table for \"not\"\n   :widths: auto\n\n   =====  =====\n     A    not A\n   =====  =====\n   False  True\n   True   False\n   =====  =====\n```\n\n## CSV Tables\n\n<https://docutils.sourceforge.io/docs/ref/rst/directives.html#csv-table-1>\n\n```rst\n.. csv-table:: Frozen Delights!\n   :header: \"Treat\", \"Quantity\", \"Description\"\n   :widths: 15, 10, 30\n\n   \"Albatross\", 2.99, \"On a stick!\"\n   \"Crunchy Frog\", 1.49, \"If we took the bones out, it wouldn't be\n   crunchy, now would it?\"\n   \"Gannet Ripple\", 1.99, \"On a stick!\"\n```\n\n## List Tables\n\n<https://docutils.sourceforge.io/docs/ref/rst/directives.html#list-table>\n\n```rst\n.. list-table:: Frozen Delights!\n   :widths: 15 10 30\n   :header-rows: 1\n\n   * - Treat\n     - Quantity\n     - Description\n   * - Albatross\n     - 2.99\n     - On a stick!\n   * - Crunchy Frog\n     - 1.49\n     - If we took the bones out, it wouldn't be\n       crunchy, now would it?\n   * - Gannet Ripple\n     - 1.99\n     - On a stick!\n```\n","n":0.091}}},{"i":312,"$":{"0":{"v":"Quote","n":1},"1":{"v":"\n## quote\n\n```rst\nnormal paragraph text\n\n    indented text is a quote\n\nnormal paragraph again\n```\n","n":0.302}}},{"i":313,"$":{"0":{"v":"Lists","n":1},"1":{"v":"\n## Lists\n\n### Unordered List\n\n```rst\n* first\n* second\n* third\n```\n\n### Ordered List\n\n```rst\n1. first\n2. second\n3. third\n```\n\n### Dynamic Ordered List\n\n```rst\n# first\n# second\n\n    # nested lists\n    # must be separated from parent list\n    # by blank lines\n\n# third\n```\n","n":0.177}}},{"i":314,"$":{"0":{"v":"Line Block","n":0.707},"1":{"v":"\n## Line Block\n\n```rst\n| These lines are\n| broken exactly like in\n| the source file.\n```\n","n":0.277}}},{"i":315,"$":{"0":{"v":"Doctest Block","n":0.707},"1":{"v":"\n## Doctest Blocks\n\n> Doctest blocks (ref) are interactive Python sessions cut-and-pasted into docstrings. They do not require the literal blocks syntax. The doctest block must end with a blank line and should not end with an unused prompt:\n\n```rst\n>>> 1 + 1\n2\n```a\n","n":0.156}}},{"i":316,"$":{"0":{"v":"Code","n":1},"1":{"v":"\n## Code Block\n\n2 colons after a paragraph and indent next section then that becomes a code Block\n\n```rst\nthis is an ordinary paragraph::\n\n    def say_hi():\n        print('Hello world')\n\nAnd back to regular text\n```\n\nUsing double colons default renders code as python so you can be more explicit with\n\n```rst\nthis is an ordinary paragraph\n\n.. code-block: python\n\n    def say_hi():\n        print('Hello world')\n\nAnd back to regular text\n```\n\nthe `.. code-block: python` is something called a directive\n","n":0.124}}},{"i":317,"$":{"0":{"v":"Read the Docs","n":0.577},"1":{"v":"\n## Public Documentation\n\n<https://www.readthedocs.org>\n\ncan link to publix github projects and when you successfully commit into a branch it will rebuild your docs on the readthedocs site.\n\n## Private Docs\n\nIn [[s.apps.azure.pipelines]] i can build the docs and return an artifact and deploy that artifact somewhere afterwards\n","n":0.152}}},{"i":318,"$":{"0":{"v":"Markdown","n":1},"1":{"v":"\n\nMarkdown is a plain text document format created by John Gruber. The purpose of which was a simplified syntax for text-to-HTML conversion. With the Pandoc tool this opened up doors that allowed markdown to be transpiled to several other document formats. Markdown has become a defacto standard in software development for documentation, as popularized by GitHub.\n\n- Reference:\n\t- [Original Specification](https://daringfireball.net/projects/markdown/)\n","n":0.13}}},{"i":319,"$":{"0":{"v":"Syntax","n":1}}},{"i":320,"$":{"0":{"v":"Lists","n":1}}},{"i":321,"$":{"0":{"v":"Unordered","n":1},"1":{"v":"\n\n## Unordered lists\n\nList items are set with specific characters: `-*+`\n\nThe sublevels are only determined only by indentation either 2 spaces or a tab for indenting the levels\n\n- spaces\n  - two of them\n\n\n- tabs\n  - one tab\n","n":0.167}}},{"i":322,"$":{"0":{"v":"Ordered","n":1},"1":{"v":"\n\n## Ordered Lists\n\nordered lists can be explicitly numbered\n\n```\n1. First item\n2. Second item\n3. Third item\n4. Fourth item\n```\n\nOr they will be automatically numbered based on order and indentation\n\n```\n1. First item\n1. Second item\n1. Third item\n1. Fourth item\n```\n\nbecomes:\n\n```\n1. First item\n2. Second item\n3. Third item\n4. Fourth item\n```\n\nIndentation levels reset the counts for each instance of a sublist\n\n1. First item\n2. Second item\n3. Third item\n   1. Indented item\n   2. Indented item\n4. Fourth item\n\nEven when unordered the relative links still work correctly\n\n```\n1. First item\n1. Second item\n1. Third item\n    1. Indented item\n    1. Indented item\n1. Fourth item\n```\n\nbecomes:\n\n```\n1. First item\n2. Second item\n3. Third item\n    1. Indented item\n    2. Indented item\n4. Fourth item\n```\n","n":0.099}}},{"i":323,"$":{"0":{"v":"Links","n":1},"1":{"v":"\n\n## Syntax\n\nMarkdown links are created with a pair of square brackets and the URL in the parens: `[Bryans Website](https://www.bryanjenks.dev)`\n\nExplicit links without alternatively displayed text you can paste them directly or within angle brackets:\n\n`https://www.bryanjenks.dev`\n\nor\n\n`<https://www.bryanjenks.dev>`\n\nLinks can also link to markdown headings in the same document like a table of contents: spaced must be replaced with dashes but have to begin with a hash:\n\n`[Headings](#Syntax)`\n\n[go to test](#test)\n\nLink text can also be subject to [[Markdown Font Formatting|s.m.markdown.syntax.font-formatting]]\n\nsuch as `**[a bold link](https://www.bryanjenks.dev)**`\n\nThese are not [[Markdown Footnotes|s.m.markdown.extended-functionality.footnotes]] however they function somewhat similarly. you link to a specific identifier, word/number with the definition later defined:\n\n`[test][1]`\n\n```\n`[1]: https://www.bryanjenks.dev`\n```\n\nspaces in markdown links need to be represented with `%20` \n","n":0.096}}},{"i":324,"$":{"0":{"v":"HTML Escape Codes","n":0.577},"1":{"v":"\n\nIn HTML often times there are special characters you want use but need to \"escape\" not with a backslash, but with a sequence.\n\nin this example an ampersand: `&` is escaped as `&amp;` and displays as **&**\n","n":0.167}}},{"i":325,"$":{"0":{"v":"Horizontal Rules","n":0.707},"1":{"v":"\n\n## Syntax\n\nin markdown a horizontal rule is created with three dashes\n\n`---`\n\nin html this is normally `<hr>` which is a self closing tag\n\nThese are all examples of valid horizontal rules:\n\n```\n---\n\n***\n\n*****\n\n- - -\n\n---------------------------------------\n```\n","n":0.18}}},{"i":326,"$":{"0":{"v":"Headings","n":1},"1":{"v":"\n\n## Traditional\n\n| Markdown               | HTML                       |\n| :--------------------- | :------------------------- |\n| # Heading level 1      | `<h1>Heading level 1</h1>` |\n| ==============         | `<h1>Heading level 1</h1>` |\n| ## Heading level 2     | `<h2>Heading level 2</h2>` |\n| --------------         | `<h2>Heading level 2</h2>` |\n| ### Heading level 3    | `<h3>Heading level 3</h3>` |\n| #### Heading level 4   | `<h4>Heading level 4</h4>` |\n| ##### Heading level 5  | `<h5>Heading level 5</h5>` |\n| ###### Heading level 6 | `<h6>Heading level 6</h6>` |\n","n":0.115}}},{"i":327,"$":{"0":{"v":"Font Formatting","n":0.707},"1":{"v":"\n\n| Markdown              | HTML                                                       |\n| --------------------- | ---------------------------------------------------------- |\n| `**BOLD**`            | `<b>BOLD</b> or <strong>BOLD</strong>`                     |\n| `__BOLD__`            | `<b>BOLD</b> or <strong>BOLD</strong>`                     |\n| `*Italic*`            | `<i>Italic</i> or <em>Italic</em>`                         |\n| `_Italic_`            | `<i>Italic</i> or <em>Italic</em>`                         |\n| `__*Bold & Italic*__` | `This text is <strong><em>really important</em></strong>.` |\n| `***Bold & Italic***` | `This text is <strong><em>really important</em></strong>.` |\n| \\``code`\\`            | `<code>code</code>`                                        |\n| `~~Strike Through~~`  | `<del>Strike Through</del>`                                |\n| `^super^`             | `<sup>super</sup>`                                         |\n| `~sub~`               | `<sub>sub</sub>`                                           |\n| Underline             | `<u>underline</u>`                                         |\n| `==highlight==`       | `<mark>highlight</mark>`                                   |\n\nStrike through is an extended specification feature\n\nsuper/sub script is an extended specification feature\n\nBut they<sup>WORK!</sup>when using inline<sub>HTML</sub> just like <u>underline</u> and <del>strike through</del>\n\n---\n\n- Reference:\n  - [Strike Through tag has changed a lot](https://www.w3schools.com/tags/tag_strike.asp)\n\n","n":0.096}}},{"i":328,"$":{"0":{"v":"Code Formatting","n":0.707},"1":{"v":"\n\n## Syntax\n\nIn Markdown inline code can be formatted with backticks \\`code\\`\n\n`code`\n\nand multi line code can be done with fenced code areas\n\n````\n```\nMulti\nline\ncode\n```\n````\n\nwhen you want to display code inline is one back tick\n\n`` `incline` ``\n\nwhen you want to show the backticks in formatted code its 2 backticks\n\n``` `` some `code` in line with backticks`` ```\n\nwhen you want to display a code fenced block including back ticks you sandwich the 3 backtick code fence inside of a 4 backtick fence:\n\n`````\n````\n```\ncode fence\n```\n````\n`````\n\nand to keep showing more levels of backtick sandwiches just keep increasing the amount of backticks, the code for the above image is:\n\n![alt](assets/images/Pasted_image_20201207031806.png)\n\n## RMarkdown\n\nin rmarkdown you can have r code executed inline with the following syntax:\n\n```\n`r mean(5,10)`\n```\n\nIn Rmarkdown the fenced code chunks have a slightly different syntax to allow for control options and meta-processing options:\n\n````\n```r{ control_option}\nx <- 7\n```\n````\n","n":0.086}}},{"i":329,"$":{"0":{"v":"Block Quotes","n":0.707},"1":{"v":"\n\n## Syntax\n\nThe block quote is created with the `>` syntax\n\n```\n> a quote\n```\n\n> a quote\n\nFor nested levels of block quotes you utilize multiple levels of angle brackets `>>`\n\n```\n> Another quote\n>> with levels\n>>> they can go far\n> \n>> They can come back\n> \n> and here's the end\n```\n\n> Another quote\n>\n> > with levels\n> >\n> > > they can go far\n>\n> > They can come back\n>\n> and here's the end\n\nThere can also be additional elements contained within thought there may be issues with line breaks between paragraphs in the quotes so you can toss in a quick `<br>` to break the line\n\n```\n> #### test\n> \"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\"\n> <br>\n> - line item\n> - another line\n> <br>\n> \n> \"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\"\n```\n\n> #### test\n>\n> \"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\"\n> <br>\n>\n> - line item\n> - another line\n>   <br>\n>\n> \"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\"\n","n":0.05}}},{"i":330,"$":{"0":{"v":"Obsidian Functionality","n":0.707}}},{"i":331,"$":{"0":{"v":"Wiki Links","n":0.707},"1":{"v":"\n\n- Internal Links\n  - `[[Internal Link]]`: links to a file named `Internal Link`\n    - `[[Internal Link|Hello]]`: Changes display text of the link to `Hello`\n  - `[[Internal Link#Welcome]]`: Links to an H1 heading in `Internal Link` that says `Welcome`\n    - `[[Internal Link#Welcome|Hello]]`: Changes display text of the link to `Hello`\n  - `[[Internal Link#^5e6366]]`: Links to a block in the `Internal Link` document\n    - `[[Internal Link#^5e6366|Hello]]`: Changes display text of the link to `Hello`\n- Transcluded (embedded Links)\n  - `![[Internal Link]]`: Transcludes a file named `Internal Link`\n  - `![[Internal Link#Welcome]]`: Transcludes content under the H1 heading in `Internal Link` that says `Welcome`\n  - `![[Internal Link#^5e6366]]`: Transcludes a block in the `Internal Link` document\n- Image Links\n  - `![[Internal Link.png)`: Inserts an image named `Internal Link`\n    - `[![[Internal Link.png)](https://www.bryanjenks.dev)`: Make an image have a hyperlink\n","n":0.088}}},{"i":332,"$":{"0":{"v":"Lint","n":1},"1":{"v":"\n\n- [Repo](https://github.com/DavidAnson/markdownlint#optionsconfig)\n  - [x] [List of Rules/Aliases](https://github.com/DavidAnson/markdownlint#rules--aliases) \n  - [x] [configuration](https://github.com/DavidAnson/markdownlint#configuration)\n  - [x] [sample config file here](https://github.com/github/super-linter/blob/master/TEMPLATES/.markdown-lint.yml) \n","n":0.236}}},{"i":333,"$":{"0":{"v":"Images","n":1},"1":{"v":"\n\nImages in markdown hijack the [[s.m.markdown.syntax.links]] syntax in markdown and prepend a `!` before the link to the image file:\n\n`![Alt Text](image.png)`\n\nif you wanted to link images you wrap the above syntax with another normal link syntax:\n\n`[![Alt Text](image.png)](Image Link)`\n","n":0.162}}},{"i":334,"$":{"0":{"v":"Extended Functionality","n":0.707}}},{"i":335,"$":{"0":{"v":"Task Lists","n":0.707},"1":{"v":"\nUsing the [[Markdown Lists|s.m.markdown.syntax.lists]] feature, tasks are just an additional syntax on top of the list syntax\n\n## Syntax\n\n```\n- an uncompleted task\n- [x] a completed task\n\t- an indented uncompleted task\n\t- [x] an indented completed task\n```\n\nIn some processors completing the parent task to children tasks causes formatting such as strike through on sub items of the completed parent:\n\n- an `uncompleted` task\n- [x] a completed task\n  - THIS IS UNCOMPLETED BUT IT'S PARENT IS COMPLETED\n  - [x] an indented completed task\n\n---\n\n- Related:\n  - [[Markdown Definition Lists|s.m.markdown.extended-functionality.definition-lists]]\n","n":0.11}}},{"i":336,"$":{"0":{"v":"Tables","n":1},"1":{"v":"\nüíªÔ∏è/Markdown\npublish: true\naliases:\n\n- null\n  cssclass: null\n  created: 2021-12-31 1946\n  updated: 2022-01-01 2151\n\n---\n\n---\n\nIn markdown the tables are denoted with pipe characters `|` \n\nThere is a minimum of 3 rows for a table\n\n1. header names\n2. separator\n3. data row\n\n| Syntax    | Description |\n| --------- | ----------- |\n| Header    | Title       |\n| Paragraph | Text        |\n\ncode:\n\n```\n| Syntax    | Description |\n| --------- | ----------- |\n| Header    | Title       |\n| Paragraph | Text        |\n```\n\n---\n\nThe separator row has some options\n\n`|:---|`: Align content of this column **Left**\n\n```\n| Syntax    | Description |\n|:--------- |:----------- |\n| Header    | Title       |\n| Paragraph | Text        |\n```\n\n| Syntax    | Description |\n| :-------- | :---------- |\n| Header    | Title       |\n| Paragraph | Text        |\n\n---\n\n`|---:|`: Align content of this column **Right**\n\n```\n|    Syntax | Description |\n| ---------:| -----------:|\n|    Header |       Title |\n| Paragraph |        Text |\n```\n\n|    Syntax | Description |\n| --------: | ----------: |\n|    Header |       Title |\n| Paragraph |        Text |\n\n---\n\n`|:---:|`: Align content of this column **Center**\n\n```\n|  Syntax   | Description |\n|:---------:|:-----------:|\n|  Header   |    Title    |\n| Paragraph |    Text     |\n```\n\n|   Syntax  | Description |\n| :-------: | :---------: |\n|   Header  |    Title    |\n| Paragraph |     Text    |\n\nRendering may differ. See 3rd party plugin for Advanced Tables for easy management of markdown tables\n\nContent within the table can contain:\n\n- [[Markdown Font Formatting|s.m.markdown.syntax.font-formatting]]\n- [[Markdown Images|s.m.markdown.images]]\n- [[Markdown Links|s.m.markdown.syntax.links]]\n\n---\n\n- ## Tags:\n- ## Reference:\n- ## Related:\n\n","n":0.069}}},{"i":337,"$":{"0":{"v":"Mermaid Diagrams","n":0.707}}},{"i":338,"$":{"0":{"v":"Syntax","n":1},"1":{"v":"\n\n## Syntax\n\nMermaid is one of those [[JavaScript|javascript]] library additions that can simply hijack the code fence syntax to add new functionality like diagrams.\n\n````\n```mermaid\n<CODE HERE>\n```\n````\n","n":0.204}}},{"i":339,"$":{"0":{"v":"Resources","n":1},"1":{"v":"\n\n### Resources\n\n[mermaid live editor](https://mermaid-js.github.io/mermaid-live-editor/#/edit/eyJjb2RlIjoiZ3JhcGggVERcbiAgQVtDaHJpc3RtYXNdIC0tPnxHZXQgbW9uZXl8IEIoR28gc2hvcHBpbmcpXG4gIEIgLS0-IEN7TGV0IG1lIHRoaW5rfVxuICBDIC0tPnxPbmV8IERbTGFwdG9wXVxuICBDIC0tPnxUd298IEVbaVBob25lXVxuICBDIC0tPnxUaHJlZXwgRltmYTpmYS1jYXIgQ2FyXVxuXHRcdCIsIm1lcm1haWQiOnsidGhlbWUiOiJkZWZhdWx0In19)\n","n":0.5}}},{"i":340,"$":{"0":{"v":"Diagram Types","n":0.707}}},{"i":341,"$":{"0":{"v":"State","n":1},"1":{"v":"\n\n### State Diagram\n\n````\n```mermaid\nstateDiagram-v2\n    [*] --> Still\n    Still --> [*]\n    Still --> Moving\n    Moving --> Still\n    Moving --> Crash\n    Crash --> [*]\n```\n````\n\n<div class=\"mermaid\">\n  stateDiagram-v2\n    [*] --> Still\n    Still --> [*]\n    Still --> Moving\n    Moving --> Still\n    Moving --> Crash\n    Crash --> [*]\n</div>\n\n[mermaid live editor](https://mermaid-js.github.io/mermaid-live-editor/#/edit/eyJjb2RlIjoic3RhdGVEaWFncmFtLXYyXG4gICAgWypdIC0tPiBTdGlsbFxuICAgIFN0aWxsIC0tPiBbKl1cbiAgICBTdGlsbCAtLT4gTW92aW5nXG4gICAgTW92aW5nIC0tPiBTdGlsbFxuICAgIE1vdmluZyAtLT4gQ3Jhc2hcbiAgICBDcmFzaCAtLT4gWypdIiwibWVybWFpZCI6eyJ0aGVtZSI6ImRlZmF1bHQifSwidXBkYXRlRWRpdG9yIjpmYWxzZX0)\n","n":0.152}}},{"i":342,"$":{"0":{"v":"Sequence","n":1},"1":{"v":"\n\n### Sequence Diagram\n\n````\n```mermaid\nsequenceDiagram\n    Alice->>+John: Hello John, how are you?\n    Alice->>+John: John, can you hear me?\n    John-->>-Alice: Hi Alice, I can hear you!\n    John-->>-Alice: I feel great!\n```\n````\n\n<div class=\"mermaid\">\n  sequenceDiagram\n    Alice->>+John: Hello John, how are you?\n    Alice->>+John: John, can you hear me?\n    John-->>-Alice: Hi Alice, I can hear you!\n    John-->>-Alice: I feel great!\n</div>\n\n[mermaid live editor](https://mermaid-js.github.io/mermaid-live-editor/#/edit/eyJjb2RlIjoic2VxdWVuY2VEaWFncmFtXG4gICAgQWxpY2UtPj4rSm9objogSGVsbG8gSm9obiwgaG93IGFyZSB5b3U_XG4gICAgQWxpY2UtPj4rSm9objogSm9obiwgY2FuIHlvdSBoZWFyIG1lP1xuICAgIEpvaG4tLT4-LUFsaWNlOiBIaSBBbGljZSwgSSBjYW4gaGVhciB5b3UhXG4gICAgSm9obi0tPj4tQWxpY2U6IEkgZmVlbCBncmVhdCEiLCJtZXJtYWlkIjp7InRoZW1lIjoiZGVmYXVsdCJ9LCJ1cGRhdGVFZGl0b3IiOmZhbHNlfQ)\n","n":0.137}}},{"i":343,"$":{"0":{"v":"Pie","n":1},"1":{"v":"\n\n### Pie Chart\n\n````\n```mermaid\npie\n    title Key elements in Product X\n    \"Calcium\" : 42.96\n    \"Potassium\" : 50.05\n    \"Magnesium\" : 10.01\n    \"Iron\" :  5\n```\n````\n\n<div class=\"mermaid\">\n  pie\n    title Key elements in Product X\n    \"Calcium\" : 42.96\n    \"Potassium\" : 50.05\n    \"Magnesium\" : 10.01\n    \"Iron\" :  5\n</div>\n","n":0.156}}},{"i":344,"$":{"0":{"v":"Journey","n":1},"1":{"v":"\n\n### Journey Diagram\n\n````\n```mermaid\n%%{init: {'theme': 'base', 'themeVariables': { 'primaryColor': '#ff0000'}}}%%\njourney \n\ttitle My working day\n\t\n    section Go to work\n      Make tea: 5: Me\n      Go upstairs: 3: Me\n      Do work: 1: Me, Cat\n    \n\tsection Go home\n      Go downstairs: 5: Me\n      Sit down: 5: Me\n```\n````\n\n<div class=\"mermaid\">\n  %%{init: {'theme': 'base', 'themeVariables': { 'primaryColor': '#ff0000'}}}%%\njourney \n\ttitle My working day\n\t\n    section Go to work\n      Make tea: 5: Me\n      Go upstairs: 3: Me\n      Do work: 1: Me, Cat\n    \n\tsection Go home\n      Go downstairs: 5: Me\n      Sit down: 5: Me\n</div>\n","n":0.111}}},{"i":345,"$":{"0":{"v":"Git Graph","n":0.707},"1":{"v":"\n\n### Git Graph\n\n````\n```mermaid\ngitGraph:\noptions\n{\n    \"nodeSpacing\": 150,\n    \"nodeRadius\": 10\n}\nend\ncommit\nbranch newbranch\ncheckout newbranch\ncommit\ncommit\ncheckout master\ncommit\ncommit\nmerge newbranch\n```\n````\n\n<div class=\"mermaid\">\n  gitGraph:\noptions\n{\n    \"nodeSpacing\": 150,\n    \"nodeRadius\": 10\n}\nend\ncommit\nbranch newbranch\ncheckout newbranch\ncommit\ncommit\ncheckout master\ncommit\ncommit\nmerge newbranch\n</div>\n","n":0.218}}},{"i":346,"$":{"0":{"v":"Gantt","n":1},"1":{"v":"\n\n### Gantt Chart\n\n````\n```mermaid\ngantt\n    dateFormat  YYYY-MM-DD\n    title       Adding GANTT diagram functionality to mermaid\n    excludes    weekends\n    %% (`excludes` accepts specific dates in YYYY-MM-DD format, days of the week (\"sunday\") or \"weekends\", but not the word \"weekdays\".)\n\n    section A section\n\t\tCompleted task            :done,    des1, 2014-01-06,2014-01-08\n\t\tActive task               :active,  des2, 2014-01-09, 3d\n\t\tFuture task               :         des3, after des2, 5d\n\t\tFuture task2              :         des4, after des3, 5d\n\n    section Critical tasks\n\t\tCompleted task in the critical line :crit, done, 2014-01-06,24h\n\t\tImplement parser and jison          :crit, done, after des1, 2d\n\t\tCreate tests for parser             :crit, active, 3d\n\t\tFuture task in critical line        :crit, 5d\n\t\tCreate tests for renderer           :2d\n\t\tAdd to mermaid                      :1d\n\n    section Documentation\n\t\tDescribe gantt syntax               :active, a1, after des1, 3d\n\t\tAdd gantt diagram to demo page      :after a1  , 20h\n\t\tAdd another diagram to demo page    :doc1, after a1  , 48h\n\n    section Last section\n\t\tDescribe gantt syntax               :after doc1, 3d\n\t\tAdd gantt diagram to demo page      :20h\n\t\tAdd another diagram to demo page    :48h\n```\n````\n\n<div class=\"mermaid\">\ngantt\n    dateFormat  YYYY-MM-DD\n    title       Adding GANTT diagram functionality to mermaid\n    excludes    weekends\n    %% (`excludes` accepts specific dates in YYYY-MM-DD format, days of the week (\"sunday\") or \"weekends\", but not the word \"weekdays\".)\n\n    section A section\n\t\tCompleted task            :done,    des1, 2014-01-06,2014-01-08\n\t\tActive task               :active,  des2, 2014-01-09, 3d\n\t\tFuture task               :         des3, after des2, 5d\n\t\tFuture task2              :         des4, after des3, 5d\n\n    section Critical tasks\n\t\tCompleted task in the critical line :crit, done, 2014-01-06,24h\n\t\tImplement parser and jison          :crit, done, after des1, 2d\n\t\tCreate tests for parser             :crit, active, 3d\n\t\tFuture task in critical line        :crit, 5d\n\t\tCreate tests for renderer           :2d\n\t\tAdd to mermaid                      :1d\n\n    section Documentation\n\t\tDescribe gantt syntax               :active, a1, after des1, 3d\n\t\tAdd gantt diagram to demo page      :after a1  , 20h\n\t\tAdd another diagram to demo page    :doc1, after a1  , 48h\n\n    section Last section\n\t\tDescribe gantt syntax               :after doc1, 3d\n\t\tAdd gantt diagram to demo page      :20h\n\t\tAdd another diagram to demo page    :48h\n</div>\n\n[mermaid live editor](https://mermaid-js.github.io/mermaid-live-editor/#/edit/eyJjb2RlIjoiZ2FudHRcbiAgICB0aXRsZSBBIEdhbnR0IERpYWdyYW1cbiAgICBkYXRlRm9ybWF0ICBZWVlZLU1NLUREXG4gICAgc2VjdGlvbiBTZWN0aW9uXG4gICAgQSB0YXNrICAgICAgICAgICA6YTEsIDIwMTQtMDEtMDEsIDMwZFxuICAgIEFub3RoZXIgdGFzayAgICAgOmFmdGVyIGExICAsIDIwZFxuICAgIHNlY3Rpb24gQW5vdGhlclxuICAgIFRhc2sgaW4gc2VjICAgICAgOjIwMTQtMDEtMTIgICwgMTJkXG4gICAgYW5vdGhlciB0YXNrICAgICAgOiAyNGRcbiAgICAgICAgICAgICIsIm1lcm1haWQiOnsidGhlbWUiOiJkZWZhdWx0In0sInVwZGF0ZUVkaXRvciI6ZmFsc2V9)\n","n":0.059}}},{"i":347,"$":{"0":{"v":"Flowchart","n":1},"1":{"v":"\n\n### FlowChart\n\n````\n```mermaid\ngraph LR\n\t%%==============%%\n\t%% Declarations %%\n\t%%==============%%\n\t\tA[text]\n\t\tB[text]\t\n\t\tC[text]\n\t%%=========%%\n\t%% Linking %%\n\t%%=========%%\n\t%% comment\n\tA --> B & C\n\t\n\t%% subgraph\n\t%% end\nclass A,B,C internal-link;\nstyle A fill:#EBDBB2,stroke:#EEE,stroke-width:4px,color:#FFF\n```\n````\n\n<div class=\"mermaid\">\n  graph LR\n\t%%==============%%\n\t%% Declarations %%\n\t%%==============%%\n\t\tA[text]\n\t\tB[text]\t\n\t\tC[text]\n\t%%=========%%\n\t%% Linking %%\n\t%%=========%%\n\t%% comment\n\tA --> B & C\n\t\n\t%% subgraph\n\t%% end\nclass A,B,C internal-link;\nstyle A fill:#EBDBB2,stroke:#EEE,stroke-width:4px,color:#FFF\n</div>\n\n[mermaid live editor](https://mermaid-js.github.io/mermaid-live-editor/#/edit/eyJjb2RlIjoiZ3JhcGggVERcbiAgQVtDaHJpc3RtYXNdIC0tPnxHZXQgbW9uZXl8IEIoR28gc2hvcHBpbmcpXG4gIEIgLS0-IEN7TGV0IG1lIHRoaW5rfVxuICBDIC0tPnxPbmV8IERbTGFwdG9wXVxuICBDIC0tPnxUd298IEVbaVBob25lXVxuICBDIC0tPnxUaHJlZXwgRltmYTpmYS1jYXIgQ2FyXVxuXHRcdCIsIm1lcm1haWQiOnsidGhlbWUiOiJkZWZhdWx0In19)\n","n":0.162}}},{"i":348,"$":{"0":{"v":"Entity Relationship","n":0.707},"1":{"v":"\n\n### ER Diagram\n\n````\n```mermaid\nerDiagram\n          CUSTOMER }|..|{ DELIVERY-ADDRESS : has\n          CUSTOMER ||--o{ ORDER : places\n          CUSTOMER ||--o{ INVOICE : \"liable for\"\n          DELIVERY-ADDRESS ||--o{ ORDER : receives\n          INVOICE ||--|{ ORDER : covers\n          ORDER ||--|{ ORDER-ITEM : includes\n          PRODUCT-CATEGORY ||--|{ PRODUCT : contains\n          PRODUCT ||--o{ ORDER-ITEM : \"ordered in\"\n```\n````\n\n<div class=\"mermaid\">\n  erDiagram\n          CUSTOMER }|..|{ DELIVERY-ADDRESS : has\n          CUSTOMER ||--o{ ORDER : places\n          CUSTOMER ||--o{ INVOICE : \"liable for\"\n          DELIVERY-ADDRESS ||--o{ ORDER : receives\n          INVOICE ||--|{ ORDER : covers\n          ORDER ||--|{ ORDER-ITEM : includes\n          PRODUCT-CATEGORY ||--|{ PRODUCT : contains\n          PRODUCT ||--o{ ORDER-ITEM : \"ordered in\"\n</div>\n\n[mermaid live editor](https://mermaid-js.github.io/mermaid-live-editor/#/edit/eyJjb2RlIjoiZXJEaWFncmFtXG4gICAgICAgICAgQ1VTVE9NRVIgfXwuLnx7IERFTElWRVJZLUFERFJFU1MgOiBoYXNcbiAgICAgICAgICBDVVNUT01FUiB8fC0tb3sgT1JERVIgOiBwbGFjZXNcbiAgICAgICAgICBDVVNUT01FUiB8fC0tb3sgSU5WT0lDRSA6IFwibGlhYmxlIGZvclwiXG4gICAgICAgICAgREVMSVZFUlktQUREUkVTUyB8fC0tb3sgT1JERVIgOiByZWNlaXZlc1xuICAgICAgICAgIElOVk9JQ0UgfHwtLXx7IE9SREVSIDogY292ZXJzXG4gICAgICAgICAgT1JERVIgfHwtLXx7IE9SREVSLUlURU0gOiBpbmNsdWRlc1xuICAgICAgICAgIFBST0RVQ1QtQ0FURUdPUlkgfHwtLXx7IFBST0RVQ1QgOiBjb250YWluc1xuICAgICAgICAgIFBST0RVQ1QgfHwtLW97IE9SREVSLUlURU0gOiBcIm9yZGVyZWQgaW5cIiIsIm1lcm1haWQiOnsidGhlbWUiOiJkZWZhdWx0In0sInVwZGF0ZUVkaXRvciI6ZmFsc2V9)\n","n":0.105}}},{"i":349,"$":{"0":{"v":"Class","n":1},"1":{"v":"\n\n### Class Diagrams\n\n````\n```mermaid\n%% https://mermaid-js.github.io/mermaid/#/classDiagram\n classDiagram\n      Animal <|-- Duck\n      Animal <|-- Fish\n      Animal <|-- Zebra\n      Animal : +int age\n      Animal : +String gender\n      Animal: +isMammal()\n      Animal: +mate()\n      class Duck{\n          +String beakColor\n          +swim()\n          +quack()\n      }\n      class Fish{\n          -int sizeInFeet\n          -canEat()\n      }\n      class Zebra{\n          +bool is_wild\n          +run()\n      }\n```\n````\n\n<div class=\"mermaid\">\n  %% https://mermaid-js.github.io/mermaid/#/classDiagram\n classDiagram\n      Animal <|-- Duck\n      Animal <|-- Fish\n      Animal <|-- Zebra\n      Animal : +int age\n      Animal : +String gender\n      Animal: +isMammal()\n      Animal: +mate()\n      class Duck{\n          +String beakColor\n          +swim()\n          +quack()\n      }\n      class Fish{\n          -int sizeInFeet\n          -canEat()\n      }\n      class Zebra{\n          +bool is_wild\n          +run()\n      }\n</div>\n\n[mermaid live editor](https://mermaid-js.github.io/mermaid-live-editor/#/edit/eyJjb2RlIjoiY2xhc3NEaWFncmFtXG4gICAgQW5pbWFsIDx8LS0gRHVja1xuICAgIEFuaW1hbCA8fC0tIEZpc2hcbiAgICBBbmltYWwgPHwtLSBaZWJyYVxuICAgIEFuaW1hbCA6ICtpbnQgYWdlXG4gICAgQW5pbWFsIDogK1N0cmluZyBnZW5kZXJcbiAgICBBbmltYWw6ICtpc01hbW1hbCgpXG4gICAgQW5pbWFsOiArbWF0ZSgpXG4gICAgY2xhc3MgRHVja3tcbiAgICAgICtTdHJpbmcgYmVha0NvbG9yXG4gICAgICArc3dpbSgpXG4gICAgICArcXVhY2soKVxuICAgIH1cbiAgICBjbGFzcyBGaXNoe1xuICAgICAgLWludCBzaXplSW5GZWV0XG4gICAgICAtY2FuRWF0KClcbiAgICB9XG4gICAgY2xhc3MgWmVicmF7XG4gICAgICArYm9vbCBpc193aWxkXG4gICAgICArcnVuKClcbiAgICB9XG4gICAgICAgICAgICAiLCJtZXJtYWlkIjp7InRoZW1lIjoiZGVmYXVsdCJ9LCJ1cGRhdGVFZGl0b3IiOmZhbHNlfQ)\n","n":0.105}}},{"i":350,"$":{"0":{"v":"Mathjax","n":1},"1":{"v":"\n\n## Syntax\n\nIn markdown you can actually use [[LaTeX|s.m.latex]] Math equations. This is through a [[s.l.javascript]] Library called [MathJaX](https://www.mathjax.org/). \n\nMathjax is also similar to eqn in [[Groff|s.m.groff]].\n\nThe basic syntax of LaTeX Math is \n\n`$inline equation$`\n\n`$\\sum\\frac{\\pi}{\\sigma}$`\n\n$\\sum\\frac{\\pi}{\\sigma}$\n\n`$$Centered Equations$$`\n\n`$$\\sum\\frac{\\pi}{\\sigma}$$`\n\n$\\sum\\frac{\\pi}{\\sigma}$\n\nas for the specifics of what equations you're putting into them that's up to you\n","n":0.143}}},{"i":351,"$":{"0":{"v":"Heading Ids","n":0.707},"1":{"v":"\n\n## Syntax\n\nSome Markdown processors support custom heading id's determined by this syntax:\n\n```\n### My Great Heading {#custom-id}\n```\n\nThe HTML looks like this:\n\n```\n<h3 id=\"custom-id\">My Great Heading</h3>\n```\n\n## rmarkdown\n\nIn Rmarkdown next to the HTML headings you can input additional metadata within braces like this flexdashboard code:\n\n```md\n## Page 1 {data-navmenu=\"Menu A\" .hidden}\n```\n","n":0.147}}},{"i":352,"$":{"0":{"v":"Footnotes","n":1},"1":{"v":"\n\nFootnotes are declared with a single pair of square brackets prepended with a carat: `^[]`\n\nFootnotes are like similar to [[Markdown Links|s.m.markdown.syntax.links]] with the separation of declaration and definition.\n\nif i declare a footnote`[^1]`\n\nThen the definition can be defined later:\n\n`[^1]: the definition`\n\nWhat is really helpful is an all in one solution with inline footnotes`^[Through leaving the footnote text in the brackets like this]`\n\nif you have a large block in the footnote definition you can indent sub-levels to make it all part of the same content block:\n\n```\nblock[^1]\n\n[^1]: this is a text link\n\tindented block\n```\n\nblock[^1]\n\n[^1]: this is a text link\n    indented block\n\nIn obsidian inside of inline footnotes you can also insert the wiki links in the footnotes themselves`^[[[Like this]]]`\t\n","n":0.094}}},{"i":353,"$":{"0":{"v":"Fenced Code Syntax Highlighting","n":0.5},"1":{"v":"\n\nfor fenced code blocks:\n\n````\n```\nconst string = \"hello there\"\n```\n````\n\nwe can denote the language of the block and have the contents highlighted based on the language:\n\n````\n```javascript\nconst string = \"hello there\"\n```\n````\n","n":0.189}}},{"i":354,"$":{"0":{"v":"Definition Lists","n":0.707},"1":{"v":"\n\n## Syntax\n\n```\nFirst Term\n: definition\n\nSecond Term\n: This is one definition of the second term.\n: This is another definition of the second term.\n```\n\nFirst Term\n: definition\n\nSecond Term\n: This is one definition of the second term.\n: This is another definition of the second term.\n\nThe HTML looks like this:\n\n```\n<dl>\n  <dt>First Term</dt>\n  <dd>This is the definition of the first term.</dd>\n  <dt>Second Term</dt>\n  <dd>This is one definition of the second term. </dd>\n  <dd>This is another definition of the second term.</dd>\n</dl>\n```\n\nIt renders like this:\n\n<dl>\n  <dt>First Term</dt>\n  <dd>This is the definition of the first term.</dd>\n  <dt>Second Term</dt>\n  <dd>This is one definition of the second term. </dd>\n  <dd>This is another definition of the second term.</dd>\n</dl>\n","n":0.098}}},{"i":355,"$":{"0":{"v":"Emojis","n":1},"1":{"v":"\n\n## Syntax\n\nin some specifications you can use emojis with double colons `:wave:` this is a common method of inserting emojis such as on Discord, or github markdown.\n\nWith UTF support you can now just directly insert emojis onto documents as well: üëãüèªÔ∏è\n\nin [[cli.cmd.vim.plugins.vimwiki]] the double colon syntax is actually used to indicate tags\n","n":0.139}}},{"i":356,"$":{"0":{"v":"Latex","n":1},"1":{"v":"\n\n> LaTeX is a high-quality typesetting system; it includes features designed for the production of technical and scientific documentation. LaTeX is the de facto standard for the communication and publication of scientific documents.\n\n## Documentation\n\n- [Appendix](http://mirrors.ibiblio.org/CTAN/macros/latex/contrib/appendix/appendix.pdf)\n- [Latex Cheat Sheet](https://wch.github.io/latexsheet/latexsheet.pdf)\n- [Excel Tabular Data To LaTeX Tabular](https://tableconvert.com/?output=latex)\n- [LaTeX Wiki Book](https://en.wikibooks.org/wiki/LaTeX)\n- [LaTeX Short Intro](https://tobi.oetiker.ch/lshort/lshort.pdf)\n- [LaTeX Lecture notes in vim](https://castel.dev/post/lecture-notes-1/)\n","n":0.135}}},{"i":357,"$":{"0":{"v":"Tricks","n":1},"1":{"v":"\n\n- `\\part`\n- `\\chapter`\n- `\\section`\n- `\\subsection`\n- `\\subsubsection`\n- `\\paragraph`\n- `\\subparagraph`\n\nStarred versions do not show up in the table of contents\n","n":0.236}}},{"i":358,"$":{"0":{"v":"Modular Documents","n":0.707},"1":{"v":"\n\n`\\input{<included file>}`\n\nThis command take an entire `.tex` file with no preamble or meta content just text, sections, etc and drops it in this location like a header file in C.\n\nuseful for modularizing your documentation\n","n":0.171}}},{"i":359,"$":{"0":{"v":"Draft Watermark","n":0.707},"1":{"v":"\n\n<https://tex.stackexchange.com/questions/118939/add-watermark-that-overlays-the-images>\n\nFigures overlay the watermark:\n\n```latex\n\\documentclass{article}\n\\usepackage[printwatermark]{xwatermark}\n\\usepackage{xcolor}\n\\usepackage{graphicx}\n\\usepackage{lipsum}\n\n\\newwatermark[allpages,color=red!50,angle=45,scale=3,xpos=0,ypos=0]{DRAFT}\n\n\\begin{document}\n\n\\lipsum[1-2]\n\\begin{figure}[!ht]\n\\centering\n\\includegraphics[width=3cm]{example-image-a}\n\\end{figure}\n\\lipsum[1-2]\n\\end{document}\n```\n\nFigures covered by watermark:\n\n```latex\n\\documentclass{article}\n\\usepackage[printwatermark]{xwatermark}\n\\usepackage{xcolor}\n\\usepackage{graphicx}\n\\usepackage{lipsum}\n\n\\newwatermark*[allpages,color=red!50,angle=45,scale=3,xpos=0,ypos=0]{DRAFT}\n\n\\begin{document}\n\n\\lipsum[1-2]\n\\begin{figure}[!ht]\n\\centering\n\\includegraphics[width=3cm]{example-image-a}\n\\end{figure}\n\\lipsum[1-2]\n\\end{document}\n```\n","n":0.378}}},{"i":360,"$":{"0":{"v":"Preamble","n":1}}},{"i":361,"$":{"0":{"v":"Title","n":1},"1":{"v":"\n\n## Title\n\n`\\title{My {\\LaTeX} R\\'esum\\'e}`\n\nyour title is defined in the title command but this is outsize of your document body, inside the document body you actually call:\n\n`\\maketitle`\n\nto render your title onto the document\n\nyou can customize the title with the [[LaTeX Titling|s.m.latex.pkg.titling]] package and the renewcommand command like so:\n\n```latex\n\\renewcommand{\\maketitle}{\n\\begin{center}\n{\\huge\\bfseries\n\\theauthor}\n\\vspace{.25em}\n\nmy email --- https://www.bryanjenks.xyz\n\n\\end{center}\n} % first new arg from titling package\n```\n\n## Documentation\n\n- [titlesec](https://mirrors.concertpass.com/tex-archive/macros/latex/contrib/titlesec/titlesec.pdf)\n","n":0.13}}},{"i":362,"$":{"0":{"v":"Custom Commands","n":0.707},"1":{"v":"\n\nTo create a new command that provides new behavior or functionality use the `\\newcommand` command\n\n```latex\n\\newcommand{<your commands name>}[<number of arguments it takes>]\n{what your command does}\n```\n\n```latex\n\\newcommand{\\bryan}[3]{\\textit{#1}, \\textbf{#2}, \\underline{#3}}\n```\n","n":0.196}}},{"i":363,"$":{"0":{"v":"Author","n":1},"1":{"v":"\n\nTo pass in your author credentials you can use `\\author{Bryan Jenks}` and to use it as another argument in another command you can also use `\\theauthor`\n\n```latex\n% Overwrite existing command '\\maktitle'\n\\renewcommand{\\maketitle}{\n\\begin{center}\n{\\huge\\bfseries\n*\\theauthor*}\n\\vspace{.25em}\n\nmy email --- https://www.bryanjenks.xyz\n\n\\end{center}\n} % first new arg from titling package\n```\n","n":0.158}}},{"i":364,"$":{"0":{"v":"Abstract","n":1},"1":{"v":"\n\nTo make an abstract for the paper you can use the abstract environment just after the `\\maketitle` command:\n\n```latex\n\\maketitle\n\\begin{abstract}\n    <Your Content>\n\\end{abstract}\n```\n","n":0.224}}},{"i":365,"$":{"0":{"v":"Pkg","n":1}}},{"i":366,"$":{"0":{"v":"Todo Notes","n":0.707},"1":{"v":"\n\n`Todonotes` is a way to allow visual note items in your compiled LaTeX document The notes can be customized for different colors and themes to correspond to different topics/categories and can be placed in-line, in the margins, and even be used as placeholders for figures that have not yet been added. \n\n```latex\n%  Documentation\n\\todo{this is my todo note}\n\\todo[inline]{here is an inline todo note}\n\\todo[background=red]{a note with a different background color}\n```\n\n## Documentation\n\n- [texdoc documentation](http://texdoc.net/texmf-dist/doc/latex/todonotes/todonotes.pdf)\n","n":0.119}}},{"i":367,"$":{"0":{"v":"Titling","n":1},"1":{"v":"\n\n`\\renewcommand`\n\n[Documentation](http://www.texdoc.net/texmf-dist/doc/latex/titling/titling.pdf)\n","n":1}}},{"i":368,"$":{"0":{"v":"Tikz","n":1},"1":{"v":"\n\n## Flow Chart\n\n```latex\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%\n% Welcome to Overleaf --- just edit your LaTeX on the left,\n% and we'll compile it for you on the right. If you open the\n% 'Share' menu, you can invite other users to edit at the same\n% time. See www.overleaf.com/learn for more info. Enjoy!\n%\n% Note: you can export the pdf to see the result at full\n% resolution.\n%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n% Decision tree\n% Author: Stefan Kottwitz\n% https://www.packtpub.om/hardware-and-creative/latex-cookbook\n\\documentclass[border=10pt]{standalone}\n%%%<\n\\usepackage{verbatim}\n%%%>\n\\begin{comment}\n:Title: Decision tree\n:Tags: Trees;Cookbook\n:Author: Stefan Kottwitz\n:Slug: decision-tree\n\nA horizontal tree, growing to the right.\nI created a basic style for tree nodes, and\nderived styles for specific kinds of nodes.\n\\end{comment}\n\n\\usepackage{tikz}\n\\tikzset{\n  treenode/.style = {shape=rectangle, rounded corners,\n                     draw, align=center,\n                     top color=white, bottom color=blue!20},\n  root/.style     = {treenode, font=\\Large, bottom color=red!30},\n  env/.style      = {treenode, font=\\ttfamily\\normalsize},\n  dummy/.style    = {circle,draw}\n}\n\\begin{document}\n\\begin{tikzpicture}\n  [\n    grow                    = right,\n    sibling distance        = 6em,\n    level distance          = 10em,\n    edge from parent/.style = {draw, -latex},\n    every node/.style       = {font=\\footnotesize},\n    sloped\n  ]\n  \\node [root] {Formula}\n    child { node [env] {equation}\n      edge from parent node [below] {single-line?} }\n    child { node [dummy] {}\n      child { node [dummy] {}\n        child { node [env] {align\\\\flalign}\n          edge from parent node [below] {at relation sign?} }\n        child { node [env] {alignat}\n          edge from parent node [above] {at several}\n                           node [below] {places?} }\n        child { node [env] {gather}\n                edge from parent node [above] {centered?} }\n        edge from parent node [below] {aligned?} }\n      child { node [env] {multline}\n              edge from parent node [above, align=center]\n                {first left,\\\\centered,}\n              node [below] {last right}}\n              edge from parent node [above] {multi-line?} };\n\\end{tikzpicture}\n\\end{document}\n```\n\n```latex\n\\usepackage{tikz}\n\\usetikzlibrary{shapes.geometric, arrows}\n\n\n    \\tikzstyle{startstop} = [rectangle, rounded corners, minimum width=3cm, minimum height=1cm, text centered, draw=black, fill=red!30]\n    \\tikzstyle{io} = [trapezium, trapezium left angle=70, trapezium right angle=110, minimum width=3cm, minimum height=1cm, text centered, draw=black, fill=blue!30]\n    \\tikzstyle{process} = [rectangle, text width=3cm, minimum width=3cm, minimum height=1cm, text centered, draw=black, fill=orange!30]\n    \\tikzstyle{decision} = [diamond, minimum width=3cm, minimum height=1cm, text centered, draw=black, fill=green!30]\n    \\tikzstyle{arrow} = [thick,->,>=stealth]\n\n\n    \\begin{tikzpicture}[node distance=2cm]\n        \\node (start) [startstop] {start};\n        \\node (in1) [io, below of=start] {Input};\n        \\node (pro1) [process, below of=in1] {Process 1};\n        \\node (dec1) [decision, below of=pro1, yshift=-0.5cm] {Decision 1};\n        \\node (pro2a) [process, below of=dec1, yshift=-0.5cm] {Process 2a};\n        \\node (pro2b) [process, right of=dec1, xshift=2cm] {Process 2b};\n        \\node (out1) [io, below of=pro2a] {Output};\n        \\node (stop) [startstop, below of=out1] {See Step \\textbf{\\ref{test}}};\n\n        \\draw [arrow] (start) -- (in1);\n        \\draw [arrow] (in1) -- (pro1);\n        \\draw [arrow] (pro1) -- (dec1);\n        \\draw [arrow] (dec1) -- node[anchor=east] {yes} (pro2a);\n        \\draw [arrow] (dec1) -- node[anchor=south] {no} (pro2b);\n        \\draw [arrow] (pro2b) |- (pro1);\n        \\draw [arrow] (pro2a) -- (out1);\n        \\draw [arrow] (out1) -- (stop);\n    \\end{tikzpicture}\n```\n\n## Documentation\n\n- [Tikz Documentations](http://texdoc.net/texmf-dist/doc/generic/pgf/pgfmanual.pdf)\n- [Short Intro To Tikz](https://cremeronline.com/LaTeX/minimaltikz.pdf)\n","n":0.05}}},{"i":369,"$":{"0":{"v":"Graphicx","n":1},"1":{"v":"\n\n- [Documentation](http://texdoc.net/texmf-dist/doc/latex/graphics/graphicx.pdf)\n\nhe `\\includegraphics{}` command is used to add images to a document and can take several optional parameters in square brackets as well an example of this function is:\n\n`\\includegraphics[width=3in,height=5in,keepaspectratio,scale=0.5]{<path to image file.png>}`\n\n## Params\n\n_width_: Obvious\n\n```\n- `width=\\textwidth`: it will fit in within the span of a line of text or `width=0.5\\textwidth` to fit it in 50% of the space of the width of your text span\n```\n\n_height_: Obvious\n_keepaspectratio_: uses width and height as maximum value args and make image keep its aspect ration\n_scale_: basically like saying the image should be a percentage of its original size so using a decimal like `scale=0.5` for 50% scale\n_angle_: this will rotate the image and uses a 360 degree number for the angle of rotation\n\nand to take an image and center it we can add it to the center environment\n\n`\\begin{center}`\n    `\\includegraphics[width=3in]{<path to image file.png>}`\n`\\end{center}`\n\nto center a figure you can use this example:\n\n```latex\n\\begin{figure}\n    \\begin{center}\n        \\includegraphics[width=0.3\\textwidth]{../Pictures/archLinuxLogo.png}\n    \\end{center}\n\\end{figure}\n```\n\nFigures are more flexible and they come with added bonuses like captions and automatic numbering which you can add or mess with this way\n\n```latex\n\\begin{figure}\n    \\begin{center}\n        \\includegraphics[width=0.3\\textwidth]{../Pictures/archLinuxLogo.png}\n        \\caption{this is my caption}\n    \\end{center}\n\\end{figure}\n```\n\nto center a figure you can also use the following command `\\centering` with the figure code block\n\n```latex\n\\begin{figure}\n    \\centering\n        \\includegraphics[width=0.3\\textwidth]{../Pictures/archLinuxLogo.png}\n        \\caption{this is my caption}\n\\end{figure}\n```\n\nto keep a figure inline where you write it in you need to pass an optional arg to the figure command `[h]`\n\n```latex\n\\begin{figure}[h]\n    \\centering\n        \\includegraphics[width=0.3\\textwidth]{../Pictures/archLinuxLogo.png}\n        \\caption{this is my caption}\n\\end{figure}\n```\n\nthe optional arg `[t]` will put the figure at the top of the page\n\n`\\begin{figure}[t]`\n\nand `[b]` will put it at the bottom\n\nand `[p]` will put it on a page of its own\n","n":0.062}}},{"i":370,"$":{"0":{"v":"Geometry","n":1},"1":{"v":"\n\n- [Documentation](http://www.texdoc.net/texmf-dist/doc/latex/geometry/geometry.pdf)\n","n":0.707}}},{"i":371,"$":{"0":{"v":"Fancy Header","n":0.707},"1":{"v":"\n\n- [Documentation](http://texdoc.net/texmf-dist/doc/latex/fancyhdr/fancyhdr.pdf)\n","n":0.707}}},{"i":372,"$":{"0":{"v":"Biblatex","n":1},"1":{"v":"\n\n## BibLaTeX\n\nUse the package via:\n\n`\\usepackage[backend=biber, style=authoryear-icomp]{biblatex}`\n`\\addbibresource{<file path to .bib file>}`\n\nTo print our your bibliography:\n\n`\\printbibliography`\n\n`\\textcite{<ref>}` will add a reference like _Mould [1]_ but 'Mould' would be the name of the ref you passed in and it has that number but adding `style=authoryear-icomp` to the biblatex package optional arg will change it to _Mould (2003)_ with no brackets and numbers\n\n`\\parencite{<ref>}` is what I typically like and use and appears like _(Mould 2003)_\n\n## Documentation\n\n- [OverleafOnBiber](https://www.overleaf.com/learn/latex/Bibliography_management_with_bibtex)\n\n---\n\n- address\n- annote\n- author\n  - booktitle\n  - chapter\n  - crossref\n  - edition\n  - editor\n  - institution\n  - journal\n  - key\n  - month\n  - note\n  - number\n  - organization\n  - pages\n- publisher\n  - school\n  - series\n- title\n  - type\n  - volume\n- year\n- URL\n- ISBN\n  - ISSN\n  - LCCN\n  - abstract\n  - keywords\n  - price\n  - copyright\n  - language\n  - contents\n\n### Notes\n\nThis package is used for references and bibliographies\n\n#### Reference guide\n\n##### Standard entry types\n\n- **article**\n  - Article from a magazine or journal\n- **booklet**\n  - A work that is printed but have no publisher or sponsoring institution\n- **conference**\n  - An article in a conference proceedings\n- **inbook**\n  - A part of a book (section, chapter and so on)\n- **incollection**\n  - A part of a book having its own title\n- **inproceedings**\n  - An article in a conference proceedings\n- **manual**\n  - Technical documentation\n- **masterthesis**\n  - A Master's thesis\n- **misc**\n  - Something that doesn't fit in any other type\n- **phdthesis**\n  - A PhD thesis\n- **proceedings**\n  - The same as conference\n- **techreport**\n  - Report published by an institution\n- **unpublished**\n  - Document not formally published, with author and title\n","n":0.063}}},{"i":373,"$":{"0":{"v":"Beamer","n":1},"1":{"v":"\n\n## Documentation\n\n- [theme gallery](http://deic.uab.es/~iblanes/beamer_gallery/index_by_theme.html)\n","n":0.5}}},{"i":374,"$":{"0":{"v":"Math","n":1},"1":{"v":"\n\n- Reference:\n  - [[assets/pdfs/undergradmath.pdf]]\n- Related:\n  - <https://castel.dev/post/lecture-notes-1/>\n  - <https://arachnoid.com/latex/>\n","n":0.333}}},{"i":375,"$":{"0":{"v":"Syntax","n":1}}},{"i":376,"$":{"0":{"v":"Super Sub Script","n":0.577},"1":{"v":"\n\n### Super and sub script\n\nSuper uses a carat `^`\n\nSub-script uses an underscore `_`\n","n":0.277}}},{"i":377,"$":{"0":{"v":"Optional Arguments","n":0.707},"1":{"v":"\n\n### Optional Arguments\n\nSome commands take optional arguments in square brackets `[ ]`\n","n":0.289}}},{"i":378,"$":{"0":{"v":"Insertable Symbols","n":0.707}}},{"i":379,"$":{"0":{"v":"Spacin","n":1},"1":{"v":"\n\n#### Spacing\n\n| **LaTeX**    | _Code_         |\n| :----------- | :------------- |\n| $x\\,y$       | `$x\\,y$`       |\n| $x\\:y$       | `$x\\:y$`       |\n| $x\\;y$       | `$x\\;y$`       |\n| $x \\quad y$  | `$x \\quad y$`  |\n| $x \\qquad y$ | `$x \\qquad y$` |\n| $x\\!y$       | `$x\\!y$`       |\n\nSometimes you may want some extra space between elements and a space wont work and you need something like `\\,`: 50285a\n\n`\\Sigma \\Delta` == $\\Sigma \\Delta$\n\nv.s.\n\n`\\Sigma\\,\\Delta` == $\\Sigma\\,\\Delta$\n\nThere is now a slight space between the two\n","n":0.115}}},{"i":380,"$":{"0":{"v":"Greek","n":1},"1":{"v":"\n\n#### Greek\n\n[[Greek Letters In Statistics|greek-letters-in-statistics]]\n\n`$\\Sigma\\,\\Delta$$` == $\\Sigma\\,\\Delta$\n","n":0.378}}},{"i":381,"$":{"0":{"v":"Fences","n":1},"1":{"v":"\n\n#### Fences\n","n":0.707}}},{"i":382,"$":{"0":{"v":"Dots","n":1},"1":{"v":"\n\n#### Dots\n\nVertical dots == _$\\vdots$_\nCentered dots == _$\\cdots$_\nLow dots == _$\\ldots$_\ndiagonal dots == _$\\ddots$_\n\nusing the spacer comma `\\,` [[s.m.latex.math#^50285a]]\n_$\\{2,3,\\,\\ldots\\}$_\n","n":0.229}}},{"i":383,"$":{"0":{"v":"Calligraphic Letter","n":0.707},"1":{"v":"\n\n#### Calligraphic letter\n\n`\\mathcal{LETTER}` == $\\mathcal{LETTER}$\n","n":0.447}}},{"i":384,"$":{"0":{"v":"Arrays and Matrices","n":0.577},"1":{"v":"\n\n#### Arrays and Matrices\n\n$$\n\\Bigg\\{\\,\\begin{array}{rcl}\n\t0&6&6 \\\\\n\t0&6&6 \\\\\n\t0&6&6 \\\\\n\\end{array}\\,\\Bigg\\}\n$$\n","n":0.378}}},{"i":385,"$":{"0":{"v":"Grouping Items","n":0.707},"1":{"v":"\n\n### Grouping Items\n\nusing the braces `{ }` we can group items together\n\nV.S.\n\n`x_ij` = $x_ij$\n\nWhere the `J` is back at the normal level not the subscript level\n","n":0.196}}},{"i":386,"$":{"0":{"v":"Escaped Operators and Characters","n":0.5},"1":{"v":"\n\n### Escaped Operators and Characters\n\nthings like `\\pi` yield $\\pi$ they have no braces `{ }` or brackets `[ ]` and instead are just themselves. This means they can be inserted into other commands and the only limitation might be a space after the escaped sequence so that it doesnt turn into something like `\\pix` when you wanted $\\pi  x$\n\n#### Equations are like sentences\n\nThese sequences all together read like a sentence with symbols and syntax determining positioning and what is rendered in a logical format\n\n```latex\n$$\\sum_{j=0}^7j^2$$\n```\n\n$\\sum_{j=5}^7j^2$\n\nReads like \"_$\\sum$_, then below it add _$J=5$_, raise that whole combo to the power of _$7$_ then adjacent to that place _$J^2$_.\n","n":0.097}}},{"i":387,"$":{"0":{"v":"Common Constructs","n":0.707},"1":{"v":"\n\n### Common Constructs\n\n- `x^2` = $x^2$ d77d52\n- `x_{ij}` = $x_{ij}$ 8a61f1\n- `\\sqrt{4}` = $\\sqrt{4}$\n- `\\sqrt[n]{4}` = $\\sqrt[n]{4}$ cc4666\n- `\\frac{2}{3}` = $\\frac{2}{3}$\n","n":0.218}}},{"i":388,"$":{"0":{"v":"Math Environment","n":0.707},"1":{"v":"\n\n## Math Environment\n\nto use LaTeX math you need to create a math environment:\n\n```\n$MATH GOES HERE$\n```\n\nWhen rendered this will look like: $MATH GOES HERE$\n\nThis is an in-line equation\n\nFor a multi-line equation that also centers itself you use double dollars\n\n```\n$$MATH GOES HERE$$\n```\n\nRendered it will center: $MATH GOES HERE$\n","n":0.147}}},{"i":389,"$":{"0":{"v":"Document","n":1},"1":{"v":"\n\n`\\tableofcontents`: displays the table of contents, good to use after maketitle and abstract\n","n":0.277}}},{"i":390,"$":{"0":{"v":"Lists","n":1},"1":{"v":"\n\n`\\begin{enumerate}` this is a numbered ordered list\n    \\\\&lt;your items in here>\n`\\end{enumerate}`\n\n`\\begin{itemize}` this is an unordered bullet list\n    \\\\&lt;your items in here>\n`\\end{itemize}`\n\n`\\item` \\\\&lt;your item text>\n","n":0.204}}},{"i":391,"$":{"0":{"v":"Labels and References","n":0.577},"1":{"v":"\n\n`\\label{}` This will add an invisible label to any item like so:\n\n```latex\n\\section{Lists\\label{List}}\n\\item Butter \\label{butter}\n```\n\n`\\ref{}` This is the number of the referenced label if its the 3rd item then it will display only a '3'\n`(\\ref{})` The same as above but wrapped in parens\n","n":0.154}}},{"i":392,"$":{"0":{"v":"Figures","n":1},"1":{"v":"\n\n```latex\n\\\\begin{wrapfigure}{\\<orientation `r` or `l`\\>}{\\<space to take up like 3in\\>}\n\t\\<your figure here\\>\n\\\\end{wrapfigure}\n```\n\nto wrap a figure with text use the following code:\n\n```latex\n\\begin{wrapfigure}\n    <your figure here>\n\\end{wrapfigure}\n```\n","n":0.209}}},{"i":393,"$":{"0":{"v":"Document Title","n":0.707}}},{"i":394,"$":{"0":{"v":"Title Spacing","n":0.707},"1":{"v":"\n\n## Title Spacing\n\n```latex\n\\\\titlespacing*{command}\n{left}\n{before-sep}\n{after-sep}[right-sep]\n```\n\n","n":0.577}}},{"i":395,"$":{"0":{"v":"Example","n":1},"1":{"v":"\n\n### Examples\n\n```latex\n\\titlespacing{\\subsubsection}\n{0em} % Left Margin\n{.25em} % Line Spacing\n{0em} % Right Margin\n```\n","n":0.302}}},{"i":396,"$":{"0":{"v":"Title Format","n":0.707},"1":{"v":"\n\n## Title Format\n\n```latex\n\\\\titleformat{\\<command\\>}[\\<shape\\>]\n{\\<format\\>}\n{\\<label\\>}\n{\\<sep\\>} <!-- The Only required Arg -->\n{\\<before-codee\\>}[\\<after-code\\>]\n```\n","n":0.333}}},{"i":397,"$":{"0":{"v":"Example","n":1},"1":{"v":"\n\n### Examples\n\n```latex\n\\titleformat{\\section}[frame]\n{\\huge}\n{}\n{.25em} % The only required argument\n{\\filcenter\\bfseries\\lowercase}% Horizontal line [\\titlerule] % Optional param\n\n% SubSection Formatting\n\\titleformat{\\subsection}\n{\\bfseries\\Large}\n{\\hspace{-.25in}$\\bullet$}\n{.3em}\n{}\n\n% SubSubSection Formatting\n\\titleformat{\\subsubsection}[runin] % Optional param\n{\\bfseries}\n{}\n{0em}\n{}[---]\n\n\\titleformat{\\section}[frame]\n{\\normalfont}\n{\\filright\\footnotesize\\enspace SECTION \\thesection\\enspace}\n{8pt}\n{\\Large\\bfseries\\filcenter}\n```\n","n":0.213}}},{"i":398,"$":{"0":{"v":"Document Class","n":0.707}}},{"i":399,"$":{"0":{"v":"Report","n":1},"1":{"v":"\n\nThis is meant for long form documentation unlike the [[LaTeX Article Document Class|latex-article-document-class]] document class and an example using a chapter argument is below:\n\n```latex\n\\documentclass{report}\n\\begin{document}\n\\chapter{this is intersting}\nin this chapter i hope to...\n\\section{section 1}\nthis is the first section where stuff happens\n\\section{section 2}\n\n\\subsection{sub section 1}\nOi hello world\n\\subsection{sub section 2}\n\n\\subsubsection{sub sub section 1}\ntis but a test\n\\section{this is section 3}\n\n\\section{this is section 4}\nending thoughts...\n\\end{document}\n```\n","n":0.13}}},{"i":400,"$":{"0":{"v":"Article","n":1},"1":{"v":"\n\nDoes not work with `\\chapter{}` as it is meant for short form writing, for long form use the [[LaTeX Report Document Class|latex-report-document-class]] Document class\n","n":0.204}}},{"i":401,"$":{"0":{"v":"Beamer","n":1}}},{"i":402,"$":{"0":{"v":"Sections","n":1},"1":{"v":"\n\n## Sections\n\nin beamer the `\\section{<section name>}` command will appear at the top of the slide deck slides and it also like a hyper link and they are evenly distributed spatially too.\n","n":0.18}}},{"i":403,"$":{"0":{"v":"Pauses","n":1},"1":{"v":"\n\n## Pauses\n\nFor your slides to pause on say a list populating on the screen use pause to control it\n\n```latex\n\t\\begin{itemize}\n\t\t\\item frame\\pause\n\t\t\\item beamer themes\\pause\n\t\t\\item pauses and slides\\pause\n\t\t\\item sections\\pause\n\t\t\\item images\n\t\t\\item columns\n\t\\end{itemize}\n```\n","n":0.189}}},{"i":404,"$":{"0":{"v":"Frame Title","n":0.707},"1":{"v":"\n\n## Frame Title\n\nInside the frame environment you run this command to give your slide a title\n\n```latex\n\\begin{frame}\n    \\frametitle{Roadmap}\n\\end{frame}\n```\n","n":0.243}}},{"i":405,"$":{"0":{"v":"HTML","n":1}}},{"i":406,"$":{"0":{"v":"Tools","n":1},"1":{"v":"\n\n## Tools\n\n- [Compress your images](https://compressor.io/)\n- [Free Vector Image Creation](https://www.drawkit.io/)\n","n":0.333}}},{"i":407,"$":{"0":{"v":"Tags","n":1},"1":{"v":"\n\n## Tags\n\n\n\n","n":0.707}}},{"i":408,"$":{"0":{"v":"Top Level","n":0.707},"1":{"v":"\n\n- <https://youtu.be/iX_QyjdctsQ?list=WL&t=391> meta og tags \n    - resource with this: <https://www.metatags.io>\n","n":0.302}}},{"i":409,"$":{"0":{"v":"Source Tag","n":0.707}}},{"i":410,"$":{"0":{"v":"Body","n":1}}},{"i":411,"$":{"0":{"v":"Template Tag","n":0.707},"1":{"v":"\n\n## What is it and what is it good for\n\nAdding lots of little tags can get very cumbersome and error prone in JavaScript, so the less HTML tags we need to write in JavaScript the better.\n\nOne way to do this is with the Template tag. The content does not render by default but is accessible by JavaScript for modification, Duplication, and more.\n\n```html\n<ul>\n  <li>\n    <span>Item 1: </span>\n    <span>Content 1</span>\n  </li>\n  <li>\n    <span>Item 2: </span>\n    <span>Content 2</span>\n  </li>\n</ul>\n```\n\nWant to easily add another `<li>` element to the list? Instead of using JavaScript to write the HTML code we can just use the Template:\n\n```html\n<ul>\n  <li>\n    <span>Item 1: </span>\n    <span>Content 1</span>\n  </li>\n  <li>\n    <span>Item 2: </span>\n    <span>Content 2</span>\n  </li>\n</ul>\n\n<template>\n  <li>\n    <span>Item: </span>\n    <span>Content</span>\n  </li>\n</template>\n```\n\n## How to use it\n\nNeed be able to grab the elements so we assign some classes and id's\n\n```html\n<ul id=\"list\">\n  <li>\n    <span>Item 1: </span>\n    <span>Content 1</span>\n  </li>\n  <li>\n    <span>Item 2: </span>\n    <span>Content 2</span>\n  </li>\n</ul>\n<button id=\"add-item\">Add Item</button>\n\n<template id=\"list-item-template\">\n  <li>\n    <span class=\"title\">Item: </span>\n    <span class=\"content\">Content</span>\n  </li>\n</template>\n```\n\nNow to access it\n\n```javascript\nconst template = document.getElementById('list-item-template')\nconst list = document.getElementById('list')\nconst button = document.getElementById('add-item')\nlet itemCount = list.children.length\n\nbutton.addEventListener('click', () => {\n  const item = template.content.cloneNode(true)\n  itemCount++\n  item.querySelector('.title').innerText = `Item ${itemCount}: `\n  item.querySelector('.content').innerText = `Content ${itemCount}`\n  list.append(item)\n})\n```\n\n---\n\n- Reference:\n  - <https://blog.webdevsimplified.com/2020-06/template-tag/>\n","n":0.071}}},{"i":412,"$":{"0":{"v":"Progress Tag","n":0.707},"1":{"v":"\n\n## Completion Percentage\n\n```html\n<label for=\"course\">Course completion:</label>\n<progress id=\"course\" value=\"67\" max=\"100\"></progress> 67%\n```\n\n---\n\n<label for=\"course\">Course completion:</label>\n<progress id=\"course\" value=\"67\" max=\"100\"></progress> 67%\n\n---\n\n- Reference:\n  - <https://javascript.plainenglish.io/9-cool-things-you-can-do-with-just-html-3f926455a3c2>\n","n":0.236}}},{"i":413,"$":{"0":{"v":"Media","n":1}}},{"i":414,"$":{"0":{"v":"Video Tag","n":0.707}}},{"i":415,"$":{"0":{"v":"Picture Tag","n":0.707},"1":{"v":"\n\nThe most common use of the [[HTML Picture Tag|‚ü®picture‚ü©]] element will be for art direction in responsive designs. Instead of having one image that is scaled up or down based on the viewport width, multiple images can be designed to more nicely fill the browser viewport.\n\nThe [[HTML Picture Tag|‚ü®picture‚ü©]] element contains two tags: one or more [[HTML Source Tag|‚ü®source‚ü©]] tags and one [[HTML Img Tag|‚ü®img‚ü©]] tag.\n\nThe browser will look for the first [[HTML Source Tag|‚ü®source‚ü©]] element where the media query matches the current viewport width, and then it will display the proper image (specified in the `srcset` attribute). The [[HTML Img Tag|‚ü®img‚ü©]] element is required as the last child of the [[HTML Picture Tag|‚ü®picture‚ü©]] element, as a fallback option if none of the source tags matches.\n\nTip: The [[HTML Picture Tag|‚ü®picture‚ü©]] element works \"similar\" to [[HTML Video Tag|‚ü®video‚ü©]] and [[HTML Audio Tag|‚ü®audio‚ü©]]. You set up different sources, and the first source that fits the preferences is the one being used.\n\n```html\n<picture>\n  <source media=\"(min-width:650px)\" srcset=\"img_pink_flowers.jpg\">\n  <source media=\"(min-width:465px)\" srcset=\"img_white_flower.jpg\">\n  <img src=\"img_orange_flowers.jpg\" alt=\"Flowers\" style=\"width:auto;\">\n</picture>\n```\n\n<picture>\n  <source media=\"(min-width:650px)\" srcset=\"img_pink_flowers.jpg\">\n  <source media=\"(min-width:465px)\" srcset=\"img_white_flower.jpg\">\n  <img src=\"img_orange_flowers.jpg\" alt=\"Flowers\" style=\"width:auto;\">\n</picture>\n\n- Reference:\n  - <https://www.w3schools.com/TAGS/tag_picture.asp>\n  \n","n":0.074}}},{"i":416,"$":{"0":{"v":"Img Tag","n":0.707}}},{"i":417,"$":{"0":{"v":"Audio Tag","n":0.707}}},{"i":418,"$":{"0":{"v":"Inline","n":1}}},{"i":419,"$":{"0":{"v":"Sub and Sup Tags","n":0.5},"1":{"v":"\n\n```html\n<!-- Sub script -->\n<p>H<sub>2</sub>O</p>\n<!-- Super script -->\n<p>H<sup>2</sup>O</p>\n```\n\n<p>H<sub>2</sub>O</p>\n\n<p>H<sup>2</sup>O</p>\n","n":0.378}}},{"i":420,"$":{"0":{"v":"Span Tag","n":0.707},"1":{"v":"\n\n## Tooltips\n\n```html\n<span title=\"See, this is the tooltip. :)\">Move your mouse over me!</span>\n```\n\n<span title=\"See, this is the tooltip. :)\">Move your mouse over me!</span>\n\n- Reference:\n  - <https://javascript.plainenglish.io/9-cool-things-you-can-do-with-just-html-3f926455a3c2>\n","n":0.2}}},{"i":421,"$":{"0":{"v":"Anchor","n":1},"1":{"v":"\n\n```html\n<a href=\"mailto:bryan@bryanjenks.dev?subject=mailto%20links\">Send Mail</a>\n```\n\n- `mailto:` links have additional properties that can be set in [[s.m.html]] but also with Markdown\n- [Resource Link](https://css-tricks.com/snippets/html/mailto-links/)\n- in markdown, to generate an email addressed to someone, with defined subjects line, body, and other addressees you use these pieces of text as part of the links remembering to escape spaces with `$20`:\n    - `?subject=` the subject line of the email. `?subject=My%20Subject`\n    - `?cc=` add carbon copy addressees `?cc=jonny.test@gmail.com`\n    - `?bcc=` blind carbon copy someone `?bcc=jonny.test@gmail.com`\n    - `?body=` your body text remembering to escape spaces with `%20`\n    - `?body=My%20lovely%20email%20body%20message`\n    -  If you only use 1 parameter after the email addressee then that parameter will start with a `?` like `?subject=` every parameter used after that will use a `&` such as `&cc=`, or `&bcc=`, etc.\n","n":0.089}}},{"i":422,"$":{"0":{"v":"Forms","n":1},"1":{"v":"\n\n[form filler chrome ext](https://chrome.google.com/webstore/detail/web-developer-form-filler/gbagmkohmhcjgbepncmehejaljoclpil)\n","n":0.5}}},{"i":423,"$":{"0":{"v":"Button Tag","n":0.707},"1":{"v":"\n\n```html\n<button>Button Text</button>\n```\n\n<button>Button Text</button>\n\nCreates a button that can be styled, have [[JavaScript Event Listeners|javascript-event-listeners#Click event]]s added to it so that when it is clicked actions can occur\n","n":0.196}}},{"i":424,"$":{"0":{"v":"Block","n":1}}},{"i":425,"$":{"0":{"v":"Meter Tag","n":0.707},"1":{"v":"\n\n## Ranges and Fractional Values\n\n```html\n<label for=\"disk_g\">Disk usage G:</label>\n<meter id=\"disk_g\" value=\"2\" min=\"0\" max=\"10\">2 out of 10</meter>\n<br>\n<label for=\"disk_h\">Disk usage H:</label>\n<meter id=\"disk_h\" value=\"0.7\">70%</meter>\n```\n\n<label for=\"disk_g\">Disk usage G:</label>\n<meter id=\"disk_g\" value=\"2\" min=\"0\" max=\"10\">2 out of 10</meter>\n<br>\n<label for=\"disk_h\">Disk usage H:</label>\n<meter id=\"disk_h\" value=\"0.7\">70%</meter>\n\n---\n\n- Reference:\n  - <https://javascript.plainenglish.io/9-cool-things-you-can-do-with-just-html-3f926455a3c2>\n- Related:\n  - [[Meter vs Progress Tags|s.m.html.meter-vs-progress-tags]]\n\n","n":0.151}}},{"i":426,"$":{"0":{"v":"Label Tag","n":0.707},"1":{"v":"\n\n## Plain Labels\n\n```html\n<label>My Label</label>\n```\n\n<label>My Label</label>\n\n## Lables with tooltips\n\n<label title=\"See, this is the tooltip. :)\">My Label</label>\n","n":0.258}}},{"i":427,"$":{"0":{"v":"Input Tag","n":0.707},"1":{"v":"\n\n## Color Picker\n\n```html\n<label for=\"favcolor\">Select your favorite color:</label>\n<input type=\"color\" id=\"favcolor\" name=\"favcolor\" value=\"#ebdbb2\">\n```\n\n<label for=\"favcolor\">Select your favorite color:</label>\n<input type=\"color\" id=\"favcolor\" name=\"favcolor\" value=\"#ebdbb2\">\n","n":0.229}}},{"i":428,"$":{"0":{"v":"Fieldset Tag","n":0.707},"1":{"v":"\n\n```html\n<fieldset>\n\t<legend>Test legend</legend>\n\t\n\t<div><label>color</label></div>\n\t\t\n\t<input list=\"animals\" name=\"animal\" id=\"animal\">\n\t<datalist id=\"animals\">\n\t\t<option value=\"Cat\">\n\t\t<option value=\"Dog\">\n\t\t<option value=\"Chicken\">\n\t\t<option value=\"Cow\">\n\t\t<option value=\"Pig\">\n\t</datalist>\n\t\t\n\t<br>\n\t\t\n\t<div><label>Animals</label></div>\n\t\t\n\t<input list=\"animals\" name=\"animal\" id=\"animal\">\n\t<datalist id=\"animals\">\n\t\t<option value=\"Cat\">\n\t\t<option value=\"Dog\">\n\t\t<option value=\"Chicken\">\n\t\t<option value=\"Cow\">\n\t\t<option value=\"Pig\">\n\t</datalist>\n</fieldset>\n```\n\n<fieldset>\n\t<legend>Test legend</legend>\n\t\n\t<div><label>color</label></div>\n\t\t\n\t<input list=\"animals\" name=\"animal\" id=\"animal\">\n\t<datalist id=\"animals\">\n\t\t<option value=\"Cat\">\n\t\t<option value=\"Dog\">\n\t\t<option value=\"Chicken\">\n\t\t<option value=\"Cow\">\n\t\t<option value=\"Pig\">\n\t</datalist>\n\t\t\n\t<br>\n\t\t\n\t<div><label>Animals</label></div>\n\t\t\n\t<input list=\"animals\" name=\"animal\" id=\"animal\">\n\t<datalist id=\"animals\">\n\t\t<option value=\"Cat\">\n\t\t<option value=\"Dog\">\n\t\t<option value=\"Chicken\">\n\t\t<option value=\"Cow\">\n\t\t<option value=\"Pig\">\n\t</datalist>\n</fieldset>\n","n":0.16}}},{"i":429,"$":{"0":{"v":"Datalist Tag","n":0.707},"1":{"v":"\n\n## Data List\n\n```html\n<input list=\"animals\" name=\"animal\" id=\"animal\">\n<datalist id=\"animals\">\n    <option value=\"Cat\">\n    <option value=\"Dog\">\n    <option value=\"Chicken\">\n    <option value=\"Cow\">\n    <option value=\"Pig\">\n</datalist>\n\n<!--\nThe <datalist> id attribute (see bold items above) \nmust be equal to the list attribute of the <input>, \nthis is what binds them together.\n-->\n\n```\n\n---\n\nStart typing and it will auto complete\n\n<input list=\"animals\" name=\"animal\" id=\"animal\">\n<datalist id=\"animals\">\n    <option value=\"Cat\">\n    <option value=\"Dog\">\n    <option value=\"Chicken\">\n    <option value=\"Cow\">\n    <option value=\"Pig\">\n</datalist>\n","n":0.129}}},{"i":430,"$":{"0":{"v":"Resources","n":1},"1":{"v":"\n\n## Resources\n\n### Tutorials \n\n- [[s.m.html.emmet-shortcuts-in-vscode]]\n\n### Tools\n\n- [See what runs a website](https://www.WhatRuns.com)\n- [Responsive design simultaneous viewing](https://responsively.app/)\n\n### Chrome Extentions\n\n- [webdeveloper checklist chrome ext](https://chrome.google.com/webstore/detail/web-developer-checklist/iahamcpedabephpcgkeikbclmaljebjp)\n- [Edit This Cookie](https://chrome.google.com/webstore/detail/editthiscookie/fngmhnnpilhplaeedifhccceomclgfbg)\n","n":0.204}}},{"i":431,"$":{"0":{"v":"Meter Vs Progress Tags","n":0.5},"1":{"v":"\n\nMeter Tag vs [[s.m.html.tags.body.progress-tag]]\n\nprogress to mark up the completion rate/degree of progress of an ‚Äúin progress‚Äù task through a progress bar, use progress element.\n\nmeter to represent a gauge use meter element\nYou can think like that: progress = dynamic ; meter = static\n\n---\n\n- Reference:\n  - <https://javascript.plainenglish.io/9-cool-things-you-can-do-with-just-html-3f926455a3c2>\n","n":0.149}}},{"i":432,"$":{"0":{"v":"Emmet Shortcuts in Vscode","n":0.5},"1":{"v":"\n\n<center>\n\t<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/45eWEO0gRHI\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n</center>\n\n- [6:01](https://youtu.be/45eWEO0gRHI?t=361) type name of tag for auto complete\n- To next a parent/child use `parent>child` for divs with classes `.parent-class>.child-class` for a parent with sibling children `.parent-class>.child-class+.child-class` or `.parent-class>.child-class*2`\n- [6:40](https://youtu.be/45eWEO0gRHI?t=400) lorem ipsum text can be indicated with `lorem` and the number of works directly after `lorem20`\n- [7:19](https://youtu.be/45eWEO0gRHI?t=439) groupings `(p>lorem20)*5` since `p>lorem20*5` just puts 5 lorems in a `p` tag\n","n":0.12}}},{"i":433,"$":{"0":{"v":"Groff","n":1}}},{"i":434,"$":{"0":{"v":"Variables","n":1},"1":{"v":"\n\n## Variables\n\nAssigns 3 to variable var\n\n.nr var 3\n\nprints var\n\n\\\\n[var]\n\nincrement var by 4\n\n.nr var +4\n\\\\n[var]\n","n":0.267}}},{"i":435,"$":{"0":{"v":"Udf Macros","n":0.707},"1":{"v":"\n\n## Make Your Own Macros\n\n.de ALL\n.B \"BIU\"\n..\n\nFirst line defines name of macro\nnext is the contents of the macro\nthe double dot ends the macro assignment and now its ready to use\n\nWant to keep your custom macros in a seperate file and source them into a document?\n\nuse the `.so` \\\\&lt;file> method to load them\n","n":0.139}}},{"i":436,"$":{"0":{"v":"Tables","n":1},"1":{"v":"\n\n## tables\n\n```troff\n.TS\noptions ;\nformat .\ntable\n.TE\n\\---\n.TS\nallbox ;\nc c c .\na|a|a\n.TE\n\\---\n.\\\" Make it so all borders show and tab character represented by pipe.\n.\\\" c = center s = skip, l = left align, n = numeral based\n.\\\" Each line of formatting corresponds to the line of data 1st format line first line of data\n\n.TS\nallbox tab(|);\nc s s s\nc s c s\nn c c c.\nTitle\nsub |sub\na |a |a| a\na |a |a| a\nAFGDGHDFH |a |a| a\n.TE\n\\---\n.TS\ntab(|);\nc s s s\nc s |c s\nn c |c c.\nTitle\n_\nsub |sub\n_\na |a |a| a\na |a |a| a\nAFGDGHDFH |a |a| a\n.TE\n```\n","n":0.105}}},{"i":437,"$":{"0":{"v":"Post Script Images","n":0.577},"1":{"v":"\n\n|    Groff cmd    |           LaTeX cmd            | markdown  |  What it is   |\n| :-------------: | :----------------------------: | :-------: | :-----------: |\n| `.PSPIC` \"file\" | `\\includegraphics{`filepath`}` | ![ ] \\( ) | insert images |\n|                 |                                |           |               |\n\n`.PSPIC` - [CLR] options for image alignment/ center default\n\nI option for indent image followed by num and unit\n\n`.PSPIC` - I 1i \"img\" 4i 2i\n\nIndents = indent, Width Height\n\ngrab a screenshot image\n\n`:!screenshot -ws <filename>`\n\nconvert captured image to postscript for import\n\n`:!convert <inputfile> <outputfile.eps>`\n\nCompile to see images\n\nalso script a key to open the preview in external viewer\n","n":0.105}}},{"i":438,"$":{"0":{"v":"Macros","n":1},"1":{"v":"\n\n|     Groff cmd      |     LaTeX cmd      |   markdown   |                         What it is                          |\n| :----------------: | :----------------: | :----------: | :---------------------------------------------------------: |\n|       `.TL`        |     `\\title{}`     |              |                            Title                            |\n|       `.AU`        |    `\\author{}`     |              |                           Author                            |\n|       `.AB`        | `\\begin{abstract}` |              |                       Start Abstract                        |\n|       `.AE`        |  `\\end{abstract}`  |              |                        End Abstract                         |\n|       `.NH`        |    `\\section{}`    |      #       |                     A Numbered section                      |\n|       `.SH`        |    `\\section{}`    |      #       |                   A Non-Numbered heading                    |\n|       `.LP`        |                    |              |                      A Left Paragraph                       |\n|       `.PP`        |   `\\paragraph{}`   |              |                    An Indented Paragraph                    |\n|       `.QP`        |                    |              |        A quoted Paragraph, `.PP` but multiple lines         |\n|     `.B`\"TEXT\"     |    `\\textbf{}`     |    _text_    |                            Bold                             |\n|     `.I`\"TEXT\"     |    `\\textit{}`     |    _text_    |                           Italics                           |\n|       `.QS`        |                    |              |                   Start Quoted text block                   |\n|       `.QE`        |                    |              |                    End Quoted text block                    |\n|       `.IP`        |                    |              | Indent paragraph can add symbol before and make bullet list |\n|       `\\(bu`       |                    |      -       |    Bullet arg after `.IP` to make it a bullet point list    |\n|       `.RS`        |                    |              |             Start indent List `.IP` list items              |\n|       `.RE`        |                    |              |              End indent List `.IP` list items               |\n| `\\f[I]`TEXT`\\f[]`  |    `\\textit{}`     |    _text_    |                 Inline italic font styling                  |\n| `\\f[B]`TEXT`\\f[]`  |    `\\textbf{}`     |    _text_    |                  Inline bold font styling                   |\n| `\\f[CW]`TEXT`\\f[]` |    `\\texttt{}`     |    `text`    |             Inline constant Width font styling              |\n| `\\f[BI]`TEXT`\\f[]` |                    |  **_text_**  |              Inline bold italics font styling               |\n|       `.\\\"`        |        `%`         | <!-- text--> |                          A comment                          |\n|       `.B1`        |                    |              |                     Start a box of text                     |\n|       `.B2`        |                    |              |                     Stop a box of text                      |\n|       `.BX.`       |                    |              |      Make box form fitting to text and no wasted space      |\n|    `.UL` \"TEXT\"    |                    | <u>text</u>  |                       Underlined text                       |\n|   `\\*{super\\*}`    |                    |    ^text^    |                        Super script                         |\n|       `.bp`        |    `\\pagebreak`    |              |                       break the page                        |\n|       `.TS`        | `\\begin{tabular}`  |              |                        Start a table                        |\n|       `.TE`        |  `\\end{tabular}`   |              |                         end a table                         |\n|   `.nr` name val   |                    |              |          assignment `val` to named register `name`          |\n|    `\\\\n[name]`     |                    |              |               print value of register `name`                |\n|     `.ds` name     |                    |              |    Define string, all after 'name' is part of string val    |\n|     `\\*[name]`     |                    |              |                     Print string value                      |\n|                    |                    |              |                                                             |\n","n":0.052}}},{"i":439,"$":{"0":{"v":"CSS","n":1},"1":{"v":"\n\n## Tools\n\n- <https://www.ExtractCSS.com>\n","n":0.577}}},{"i":440,"$":{"0":{"v":"Pre Processors","n":0.707}}},{"i":441,"$":{"0":{"v":"Sass","n":1}}},{"i":442,"$":{"0":{"v":"Language","n":1}}},{"i":443,"$":{"0":{"v":"Vba","n":1},"1":{"v":"\n\n> **V**isual **B**asic For **A**pplications\n\nA horrible language that has no place in production systems.\n\n- Related: [[Excel|s.apps.excel]]\n- [Wise Owl Tutorials](https://www.youtube.com/c/WiseOwlTutorials)\n- [MSDN official Docs](https://docs.microsoft.com/en-us/office/vba/api/overview/excel)\n- [Analyst Cave](https://analystcave.com/excel-vba-tutorial/)\n- [Automate Excel](https://www.automateexcel.com/learn-vba-tutorial/)\n- [Excel Automation](https://www.rondebruin.nl/win/s1/outlook/mail.htm)\n- [Auto Macro](https://www.automateexcel.com/vba-code-generator#shortcuts)\n- [Cpearson](http://www.cpearson.com/Excel/Topic.aspx)\n- Rubber Duck IDE\n  - [Rubber Duck GitHub](https://github.com/rubberduck-vba/Rubberduck/)\n  - [Rubber Duck Website](https://rubberduckvba.com/)\n- [Learn Excel Macro](http://learnexcelmacro.com/wp/download/)\n","n":0.149}}},{"i":444,"$":{"0":{"v":"Rust","n":1},"1":{"v":"\n\n- Setup\n- Resources\n  - [Google's Dependency Management service](https://deps.dev/)\n- Tools\n- Libraries\n- Projects\n- Syntax\n- Data Types & Structs\n- Flow Control\n- Functions\n- Object Oriented Programming\n- File Handling\n- Tips, Tricks, & Hacks\n","n":0.189}}},{"i":445,"$":{"0":{"v":"R","n":1}}},{"i":446,"$":{"0":{"v":"Tools","n":1}}},{"i":447,"$":{"0":{"v":"Rmarkdown","n":1}}},{"i":448,"$":{"0":{"v":"Tips Tricks and Hacks","n":0.5},"1":{"v":"\n\n## How to add indexed areas to your R script:\n\n```r\n# Steps:\n# 1.) Add the hashtag in line to start the comment\n# 2.) Type what you'd like then space\n# 3.) then add 4 dashes \"----\"\n# This will inxes your code area and make it collapsable as well\n# the indexed option appears at the bottom of this window \n\n# PART A ----\nprint(\"Hello World\")\n# PART B ----\n```\n","n":0.125}}},{"i":449,"$":{"0":{"v":"Resources","n":1},"1":{"v":"\n\n- [Ten random useful things in R that you might not know about](https://towardsdatascience.com/ten-random-useful-things-in-r-that-you-might-not-know-about-54b2044a3868)\n- [HexSticker Maker](https://connect.thinkr.fr/hexmake/)\n- [Control HTML Code Folding](https://stackoverflow.com/questions/37755037/how-to-add-code-folding-to-output-chunks-in-rmarkdown-html-documents)\n- [R Seek](https://rseek.org/)\n- [R Graph Gallery](https://www.r-graph-gallery.com/)\n- [knitr Options](https://yihui.org/knitr/options/)\n- [Pimp my Rmd](https://holtzy.github.io/Pimp-my-rmd/)\n","n":0.186}}},{"i":450,"$":{"0":{"v":"Package Development","n":0.707},"1":{"v":"\n\n- [Pkg Dev From Scratch](https://hilaryparker.com/2014/04/29/writing-an-r-package-from-scratch/)\n- [R Pkgs Book](https://r-pkgs.org/index.html)\n","n":0.354}}},{"i":451,"$":{"0":{"v":"Libs","n":1}}},{"i":452,"$":{"0":{"v":"Slidev","n":1},"1":{"v":"\n\n  - [[s.l.r.libs.slidev]] [Website](https://sli.dev/)\n    - Another presentation format for slideshows\n","n":0.316}}},{"i":453,"$":{"0":{"v":"Libraries","n":1}}},{"i":454,"$":{"0":{"v":"Shiny","n":1},"1":{"v":"\n\n- Shiny dashboards consist of 2 main elements the `ui` and the `server` files\n- Shiny dashboards are not great for high user traffic but can still handle mutliple user sessions. Hosting on RStudio is an option but shiny server can be hosted on your own system or containers.\n- A great practice is to store shiny dashboards as R Packages to be distributed for interactive reproducable analysis.\n- Shinydashboard and shinydashboard+ are packages that build off the shiny package base to allow greater aesthetic elements and more functionality with the web app.\n- For unit testing shiny applications there is shinytest\n  and for load testing there is shinyloadtest\n- for making sure shiny apps load quickly you can use `profvis` and other methods to tackle your bigger and slower processes, another is to not load csv data into shiny directly, if loading data like this do your ETL first and save data as feather files, feather is slower to write but faster to read than csv's\n- another would be to implement plot caching if the plots are taking a while to load\n- Great presentations of your shiny apps like a walk along tutorial: [cicerone](https://github.com/JohnCoene/cicerone)\n\n## Documentation\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Wy3TY0gOmJw\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n\n## Code\n\n```r\n########################################\n# A basic example of a shiny dashboard #\n########################################\nlibrary(shiny)\n\n# Define UI for application\nshinyUI(fluidPage(\n# Application title\ntitlePanel(\"Old Faithful Geyser Data\"),\n# Sidebar with input\nsidebarLayout(\n sidebarPanel(\n  sliderInput(\"bins\",\n     \"Number of bins:\",\n     min = 1,\n     max = 50,\n     value = 30\n  )#sliderInput\n ),#sidebarPanel\n # Show a plot of the generated distribution\n mainPanel(\n  plotOutput(\"distPlot\")\n )#mainPanel\n)#sidebarLayout\n))#shinyUI(fluidPage(\n\n# Define server logic required to draw a histogram\nshinyServer(function(input, output) {\n\noutput$distPlot <- renderPlot({\n\n # generate bins based on input$bins from ui.R\n x    <- faithful[, 2]\n bins <- seq(min(x), max(x), length.out = input$bins + 1)\n\n # draw the histogram with the specified number of bins\n hist(x, breaks = bins, col = 'darkgray', border = 'white')\n\n})#renderPlot\n})#shinyServer\n```\n","n":0.058}}},{"i":455,"$":{"0":{"v":"Pins","n":1},"1":{"v":"\n\n- <https://www.youtube.com/embed/dsfEsJCiH-E>\n","n":0.707}}},{"i":456,"$":{"0":{"v":"Packrat","n":1}}},{"i":457,"$":{"0":{"v":"Ggplot2","n":1},"1":{"v":"\n\n```r\n#### engine size / highway MPG ####\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, \n\t\t\t\t\t\t   y = hwy)\n\t\t\t )\nggplot(data = mpg) + #--------------------------------------------------# Play with changing color to size \n  geom_point(mapping = aes(x = displ, #-------------------------------# (discrete variable \"class\" to ordered aesthetic \"Size\" not advised)\n\t\t\t\t\t\t   y = hwy, \n\t\t\t\t\t\t   size = class)\n\t\t\t )\nggplot(data = mpg) + #--------------------------------------------------# Transparancy of the points\n  geom_point(mapping = aes(x = displ, \n\t\t\t\t\t\t   y = hwy, \n\t\t\t\t\t\t   alpha = class)\n\t\t\t )\nggplot(data = mpg) + #--------------------------------------------------# Shape of the points\n  geom_point(mapping = aes(x = displ, \n\t\t\t\t\t\t   y = hwy, \n\t\t\t\t\t\t   shape = class)\n\t\t\t )\nggplot(data = mpg) + #--------------------------------------------------# Add Colors by class and add this to the aesthetic layer\n  geom_point(mapping = aes(x = displ, \n\t\t\t\t\t\t   y = hwy, \n\t\t\t\t\t\t   color = class)\n\t\t\t ) \nggplot(data = mpg) + #--------------------------------------------------# change color of the points\n  geom_point(mapping = aes(x = displ, \n\t\t\t\t\t\t   y = hwy), \n\t\t\t color = \"blue\"\n\t\t\t )\nggplot(data = mpg) + #--------------------------------------------------# change size and color to continious variables and shape to a categorical variable\n  geom_point(mapping = aes(x = displ, \n\t\t\t\t\t\t   y = hwy, \n\t\t\t\t\t\t   color = year, \n\t\t\t\t\t\t   size = cyl, \n\t\t\t\t\t\t   shape = drv)\n\t\t\t )\nggplot(data = mpg) + #--------------------------------------------------# Making the save variable cover multiple fields\n  geom_point(mapping = aes(x = displ, \n\t\t\t\t\t\t   y = hwy, \n\t\t\t\t\t\t   color = cyl, \n\t\t\t\t\t\t   size = cyl, \n\t\t\t\t\t\t   shape = drv)\n\t\t\t )\nggplot(data = mpg) + #--------------------------------------------------# testing the \"stroke\" argument\n  geom_point(mapping = aes(x = displ, \n\t\t\t\t\t\t   y = hwy, \n\t\t\t\t\t\t   color = cyl, \n\t\t\t\t\t\t   size = cyl, \n\t\t\t\t\t\t   shape = drv, \n\t\t\t\t\t\t   stroke = 5)\n\t\t\t )   \nggplot(data = mpg) + #--------------------------------------------------# passing a condition into a aesthetic argument instead of the straight variable\n  geom_point(mapping = aes(x = displ, \n\t\t\t\t\t\t   y = hwy, \n\t\t\t\t\t\t   color = displ < 5, \n\t\t\t\t\t\t   size = cyl, \n\t\t\t\t\t\t   shape = drv, \n\t\t\t\t\t\t   stroke = 5)\n\t\t\t )   \nggplot(data = mpg) + #--------------------------------------------------# Highway MPg / Engine Cylinders\n  geom_point(mapping = aes(x = hwy, \n\t\t\t\t\t\t   y = cyl)\n\t\t\t )\nggplot(data = mpg) + #--------------------------------------------------# Type of car / What \"Wheel Drive\" the car is (F,B,4)\n  geom_point(mapping = aes(x = class, \n\t\t\t\t\t\t   y = drv)\n\t\t\t )\n\n\n#### Facets on descrete variables ####\n\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, \n\t\t\t\t\t\t   y = hwy)\n\t\t\t ) +\n  facet_wrap(~ class, nrow = 2) #-------------------------------------# the tilda \"~\" means a formula not akin to an equation\n\nggplot(data = mpg) + #--------------------------------------------------# testing facet grid\n  geom_point(mapping = aes(x = displ,\n\t\t\t\t\t\t   y = hwy)\n\t\t\t ) +\n  facet_grid(drv ~ cyl) \n\nggplot(data = mpg) + #--------------------------------------------------# testing facet grid 2\n  geom_point(mapping = aes(x = displ, \n\t\t\t\t\t\t   y = hwy)\n\t\t\t ) +\n  facet_grid(. ~ cyl) #-----------------------------------------------# puts cyl facet into columns since argument is (r,c)\n\nggplot(data = mpg) + #--------------------------------------------------# testing facet grid 3\n  geom_point(mapping = aes(x = displ, \n\t\t\t\t\t\t   y = hwy)\n\t\t\t ) +\n  facet_grid(drv ~ .) #-----------------------------------------------# puts drv facet into rows since argument is (r,c)\n\n\n\n#### Changing Geoms ####\nggplot(data = mpg) + \n  geom_smooth(mapping = aes(x = displ, \n\t\t\t\t\t\t\ty = hwy)\n\t\t\t  ) #-----------------------------------------------------# from point to smooth\n\n\nggplot(data = mpg) + #--------------------------------------------------# line type based on a variable\n  geom_smooth(mapping = aes(x = displ, \n\t\t\t\t\t\t\ty = hwy, \n\t\t\t\t\t\t\tlinetype = drv)\n\t\t\t  )\nggplot(data = mpg) + #--------------------------------------------------# line type based on a variable with points and colors to show the seperation\n  geom_point(mapping = aes(x = displ, \n\t\t\t\t\t\t   y = hwy, \n\t\t\t\t\t\t   color = drv)\n\t\t\t ) + \n  geom_smooth(mapping = aes(x = displ, \n\t\t\t\t\t\t\ty = hwy, \n\t\t\t\t\t\t\tlinetype = drv, \n\t\t\t\t\t\t\tcolor = drv)\n\t\t\t  )\n\n\nggplot(data = mpg, mapping = aes(x = displ,\n\t\t\t\t\t\t\t   y = hwy)\n\t ) + \n  geom_point() +\n  geom_smooth()\n\n\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, \n\t\t\t\t\t\t   y = hwy)\n\t\t\t ) +\n  geom_smooth(mapping = aes(x = displ, \n\t\t\t\t\t\t\ty = hwy, \n\t\t\t\t\t\t\tlinetype = drv), \n\t\t\t  show.legend = F\n\t\t\t  )\n\n\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, \n\t\t\t\t\t\t   y = hwy, \n\t\t\t\t\t\t   color = drv)\n\t\t\t ) +\n  geom_smooth(mapping = aes(x = displ, \n\t\t\t\t\t\t\ty = hwy, \n\t\t\t\t\t\t\tlinetype = drv, \n\t\t\t\t\t\t\tcolor = drv), \n\t\t\t  show.legend = F\n\t\t\t  )\n\n\n#### Bar Plots ####\n\nggplot(data = diamonds) +\n  geom_bar(mapping = aes(x = cut))\n\n\n```\n","n":0.039}}},{"i":458,"$":{"0":{"v":"Dplyr","n":1},"1":{"v":"\n\n```r\nknitr::opts_chunk$set(echo = TRUE, results = 'hide')\nlibrary(tidyverse)\nlibrary(nycflights13)\n```\n\n## Initial Items\n\n```r\nnycflights13::flights\n\nairlines #--------------------------------------------------# not just a data frame but a tibble\nview(flights) #---------------------------------------------# opens the viewer on the tibble so we can observe data in tabular format\nfilter(flights, month == 1, day == 1) #---------------------# prints the result of the filter\njan1 <- filter(flights, month == 1, day == 1) #-------------# assigns the result of the filter to a dataframe\n(dec25 <- filter(flights, month == 12, day == 25)) #--------# wrapped parenthese both assigns and prints out the dataframe\nsqrt(2) ^ 2 == 2 #------------------------------------------# False as its approximate and not exact, use near() to get around this\n1/49 * 49 == 1 #--------------------------------------------# also false\nnear(sqrt(2) ^ 2,2) #---------------------------------------# Returns True as it should\nnear(1/49 * 49,1) #-----------------------------------------# Returns True as it should\nnov_dec <- filter(flights, month %in% c(11, 12)) #----------# will select rows where x is one of the values in y\n```\n\n### More Exercises\n\n```r\n# Exercise 1\ntransmute(flights,\n  dep_time,\n  dep_hours = dep_time %/% 100,\n  dep_minutes = dep_time %% 100,\n  sched_dep_time,\n  sched_dep_hours = sched_dep_time %/% 100,\n  sched_dep_minutes = sched_dep_time %% 100\n)\n\n# Exercise 2\nnewFlights <- transmute(flights,\n  air_time,\n  realTime = arr_time - dep_time,\n  accuracy = air_time == realTime\n)\naccurateFlights <- filter(newFlights, accuracy == T) #------# 0.36% Accuracy of AirTime\n\n# Exercise 3\nflightsDelay <- transmute(flights,\n  dep_delay,\n  realDelay = dep_time - sched_dep_time,\n  accurate = dep_delay == realDelay\n)\naccurateDelays <- filter(flightsDelay, accurate == T) #-----# 67.9% Accuracy of delay times\n\n# Exercise 4\nmin_rank(flightsDelay$realDelay)\nsubset <- sort(flightsDelay$realDelay,decreasing = T)\nsubset[1:10] %>% mean()\n\n# Exercise 5\nsubset[1:3]+subset[1:10]\n```\n","n":0.066}}},{"i":459,"$":{"0":{"v":"Transmute","n":1},"1":{"v":"\n\n### Transmute\n\n```r\ntransmute(flights_small, #----------------------------------# Using transmute will let you mutate the variables but keeps only \ngain = arr_delay - dep_delay,                        # The Newly mutated variables in your tibble\nspeed = distance / air_time * 60, \nhours = air_time / 60,\ngain_per_hour = gain / hours \n)\n```\n","n":0.152}}},{"i":460,"$":{"0":{"v":"Summarize","n":1},"1":{"v":"\n\n### Summarize\n\n```r\navgDelay <- as.numeric(summarize(flights, delay = mean(dep_delay, na.rm = T)))\ncat(\"The average delay of all flights is:\", avgDelay)\n\nby_day <- group_by(flights, year, month, day)\nsummarize(by_day, delay = mean(dep_delay,na.rm = T))\n```\n","n":0.192}}},{"i":461,"$":{"0":{"v":"Select","n":1},"1":{"v":"\n\n### Select\n\n```r\nselect(flights, year, month, day) #-------------------------# Selecting specific variables from the data set (variables = columns)\nselect(flights, year:day) #---------------------------------# Selecting specific variables using colon (this to this)\nselect(flights, -(year:day)) #------------------------------# selects all variables EXCEPT those in the parens with the minus sign operating on it\n# functions to use with select\n# starts_with\n# ends_with\n# contains\n# matches\n# num_range\nselect(flights, origin, dest, everything()) #---------------# Puts selected columns at front of data set while keeping all variable in data set\nselect(flights, tailnum, tailnum) #-------------------------# If same variable named twice, it is displayed only once\nvars <- c(\"year\",\"month\",\"day\",\"dep_delay\",\"arr_delay\") #---# Give character vector the variable names\nselect(flights,one_of(vars)) #------------------------------# Use one_of function with character vector variable to grab variables from tibble that match\nselect(flights, contains(\"TIME\")) #-------------------------# Selects all tibble variables that contain substring \"Time\"\n\nflights_small <- select(flights, #--------------------------# Selecting desired variables for a lean-er data set through various methods\n\t\t\t   year:day,\n\t\t\t   ends_with(\"delay\"),\n\t\t\t   distance,\n\t\t\t   air_time\n\t\t\t   )\n```\n","n":0.085}}},{"i":462,"$":{"0":{"v":"Mutate","n":1},"1":{"v":"\n\n### Mutate\n\n```r\nmutate(flights_small, \ngain = arr_delay - dep_delay, #----------------------# Usage of \"=\" instead of <- because its assigning that value to the variable\nspeed = distance / air_time * 60, #------------------# we're saying that this variable is \"=\" to this equation\nhours = air_time / 60, #-----------------------------# Not that we're assigning these valus to a vector\ngain_per_hour = gain / hours #-----------------------# Can even use new variables made within mutate to create new variables\n) #--------------------------------------------------# if we had used \"<-\" then it displayed the operator in the variable name \n```\n","n":0.108}}},{"i":463,"$":{"0":{"v":"Modular Arithmatic","n":0.707},"1":{"v":"\n\n### Modular Arithmatic\n\n```r\ntransmute(flights,\n  dep_time,\n  hour = dep_time %/% 100, #------------------------# %/% is integer division\n  minute = dep_time %% 100 #------------------------# %% is remainder division\n)\n```\n","n":0.204}}},{"i":464,"$":{"0":{"v":"Filters","n":1},"1":{"v":"\n\n### Filters\n\n```r\nfilter(flights, arr_delay >= 2) #---------------------------# arrival delay greater than 2 hours\nfilter(flights, dest %in% c(\"IAH\", \"HOU\")) #----------------# flew to IAH or HOU\nfilter(flights, carrier %in% c(\"UA\",\"AA\",\"DL\")) #-----------# Operated by United, American, or Delta\nfilter(flights, between(month, left = 7, right = 9)) #------# Departed in summer (July, August, September)\nfilter(flights, arr_delay > 120 & dep_delay <= 0)#----------# arrived more than 2 hours late but(AND) didnt leave late\nfilter(flights, dep_delay >= 120 & arr_delay <= 90) #-------# delayed by at least an hour but made up 30min in flight\nfilter(flights, between(dep_time,left = 0, right = 600)) #--# departed between midnight and 6am (Inclusive), using between() \nfilter(flights, is.na(dep_time))#---------------------------# count of flights with missing departure time\n```\n","n":0.097}}},{"i":465,"$":{"0":{"v":"Arrange","n":1},"1":{"v":"\n\n### Arrange\n\n```r\narrange(flights, desc(is.na(dep_time))) #-------------------# Sorted on the dep_time column using is.na to put missing values at top\narrange(flights, desc(dep_delay)) #-------------------------# most delayed flights\narrange(flights, dep_delay) #-------------------------------# flights that left the earliest, AESC is the default setting so no function exists for that\narrange(flights, air_time) #--------------------------------# Fastest flights\narrange(flights, desc(distance), desc(air_time)) #----------# flights that traveled the longest\narrange(flights, distance) #--------------------------------# flights that traveled the shortest\n```\n","n":0.13}}},{"i":466,"$":{"0":{"v":"Functions","n":1},"1":{"v":"\n\n```r\n# Functions ----\n# Descriptive Statistics Functions ----\n\nmyValues <- c(1:100)\nmyValues\n\nmean(myValues)\nmedian(myValues)\nmode(myValues)\nmin(myValues)\nmax(myValues)\nsum(myValues)\nsd(myValues) #standard deviation\nclass(myValues)\nlength(myValues)\nlog(myValues)\nlog10(myValues)\n\n\nmySqrt <- sqrt(myValues)\nmySqrt\n\n?rnorm # Adding a question mark before the name of a function opens a help pane with all the details\n# on that function, this is a great way to learn about what the functions require as arguments\n?rgb\n\nhist(rnorm(100, mean = 5))\n\n# Data frame Functioons ----\n\n# setting up the data frame vectors\nid <- 1:200\ngroup <- c(rep(\"Vehicle\",100),\n\t   rep(\"Drug\",100))\nresponse <- c(rnorm(100,mean = 25, sd = 5),\n\t\t  rnorm(100,mean = 23, sd=5))\n\n#compiling the data frame\nmyData <- data.frame(Patient = id,\n\t\t\t\t Treatment = group,\n\t\t\t\t Response = response)\n\nmyData\nhead(myData,10)\ntail(myData,10)\ndim(myData)\nstr(myData)\nsummary(myData)\n\n\n# Change Value of data type present can work for entire columns ----\nas.numeric(c(\"1\",\"2\",\"3\"))\nas.character(1:10)\n\n\n# Remove Objects ----\n# Objects names cannot contain  spaces in varialbe/object names \n# But underscores and periods allowed but best to just stick with camel case\n\nmy_Object <- 3\nmy.Object <- 3\nmyObject <-3\n\n# all of these are valid\n# to remove an object use the RM command\n\nrm(my_Object)\nrm(my.Object)\n```\n","n":0.083}}},{"i":467,"$":{"0":{"v":"Data Types","n":0.707}}},{"i":468,"$":{"0":{"v":"Vectors","n":1},"1":{"v":"\n\n## Vectors\n\n```r\n#vectors ----\n#5 types\n# Logical\n# Integer\n# Numeric 'value greater than 7 digits will always be converted to the exponential format\n# Complex\n# Character\n\n#============#\n#  EXAMPLES  #----\n#============#\n\n#Logical\nvtr1 = c(TRUE,FALSE)\n\n#Numeric\nvtr2 = c(15,85.674954,999999)\n\n#Integer requires \"L\" after number to treat as integer\nvtr3 = c(35L,58L,146L)\n\n#Integer with decemals converted with warning to numeric\nvtr4 = c(85.64L)\n\n#Wrong data types passed to vector\nvtr5 = c(TRUE,35L,3.14) #TRUE will be converted to Boolean 1 if put into a Numeric/Integer Vector\n\n#now incude a character string\nvtr6 = c(TRUE,35L,3.14,\"hello\")\n\n#===========#\n#  Results  #----\n#===========#\n\nclass(vtr1)\nvtr1\nclass(vtr2)\nvtr2\nclass(vtr3)\nvtr3\nclass(vtr4)\nvtr4\nclass(vtr5)\nvtr5\nclass(vtr6)\nvtr6\n\n# Vector Math ----\n\nnumbers <- c(1:10)\nnumbers * 2\n\n# Subsetting Vectors ----\n\ndays <- c(\"mon\", \"tue\", \"wed\", \"thurs\", \"fri\")\ndays\n# to return a specific value of a vector in square brackets after its object holding the vector\n# use square brackets and the index of the value to pull out a subset of a vector\ndays[1]\n# square brackets are ALWAYS for subsetting the parens \"()\" are for functions\ndays[c(1,3,5)] #vector within the sub setting brackets to pull out specific values\ndays[2:5] #if you wanted everything except monday\ndays[-5] #basically saying \"give me everything except what's in index 5\" or in this case \"Friday\n\n```\n","n":0.077}}},{"i":469,"$":{"0":{"v":"Null and Na","n":0.577},"1":{"v":"\n\n## Null & NA\n\n```r\n# empty value ----\n\nNA #NA is a logical constant of length 1 which contains a missing value indicator\n\nNULL #NULL represents the null object in R: \n# it is a reserved word. NULL is often returned by expressions and \n# functions whose value is undefined.\n\n?NA\n```\n","n":0.146}}},{"i":470,"$":{"0":{"v":"Matrix","n":1},"1":{"v":"\n\n## Matrix\n\n```r\n# Matrix\n# R Objects in which the elements are arranged in a 2 dimensional rectangular layout\n# Syntax: matrix(data, nrow, ncol, byrow, dimnames)\n# Data: the input vector which becomes the data elements of the matrix\n# NRow: number of rows to be created\n# NCol: number of columns to be created\n# ByRow: a logical clue. If TRUE then the input vector elements are arranged by row\n# DimName: The names assigned to the rows and columns\n\n#============#\n#  EXAMPLES  #\n#============#\n\nmtr = matrix(c(1:25),5,5)\nmtr\n# Warning message:\n# In matrix(c(5:30), 5, 5) :\n# data length [26] is not a sub-multiple or multiple of the number of rows [5]\n# If your total number of data points spills out of the matrix, error returns\n\n```\n","n":0.094}}},{"i":471,"$":{"0":{"v":"List","n":1},"1":{"v":"\n\n## List\n\n```r\n# List ----\n# The R Objects which can contain elements of different types like \n# Numbers, Strings, Vectors, and another List inside of it\n# Syntax: list(data)\n\n#============#\n#  EXAMPLES  # ----\n#============#\n\nvtr1 = c('hello','world')\nvtr2 = c(24.6345,3.6,345.5678)\nvtr3 = c(45L,'hi')\n\nls = list(vtr1,vtr2,vtr3)\nls\n\n# Within each list item/variable returned, it will not let seperate list items/variables\n# Dictate the data type of the other items/variable\n# It will allow this dictation if inside the variable itself it contains differing\n# data types\n\n# Nested Lists ----\nlist(1,2,list(\"a\",\"b\",list(T,T,F)),\"hello\",T)\n# you can have lists within lists and it displays nested lists effectively in the console\n\n```\n","n":0.105}}},{"i":472,"$":{"0":{"v":"Dataframe","n":1},"1":{"v":"\n\n## Data Frame\n\n```r\n# PART 1 ----\n\n# Data Frames\n# A Table or a 2-dimensional array-like structure in which each column contains \n# values of one variable and each row contains one set of values from each column\n# Syntax: data.frame(data)\n\n#============#\n#  EXAMPLES  #\n#============#\n\nRowCount = c(1:5)\nPeopleNames = c(\"Bryan\",\"Jude\",\"kelly\",\"janelle\",\"Rosa\")\nValues = c(15,25,65,145,74)\n\ndf <- data.frame(RowCount,PeopleNames,Values)\ndf\n# This alone will display the valeus of the data frame each vector in the frame\n# represents a vertical column of values that each contibue a value to each row\n\ndata.frame(airquality) \n# Built in sample data table, can also import Excel files\n\n\n# PART 2 ----\n\nmyDataFrame <- read.csv(\"20190208 RC Registry.csv\")\nmyDataFrame <- myDataFrame[myDataFrame$Medical..Screening.Due.Date <date, c(\"CDCR\", \"Medical..Screening.Due.Date\")]\nmyDataFrame\n\n\n# PART 3 ----\n\n# setting up the data frame vectors\nid <- 1:200\ngroup <- c(rep(\"Vehicle\",100),\n\t   rep(\"Drug\",100))\nresponse <- c(rnorm(100,mean = 25, sd = 5),\n\t\t  rnorm(100,mean = 23, sd=5))\nage <- round(rnorm(200,40,20))\n\n#compiling the data frame\nmyData <- data.frame(Patient = id,\n\t\t\t\t Patient.Age = age,\n\t\t\t\t Treatment = group,\n\t\t\t\t Response = response)\n\nmyData\nhead(myData,10)\ntail(myData,10)\ndim(myData)\nstr(myData)\nsummary(myData)\n\n# subsetting Data.frames ----\n\nmyData[1,2]\nmyData[2,3]\nmyData[1:20,2:3] # first 20 rows with columns 2 & 3 present\nmyData[1:20,] # returns 20 rows and all columns if left blank\nmyData[,1] # returns everythingh in the first column only\nmyData[,\"Response\"] # returns just the columns values for the column named \"Response\"\nmyData$Response #the Dollar sign $ after the name of the data frame will return the entire column without quotes or brackets\n\nmyData[myData$Response>26,] # give me the rows and all columns for every row that meets the criteria\n# of Response > 26\n\n#perform a calculation and then add values to a new column of the data frame\nmyData$Positive <- myData$Response<26\nwrite.csv(myData[myData$Response>26,],file = \"testData.csv\", row.names = F) # write a CSV file to the current working directory\n\n# multiple filter criteria and then assigned\n# to a new object for ease of exporting to CSV\nCSVMyData <- myData[myData$Treatment == \"Vehicle\"\n\t\t\t\t& myData$Response>26 &\n\t\t\t\t\tmyData$Patient.Age > 0,] \n\n\nwrite.csv(CSVMyData,file = \"testData.csv\", row.names = F)\n\nhead(CSVMyData)\n\n```\n","n":0.059}}},{"i":473,"$":{"0":{"v":"Data Classes","n":0.707},"1":{"v":"\n\n## Data Classes\n\n```r\n# Data Classes ----\n\n12.6    #Numeric\n3       #Numeric\n100     #Numeric\n\n\"male\"  #Character\n\nTRUE    #Logical\nFALSE   #Logical\nT       #Logical\nF       #Logical\n\n# Data Structures ----\n\n# Vector\n# List\n# Matrix\n# Data Frame\n```\n","n":0.213}}},{"i":474,"$":{"0":{"v":"Array","n":1},"1":{"v":"\n\n## Array\n\n```r\n# Array\n# The R Objects which can store data in more than 2 dimensions\n# Syntax: array(data, dim, dimnames)\n\n#============#\n#  EXAMPLES  #\n#============#\n\narr = array(c(0:15),dim = c(4,4,2,2))\n\n#this makes the array = 0-15\n#the dimension makes the 0-15 display in a 4x4 grid\n#the other dimension makes it a 3d array by making 4 copies of the array in a \n#2x2 grid of arrays\narr\n\narr2 = array(c(1:9),dim = c(3,3,4,2))\narr2\n\n```\n","n":0.126}}},{"i":475,"$":{"0":{"v":"Data Operators","n":0.707},"1":{"v":"\n\n```r\n# Arithmatic\n\t# Addition (+)\n\t# Subtraction (-)\n\t# Multiplication (*)\n\t# Division (/)\n\t# Modulus (%%)\n\t# Exponent (^)\n\t# Floor Division (%/%)\n# Relational\n\t# Equal To (==) #asking \"is this equal to that\" returns Bool\n\t# Not Equal To (!=)\n\t# Greater Than (>)\n\t# Less Than (<)\n\t# Greater Than Equal To (>=)\n\t# Less Than Equal To (<=)\n# Assignment\n\t# Left\n\t# Equals (=)\n\t# Assign (<-)\n\t# Right\n\t# Equals (=)\n\t# Assign (->)\n# Logical\n\t# AND (&) in 2 concurrent vectors, compare each aligned item ask AND\n\t# AND (&&) compre whole vector to whole vector and all AND's need to be\n\t# TRUE or else False\n\t# NOT (!)\n\t# OR (|) in 2 concurrent vectors, compare each aligned item ask OR\n\t# OR (||) compareshole vector to whole vector and either side needs\n\t# tobe TRUE or else False \n```\n","n":0.091}}},{"i":476,"$":{"0":{"v":"Conditional Statements","n":0.707},"1":{"v":"\n\n```r\n# IF\n\t# Syntax:\n\t\t# if(expression)\n\t\t#   {\n\t\t#        //statements\n\t\t#   }\n# ELSE IF\n\t# Syntax:\n\t\t# if(expression 1)\n\t\t#   {\n\t\t#        //statements\n\t\t#   }\n\t\t# Else If(expression 2)\n\t\t#   {\n\t\t#        //statements\n\t\t#   }\n\n\nvtr1 <- c(5)\n\nif(vtr1==5)\n{\nprint(\"hello world\")\n}\n```\n","n":0.204}}},{"i":477,"$":{"0":{"v":"Python","n":1},"1":{"v":"\n\n> Python is the most powerful language you can still read.\n>\n> - Paul Dubois\n","n":0.267}}},{"i":478,"$":{"0":{"v":"Workflow","n":1},"1":{"v":"\n\n## Workflow\n\n- Make a new Git Repo\n- vscode gitignore extension to add Python gitignore\n- add gitattributes file\n- Add config files for terminal/vscode/Extensions\n- Setup Linting CI/CD with the `github super linter`\n  - Super linter file\n\n```yaml\n# https://aka.ms/yaml\n# Initial code src: https://www.meziantou.net/running-github-super-linter-in-azure-pipelines.htm\n# referenced docker container script: https://github.com/github/super-linter\n# Official MS Documentation: https://docs.microsoft.com/en-us/azure/devops/pipelines/?view=azure-devops\n# YAML Schema Info: https://docs.microsoft.com/en-us/azure/devops/pipelines/yaml-schema?view=azure-devops&tabs=schema%2Cparameter-schema\n#============================================================================================================#\nname: 'Super Linter -- $(Date:yyyyMMdd)$(Rev:.r)' #............................# Name of the Job Instance When Ran\ntrigger: #.....................................................................# What triggers the job to run?\n- '*' #........................................................................# Everything triggers it\nvariables: #...................................................................# Variables for any parameter testing or changes\ndefault_branch: 'prod' #.....................................................# What Branch is the default branch to run the job on\nlog_level: 'WARN' #..........................................................# What level and above of notices do you want to receive? WARN & ERROR\nexcluded_paths: '.*(\\.github|\\.vscode).*' #..................................# What Locations are ignored by this job?\njobs: #........................................................................# No stages so top level list of jobs to run\n- job: 'super_linter' #......................................................# Name of the job\n  #pool: 'default' #.........................................................# The Agent Pool if we wanted to use our self hosted option\n  pool: #....................................................................# Which Agent Pool runs the job?\n\tvmImage: 'ubuntu-latest' #...............................................# Microsoft Hosted Image to Run Job on\n  steps: #...................................................................# The list of steps that make up the job\n  - script: 'docker pull github/super-linter:latest' #.......................# Commands to Run in the default shell of the host machine See VmImage\n\tdisplayName: 'Pull GitHub Super-Linter image' #..........................# Display name of this step when it executed in the pipeline\n  - script: >-\n\t  docker run \\\n\t\t-e IGNORE_GITIGNORED_FILES=true \\\n\t\t-e MARKDOWN_CONFIG_FILE=.markdownlint.jsonc \\\n\t\t-e JAVASCRIPT_ES_CONFIG_FILE=.eslintrc.json \\\n\t\t-e PYTHON_BLACK_CONFIG_FILE=.python-black \\\n\t\t-e PYTHON_FLAKE8_CONFIG_FILE=.flake8 \\\n\t\t-e PYTHON_ISORT_CONFIG_FILE=.isort.cfg \\\n\t\t-e DEFAULT_BRANCH=$(default_branch) \\\n\t\t-e LOG_LEVEL=$(log_level) \\\n\t\t-e FILTER_REGEX_EXCLUDE='$(excluded_paths)' \\\n\t\t-e RUN_LOCAL=true \\\n\t\t-v $(System.DefaultWorkingDirectory):/tmp/lint github/super-linter\n# - script: >- #...............................................................# The Below is the multi-line inline script ran in the default shell formatted for legibility\n#     docker run \\ #...........................................................# Running the docker image with the following commands `-e` is enviornmental variable `-v` is the volume to attach to (a file path)\n#       -e IGNORE_GITIGNORED_FILES=true \\ #....................................# BOOL Variable asking if the job should lint .gitignored files\n#       -e MARKDOWN_CONFIG_FILE=.markdownlint.jsonc \\ #........................# STRING Variable of Markdown config file\n#       -e JAVASCRIPT_ES_CONFIG_FILE=.eslintrc.json \\ #........................# STRING Variable of JSON config file\n#       -e PYTHON_BLACK_CONFIG_FILE=.python-black \\ #..........................# STRING Variable of Python Black config file\n#       -e PYTHON_FLAKE8_CONFIG_FILE=.flake8 \\ #...............................# STRING Variable of Python flake8 config file\n#       -e PYTHON_ISORT_CONFIG_FILE=.isort.cfg \\ #.............................# STRING Variable of Python isort config file\n#       -e DEFAULT_BRANCH=$(default_branch) \\ #................................# STRING Variable of default branch to run job on when not targeted manually\n#       -e LOG_LEVEL=$(log_level) \\ #..........................................# STRING Variable of desired log output level\n#       -e FILTER_REGEX_EXCLUDE=$(excluded_paths) \\ #..........................# STRING Variable of regex path list to ignore for the job\n#       -e RUN_LOCAL=true \\ #..................................................# BOOL Variable to Run the container locally (On VmImage)\n#       -v $(System.DefaultWorkingDirectory):/tmp/lint github/super-linter #...# Volume to attach to\n\tdisplayName: 'Run GitHub Super-Linter' #.................................# Name of this step in the job\n```\n\n- [[black]] with a `pyproject.toml` addition\n\n```toml\n[tool.black]\nline-length = 88\ninclude = '\\.pyi?\nexclude = '''\n/(\n\\.git\n| \\.hg\n| \\.mypy_cache\n| \\.tox\n| \\.venv\n| _build\n| buck-out\n| build\n| dist\n| docs\n| notes\n)/\n'''\n```\n\n- [[s.l.python.libs.flake8]] with a `.flake8` file\n\n```\n[flake8]\nmax-line-length = 88\nmax-complexity = 18\nexclude =\n.git,\n__pycache__,\nbuild,\ndist\nselect = B,C,E,F,W,T4,B9\nignore =\nE203, # E203: whitespace before ‚Äò:‚Äô\nE266, # E266: too many leading ‚Äò#‚Äô for block comment\nE501, # E501: line too long (82 > 79 characters)\nW503, # W503: line break before binary operator\nF401, # F401: module imported but unused\nF403  # F403: ‚Äòfrom module import *‚Äô used; unable to detect undefined names\n\n```\n\n- [[s.l.python.libs.isort]] with a `pyproject.toml` addition\n\n```toml\n[tool.isort]\nline_length = 88\nmulti_line_output = 3\ninclude_trailing_comma = true\nskip_glob = []\nknown_third_party = []\n```\n\n- [[s.l.python.libs.venv.vulture]] with a `pyproject.toml` addition\n\n```toml\n[tool.vulture]\nexclude = []\nignore_decorators = [\"@app.route\", \"@require_*\"]\nignore_names = []\nmake_whitelist = true\nmin_confidence = 80\npaths = [\"src/\"]\nsort_by_size = true\nverbose = false\n```\n\n- setup repo branch policies and settings\n- [[s.l.python.build.poetry]] setup\n  - `poetry new <PROJECT>` or `poetry init`\n  - Spin up virtual environment `poetry shell`\n  - `poetry add --dev pre-commit pytest pytest-cov`\n  - setup pre-commit hooks for formatting\n  - make `.pre-commit-config.yaml` file\n  - `poetry run pre-commit install`\n  - `poetry run pre-commit autoupdate`\n  - `poetry run pre-commit run` (to test that it works)\n\n```yaml\nrepos:\n- repo: https://github.com/asottile/seed-isort-config\n  rev: v2.2.0\n  hooks:\n  - id: seed-isort-config\n- repo: https://github.com/pre-commit/mirrors-isort\n  rev: v5.8.0\n  hooks:\n  - id: isort\n- repo: https://github.com/psf/black\n  rev: 21.6b0\n  hooks:\n  - id: black\n\tlanguage_version: python3\n\tdescription: \"Black: The uncompromising Python code formatter\"\n- repo: https://gitlab.com/pycqa/flake8\n  rev: 3.9.2\n  hooks:\n  - id: flake8\n- repo: https://github.com/jendrikseipp/vulture\n  rev: 'v2.3'\n  hooks:\n  - id: vulture\n- repo: https://github.com/pre-commit/pre-commit-hooks\n  rev: v4.0.1\n  hooks:\n  - id: trailing-whitespace\n\tlog_file: src/logs/hooks.log\n  - id: end-of-file-fixer\n\tlog_file: src/logs/hooks.log\n  - id: check-docstring-first\n\tlog_file: src/logs/hooks.log\n  - id: requirements-txt-fixer\n\tlog_file: src/logs/hooks.log\n  - id: check-added-large-files\n\tlog_file: src/logs/hooks.log\n  - id: check-json\n\tlog_file: src/logs/hooks.log\n\texclude: .vscode/settings.json\n  - id: check-yaml\n\tlog_file: src/logs/hooks.log\n  - id: check-toml\n\tlog_file: src/logs/hooks.log\n  - id: check-xml\n\tlog_file: src/logs/hooks.log\n  - id: debug-statements\n\tlog_file: src/logs/hooks.log\n  - id: name-tests-test\n\tlog_file: src/logs/hooks.log\n  - id: check-shebang-scripts-are-executable\n\tlog_file: src/logs/hooks.log\n  - id: check-merge-conflict\n\tlog_file: src/logs/hooks.log\n  - id: check-symlinks\n\tlog_file: src/logs/hooks.log\n  - id: destroyed-symlinks\n\tlog_file: src/logs/hooks.log\n  - id: debug-statements\n\tlog_file: src/logs/hooks.log\n  - id: detect-private-key\n\tlog_file: src/logs/hooks.log\n  - id: no-commit-to-branch\n\tlog_file: src/logs/hooks.log\n\targs: [--branch, prod]\n\n```\n\n- Set up logging and this directory structure to start:\n\n```\n.\n‚îú‚îÄ‚îÄ‚îÄ.github\n‚îÇ   ‚îú‚îÄ‚îÄ‚îÄISSUE_TEMPLATE\n‚îÇ   ‚îú‚îÄ‚îÄ‚îÄlinters\n‚îÇ   ‚îî‚îÄ‚îÄ‚îÄworkflows\n‚îú‚îÄ‚îÄ‚îÄdoc\n‚îî‚îÄ‚îÄ‚îÄsrc\n  ‚îú‚îÄ‚îÄ‚îÄlogger\n  ‚îÇ\t‚îú‚îÄ‚îÄ‚îÄ__init__.py\n  ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄlogger.py\n  ‚îú‚îÄ‚îÄ‚îÄlogs\n  ‚îú‚îÄ‚îÄ‚îÄmypackage\n  ‚îÇ \t‚îú‚îÄ‚îÄ‚îÄ__init__.py\n  ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄmypackage.py\n  ‚îî‚îÄ‚îÄ‚îÄapp.py\n```\n\n- Set up unit testing framework with [[s.l.python.libs.pytest]]\n  - `pytest-cov --cov <SRC DIR> --cov-report html`\n    - This tests the coverage of the entire source code directory and writes an intricate [[s.m.html]] report for viewing test results\n- Set up auto documentation with [[s.l.python.libs.sphinx]] & [[s.m.restructured-text]]\n- **More on Packaging**\n  - build your distribution: `poetry build`\n  - publish your distribution: `poetry publish`\n- **Opening someone elses poetry project**\n  - install dependencies `poetry install`\n","n":0.035}}},{"i":479,"$":{"0":{"v":"Vars","n":1}}},{"i":480,"$":{"0":{"v":"Tools","n":1},"1":{"v":"\n\n- [[s.l.python.tools.jupyter]]\n- vscode Extensions\n  - `ms-python.python` Python language support\n  - `ms-python.vscode-pylance` Python language support\n  - `brainfit.vscode-importmagic` Fix missing module imports\n  - `formulahendry.code-runner` Code runner to run the language for output and not just python code\n  - AI Code Completion\n    - [Comparisons here](https://medium.com/swlh/kite-vs-tabnine-which-ai-code-autocomplete-should-you-choose-eb6eba85c3a6)\n      - ‚ùåÔ∏è `kiteco.kite` Kite\n        - [[s.l.python.tools.kite]]\n      - ‚úÖÔ∏è `tabnine.tabnine-vscode` TabNine\n  - `almenon.arepl` Coding REPL\n  - `njpwerner.autodocstring` Auto Generatre Doc Strings\n  - `kevinrose.vsc-python-indent` Correct Indentation\n  - `dongli.python-preview` Preview execution stack\n  - `littlefoxteam.vscode-python-test-adapter` Python Test explorer\n  - `njqdev.vscode-python-typehint` Data type hint\n  - `ms-pyright.pyright` for static type checking\n  - ‚ùåÔ∏è `nikolapaunovic.tkinter-snippets` [[tkinter]] snippets\n  - `njqdev.vscode-python-typehint` Data type hint\n  - `jithurjacob.nbpreviewer` Jupyter Notebook Support and Viewing\n  - `ms-toolsai.jupyter` Jupyter Notebook Support and Viewing\n\n## Build Tools\n\n- [[s.l.python.build.poetry]] build tool\n- [Pants](https://www.pantsbuild.org/docs)\n\n## Linting\n\n- [[s.l.python.libs.black]] Code formatter\n\n## Visualization Tools\n\n- [[visualize call stacks|s.l.python.libs.code2flow]]\n- [[visualize project dependencies|s.l.python.libs.pydeps]]\n\n## Project Oversight\n\n- [[cli.cmd.git.tools.github.tools.deep-source]]\n","n":0.087}}},{"i":481,"$":{"0":{"v":"Kite","n":1},"1":{"v":"\n\n- <https://www.kite.com/>\n","n":0.707}}},{"i":482,"$":{"0":{"v":"Jupyter","n":1},"1":{"v":"\n\n- **Themes**\n  - To get a custom theme (_gruvboxdark_) onto my jupyter notebook i used the tool [jupyter-themes](https://github.com/dunovank/jupyter-themes)\n  - Then the command i ran was `jt -t gruvboxd -f fira -fs 115`\n  - [SO answer about theming notebooks](https://stackoverflow.com/questions/46510192/change-the-theme-in-jupyter-notebook#46561480)\n- **Line Magics**\n  - Running this in a cell `%lsmagic` will give you a list of magic commands you can run they look like the bash built-ins\n  - You can access them like `%ls` `%cp` `%rm` etc. if `Automagic` is turned on then you can run cells with straight up bash in them too. Command flags and everything.\n- **Inline Charts**\n  - To display an inline chart you need line magic . The one in question is `%matplotlib inline` that will allow you to display charts inline in the notebook\n- ==Jupyter Lab==\n  - **Installation**\n    - pip install jupyterlab\n  - **Extensions**\n    - pip install jupyterlab-git\n    - pip install jupyterlab-pullrequests\n    - pip install jupyterlab_github\n    - pip install jupyterlab_vim\n    - pip install jupyter_contrib_nbextensions\n","n":0.08}}},{"i":483,"$":{"0":{"v":"Tips Tricks","n":0.707}}},{"i":484,"$":{"0":{"v":"Variable Swap","n":0.707},"1":{"v":"\n\n## Swap Variable Values\n\n```python\nx, y = 1, 0\n```\n","n":0.354}}},{"i":485,"$":{"0":{"v":"Underscore Variable","n":0.707},"1":{"v":"\n\n## The \\_ in Python\n\n- The `_` in python can hold the last value in an interactive shell session but can be used like the unnamed register in [[cli.cmd.vim]] and you can use it to avoid issues when unpacking tuples or just throwing something away:\n\n```python\nmy_tuple = (1,2,3)\nx, _, z = my_tuple # (1,2,3)\n#> x = 1\n#> _ = 2\n#> z = 3\n```\n","n":0.127}}},{"i":486,"$":{"0":{"v":"Named Tuples","n":0.707},"1":{"v":"\n\n## Named Tuples\n\n```python\nfrom collections import namedtuple\n\nCoordinate = namedtuple(\"Coordinate\", \"longitude latitude\")\nlocation = Coordinate(90, 37.5)\nprint(\"location:\", location) \n# accessing attributes with dot notation\nprint(location.longitude, location.latitude) \n# Output: \n# location: Coordinate(longitude=90, latitude=37.5) \n# (90, 37.5) \n```\n","n":0.18}}},{"i":487,"$":{"0":{"v":"Multi Variable Assignment","n":0.577},"1":{"v":"\n\n## Multi-Variable Assignment\n\n```python\nx = 0\ny = 0\n\n# can be:\nx, y = 0, 0\n```\n","n":0.277}}},{"i":488,"$":{"0":{"v":"Multi List Iteration with Zip","n":0.447},"1":{"v":"\n\n## Simplify Iterating Over Multiple Lists With Zip()\n\n### Before\n\n```python\n\nnames = ['Nik', 'Jane', 'Melissa', 'Doug']\nages = [32, 28, 37, 53]\ngender = ['Male', 'Female', 'Female', 'Male']\n\n# Old boring way:\nfor_looped = []\nfor i in range(len(names)):\nfor_looped.append((names[i], ages[i], gender[i]))\n\nprint(for_looped)\n\n# Returns:\n# [('Nik', 32, 'Male'), ('Jane', 28, 'Female'), ('Melissa', 37, 'Female'), ('Doug', 53, 'Male')]\n```\n\n### After\n\n```python\n\nnames = ['Nik', 'Jane', 'Melissa', 'Doug']\nages = [32, 28, 37, 53]\ngender = ['Male', 'Female', 'Female', 'Male']\n\n# Zipping through lists with zip()\nzipped = zip(names, ages, gender)\nzipped_list = list(zipped)\n\nprint(zipped_list)\n\n# Returns:\n# [('Nik', 32, 'Male'), ('Jane', 28, 'Female'), ('Melissa', 37, 'Female'), ('Doug', 53, 'Male')]\n```\n","n":0.107}}},{"i":489,"$":{"0":{"v":"Kwargs","n":1},"1":{"v":"\n\n## Kwargs\n\n```python\n# Python 3.5+ allows passing multiple sets\n# of keyword arguments (\"kwargs\") to a\n# function within a single call, using\n# the \"\" syntax:\n\ndef process_data(a, b, c, d):\nprint(a, b, c, d)\n\nx = {'a': 1, 'b': 2}\ny = {'c': 3, 'd': 4}\n\nprocess_data(**x, **y)\n# >>> 1 2 3 4\n\nprocess_data(**x, c=23, d=42)\n# >>> 1 2 23 42\n```\n","n":0.137}}},{"i":490,"$":{"0":{"v":"Enums","n":1},"1":{"v":"\n\n## enums with the [[s.l.python.libs.enum]] module\n\n```python\nfrom enum import Enum\nSeason = Enum('Season', 'winter summer spring autumn')\nprint(Season.summer.name)\nprint(Season.summer.value)\n\n#using class\nclass Season(Enum):\nwinter = 1\nsummer = 2\nspring = 3\nautumn = 4\nprint(Season.winter.name)\nprint(Season.winter.value)\n\n# Output:\n# summer\n# 2\n# winter\n# 1\n```\n","n":0.183}}},{"i":491,"$":{"0":{"v":"Enumerate","n":1},"1":{"v":"\n\n## Replace len() with enumerate()\n\n### Before\n\n```python\n# Define a collection, such as list:\nnames = ['Nik', 'Jane', 'Katie', 'Jim', 'Luke']\n\n# Using the range(len(collection)) method, you'd write:\nfor i in range(len(names)):\nprint(i, names[i])\n\n# Using enumerate, you can define this by writing:\nfor idx, name in enumerate(names):\nprint(idx, name)\n\n# Both ways of doing this return:\n# 0 Nik\n# 1 Jane\n# 2 Katie\n# 3 Jim\n# 4 Luke\n```\n\n### After\n\n```python\n# Define a collection, such as list:\nnames = ['Nik', 'Jane', 'Katie', 'Jim', 'Luke']\n\n# Using enumerate, you can define this by writing:\nfor idx, name in enumerate(names, start=1):\nprint(idx, name)\n\n# This returns:\n# 1 Nik\n# 2 Jane\n# 3 Katie\n# 4 Jim\n# 5 Luke\n```\n","n":0.102}}},{"i":492,"$":{"0":{"v":"Ellipses","n":1},"1":{"v":"\n\n## For ... Else\n\n```python\n#case 1\nfor letter in 'foo':\nprint(letter)\nelse:\nprint(\"All letters have been printed\")\n\n#case 2\nfor letter in 'foo':\nprint(letter)\nif letter == 'o':\nbreak\nelse:\nprint(\"Letters have been printed\")\n\n# Output:\n# case 1\n# f\n# o\n# o\n# All letters have been printed\n# case 2\n# f\n# o\n```\n","n":0.164}}},{"i":493,"$":{"0":{"v":"Dictionary Access with Get","n":0.5},"1":{"v":"\n\n## Stop Using Square Brackets To Get Dictionary Items ‚Äî Use .get()\n\n### Before\n\n```python\nnik = {\n'age':32,\n'gender':'male',\n'employed':True,\n}\n\nprint(nik['location'])\n\n# Returns:\n# KeyError: 'location'\n```\n\n### After\n\n```python\nnik = {\n'age':32,\n'gender':'male',\n'employed':True,\n}\n\nprint(nik.get('location'))\n\n# Returns:\n# None\n```\n","n":0.209}}},{"i":494,"$":{"0":{"v":"Default Parameters","n":0.707},"1":{"v":"\n\n## Default Parameters\n\n```python\n# In Python 3 you can use a bare \"*\" asterisk\n# in function parameter lists to force the\n# caller to use keyword arguments for certain\n# parameters:\n\ndef f(a, b, *, c='x', d='y', e='z'):\nreturn 'Hello'\n\n# To pass the value for c, d, and e you\n# will need to explicitly pass it as\n# \"key=value\" named arguments:\nf(1, 2, 'p', 'q', 'v')\n# TypeError: \"f() takes 2 positional arguments but 5 were given\"\n\nf(1, 2, c='p', d='q',e='v')\n'Hello'\n```\n","n":0.118}}},{"i":495,"$":{"0":{"v":"Setup","n":1}}},{"i":496,"$":{"0":{"v":"Sec","n":1},"1":{"v":"\n\n- [10 common security gotchas in Python and how to avoid them](https://hackernoon.com/10-common-security-gotchas-in-python-and-how-to-avoid-them-e19fbe265e03)\n  - [SQL injection Cheat Sheet](https://www.netsparker.com/blog/web-security/sql-injection-cheat-sheet/)\n  \n","n":0.236}}},{"i":497,"$":{"0":{"v":"Run","n":1}}},{"i":498,"$":{"0":{"v":"Global Interpreter Lock","n":0.577},"1":{"v":"\n\n- Reference:\n  - [[Python behind the scenes 13 the GIL and its effects on Python multithreading|r.(.python-behind-the-scenes-13-the-gil-and-its-effects-on-python-multithreading]]\n\n#üå±Ô∏è\n","n":0.25}}},{"i":499,"$":{"0":{"v":"Resources","n":1},"1":{"v":"\n\n- [[assets/pdfs/2_page_python_cheatsheet.pdf]]\n- [Comprehensive Cheatsheet](https://github.com/gto76/python-cheatsheet)\n  - [[s.l.python.peps]] - [PEP's](https://www.python.org/dev/peps/)\n  - [Dev Docs](https://devdocs.io/python~3.9/)\n  - [Google's Dependency Management service](https://deps.dev/) **COMING SOON**\n","n":0.236}}},{"i":500,"$":{"0":{"v":"Python and Docker","n":0.577},"1":{"v":"\n- [scaffoldy](https://scaffoldy.io/) service to make the generation of [[s.containers.docker]] template files easier\n","n":0.289}}},{"i":501,"$":{"0":{"v":"Releases","n":1}}},{"i":502,"$":{"0":{"v":"3","n":1}}},{"i":503,"$":{"0":{"v":"10","n":1}}},{"i":504,"$":{"0":{"v":"Union Operator Type Hint","n":0.5},"1":{"v":"\n\n### Union Operator for Type Hints\n\n```python\ndef add(x: int | float, y: int | float):\n\treturn x + y\n```\n","n":0.243}}},{"i":505,"$":{"0":{"v":"Structural Pattern Matching","n":0.577},"1":{"v":"\n\n## Structural Pattern Matching\n\n#### From\n\n```python\nname = input() \nmatch name: \n\tcase \"Misha\": \n\t\treturn \"Hello Misha\" \n\tcase \"John\": \n\t\treturn \"Hello John\" \n\tcase _: \n\t\treturn \"Go away\"\n```\n\n#### To\n\n```python\nmatch name: \n\tcase \"Misha\" | \"John\": \n\t\treturn f\"Hello {name}\" \n\tcase \"Michelle\": \n\t\treturn \"Long time no see, Michelle\" \n\tcase _: \n\t\treturn \"Go away\"\n```\n\n- Add Additional Conditions on matches with `if`\n\n```python\n\ndef get_car_price(make, is_turbocharged): \n\tmatch make: \n\tcase \"Subaru\" if is_turbocharged: \n\t\treturn 10000 \n\tcase \"Toyota\" if not is_turbocharged: \n\t\treturn 7500 \n\tcase _: \n\t\treturn 2300\n```\n\n- [Video on Pattern Matching](https://youtu.be/-79HGfWmH_w)\n","n":0.113}}},{"i":506,"$":{"0":{"v":"Parenthesized Context Managers","n":0.577},"1":{"v":"\n\n### Parenthesized Context Managers\n\n```python\nwith (open('file1.txt', 'r') as fin, open('file2.txt', 'w') as fout):\n\tfout.write(fin.read()) \n# In essence: cat file1.txt > file2.txt \n# if file2 were in append mode 'a' then it would be like: \n# cat file1.txt >> file2.txt\n```\n","n":0.164}}},{"i":507,"$":{"0":{"v":"Quirks","n":1}}},{"i":508,"$":{"0":{"v":"Whitespace and Line Terminations","n":0.5},"1":{"v":"\n\n- Python uses whitespace indentation to denote scope without braces.\n- It is bad practice to:\n  - Use tabs instead of spaces üò≠\n  - mix whitespace types (tabs with spaces)\n- line termination in python files is denoted with the standard `\\n`\n  - however early on in python to aid in transitions from [[s.l.clang]] languages there is an optional usage of `;` especially to end a line and have multiple statements on a single line like this:\n    - `import datetime; print(f'{datetime.datetime.utcnow():%Y-%m-%d}')`\n\n---\n\n- Related:\n  - [[r.(.2021.12.13.the-secret-world-of-newline-characters]]\n\n","n":0.11}}},{"i":509,"$":{"0":{"v":"Dunder Methods","n":0.707}}},{"i":510,"$":{"0":{"v":"Resources","n":1},"1":{"v":"\n\n## Resources\n\n- [What's the meaning of underscores in Python variable names][0]\n- [Special Attributes][1]\n- [Dunder/Magic Methods in Python][2]\n\n[0]: https://youtu.be/ALZmCy2u0jQ\n[1]: https://docs.python.org/3/reference/datamodel.html#:~:text=formal%20parameter%20list.-,Special%20attributes%3A,-Attribute\n[2]: https://www.section.io/engineering-education/dunder-methods-python/\n","n":0.224}}},{"i":511,"$":{"0":{"v":"In Oop","n":0.707},"1":{"v":"\n\n### In OOP Code\n\n> items can have their operations, `__add__` == `( + )` have their operations of arithmatic assignments `__iadd__` == `( += )` and If one of those methods does not support the operation with the supplied arguments, it should return `NotImplemented` == `__radd__`.\n\n- `__add__` == `( + )` [[s.l.python.quirks.dunder-methods.in-oop.__add__]]\n- `__sub__` == `( - )`\n- `__mul__` == `( * )`\n- `__matmul__` == `( @ )`\n- `__truediv__` == `( \\ )`\n- `__floordiv__` == `( \\\\ )`\n- `__mod__` == `( % )`\n- `__divmod__` == `divmod()`\n- `__pow__` == `( ** )`\n- `__lshift__` == `( << )`\n- `__rshift__` == `( >> )`\n- `__and__` == `( & )`\n- `__xor__` == `( ^ )`\n- `__or__` == `( | )`\n- `__lt__` == `( < )`\n- `__le__` == `( <= )`\n- `__eq__` == `( == )`\n- `__ne__` == `( != )`\n- `__gt__` == `( > )`\n- `__ge__` == `( >= )`\n- `__neg__` == `( - )`\n- `__pos__` == `( + )`\n- `__abs__` == `abs()`\n- `__invert__` == `( ~ )`\n- `__complex__` == `complex()`\n- `__int__` == `int()`\n- `__float__` == `float()`\n- `__index__` [https://docs.python.org/3/reference/datamodel.html#object.\\_\\_index\\_\\_](https://docs.python.org/3/reference/datamodel.html#object.__index__)\n- `__round__` == `round()`\n- `__trunc__` == `math.trunc()`\n- `__floor__` == `math.floor()`\n- `__ceil__` == `math.ceil()`\n- [[s.l.python.quirks.dunder-methods.in-oop.dictionary-dunders]]\n  - `__setitem__` When assigning values in a dictionary\n  - `__getitem__` Executed when we run the `dict['key']` type of operation\n  - `__delitem__` ran when deleting a dictionary value `del dict['key']`\n  - `__contains__` Executed when we run the `in` operator `if item in class_instance:`\n  - `__len__` Is called if we ran a `len()` operation on our class instance \n- `__call__` if `instance = Class()` then `__call__` is ran when we do: `instance()` right after\n- `__init__` init function is run as soon as a class instance is generated. It's the constructor.\n- `__post_init__` used in [[s.l.python.oop.data-classes]] for after `__init__` as thats overwritten by data class\n- `__getattr__` Called when the default attribute access fails with an AttributeError\n- `__getattribute__` Called unconditionally to implement attribute accesses for instances of the class. \n  - If the class also defines `__getattr__()`, the latter will not be called unless \n    - `__getattribute__()` either calls it explicitly or raises an AttributeError.\n- `__setattr__` Called when an attribute assignment is attempted. \n  - This is called instead of the normal mechanism (i.e. store the value in the instance dictionary).\n- `__delattr__` Like `__setattr__()` but for attribute deletion instead of assignment. \n  - This should only be implemented if `del obj.name` is meaningful for the object.\n- `__dir__` Called when `dir()` is called on the object. A sequence must be returned. \n  - dir() converts the returned sequence to a list and sorts it.\n- `__format__` when the class is being formatted in an fstring for with `.format()`\n- `__bool__` [https://docs.python.org/3/reference/datamodel.html#object.\\_\\_bool\\_\\_](https://docs.python.org/3/reference/datamodel.html#object.__bool__)\n- `__del__` The destructor of the class and what runs when attempting to `del instance`\n- `__bytes__` Computes a byte-string representation of an object. This should return a bytes object.\n- `__format__` produces a ‚Äúformatted‚Äù string representation of an object.\n- `__hash__` [https://docs.python.org/3/reference/datamodel.html#object.\\_\\_hash\\_\\_](https://docs.python.org/3/reference/datamodel.html#object.__hash__)\n- `__repr__` Returns a representation of an object instance as a string [[s.l.python.quirks.dunder-methods.in-oop.__repr__]]\n- `__str__` when not defined it calls `__repr__` by default to represent the instance as a string [[s.l.python.quirks.dunder-methods.in-oop.__str__]]\n- `__unicode__` New preferred method compared to `__str__` in python 2\n  - Python 3 uses unicode and therefore defaults to the `__str__` method \n- `__enter__` Enter the runtime context related to this object using the `with` statement\n- `__exit__` Exit the runtime context related to this object\n- `__reversed__` not used with slice `[::-1]` but rather with `reversed()`\n- `__slots__` <https://medium.com/@stephenjayakar/a-quick-dive-into-pythons-slots-72cdc2d334e>\n","n":0.042}}},{"i":512,"$":{"0":{"v":"Dictionary Dunders","n":0.707},"1":{"v":"\n\n```python\nclass softwares:\n    names = []\n    versions = {}\n\t\n\tdef __init__(self, names):\n\t\tprint(\"running init method\")\n\t\tif names:\n\t\t\tself.names = names.copy()\n\t\t\tfor name in names:\n\t\t\t\tself.versions[name] = 1\n\t\telse:\n\t\t\traise Exception(\"Please Enter the names\")\n\t\n\tdef __setitem__(self, name, version):\n        print(\"running set item\")\n        if name in self.versions:\n            self.versions[name] = version\n        else:\n            raise Exception(\"Software Name doesn't exist\")\n    def __getitem__(self,name):\n        print(\"running get item\")\n        if name in self.versions:\n            return self.versions[name]\n        else:\n            raise Exception(\"Software Name doesn't exist\")\n\tdef __delitem__(self,name):\n\t\tprint(\"running del item\")\n\t\tif name in self.versions:\n\t\t\tdel self.versions[name]\n\t\t\tself.names.remove(name)\n\t\telse:\n\t\t\traise Exception(\"Software Name doesn't exist\")\n\tdef __len__(self):\n    \treturn len(self.names)\n\tdef __contains__(self,name):\n\t\tif name in self.versions:\n\t\t\treturn True\n\t\telse:\n\t\t\treturn False\n#==========================================================================#\np = softwares(['S1','S2','S3'])\np['S1'] = 2 # assigning values to a dictionary is when the __setitem__ dunder is invoked\np['2'] = 2 # assigning values to a dictionary is when the __setitem__ dunder is invoked\n \nprint(p['S1']) # using the brackets to access a dict value runes the __getitem__ method\nprint(p['2']) # using the brackets to access a dict value runes the __getitem__ method\n# print(p['1']) # throws exception\ndel p['S1']  # deleting a dictionary key/val pair runs the __delitem__ method\nlen(p) # runs the class's __len__ method\nif 'S2' in p: # this usage of the `in` operator uses the __contains__ function\n\tprint('found!')\n\t\n```\n","n":0.076}}},{"i":513,"$":{"0":{"v":"__str__","n":1},"1":{"v":"\n\n```python\nclass MyClass:\n    x = 0\n    y = \"\"\n\n    def __init__(self, anyNumber, anyString):\n        self.x = anyNumber\n        self.y = anyString\n\nmyObject = MyClass(12345, \"Hello\")\n\nprint(myObject.__str__())\nprint(myObject.__repr__())\nprint(myObject)\n\n# >>> <__main__.MyClass object at 0x7f75d994f1f0>\n# >>> <__main__.MyClass object at 0x7f75d994f1f0>\n# >>> <__main__.MyClass object at 0x7f75d994f1f0>\n\n#==========================================================================#\n\nclass MyClass:\n    x = 0\n    y = \"\"\n\n    def __init__(self, anyNumber, anyString):\n        self.x = anyNumber\n        self.y = anyString\n    def __str__ (self):\n        return 'MyClass(x=' + str(self.x) + ' ,y=' + self.y + ')'\nmyObject = MyClass(12345, \"Hello\")\n\nprint(myObject.__str__())\nprint(myObject)\nprint(str(myObject))\nprint(myObject.__repr__())\n\n# >>> MyClass(x=12345 ,y=Hello)\n# >>> MyClass(x=12345 ,y=Hello)\n# >>> MyClass(x=12345 ,y=Hello)\n# >>> <__main__.MyClass object at 0x7f8f023ef1f0>\n\n#==========================================================================#\n\nclass MyClass:\n    x = 0\n    y = \"\"\n\n    def __init__(self, anyNumber, anyString):\n        self.x = anyNumber\n        self.y = anyString\n    def __repr__ (self):\n        return 'MyClass(x=' + str(self.x) + ' ,y=' + self.y + ')'\nmyObject = MyClass(12345, \"Hello\")\n\nprint(myObject.__str__())\nprint(myObject)\nprint(str(myObject))\nprint(myObject.__repr__())\n\n# >>> MyClass(x=12345 ,y=Hello)\n# >>> MyClass(x=12345 ,y=Hello)\n# >>> MyClass(x=12345 ,y=Hello)\n# >>> MyClass(x=12345 ,y=Hello)\n```\n","n":0.088}}},{"i":514,"$":{"0":{"v":"__repr__","n":1},"1":{"v":"\n\n```python\n# A simple Person class\n\nclass Person:\n    def __init__(self, name, age):\n        self.name = name\n        self.age = age\n\n    def __repr__(self):\n        rep = 'Person(' + self.name + ',' + str(self.age) + ')'\n        return rep\n\n\n# Let's make a Person object and print the results of repr()\n\nperson = Person(\"John\", 20)\nprint(repr(person))\n# >>> Person(John,20)\n```\n","n":0.146}}},{"i":515,"$":{"0":{"v":"__new__","n":1},"1":{"v":"\n```python\nclass A:\n    def __new__(cls, *args, **kwargs):\n        print ('new', cls, args, kwargs)\n        return super().__new__(cls)\n    def __init__(self, *args, **kwargs):\n        print ('init', self, args, kwargs)\n\nx = A()\n```\n\n`__new__` allows you to modify immutable types before the object instance is created. `__new__` occurs before `__init__` so things like this are possible:\n\n```python\nclass Uppercase Tuple(tuple):\n    def __new__(cls, iterable):\n        upper_iterable = (s.upper() for s in iterable)\n        return super().__new__(cls, upper_iterable)\n```\n\nWhereas this was not possible because the class object already exists even if the instance doesnt yet exist. the OBJECT is what we're trying to beat to the punch\n\n```python\nclass Uppercase Tuple(tuple):\n    def __init__(self, iterable):\n        print (f'init {iterable}')\n        for i, arg in enumerate (iterable):\n            self[i] = arg. upper()\n```\n","n":0.097}}},{"i":516,"$":{"0":{"v":"__add__","n":1},"1":{"v":"\n\n```python\nclass point:\n    x = None\n    y = None\n    \n    def __init__(self, x , y):\n        self.x = x\n        self.y = y\n    \n    def __str__(self):\n        s = f'({self.x},{self.y})'\n        return s\n\n\tdef __add__(self, p2):\n\t\tx = self.x + p2.x\n\t\ty = self.y + p2.y\n\t\treturn point(x,y)\n\t\n\tdef __iadd__(self, p2):\n\t\tself.x += p2.x\n\t\tself.y += p2.y\n\t\treturn self\n\np1 = point(5,4)\np2 = point(2,3)\n\np3 = p1 + p2 # this runs the __add__ method\n# >>> p3 = (7,7)\n\np1 += p2\n# >>> p1 = (7,7)\n```\n","n":0.12}}},{"i":517,"$":{"0":{"v":"In Files","n":0.707}}},{"i":518,"$":{"0":{"v":"__main__","n":1},"1":{"v":"\n\n- `__main__.py`\n  - When there is a file with this name in a module folder it makes it so that you dont have to explicitly point to a script to run the module.\n    - instead of: `python repo/script.py`\n    - it can just be `python repo`\n","n":0.149}}},{"i":519,"$":{"0":{"v":"__init__","n":1},"1":{"v":"\n\n- `__init__.py`\n  - Determines what happens when the directory it's in is imported as a package\n","n":0.25}}},{"i":520,"$":{"0":{"v":"In Code","n":0.707}}},{"i":521,"$":{"0":{"v":"Variable Names","n":0.707},"1":{"v":"\n\n### Variable Names\n\n- Name a private identifier with a leading underscore ( `_username`)\n  - These items are not meant to be part of the public interface\n  - They may just be managing some part of internal state\n  - **CAN** be accessed via `obj._method_` but items flow to the bottom of the suggestions\n- Name a strongly private identifier with two leading underscores (`__password`)\n  - when viewing objects `dir(obj)` these methods are not depicted as\n    - `__method`\n  - But rather as `_obj__method`\n    - This prevents collisions when in a subclass from `obj` wanting to re-use the `__method`name\n  - **CANNOT** be accessed via `obj.__method` an AttributeError will be thrown and cant be found\n    - Only way to find it is with the mangled name: `instance._obj__method` but not recommended\n- Special identifiers in Python end with two leading underscores.\n  - _A.K.A. Dunder methods (double under-score)_ `__main__`\n","n":0.084}}},{"i":522,"$":{"0":{"v":"General","n":1},"1":{"v":"\n\n### In General Code\n\n- `__annotations__` gets a returned dictionary of type annotations for the object\n- `class.__bases__` The tuple of base classes of a class object.\n- `__builtins__` <https://newbedev.com/python-what-s-the-difference-between-builtin-and-builtins>\n- `__cached__`  is the path to any compiled version of the code\n- `instance.__class__` The class to which a class instance belongs.\n- _R_ `__closure__` `None` or a tuple of cells that contain bindings for the function‚Äôs free variables.\n- `__code__` The code object representing the compiled function body.\n- `__defaults__` A tuple containing default args values for those args that have defaults, or `None`\n- `object.__dict__` The namespace supporting arbitrary function attributes.\n- `__doc__` The function‚Äôs documentation string, or None if unavailable; not inherited by subclasses.\n- `__file__` The absolute path to the file that the code currently executing is within\n- _R_ `__globals__` A reference to the dict that holds the function‚Äôs global vars \n  - the global namespace of the module in which the function was defined.\n- `__import__` will return the top level module of a package, unless you pass a nonempty `fromlist` arg\n- `__kwdefaults__` A dict containing defaults for keyword-only parameters.\n- `__loader__` <https://stackoverflow.com/questions/22185888/pythons-loader-what-is-it>\n- `__main__` The Entry point to a program, used in `if __name__ == \"__main__\":`\n- `__module__` The name of the module the function was defined in, or None if unavailable.\n- `__mro__` [https://docs.python.org/3/library/stdtypes.html#class.\\_\\_mro\\_\\_](https://docs.python.org/3/library/stdtypes.html#class.__mro__)\n- `__name__` The function‚Äôs name. same as `__qualname__` but not showing the parents\n- `__package__` <https://stackoverflow.com/a/21233334/12339658>\n- `__path__` <https://stackoverflow.com/a/2700924/12339658>\n- `__qualname__` A dotted name showing the ‚Äúpath‚Äù from the global scope to an item in that module\n- `__spec__` `None` in `__main__` or interactive mode otherwise, information about the module\n- `class.__subclasses__()` Returns a list of weak references to its immediate alive subclasses.\n","n":0.062}}},{"i":523,"$":{"0":{"v":"Proj","n":1},"1":{"v":"\n\n- [[p.backlog.ftp-file-transfer-application]]\n  - [[p.backlog.make-a-discord-bot]]\n  - [Turn your Python Script into a 'Real' Program with Docker](https://python.plainenglish.io/turn-your-python-script-into-a-real-program-with-docker-c200e15d5265)\n    - [Project Repo](https://github.com/adamcyber1/mypythondocker)\n","n":0.236}}},{"i":524,"$":{"0":{"v":"Pkg","n":1},"1":{"v":"\n\n\n- Workflow\n\n\n```bash\npython -m pip install jupyterlab\npython -m jupyter lab\n```\n\n```\n%load_ext autoreload\n%autoreload 2\n```\n\n- Upload package to PyPi (Python Package Index)\n\n```bash\npython -m pip install twine wheel\n```\n\n- Documentation\n  - Create Documentation automatically. [Example config file](https://github.com/koaning/clumper/blob/main/mkdocs.yml) \\| [Explanation](https://calmcode.io/docs/mkdocs.yml.html)\n  - also [[sphinx]] and [[Restructured Text|restructured-text]]\n","n":0.16}}},{"i":525,"$":{"0":{"v":"Workflow","n":1},"1":{"v":"\n\n- Setup Git Repo and clone\n- Make directory and `*.py` file for your project name\n  - In that directory add an `__init__.py` file and in that file add code to import your desired objects from your package\n  - like \"Install module but also add to working session these objects\"\n- in the root set up a `setup.py` file\n  - This file lets the local files be installed by pip as a proper package\n- Live iteration through [[s.l.python.tools.jupyter]] lab with magics:\n\n```bash\npython -m pip install jupyterlab\npython -m jupyter lab\n```\n\n```\n%load_ext autoreload\n%autoreload 2\n```\n\n- Upload package to PyPi (Python Package Index)\n\n```bash\npython -m pip install twine wheel\n```\n","n":0.1}}},{"i":526,"$":{"0":{"v":"Resources","n":1},"1":{"v":"\n\n- [Calm Code Setup](https://calmcode.io/setup/introduction.html)\n","n":0.5}}},{"i":527,"$":{"0":{"v":"Documentation","n":1},"1":{"v":"\n\n- Create Documentation automatically. [Example config file](https://github.com/koaning/clumper/blob/main/mkdocs.yml) \\| [Explanation](https://calmcode.io/docs/mkdocs.yml.html)\n  - also [[s.l.python.libs.sphinx]] and [[s.m.restructured-text]]\n","n":0.267}}},{"i":528,"$":{"0":{"v":"Peps","n":1},"1":{"v":"\n\n> PEP stands for Python Enhancement Proposal\n\n| PEP #                                                | Subject                |\n| :--------------------------------------------------- | :--------------------- |\n| [PEP 8](https://www.python.org/dev/peps/pep-0008/)   | Code Style Conventions |\n| [PEP 282](https://www.python.org/dev/peps/pep-0282/) | Logging System         |\n| [PEP 484](https://www.python.org/dev/peps/pep-0484/) | Type Hints             |\n| [PEP 572](https://www.python.org/dev/peps/pep-0572/) | Walrus Operator `:=`   |\n","n":0.154}}},{"i":529,"$":{"0":{"v":"Oop","n":1},"1":{"v":"\n\n- Reference:\n  - [Operator Overloading](https://www.programiz.com/python-programming/operator-overloading)\n  - [[Python Data Classes|s.l.python.oop.data-classes]]\n","n":0.333}}},{"i":530,"$":{"0":{"v":"Super","n":1},"1":{"v":"\n![[r.+.2022.03.16.super-pythons-most-misunderstood-feature]]\n","n":1}}},{"i":531,"$":{"0":{"v":"Static Methods","n":0.707},"1":{"v":"\n\n## Before\n\n```python\nclass Calendar:\n    \n    def __init__(self, date):\n        self.year = date.year\n        self.month = date.month\n        self.day = date.day\n        self.weekday = date.weekday()\n    \n    \n    def is_leap_year(self):\n        return self.year % 400 == 0 or \n               (self.year % 4 == 0 and self.year % 100 != 0)\n    \n    \n    def is_weekend(self):\n        return self.weekday > 4\n```\n\n![alt](assets/images/Pasted_image_20211213151355.png)\n\nWe want to decouple the `is_weekend` and `is_leap_year` from the calendar class instance because they relate to any date not just that class instance.\n\n## After\n\n```python\nclass Calendar:\n    \n    def __init__(self, date):\n        self.year = date.year\n        self.month = date.month\n        self.day = date.day\n        self.weekday = date.weekday()\n    \n    \n    @staticmethod\n    def is_leap_year(date):\n        return date.year % 400 == 0 or \n        (date.year % 4 == 0 and date.year % 100 != 0)\n    \n    \n    @staticmethod\n    def is_weekend(date):\n        return date.weekday() > 4\n```\n\nOk, the changes are:\n\n1. Add the decorator `@staticmethod`;\n2. Rename the expected parameter to be a date object;\n3. Adjust the is_weekend function to get weekday as function and not variable.\n\nUsage:\n\n![alt](assets/images/Pasted_image_20211213151513.png)\n","n":0.081}}},{"i":532,"$":{"0":{"v":"Protocol Classes","n":0.707},"1":{"v":"\n\n## Sample Implementation\n\n> from: <https://stackoverflow.com/a/50255847/12339658>\n\n```python\nfrom typing import Protocol\n\nclass SupportsClose(Protocol):\n    def close(self) -> None:\n        # ...\n\nclass Resource:\n    # ...\n    def close(self) -> None:\n        self.file.close()\n        self.lock.release()\n\ndef close_all(things: Iterable[SupportsClose]) -> None:\n    for thing in things:\n        thing.close()\n\nfile = open('foo.txt')\nresource = Resource()\nclose_all([file, resource])  # OK!\nclose_all([1])     # Error: 'int' has no 'close' method\n```\n\n---\n\n- Related:\n  - [[s.l.python.libs.typing]]\n  - [[s.l.python.oop.abstract-base-classes]]\n\n","n":0.139}}},{"i":533,"$":{"0":{"v":"Making a Class","n":0.577},"1":{"v":"\n\n## Making A Class\n\n```python\nclass User\n\tdef say_hi(self):\n\t\tprint(\"Hi!\")\n\nMy_User = User()\nMy_User.say_hi()\n#>>> \"Hi!\"\n```\n","n":0.333}}},{"i":534,"$":{"0":{"v":"Initializing","n":1},"1":{"v":"\n\n## Initializing A Class\n\n```python\nclass User\n\tdef __init__(self):\n\t\tprint(\"I Live!\")\n\nMy_User = User()\n#>>> \"I Live!\"\n```\n","n":0.302}}},{"i":535,"$":{"0":{"v":"Deleting a Class","n":0.577},"1":{"v":"\n\n## Deleting A Class Instance\n\n```python\nclass User\n\tdef __init__(self):\n\t\tprint(\"I Live!\")\n\tdef say_hi(self):\n\t\tprint(\"Hi!\")\n\nMy_User = User()\n#>>> \"I Live!\"\nMy_User.say_hi()\n#>>> \"Hi!\"\nMY_User\n#>>> <__main__.User object at 0x000001BF37B38D30>\ndel My_User\nMy_User\n#>>> Traceback (most recent call last):\n#>>>   File \"<stdin>\", line 1, in <module>\n#>>> NameError: name 'My_User' is not defined\n```\n","n":0.167}}},{"i":536,"$":{"0":{"v":"Data Classes","n":0.707},"1":{"v":"\n\n- [x] [If you're not using Python DATA CLASSES yet, you should üöÄ](https://youtu.be/vRVVyl9uaZc)\n- <https://youtu.be/CvQ7e6yUtnw>\n\n```python\n# Regular classes\nclass Person:\n\tname: str\n\tjob: str\n\tage: int\n\t\n\tdef __init__(self, name, job, age)\n\t\tself.name = name\n\t\tself.job = job\n\t\tself.age = age\n\t\t\nperson1 = Person(\"Geralt\", \"Witcher\", 30)\nperson2 = Person(\"Yennefer\", \"Sorceress\", 25)\nperson3 = Person(\"Yennefer\", \"Sorceress\", 25)\n\nprint(id(person2))\nprint(id(person3))\nprint(person1)\n\nprint(person3 == person2)\n\n# Data Class\nfrom dataclasses import dataclass, field\n\n@dataclass(order=True,frozen=False)\nclass Person:\n    sort_index: int = field(init=False, repr=False)\n    name: str\n    job: str\n    age: int\n    strength: int = 100\n\n    def __post_init__(self):\n        object.__setattr__(self, 'sort_index', self.strength)\n\n    def __str__(self):\n        return f'{self.name}, {self.job} ({self.age})'\n\n\nperson1 = Person(\"Geralt\", \"Witcher\", 30, 99)\nperson2 = Person(\"Yennefer\", \"Sorceress\", 25)\nperson3 = Person(\"Yennefer\", \"Sorceress\", 25)\n\nprint(person1)\nprint(id(person2))\nprint(id(person3))\nprint(person3 == person2)\nprint(person1 > person2)\n```\n\n```python\n@dataclass\nclass Person:\n    name: str\n    address: str\n    active: bool = True\n    email_addresses: list[str] = field(default_factory=list)\n    id: str = field (init=False, default_factory=generate_id)\n    _search_string: str = field(init=False)\n    def __post_init__(self) None:\n        self. _search_string = f\" {self.name} {self.address}\"\n```\n","n":0.089}}},{"i":537,"$":{"0":{"v":"Pydantic Type Hints","n":0.577},"1":{"v":"\n\n## Pydantic for Data Class Type Hints\n\n> [Do we still need dataclasses? // PYDANTIC tutorial](https://youtu.be/Vj-iU-8_xLs)\n> Source: <https://pydantic-docs.helpmanual.io/>\n\n```python\nfrom datetime import datetime\nfrom typing import List, Optional\nfrom pydantic import BaseModel\n\n\nclass User(BaseModel):\n    id: int\n    name = 'John Doe'\n    signup_ts: Optional[datetime] = None\n    friends: List[int] = []\n\n\nexternal_data = {\n    'id': '123',\n    'signup_ts': '2019-06-01 12:22',\n    'friends': [1, 2, '3'],\n}\nuser = User(**external_data)\nprint(user.id)\n#> 123\nprint(repr(user.signup_ts))\n#> datetime.datetime(2019, 6, 1, 12, 22)\nprint(user.friends)\n#> [1, 2, 3]\nprint(user.dict())\n\"\"\"\n{\n    'id': 123,\n    'signup_ts': datetime.datetime(2019, 6, 1, 12, 22),\n    'friends': [1, 2, 3],\n    'name': 'John Doe',\n}\n\"\"\"\n```\n","n":0.113}}},{"i":538,"$":{"0":{"v":"Benefits","n":1},"1":{"v":"\n\n### Benefits\n\n> **The benefits of using it and when to use it.**\n> The most important to take from this decorator is the purpose of using it.\n> You should consider this decorator when writing any function that you believe is connected to the ‚Äúsubject‚Äù or the class that you are using but do not necessarily need that ‚Äúsubject‚Äù or class where you created the function.\n> By doing this you can decouple the function itself, but still, keep it organized and with a clear meaning for which purpose can be used.\n> From now on, any piece of code that you want to be reusable, but, at the same time you want to make it clear the ‚Äúmeaning‚Äù of when or how it could be used you should consider using this decorator.\n","n":0.088}}},{"i":539,"$":{"0":{"v":"Abstract Base Classes","n":0.577},"1":{"v":"\n\n> you should use abstract classes to specify which methods must be implemented by the child classes. The abc module \"make sure\" that you implement all those methods before being able to instantiate the objects.\n\n```python\ndef animate(animal):\n\tprint(animal.get_sound())\n\tfor leg in animal.legs_number:\n\t\tprint(\"Moving leg\", leg)\n\tprint(\"Moved!\")\n```\n\n```python\nfrom abc import ABC, abstractmethod\n \nclass Animal(ABC):\n\t\n\t@abstractmethod\n\tdef get_sound(self) -> str:\n\t\tpass\n\t\n\t@property #  you need to add the @propertydecorator both in the abstract class and in every sub-class.\n\t@abstractmethod\n\tdef legs_number(self) -> int:\n\t\tpass\n \n# >>>a = Animal()\n# Traceback (most recent call last):\n#   File \"c:\\abstract_class.py\", line 9, in <module>\n#     a = Animal()\n# TypeError: Can't instantiate abstract class Animal with abstract method get_sound\n \nclass Cat(Animal):\n\t\n\tdef get_sound(self) -> str:\n\t\treturn \"Meow\"\n\t\n\t@property #  you need to add the @propertydecorator both in the abstract class and in every sub-class.\n\tdef legs_number(self) -> int:\n  \t\treturn 4\n \n# >>> a = Cat()\n# >>> a.get_sound()\n# Meow\n \n```\n\n---\n\n- Reference:\n  - [[r.(.2021.11.10.level-up-your-python-code-with-abstract-classes]]\n\n","n":0.086}}},{"i":540,"$":{"0":{"v":"Mem Mgmt","n":0.707}}},{"i":541,"$":{"0":{"v":"Machine Learning","n":0.707},"1":{"v":"\n\n- [perceptilabs](https://www.perceptilabs.com/papers)\n  - Model Building Steps:\n\n1. _Define_: What type of model will it be? A decision tree? Some other type of model? Some other parameters of the model type are specified too.\n2. _Fit_: Capture patterns from provided data. This is the heart of modeling.\n3. _Predict_: Just what it sounds like\n4. _Evaluate_: Determine how accurate the model's predictions are.\n","n":0.131}}},{"i":542,"$":{"0":{"v":"Libs","n":1}}},{"i":543,"$":{"0":{"v":"Yarl","n":1},"1":{"v":"\n\n- [yarl.py](https://calmcode.io/shorts/yarl.py.html)\n\n","n":0.707}}},{"i":544,"$":{"0":{"v":"Workalendar","n":1},"1":{"v":"\n\n\n```python\nfrom datetime import date\nfrom workalendar.europe import Netherlands\n\ncal = Netherlands(include_carnival=True)\ncal.holidays(2021)\n```\n\n```python\n[(datetime.date(2021, 1, 1), 'New year'),\n (datetime.date(2021, 2, 14), 'Carnival'),\n (datetime.date(2021, 2, 15), 'Carnival'),\n (datetime.date(2021, 2, 16), 'Carnival'),\n (datetime.date(2021, 4, 2), 'Good Friday'),\n (datetime.date(2021, 4, 4), 'Easter Sunday'),\n (datetime.date(2021, 4, 5), 'Easter Monday'),\n (datetime.date(2021, 4, 27), \"King's day\"),\n (datetime.date(2021, 5, 5), 'Liberation Day'),\n (datetime.date(2021, 5, 13), 'Ascension Thursday'),\n (datetime.date(2021, 5, 23), 'Whit Sunday'),\n (datetime.date(2021, 5, 24), 'Whit Monday'),\n (datetime.date(2021, 12, 25), 'Christmas Day'),\n (datetime.date(2021, 12, 26), 'Boxing Day')]\n```\n\nYou can also check if a date is a \"working date\" directly.\n\n```python\ncal.is_working_day(date(2020, 12, 23)) # True\ncal.is_working_day(date(2020, 12, 25)) # False\n```\n\nAnother useful function is to check the number of working days between two dates.\n\n```python\ncal.get_working_days_delta(date(2018, 4, 2), date(2018, 6, 17))\n```\n\nA common use-case for this package will be to use it together with [[pandas|s.l.python.libs.pandas]], so we've added a demo snippet below that shows you the fast way to check if a date is a holiday.\n\n```python\nimport pandas as pd\n\n# Make a pandas series with holidays of interest\nholidates = cal.holidays(2020) + cal.holidays(2021) + cal.holidays(2022)\npd_holidays = pd.to_datetime([d[0] for d in holidates])\n\n# Use vectorised (fast!) .isin method to compare dates\ndf = pd.DataFrame({\"date\": pd.date_range(start='2020-01-01', end='2022-01-01')})\ndf.assign(holiday=lambda d: d['date'].isin(pd_holidays)).loc[lambda d: d['holiday']]\n```\n\n---\n\n- Tags: \n  - [[datetime|s.l.python.libs.datetime]]\n  - [[time series|time-series]]\n- Reference:\n  - <https://calmcode.io/shorts/workalendar.py.html>\n- Related:\n  - [[pandas|s.l.python.libs.pandas]]\n\n","n":0.071}}},{"i":545,"$":{"0":{"v":"Watermark","n":1},"1":{"v":"\n\n- used in [[jupyter|s.l.python.tools.jupyter]] to grab system and package info:\n  - In a jupyter cell:\n\n```python\npip install watermark\n%load_ext watermark\n%watermark?\n%watermark --machine --python --packages black,flake8,isort\n```\n","n":0.213}}},{"i":546,"$":{"0":{"v":"Watchdog","n":1}}},{"i":547,"$":{"0":{"v":"Venv","n":1},"1":{"v":"\n\n- **Python Virtual Environments**\n  - **What are they**\n    - a place to install packages that are specific to a certain project\n      - also like [[s.l.r.libraries.packrat]] where you want to use a specific older version of a package in a snapshot\n  - **How to use them**\n    - A good module to use for this is the `venv` module\n    - `python3 -m venv project_env`\n      - make a new project in a virtual environment\n    - `python3 -m venv projects/env_name`\n      - Makes multiple environments for different projects but all in a single overarching directory\n    - `source project_env/bin/activate`\n      - activates it\n      - if on windows in power shell its `& project_env/scripts/activate.ps1`\n    - `which python`\n      - confirms usage by\n    - `pip list`\n      - in the venv if you this command it will show you all the installed packages (only pip and setup tools) installed packages will now be stored here\n    - `pip freeze`\n      - Gets a list of the packages to send for reproducible analysis\n      - and the output can go to _requirements.txt_\n    - `deactivate`\n      - to deactivate the venv\n    - `pip install -r requrirements.txt`\n      - To take a new virtual environment and install a list of requirements that we exported above\n  - **Package Management**\n    - `python3 -m venv venv --system-site-packages`\n      - Create a venv with access to the system global packages for python from within a virtual environment\n      - the difference is that now you copied your system packages to the venv but new installs will only go into the venv until you remove it\n    - `pip list --local`\n      - to see packages that are only installed in the venv and not the system\n    - `pip freeze --local`\n      - same logic as above\n  - **Information**\n    - You can put your virtual environment into the project folder but you dont want to put your project files into the venv as the venv is just the place where execution is taking place, your working files should be in your project directory.\n    - the venv's are meant to be disposable and easy to throw away so no project files in them.\n    - Never commit your venv's to source control, put them in gitignore\n    - but what you would commit to source control is the _requirements.txt_ doc\n","n":0.052}}},{"i":548,"$":{"0":{"v":"Vulture","n":1},"1":{"v":"\n\n- find dead code in python!\n- Can also be used as a [[s.l.python.libs.pre-commit]] [[Git|cli.cmd.git]] hook to run before each `git commit` command\n\n","n":0.213}}},{"i":549,"$":{"0":{"v":"Virtualenv","n":1},"1":{"v":"\n\n![alt](assets/images/Pasted_image_20210915142429.png)\n\nfrom [TUTORIAL / Bern√°t Gabor / Python Packaging Demystified](https://youtu.be/ApDThpsr2Fw?list=PL2Uw4_HvXqvYk1Y5P8kryoyd83L_0Uk5K)\n","n":0.333}}},{"i":550,"$":{"0":{"v":"Unittest","n":1}}},{"i":551,"$":{"0":{"v":"Typing","n":1},"1":{"v":"\n\n- To do a type annotation for items in a list (a vector basically) you can pass the type like `list[int]` but this can also be used to pass things like a list of int lists: `list[list[int]]`\n- But now in newer versions of python you can just use the built in types\n  - To use `List` as a type you need to `from typing import List` : `List[List[int]]`\n  - Dictionary typing: `x: Dict[str, str] = {\"a\": \"b\"}`\n    - `from typing import Dict`\n  - Set typing: `x: Set[str] = {\"a\", \"b\"}`\n    - `from typing import Set`\n  - Now all of these are available as `set` `dict` `list`\n\n---\n\n- Reference:\n  - [[r.+.2021.12.15.python-typing-type-hints-and-annotations]]\n- Related:\n  - [[s.l.python.oop.protocol-classes]]\n\n","n":0.094}}},{"i":552,"$":{"0":{"v":"Tuple","n":1},"1":{"v":"\n\n### Tuple Type:\n\n```python\nfrom typing import Tuple\n\n# This is an error because the tuple can contain items of differing types \n# so you need to specify the type of each item within it\nx: Tuple[int] = (1, 2, 3) \n\nx: Tuple[int, int, int] = (1, 2, 3)\n```\n","n":0.149}}},{"i":553,"$":{"0":{"v":"Sequence","n":1},"1":{"v":"\n\n### Sequence Type\n\n```python\nfrom typing import Sequence\n\ndef foo(seq: Sequence[str]):\n\tpass\nfoo(\"Hello\") # This is fine because a string is a sequence of characters\nfoo((\"a\", \"b\", \"c\")) # a Tuple is an ordered and immutable indexed Object\nfoo([\"a\", \"b\", \"c\"]) # A list is an ordered and indexed object \nfoo({1, 2, 3}) # A set is hashed and not indexed or ordered so it cannot be a sequence\nfoo(1)\n#>>> Last one throws an error because static analysis determines that it is an incompabile type\n```\n","n":0.114}}},{"i":554,"$":{"0":{"v":"Optional","n":1},"1":{"v":"\n\n### Optional typing\n\n```python\nfrom typing import Optional\n\ndef foo(output: Optional[bool]=False):\n\tpass\nfoo()\n```\n","n":0.354}}},{"i":555,"$":{"0":{"v":"Generics","n":1},"1":{"v":"\n\n### Generics:\n\n```python\nfrom typing import TypeVar, List\n\nT = TypeVar('T')\n\ndef get_item(lst: List[T], index: int) -> T:\n\treturn lst[index]\n```\n","n":0.258}}},{"i":556,"$":{"0":{"v":"Custom","n":1},"1":{"v":"\n\n### Custom Typing:\n\n```python\nfrom typing import List\n\nVector = List[float]\t\n\ndef foo(v: Vector) -> Vector:\n\tprint(v)\n```\n\n![alt](assets/images/Pasted_image_20211215085306.png)\n\nCan also use our own custom types like this: \n\n```python\nfrom typing import List\n\nVector = List[float]\nVectors = List[Vector]\n\ndef foo(v: Vectors) -> Vectors:\n\tprint(v)\n```\n","n":0.177}}},{"i":557,"$":{"0":{"v":"Callable","n":1},"1":{"v":"\n\n### Callable Type:\n\n```python\nfrom typing import callable, Optional\n\ndef foo(func: Callable[[int, int, Optional[int]], int]) -> None:\n\tfunc(1, 2)\n\ndef add(x: int, y: int) -> int:\n\treturn x + y\n\nfoo(add)\n\n#=================================================================#\n\ndef foo() -> Callable[[int, int, Optional[int]], int]):\n\tdef add(x: int, y: int) -> int:\n\t\treturn x + y\n\treturn add\n\nfoo()\n\n#=================================================================#\n\ndef foo() -> Callable[[int, int], int]):\n\tfunc: Callable[[int, int], int]) = Lambda x, y: x + y\n\treturn func\n\nfoo()\n```\n","n":0.134}}},{"i":558,"$":{"0":{"v":"Any","n":1},"1":{"v":"\n\n### Any Type is the same as not adding an annotation but more explicit\n\n```python\nfrom typing import Any\n\ndef foo(output: Any):\n\tpass\n```\n","n":0.229}}},{"i":559,"$":{"0":{"v":"Tqdm","n":1},"1":{"v":"\n\n- [GitHub Repo](https://github.com/tqdm/tqdm) \\| [Docs](https://tqdm.github.io/) \\| [Calm Code tqdm](https://calmcode.io/tqdm/making-a-progress-bar.html)\n- Wrap an itterable in the function for an aesthetic progress bar:\n\n```python\nimport this\nimport tqdm\n\nfor i in tqdm.tqdm(range(100), desc=\" first loop\"):\n  time.sleep(0.02)\n\nfor i in tqdm.tqdm(range(100), desc=\" second loop\"):\n  time.sleep(0.02)\n\nprint(\"done!\")\n```\n\n- Nested Loops\n\n```python\nimport this\nimport tqdm\n\nfor outer in tqdm.tqdm([10, 20, 30, 40, 50], desc=\" outer\", position=0):\n  for inner in tqdm.tqdm(range(outer), desc=\" inner loop\", position=1, leave=False):\n\t  time.sleep(0.05)\nprint(\"done!\")\n```\n","n":0.129}}},{"i":560,"$":{"0":{"v":"Tkinter","n":1}}},{"i":561,"$":{"0":{"v":"Resources","n":1},"1":{"v":"\n\n## Resources\n\n- [TKinter Designer](https://github.com/ParthJadhav/Tkinter-Designer)\n- [Keeping packaged TKinter app icons available](https://realpython.com/python-import/#example-add-icons-to-tkinter-guis)\n","n":0.316}}},{"i":562,"$":{"0":{"v":"Textual","n":1},"1":{"v":"\n\n- Reference: [This Tweet](https://twitter.com/simonw/status/1406336417500860423)\n\n```bash\npip install textual\npython -m textual.app\n```\n\n- Windows Error:\n\n```\nTraceback (most recent call last):\nFile \"C:\\Users\\bjenks\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n  return _run_code(code, main_globals, None,\nFile \"C:\\Users\\bjenks\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 87, in _run_code\n  exec(code, run_globals)\nFile \"C:\\Users\\bjenks\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\textual\\app.py\", line 19, in <module>\n  from .driver import Driver\nFile \"C:\\Users\\bjenks\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\textual\\driver.py\", line 8, in <module>\n  import curses\nFile \"C:\\Users\\bjenks\\AppData\\Local\\Programs\\Python\\Python39\\lib\\curses\\__init__.py\", line 13, in <module>\n  from _curses import *\nModuleNotFoundError: No module named '_curses'\n```\n","n":0.13}}},{"i":563,"$":{"0":{"v":"Tablib","n":1},"1":{"v":"\n\n> Tablib: format-agnostic tabular dataset library\n\n\n\n```python\ndata = tablib.Dataset(headers=['First Name', 'Last Name', 'Age'])\nfor i in [('Kenneth', 'Reitz', 22), ('Bessie', 'Monke', 21)]:\n  data.append(i)\n\n\nprint(data.export('json'))\n# [{\"Last Name\": \"Reitz\", \"First Name\": \"Kenneth\", \"Age\": 22}, {\"Last Name\": \"Monke\", \"First Name\": \"Bessie\", \"Age\": 21}]\n\nprint(data.export('yaml'))\n# {Age: 22, First Name: Kenneth, Last Name: Reitz}\n# {Age: 21, First Name: Bessie, Last Name: Monke}\n\ndata.export('xlsx')\n# <redacted binary data>\n\ndata.export('df')\n#   First Name Last Name  Age\n# 0    Kenneth     Reitz   22\n# 1     Bessie     Monke   21\n```\n","n":0.12}}},{"i":564,"$":{"0":{"v":"Resources","n":1},"1":{"v":"\n\n## Resources\n\n- <https://github.com/jazzband/tablib>\n- <http://docs.python-tablib.org/en/master/>\n","n":0.5}}},{"i":565,"$":{"0":{"v":"Sys","n":1}}},{"i":566,"$":{"0":{"v":"Sqlite3","n":1},"1":{"v":"\n\n- <https://devdocs.io/python~3.9/library/sqlite3>\n\n```python\nimport sqlite3\nconn = sqlite3.connect(\"example.db\")\nc = conn.cursor()\nc.execute('create table Persons (id int, name text, city text)')\nc.execute('insert into Persons VALUES (1, \"smith\", \"dallas\")')\nconn.commit()\nconn.close()\n```\n\n```python\nimport sqlite3\nconn = sqlite3.connect('example.db')\nc = conn.cursor()\nx = c.execute(\"select * from Persons\")\nx.fetchall()\n[(1, u'smith', u'dallas')]\n```\n","n":0.174}}},{"i":567,"$":{"0":{"v":"Tools","n":1},"1":{"v":"\n\n- <https://sqlitebrowser.org/>\n","n":0.707}}},{"i":568,"$":{"0":{"v":"CLI","n":1},"1":{"v":"\n\n## Scripting with sqlite3 on the cli\n\n```bash\nsqlite3 database.db < file.sql\n```\n","n":0.316}}},{"i":569,"$":{"0":{"v":"Sql Alchemy","n":0.707},"1":{"v":"\n\n- Working with a [[s.l.python.libs.sqlite3]] database using sql alchemy\n\n```python\nfrom sqlalchemy import create_engine\nfrom sqlalchemy import Column\n\nfrom sqlalchemy import String\nfrom sqlalchemy import DateTime\nfrom sqlalchemy import Integer\n\nfrom sqlalchemy import select\nfrom sqlalchemy import Table\nfrom sqlalchemy import Identity\nfrom sqlalchemy import MetaData\n\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker\n\nimport pandas as pd\nfrom sqlalchemy.sql.elements import Null\n\nengine = create_engine(\"sqlite:///test_db.db\")\nsession = sessionmaker(bind=engine)()\n# con = engine.connect()\n\nBase = declarative_base()\n\nclass Log(Base):\n\n  __tablename__=\"Log\"\n\n  Log_ID = Column(Integer, primary_key=True)\n  Email_ID = Column(Integer)\n  Ticket_ID = Column(Integer)\n  Work_Item_ID = Column(Integer)\n\n  def __init__(self, Log_ID, Email_ID, Ticket_ID, Work_Item_ID):\n\t  self.Log_ID = Log_ID\n\t  self.Email_ID = Email_ID\n\t  self.Ticket_ID = Ticket_ID\n\t  self.Work_Item_ID = Work_Item_ID\n\nlogentry = Log(1, Null, Null, Null)\n\n\nsession.add(logentry)\nsession.commit()\n```\n","n":0.103}}},{"i":570,"$":{"0":{"v":"Sphinx","n":1},"1":{"v":"\n\nRelated: [[s.m.restructured-text]]\n\n- [Potential Azure Pipeline to run doc build](https://github.com/psf/black/blob/main/.github/workflows/doc.yml)\n\n```yaml\nname: Documentation Build\n\non: [push, pull_request]\n\njobs:\nbuild:\n  # We want to run on external PRs, but not on our own internal PRs as they'll be run\n  # by the push to the branch. Without this if check, checks are duplicated since\n  # internal PRs match both the push and pull_request events.\n  if:\n\tgithub.event_name == 'push' || github.event.pull_request.head.repo.full_name !=\n\tgithub.repository\n\n  strategy:\n\tfail-fast: false\n\tmatrix:\n\t  os: [ubuntu-latest, windows-latest]\n\n  runs-on: ${{ matrix.os }}\n  steps:\n\t- uses: actions/checkout@v2\n\n\t- name: Set up latest Python\n\t  uses: actions/setup-python@v2\n\n\t- name: Install dependencies\n\t  run: |\n\t\tpython -m pip install --upgrade pip setuptools wheel\n\t\tpython -m pip install -e \".[d]\"\n\t\tpython -m pip install -r \"docs/requirements.txt\"\n\n\t- name: Build documentation\n\t  run: sphinx-build -a -b html -W --keep-going docs/ docs/_build\n```\n","n":0.093}}},{"i":571,"$":{"0":{"v":"Spacy","n":1},"1":{"v":"\n\n- Reference:\n  - [[Natural Language Processing with spaCy and Python Course for Beginners|r.+.natural-language-processing-with-spacy-and-python-course-for-beginners]]\n","n":0.277}}},{"i":572,"$":{"0":{"v":"Socket","n":1},"1":{"v":"\n\n- [Official Docs](https://docs.python.org/3/library/socket.html)\n- [Socket Programming](https://docs.python.org/3/howto/sockets.html)\n","n":0.447}}},{"i":573,"$":{"0":{"v":"Smtplib","n":1},"1":{"v":"\n\n- [Article About Sending Emails](https://www.courier.com/blog/three-ways-to-send-emails-using-python-with-code-tutorials)\n\n> To create a secure connection, you can either use `SMTP_SSL()` with 465 port or `.starttls()` with 587 port. The former creates an SMTP connection that is secured from the beginning. The latter creates an unsecured SMTP connection that is encrypted via `.starttls()`.\n\n- To send email through `SMTP_SSL()`:\n\n```python\nimport smtplib\n\ngmail_user = 'your_email@gmail.com'\ngmail_password = 'your_password'\n\nsent_from = gmail_user\nto = ['person_a@gmail.com', 'person_b@gmail.com']\nsubject = 'Lorem ipsum dolor sit amet'\nbody = 'consectetur adipiscing elit'\n\nemail_text = \"\"\"\\\nFrom: %s\nTo: %s\nSubject: %s\n\n%s\n\"\"\" % (sent_from, \", \".join(to), subject, body)\n\ntry:\n\tsmtp_server = smtplib.SMTP_SSL('smtp.gmail.com', 465)\n\tsmtp_server.ehlo()\n\tsmtp_server.login(gmail_user, gmail_password)\n\tsmtp_server.sendmail(sent_from, to, email_text)\n\tsmtp_server.close()\n\tprint (\"Email sent successfully!\")\nexcept Exception as ex:\n\tprint (\"Something went wrong‚Ä¶.\",ex)\n```\n\n- To send email through `.starttls()`:\n\n```python\nimport smtplib \ntry: \n\t#Create your SMTP session \n\tsmtp = smtplib.SMTP('smtp.gmail.com', 587) \n\n\t#Use TLS to add security \n\tsmtp.starttls() \n\n\t#User Authentication \n\tsmtp.login(\"sender_email_id\",\"sender_email_id_password\")\n\n\t#Defining The Message \n\tmessage = \"Message_you_need_to_send\" \n\n\t#Sending the Email\n\tsmtp.sendmail(\"sender_email_id\", \"receiyer_email_id\",message) \n\n\t#Terminating the session \n\tsmtp.quit() \n\tprint (\"Email sent successfully!\") \n\nexcept Exception as ex: \n\tprint(\"Something went wrong....\",ex) \n```\n","n":0.082}}},{"i":574,"$":{"0":{"v":"Sklearn","n":1},"1":{"v":"\n\n## Kaggle ML Course\n\n### Reading and looking at the shape of the data\n\n```python\nimport pandas as pd\n\nmelbourne_file_path = '../input/melbourne-housing-snapshot/melb_data.csv'\nmelbourne_data = pd.read_csv(melbourne_file_path) \nmelbourne_data.columns\n# The Melbourne data has some missing values (some houses for which some variables weren't recorded.)\n# We'll learn to handle missing values in a later tutorial.  \n# Your Iowa data doesn't have missing values in the columns you use. \n# So we will take the simplest option for now, and drop houses from our data. \n# Don't worry about this much for now, though the code is:\n\n# dropna drops missing values (think of na as \"not available\")\nmelbourne_data = melbourne_data.dropna(axis=0)\n# Seleting the target prediction\ny = melbourne_data.Price\n# Choosing features to help you predict the target\nmelbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'Lattitude', 'Longtitude']\n# Concention is that the data is called X\nX = melbourne_data[melbourne_features]\nX.describe()\nX.head()\n\n```\n\n### Define the Model\n\n```python\nfrom sklearn.tree import DecisionTreeRegressor\n\n# Define model. Specify a number for random_state to ensure same results each run\nmelbourne_model = DecisionTreeRegressor(random_state=1)\n\n# Fit model\nmelbourne_model.fit(X, y)\nprint(\"Making predictions for the following 5 houses:\")\nprint(X.head())\nprint(\"The predictions are\")\nprint(melbourne_model.predict(X.head()))\n\n```\n\n### Mean Absolute Error\n\n```python\nfrom sklearn.metrics import mean_absolute_error\n\npredicted_home_prices = melbourne_model.predict(X)\nmean_absolute_error(y, predicted_home_prices)\n```\n\n### Split data into test and validation sets\n\n```python\nfrom sklearn.model_selection import train_test_split\n\n# split data into training and validation data, for both features and target\n# The split is based on a random number generator. Supplying a numeric value to\n# the random_state argument guarantees we get the same split every time we\n# run this script.\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)\n# Define model\nmelbourne_model = DecisionTreeRegressor()\n# Fit model\nmelbourne_model.fit(train_X, train_y)\n\n# get predicted prices on validation data\nval_predictions = melbourne_model.predict(val_X)\nprint(mean_absolute_error(val_y, val_predictions))\n```\n\n### Be careful and consider the effects of both over/underfitting\n\n```python\n# Code you have previously used to load data\nimport pandas as pd\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeRegressor\n\n\n# Path of the file to read\niowa_file_path = '../input/home-data-for-ml-course/train.csv'\n\nhome_data = pd.read_csv(iowa_file_path)\n# Create target object and call it y\ny = home_data.SalePrice\n# Create X\nfeatures = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\nX = home_data[features]\n\n# Split into validation and training data\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n\n# Specify Model\niowa_model = DecisionTreeRegressor(random_state=1)\n# Fit Model\niowa_model.fit(train_X, train_y)\n\n# Make validation predictions and calculate mean absolute error\nval_predictions = iowa_model.predict(val_X)\nval_mae = mean_absolute_error(val_predictions, val_y)\nprint(\"Validation MAE: {:,.0f}\".format(val_mae))\n\n# Set up code checking\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.machine_learning.ex5 import *\nprint(\"\\nSetup complete\")\n```\n\n```python\ndef get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n  model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n\tmodel.fit(train_X, train_y)\n\tpreds_val = model.predict(val_X)\n\tmae = mean_absolute_error(val_y, preds_val)\n\treturn(mae)\n```\n\n```python\n# Here is a short solution with a dict comprehension.\n# The lesson gives an example of how to do this with an explicit loop.\nscores = {leaf_size: get_mae(leaf_size, train_X, val_X, train_y, val_y) for leaf_size in candidate_max_leaf_nodes}\nbest_tree_size = min(scores, key=scores.get)\n```\n\n### Fit Model Using All Data\n\n```python\n# Fit the model with best_tree_size. Fill in argument to make optimal size\nfinal_model = DecisionTreeRegressor(max_leaf_nodes=best_tree_size, random_state=1)\n\n# fit the final model\nfinal_model.fit(X, y)\n```\n\n- `sklearn.metrics.mean_absolute_error`\n- `sklearn.tree.DecisionTreeRegressor`\n  - <https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html>\n- `sklearn.ensemble.RandomForestRegressor`\n\n```python\nimport pandas as pd\n\n# Load data\nmelbourne_file_path = '../input/melbourne-housing-snapshot/melb_data.csv'\nmelbourne_data = pd.read_csv(melbourne_file_path) \n# Filter rows with missing values\nmelbourne_data = melbourne_data.dropna(axis=0)\n# Choose target and features\ny = melbourne_data.Price\nmelbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'BuildingArea', \n\t\t\t\t\t  'YearBuilt', 'Lattitude', 'Longtitude']\nX = melbourne_data[melbourne_features]\n\nfrom sklearn.model_selection import train_test_split\n\n# split data into training and validation data, for both features and target\n# The split is based on a random number generator. Supplying a numeric value to\n# the random_state argument guarantees we get the same split every time we\n# run this script.\ntrain_X, val_X, train_y, val_y = train_test_split(X, y,random_state = 0)\n```\n\n```python\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\n\nforest_model = RandomForestRegressor(random_state=1)\nforest_model.fit(train_X, train_y)\nmelb_preds = forest_model.predict(val_X)\nprint(mean_absolute_error(val_y, melb_preds))\n```\n\n- `sklearn.impute.SimpleImputer`\n  - Inserting the mean value of the column into the `NA` values so that it can lend itself to modeling purposes still without generating outliers or skewing the probability curve with anything other than the mean\n\n```python\nfrom sklearn.impute import SimpleImputer\n\n# Imputation\nmy_imputer = SimpleImputer()\nimputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\nimputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))\n\n# Imputation removed column names; put them back\nimputed_X_train.columns = X_train.columns\nimputed_X_valid.columns = X_valid.columns\n\nprint(\"MAE from Approach 2 (Imputation):\")\nprint(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_valid))\n```\n\n- Better yet than just imputing is to track which values were imputed by row/column reference so that you can see the model differences by including and excluding those values\n\n```python\n# Make copy to avoid changing original data (when imputing)\nX_train_plus = X_train.copy()\nX_valid_plus = X_valid.copy()\n\n# Make new columns indicating what will be imputed\nfor col in cols_with_missing:\n\tX_train_plus[col + '_was_missing'] = X_train_plus[col].isnull()\n\tX_valid_plus[col + '_was_missing'] = X_valid_plus[col].isnull()\n\n# Imputation\nmy_imputer = SimpleImputer()\nimputed_X_train_plus = pd.DataFrame(my_imputer.fit_transform(X_train_plus))\nimputed_X_valid_plus = pd.DataFrame(my_imputer.transform(X_valid_plus))\n\n# Imputation removed column names; put them back\nimputed_X_train_plus.columns = X_train_plus.columns\nimputed_X_valid_plus.columns = X_valid_plus.columns\n\nprint(\"MAE from Approach 3 (An Extension to Imputation):\")\nprint(score_dataset(imputed_X_train_plus, imputed_X_valid_plus, y_train, y_valid))\n```\n\n```python\n# Shape of training data (num_rows, num_columns)\nprint(X_train.shape)\n\n# Number of missing values in each column of training data\nmissing_val_count_by_column = (X_train.isnull().sum())\nprint(missing_val_count_by_column[missing_val_count_by_column > 0])\n```\n","n":0.038}}},{"i":575,"$":{"0":{"v":"Shutil","n":1},"1":{"v":"\n\n> Shell Util\n\n- You can use the function shutil.move() to rename a file:\n\n```python\nimport shutil\nshutil.move(\"server.log\", \"server.log.backup\") # Rename\nshutil.move(\"image.png\", \"/home/user/\") # Move\nshutil.copy() #to copy a file:\n```\n","n":0.204}}},{"i":576,"$":{"0":{"v":"Schedule","n":1},"1":{"v":"\n\n```python\nimport schedule\nimport time\n\ndef job():\n  print(\"I'm working...\")\nschedule.every(10).seconds.do(job)\nschedule.every(10).minutes.do(job)\nschedule.every().hour.do(job)\nschedule.every().day.at(\"10:30\").do(job)\nschedule.every(5).to(10).minutes.do(job)\nschedule.every().monday.do(job)\nschedule.every().wednesday.at(\"13:15\").do(job)\nschedule.every().minute.at(\":17\").do(job)\nwhile True:\n  schedule.run_pending()\n  time.sleep(1)\n```\n\n- The package includes many other actions available from the main API including:\n  - Use a decorator to schedule a job\n  - Pass arguments to a job schedule.every(2).seconds.do(greet, name=\"Alice\")\n  - Cancel a job\n  - Run a job once\n  - Get all jobs\n  - Cancel all jobs\n  - Get several jobs, filtered by tags\n  - Cancel several jobs, filtered by tags\n  - Run a job at random intervals\n  - Run a job until a certain time\n  - Time until the next execution\n  - Run all jobs now, regardless of their scheduling\n\n- Reference:\n  - [[r.(.2021.12.20.an-extremely-simple-way-to-schedule-programs-with-python-on-windows]]\n","n":0.1}}},{"i":577,"$":{"0":{"v":"Rich","n":1},"1":{"v":"\n\n- [GitHub](https://github.com/willmcgugan/rich)\n","n":0.707}}},{"i":578,"$":{"0":{"v":"Rich Inspect","n":0.707},"1":{"v":"\n\n- ![alt](assets/images/Pasted_image_20211014090651.png)\n- ![alt](assets/images/Pasted_image_20211014090656.png)\n- ![alt](assets/images/Pasted_image_20211014090705.png)\n- ![alt](assets/images/Pasted_image_20211014090712.png)\n\n---\n\n- Reference:\n  - <https://twitter.com/willmcgugan/status/1343945493559304198?s=20>\n","n":0.354}}},{"i":579,"$":{"0":{"v":"Retry","n":1},"1":{"v":"\n<https://calmcode.io/shorts/retry.py.html>\n\nRelated to [[s.l.python.libs.fastapi]]\n\n> The retry library has a single decorator that can tell the function to try again after failing. Here's how you can use it:\n\n## Setup\n\n```python\nimport random\nfrom requests.exceptions import HTTPError\n\ndef pretend_request():\n    if random.random() < 0.01:\n        raise HTTPError(\"Something went wrong!\")\n    return {\"status\": \"alive\"}\n\n# You'll likely hit an error\nfor i in range(500):\n    pretend_request()\n```\n\n## Usage\n\n```python\nfrom retry import retry\n\n@retry(tries=3, delay=0.1)\ndef pretend_request():\n    if random.random() < 0.01:\n        raise HTTPError(\"Something went wrong!\")\n    return {\"status\": \"alive\"}\n\n# You'll likely hit an error\nfor i in range(500):\n    pretend_request()\n```\n\n## Put it all toether\n\n```python\nimport random\nimport logging\nfrom requests.exceptions import HTTPError\nfrom retry import retry\n\nlogging.basicConfig()\n\n@retry(HTTPError, tries=10, delay=0.1, backoff=2)\ndef pretend_request():\n    if random.random() < 0.1:\n        raise rq.exceptions.HTTPError(\"Something went wrong!\")\n    return {\"status\": \"alive\"}\n\nfor i in range(100):\n    pretend_request()\n\n# >>> WARNING:retry.api:Something went wrong!, retrying in 0.1 seconds...\n# >>> WARNING:retry.api:Something went wrong!, retrying in 0.2 seconds...\n# >>> WARNING:retry.api:Something went wrong!, retrying in 0.4 seconds...\n```\n\n## Configuration\n\n```python\nimport random\nfrom retry import retry\nfrom requests.exceptions import HTTPError\n\n\n@retry(HTTPError, tries=3, delay=0.1)\ndef pretend_request():\n    if random.random() < 0.01:\n        raise HTTPError(\"Something went wrong!\")\n    return {\"status\": \"alive\"}\n\n# Now, the function will only retry if detects a HTTPError. If you were to configure it to only respond to ValueError and TypeError then any other errors will be ignored.\n\n@retry((ValueError, TypeError), tries=3, delay=0.1)\ndef pretend_request():\n    if random.random() < 0.01:\n        raise HTTPError(\"Something went wrong!\")\n    return {\"status\": \"alive\"}\n\n# You'll likely hit an error again\nfor i in range(500):\n    pretend_request()\n```\n\n\n\n\n","n":0.069}}},{"i":580,"$":{"0":{"v":"Requests","n":1},"1":{"v":"\n\n- [Docs](https://docs.python-requests.org/en/master/)\n- [GitHub](https://github.com/psf/requests)\n\n```python\nimport requests\n\n# Get API Request from Azure DevOps\n\nr = requests.get(f\"https://dev.azure.com/{organization}/{project}/_apis/wit/workitems?ids={ids}&api-version=6.1-preview.3\", auth=(username, token))\n#['Body'].read().decode('utf-8-sig')\nprint(r.status_code)\nprint(r.headers['content-type'])\nprint(r.encoding)\n# print(r.text)\n# r.json()[\"value\"]\nprint(json.dumps(r.json(), indent=4))\n```\n","n":0.243}}},{"i":581,"$":{"0":{"v":"Re","n":1}}},{"i":582,"$":{"0":{"v":"Ray","n":1},"1":{"v":"\n\n## Resources\n\n- [Calm Code Ray](https://calmcode.io/ray/introduction.html)\n","n":0.447}}},{"i":583,"$":{"0":{"v":"Qrcode","n":1},"1":{"v":"\n\n```python\nimport qrcode\nimg = qrcode.make('https://www.bryanjenks.dev')\nimg.save(\"some_file.png\")\n```\n\nhad to `pip install qrcode`  and also a package dependency `pip install Image`\nproduced this image, which when scanned goes to the the URL:\n\n![alt](assets/images/Pasted_image_20211103105409.png)\n","n":0.196}}},{"i":584,"$":{"0":{"v":"Pyyaml","n":1},"1":{"v":"\n\n- <https://pypi.org/project/PyYAML/>\n- <https://pyyaml.org/>\n\n```python\nimport yaml\nwith open(\"example.yaml\") as file:\n\tdata = yaml.safe_load(file.read())\n```\n","n":0.333}}},{"i":585,"$":{"0":{"v":"Pywebio","n":1}}},{"i":586,"$":{"0":{"v":"Install","n":1},"1":{"v":"\n\n- `pip install -U pywebio`\n","n":0.447}}},{"i":587,"$":{"0":{"v":"Input Output Funcs","n":0.577},"1":{"v":"\n\n## Input Output Functions\n\n- <https://pywebio.readthedocs.io/en/latest/output.html#functions-list>\n\n| Function name | Description           |\n| ------------- | --------------------- |\n| input         | Text input            |\n| textarea      | Multi-line text input |\n| select        | Drop-down selection   |\n| checkbox      | Checkbox              |\n| radio         | Radio                 |\n| actions       | Actions selection     |\n| file_upload   | File uploading        |\n| input_group   | Input group           |\n","n":0.137}}},{"i":588,"$":{"0":{"v":"Input Funcs","n":0.707},"1":{"v":"\n\n## Basic Input Functions\n\n```python\n# Text Input\nname = input('What is your Name?', type=TEXT)\n# Number Input\nname = input('How old are you?', type=TEXT)\n# Single choice\nanswer = radio(\"Which Continent?\", options=['Africa', 'Asia', 'Australia', 'Europe', 'North America', 'South America'])\n# Checkbox\nagree = checkbox(\"User Term\", options=['I agree to terms and conditions'])\n```\n","n":0.152}}},{"i":589,"$":{"0":{"v":"Input Groups","n":0.707},"1":{"v":"\n\n## Input Groups\n\n```python\n#!/usr/bin/env python\n\nfrom pywebio.input import *\nfrom pywebio.output import *\n\ndata = input_group(\n  \"User data\",\n  [\n\t  input(\"What is your Name?\", name=\"name\", type=TEXT),\n\t  input(\"Input your age\", name=\"age\", type=NUMBER),\n\t  radio(\n\t\t  \"Which Continent?\",\n\t\t  name=\"continent\",\n\t\t  options=[\n\t\t\t  \"Africa\",\n\t\t\t  \"Asia\",\n\t\t\t  \"Australia\",\n\t\t\t  \"Europe\",\n\t\t\t  \"North America\",\n\t\t\t  \"South America\",\n\t\t  ],\n\t  ),\n\t  checkbox(\n\t\t  \"User Term\", name=\"agreement\", options=[\"I agree to terms and conditions\"]\n\t  ),\n  ],\n)\n\n# Output functions\n\nput_text(\"The output in a table:\")\n\nput_table(\n  [\n\t  [\"Name\", data[\"name\"]],\n\t  [\"Age\", data[\"age\"]],\n\t  [\"Continent\", data[\"continent\"]],\n\t  [\"Agreement\", data[\"agreement\"]],\n  ]\n)\n```\n","n":0.12}}},{"i":590,"$":{"0":{"v":"Pytest","n":1}}},{"i":591,"$":{"0":{"v":"Resources","n":1},"1":{"v":"\n\n## Resources\n\n- <https://testdriven.io/blog/testing-python>\n- [Calm Code pytest](https://calmcode.io/pytest/introduction.html)\n- [[s.l.python.libs.pytest]] azure pipelines to [build test suite with an artifact report](https://pypi.org/project/pytest-azurepipelines/) with [some helpful docs](https://medium.com/@anthonypjshaw/azure-pipelines-with-python-by-example-aa65f4070634)\n- [pytest-duration-insights](https://calmcode.io/labs/pytest-duration-insights.html) for test treemap dashboarding\n","n":0.196}}},{"i":592,"$":{"0":{"v":"Black Jack Example","n":0.577},"1":{"v":"\n\n### Black Jack Repo Project Example\n\n- [Sample Repo for this project](https://github.com/koaning/blackjack/)\n\n#### blackjack.py\n\n```python\ndef card_score(cards):\n  numbers = [c for c in cards if c in \"23456789\"]\n  faces = [c for c in cards if c in \"JQK\"]\n  n_aces = sum([1 for c in cards if c == \"A\"])\n  score = sum([int(i) for i in numbers]) + len(faces) * 10\n  while n_aces > 0:\n\t  score += 1 if score + 11 > 21 else 11\n\t  n_aces -= 1\n  return score if score <= 21 else 0\n```\n\n#### test_blackjack.py\n\n```python\nimport pytest\n\nfrom blackjack import card_score\n\ndef test_simple_usecase1():\n  card_score(\"JK\") == 20\n\ndef test_simple_usecase2():\n  card_score(\"JKQ\") == 0\n\ndef test_simple_usecase3():\n  card_score(\"KA\") == 21\n\ndef test_simple_usecase4():\n  card_score(\"AA\") == 12\n```\n\n- A more robust way to stay [[DRY|terms.dry]] is to use [[pytest|import.pytest]]\n\n```python\n@pytest.mark.parametrize(\"cards,score\", [('JK', 20), ('KKK', 0), ('AA', 12), ('AK', 21)])\ndef test_simple_usecase(cards, score):\n  assert card_score(cards) == score\n```\n\n- Run tests with `pytest --verbose` or configure auto process to do that\n  - pytest is looking for files and functions whose names begin with `test_*`\n  - You can run singular unit tests with the following syntax:\n\n```bash\npytest --verbose test_blackjack.py::test_Simple_case4\n```\n\n#### Blackjack with DRY Pytests\n\n- [[pytest|import.pytest]] in a package\n\n```\n‚îú‚îÄ‚îÄ blackjack\n‚îÇ   ‚îú‚îÄ‚îÄ __init__.py\n‚îÇ   ‚îî‚îÄ‚îÄ common.py\n‚îú‚îÄ‚îÄ setup.py\n‚îî‚îÄ‚îÄ tests\n  ‚îú‚îÄ‚îÄ __init__.py\n  ‚îî‚îÄ‚îÄ test_blackjack.py\n```\n\n##### blackjack\n\n- `__init__.py` should be empty\n- `common.py` (user preference on naming, example said \"common utilities\")\n\n```python\ndef card_score(cards):\n  if len(cards) < 2:\n\t  raise ValueError(\"The `card_score` function requires at least 2 cards.\")\n  if not isinstance(cards, str):\n\t  raise ValueError(\"The input for `card_score` needs to be a string.\")\n  numbers = [c for c in cards if c in \"23456789\"]\n  faces = [c for c in cards if c in \"JQK\"]\n  n_aces = sum([1 for c in cards if c == \"A\"])\n  score = sum([int(i) for i in numbers]) + len(faces) * 10\n  while n_aces > 0:\n\t  score += 1 if score + 11 > 21 else 11\n\t  n_aces -= 1\n  return score if score <= 21 else 0\n```\n\n##### tests\n\n- `__init__.py` should be empty\n- `test_blackjack.py`\n\n```python\nimport pytest\n\nfrom blackjack.common import card_score\n\n@pytest.mark.parametrize(\"cards,score\", [('JK', 20), ('KKK', 0), ('AA', 12), ('AK', 21)])\ndef test_simple_usecase(cards, score):\n  assert card_score(cards) == score\n```\n\n- To be able to work on the package in developer mode you'll need to run;\n  - `python setup.py develop`\n- And from here you can safely run pytest again.\n- `pytest --verbose`\n- `pytest-cov` for code coverage testing\n  - `python -m pip install pytest-cov`\n  - [[s.m.html]] output: `pytest --cov blackjack --cov-report html`\n- [Calm Code Conftest](https://calmcode.io/test/conftest.html)\n  - For greater code reusability and provide data to the testing suite, you can use `conftest.py` in the `tests` directory\n  - This allows you to repeat yourself less and have a single location that feeds data into the testing suite instead of making the data for each test individually.\n\n```python\nfrom clumper import Clumper # our custom module\nimport pytest\n\n@pytest.fixture(scope=\"module\")\ndef base_clumper():\n  data = [\n\t  {\"data\": [i for _ in range(2)], \"i\": i, \"c\": c}\n\t  for i, c in enumerate(\"abcdefghijklmnopqrstuvwxyz\")\n  ]\n  return Clumper(data)\n\n# So that tests like this:\n\ndef test_headtail_size():\n  data = [{'i': i} for i in range(10)]\n  c = Clumper(data)\n  assert len(c.head(10)) == 10\n  assert len(c.tail(10)) == 10\n  assert len(c.head(5)) == 5\n  assert len(c.tail(5)) == 5\n\n# can become like:\n\ndef test_headtail_size(base_clumper):\n  assert len(base_clumper.head(10)) == 10\n  assert len(base_clumper.tail(10)) == 10\n  assert len(base_clumper.head(5)) == 5\n  assert len(base_clumper.tail(5)) == 5\n```\n","n":0.044}}},{"i":593,"$":{"0":{"v":"Pytest Duration Insights","n":0.577}}},{"i":594,"$":{"0":{"v":"Pytesseract","n":1}}},{"i":595,"$":{"0":{"v":"Pysnmp","n":1},"1":{"v":"\n\n![[n.protocol.snmp]]\n\n- <https://www.yaklin.ca/2022/01/11/pysnmp-hlapi-overview.html>\n\n```python\nfrom pysnmp.hlapi import SnmpEngine, CommunityData, UdpTransportTarget,\\\n                         ContextData, ObjectType, ObjectIdentity, getCmd\n\niterator = getCmd(\n    SnmpEngine(),\n    CommunityData('rostring', mpModel=1),\n    UdpTransportTarget(('192.168.11.201', 161)),\n    ContextData(),\n    ObjectType(ObjectIdentity('SNMPv2-MIB', 'sysName', 0))\n)\n\nerrorIndication, errorStatus, errorIndex, varBinds = next(iterator)\n\nif errorIndication:\n    print(errorIndication)\nelif errorStatus:\n    print('{} at {}'.format(errorStatus.prettyPrint(),\n                        errorIndex and varBinds[int(errorIndex) - 1][0] or '?'))\n\nfor oid, val in varBinds:\n    print(f'{oid.prettyPrint()} = {val.prettyPrint()}')\n```\n\n\n","n":0.146}}},{"i":596,"$":{"0":{"v":"Pysimplegui","n":1},"1":{"v":"\n\n- [GitHub Repo](https://github.com/PySimpleGUI/PySimpleGUI)\n","n":0.577}}},{"i":597,"$":{"0":{"v":"Pyqt","n":1},"1":{"v":"\n\n> Create GUI apps\n\n## Resources\n\n- [Real Python Article](https://realpython.com/qt-designer-python/)\n- [Tutorials Point Course](https://www.tutorialspoint.com/pyqt/pyqt_qpixmap_class.htm)\n- Using a GUI designer to spit out code for you to use:\n\n```bash\npip install pyqt5 pyqt5-tools pyqt-builder \n```\n\n- open the app builder from [[s.l.powershell]]: `pyqt5-tools.exe designer`\n- Quick [[s.l.python.libs.venv]] setup workflow with the designer:\n\n```powershell\npip install venv\npython -m venv my_virtual_env\ncd my_virtual_env\n& scripts\\activate.ps1\npip install pyqt5 pyqt5-tools pyqt-builder\npyqt5-tools.exe designer\n```\n","n":0.135}}},{"i":598,"$":{"0":{"v":"Pypdf2","n":1},"1":{"v":"\n\n- Use this to append all PDF's in the given directory into 1\n\n```python\nimport PyPDF2, os\n\n# Get all the PDF filenames.\npdfFiles = []\nfor filename in os.listdir('.'):\n  if filename.endswith('.pdf'):\n\t  pdfFiles.append(filename)\npdfFiles.sort()\n\npdfWriter = PyPDF2.PdfFileWriter()\n\n# Loop through all the PDF files.\nfor filename in pdfFiles:\n  pdfFileObj = open(filename, 'rb')\n  pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n\n  # Loop through all the pages (except the first) and add them.\n  for pageNum in range(1, pdfReader.numPages):\n\t  pageObj = pdfReader.getPage(pageNum)\n\t  pdfWriter.addPage(pageObj)\n\n# Save the resulting PDF to a file.\npdfOutput = open('allminutes.pdf', 'wb')\npdfWriter.write(pdfOutput)\npdfOutput.close()\n\n```\n","n":0.114}}},{"i":599,"$":{"0":{"v":"Pypager","n":1}}},{"i":600,"$":{"0":{"v":"Pyinstrument","n":1},"1":{"v":"\nGreat visual profiling library\n\n## installation\n\n```shell\npip install Pyinstrument\n```\n\n## Get great output from testing\n\n```shell\nPyinstrument -r 'html' -o output.html file.py\n```\n\n![pyinstrument html output](assets/images/2022-01-06-15-25-38.png)\n\n## Get an interactive graphical flamegraph\n\n```shell\npyinstrument -r speedscope -o speedscope.json path/script.py\n```\n\nThen open your [[s.df.json]] file with <https://www.speedscope.app/>\n\n![flamegraph](/assets/images/2022-01-06-15-33-51.png)\n\n## running the profiler on inline code\n\nusing the function at the bottom `profiler.open_in_browser()` would be great if\npassing a flag to a [[cli]] program to enter into a testing/troubleshooting mode\n\n```python\nimport time\nfrom pyinstrument import Profiler\n\n# Note the interval value is 1/10th the sleeptime!\n# This lets you change the speed graph intervals\n# profiler = Profiler(interval=0.000001)\n\nprofiler = Profiler()\nprofiler.start()\n\nsleep_time = 0.1\n\ndef start():\n    time.sleep(sleep_time)\n    do_sleep1()\n    do_sleep2()\n\ndef do_sleep1():\n    time.sleep(sleep_time)\n\ndef do_sleep2():\n    do_sleep1()\n    time.sleep(sleep_time)\n\nstart()\n\nprofiler.stop()\nprofiler.open_in_browser() # Several Options here\n```\n","n":0.099}}},{"i":601,"$":{"0":{"v":"Pyinstaller","n":1},"1":{"v":"\n\n- [[s.l.python.libs.pyinstaller]] package to make a python script into a `.exe` file\n- [resource link](https://datatofish.com/executable-pyinstaller/)\n","n":0.267}}},{"i":602,"$":{"0":{"v":"Pyinputplus","n":1},"1":{"v":"\n\n## Installation\n\n```bash\npip install pyinputplus\n```\n\n## Usage\n\n```python\nimport pyinputplus as pyinput\n\nprompt = 'How old are you:'\nage = pyinput.inputInt(prompt=prompt, greaterThan=0)\n```\n\n## Example Output\n\n```markdown\nHow old are you:-1\nNumber must be greater than 0.\nHow old are you: 11.5\n'11.5' is not an integer.\nHow old are you: 14\n```\n","n":0.162}}},{"i":603,"$":{"0":{"v":"Pydoc","n":1},"1":{"v":"\n\n- [Socratica Video](https://www.youtube.com/watch?v=URBSvqib0xw&ab_channel=Socratica)\n- using the [[s.l.python.libs.pydoc]] module you can review documentation\n- This command ( `python -m pydoc <++>` ) searches for the following:\n  - modules ( `math` )\n  - classes ( `tuple` )\n  - functions ( `pow` )\n- [[s.l.python.libs.pydoc]] commands:\n  - `pydoc -b`\n    - Start an HTTP server with the given hostname (default: localhost).\n    - Start an HTTP server on the given port on the local machine. Port number 0 can be used to get an arbitrary unused port.\n    - Write out the HTML documentation for a module to a file in the current directory. If `<name>` contains a '' it is treated as a filename; if it names a directory, documentation is written for all the contents.\n  - `pydoc -k <keyword>`\n    - Search for a keyword in the synopsis lines of all available modules.\n    - Start an HTTP server on an arbitrary unused port and open a Web browser to interactively browse documentation. This option can be used in combination with -n and/or - p\n  - `pydoc -n <hostname>`\n    - Start an HTTP server with the given hostname (default: localhost).\n  - `pydoc -p <port>`\n    - Start an HTTP server on the given port on the local machine. Port number 0 can be used to get an arbitrary unused port.\n  - `pydoc -b`\n    - Start an HTTP server on an arbitrary unused port and open a Web browser to interactively browse documentation. This option can be used in combination with -n and/or - p‚Ä¢\n  - `pydoc -W <name> ...`\n    - Write out the HTML documentation for a module to a file in the current directory. If `<name>` contains a '' it is treated as a filename; if it names a directory, documentation is written for all the contents.\n","n":0.059}}},{"i":604,"$":{"0":{"v":"Pydeps","n":1},"1":{"v":"\n\n- <https://github.com/thebjorn/pydeps>\n","n":0.707}}},{"i":605,"$":{"0":{"v":"Pyarrow","n":1},"1":{"v":"\n\n- Pyarrow for faster data reads\n  - `pip install pyarrow`\n- video format of this article <https://youtu.be/gFd4I1oXG8E>\n\n![alt](assets/images/Pasted_image_20211101091818.png)\n\n![alt](assets/images/Pasted_image_20211101091826.png)\n\n![alt](assets/images/Pasted_image_20211101091836.png)\n\n```python\n# Create a dummy dataset:\nimport random\nimport string\nimport numpy as np\nimport pandas as pd\nimport pyarrow as pa\nimport pyarrow.csv as csv\nfrom datetime import datetime\n\ndef gen_random_string(length: int = 32) -> str:\n    return ''.join(random.choices(\n        string.ascii_uppercase + string.digits, k=length)\n    )\n\ndt = pd.date_range(\n    start=datetime(2000, 1, 1),\n    end=datetime(2021, 1, 1),\n    freq='min'\n)\n\nnp.random.seed = 42\ndf_size = len(dt)\nprint(f'Dataset length: {df_size}')\n\n\ndf = pd.DataFrame({\n    'date': dt,\n    'a': np.random.rand(df_size),\n    'b': np.random.rand(df_size),\n    'c': np.random.rand(df_size),\n    'd': np.random.rand(df_size),\n    'e': np.random.rand(df_size),\n    'str1': [gen_random_string() for x in range(df_size)],\n    'str2': [gen_random_string() for x in range(df_size)]\n})\n# 1 test baseline speed of pandas\n## even being kind by using the compression parameter\n\ndf.to_csv('csv_pandas.csv.gz', index=False, compression='gzip')\n\n# Check read times\n\ndf1 = pd.read_csv('csv_pandas.csv')\n\n# **NOTE:** Here‚Äôs a thing you should know about PyArrow ‚Äî it can‚Äôt handle datetime columns. You‚Äôll have to convert the date attribute to a timestamp. Here‚Äôs how:\n\ndf_pa = df.copy()\ndf_pa['date'] = df_pa['date'].values.astype(np.int64) // 10 ** 9\ndf_pa_table = pa.Table.from_pandas(df_pa)\ncsv.write_csv(df_pa_table, 'csv_pyarrow.csv')\n\n# Adding compression\n\nwith pa.CompressedOutputStream('csv_pyarrow.csv.gz', 'gzip') as out:\n    csv.write_csv(df_pa_table, out)\n\n# You can read both compressed and uncompressed dataset with the csv.read_csv() function:\n\ndf_pa_1 = csv.read_csv('csv_pyarrow.csv')\ndf_pa_2 = csv.read_csv('csv_pyarrow.csv.gz')\n\n# Both will be read in the pyarrow.Table format, so use the following command to convert them to a Pandas DataFrame:\n\ndf_pa_1 = df_pa_1.to_pandas()\n```\n\n---\n\n- Reference:\n  - [[r.(.2021.11.01.write-data-this-alternative-is-7-times-faster]]\n","n":0.071}}},{"i":606,"$":{"0":{"v":"Prompt_toolkit","n":1},"1":{"v":"\n\n- [GitHub](https://github.com/prompt-toolkit/python-prompt-toolkit)\n- [Docs - Interactive REPL](https://python-prompt-toolkit.readthedocs.io/en/stable/pages/tutorials/repl.html)\n","n":0.408}}},{"i":607,"$":{"0":{"v":"Prettytable","n":1},"1":{"v":"\n\n## Resources\n\n- <https://pypi.org/project/prettytable/>\n- <https://zetcode.com/python/prettytable/>\n- <https://github.com/adamlamers/prettytable>\n\n## Examples\n\n```python\n#!/usr/bin/python3\n\nfrom prettytable import PrettyTable\n\nx = PrettyTable()\n\nx.field_names = [\"City name\", \"Area\", \"Population\", \"Annual Rainfall\"]\n\nx.add_row([\"Adelaide\",  1295, 1158259, 600.5])\nx.add_row([\"Brisbane\",  5905, 1857594, 1146.4])\nx.add_row([\"Darwin\",    112,  120900,  1714.7])\nx.add_row([\"Hobart\",    1357, 205556,  619.5])\nx.add_row([\"Sydney\",    2058, 4336374, 1214.8])\nx.add_row([\"Melbourne\", 1566, 3806092, 646.9])\nx.add_row([\"Perth\",     5386, 1554769, 869.4])\n\nprint(x)\n```\n\n```\n+-----------+------+------------+-----------------+\n| City name | Area | Population | Annual Rainfall |\n+-----------+------+------------+-----------------+\n|  Adelaide | 1295 |  1158259   |      600.5      |\n|  Brisbane | 5905 |  1857594   |      1146.4     |\n|   Darwin  | 112  |   120900   |      1714.7     |\n|   Hobart  | 1357 |   205556   |      619.5      |\n|   Sydney  | 2058 |  4336374   |      1214.8     |\n| Melbourne | 1566 |  3806092   |      646.9      |\n|   Perth   | 5386 |  1554769   |      869.4      |\n+-----------+------+------------+-----------------+\n```\n","n":0.098}}},{"i":608,"$":{"0":{"v":"Pretty Errors","n":0.707},"1":{"v":"\n\n- <https://github.com/onelivesleft/PrettyErrors>\n","n":0.707}}},{"i":609,"$":{"0":{"v":"Prefect","n":1}}},{"i":610,"$":{"0":{"v":"Service Dashboard UI","n":0.577},"1":{"v":"\n\n## UI Dashboard of your service\n\n![image.png](/DevLog/Media/image_1629409912162_0.png)\n\n- To run this, you need to have docker and docker-compose installed on your computer. But starting it is surprisingly a single command.\n\n```shell\nprefect server start\n```\n","n":0.183}}},{"i":611,"$":{"0":{"v":"Send Emails","n":0.707},"1":{"v":"\n\n## Sending Emails\n\n- To send emails, we need to make the credentials accessible to the Prefect agent. You can do that by creating the below file in `$HOME/.prefect/config.toml`.\n\n```toml\n[context.secrets]\n\nEMAIL_USERNAME = \"<Your email id>\"\nEMAIL_PASSWORD = \"<your email password>\"\n```\n\n```python\n# Import email task\nfrom prefect.tasks.notifications.email_task import EmailTask\n\n# Create an email_task object. Use all static content here.\nemail_task = EmailTask(\n  subject=\"A new windspeed captured\",\n  email_to=\"receiver_email@gmail.com\",\n  email_from=\"your_email@gmail.com\",\n)\n\nwith Flow(\"Windspeed Tracker\", schedule=schedule) as flow:\n\n  # Call the email task with variable content.\n  email_task(\n\t  msg=str(windspeed),\n  )\n```\n","n":0.115}}},{"i":612,"$":{"0":{"v":"Schedule Your Workflow","n":0.577},"1":{"v":"\n\n> The @task decorator converts a regular python function into a Prefect task. The optional arguments allow you to specify its retry behavior.\n\n## Scheduling The Workflow\n\n```python\n# Imports to facilitate Scheduling.\nfrom datetime import timedelta, datetime\nfrom prefect.schedules import IntervalSchedule\n\n# Create a schedule object\nschedule = IntervalSchedule(\n  start_date=datetime.utcnow() + timedelta(seconds=5),\n  interval=timedelta(minutes=1),\n)\n\n# Attach the schedule object to the windspeed trakcer flow.\nwith Flow(\"Windspeed Tracker\", schedule=schedule) as flow:\n  response = extract()\n  windspeed = transform(response)\n  load(windspeed)\n```\n","n":0.121}}},{"i":613,"$":{"0":{"v":"Resources","n":1},"1":{"v":"\n\n## Resources\n\n- [Official Docs](https://docs.prefect.io/core/concepts/schedules.html#clocks)\n","n":0.5}}},{"i":614,"$":{"0":{"v":"Before and after Example","n":0.5},"1":{"v":"\n\n## Before ETL Process:\n\n```python\nimport requests\n\ndef extract() -> dict:\n  \"\"\"Use the Open Weather Map API to fetch Boston weather data.\n  Returns:\n\t  dict: a JSON response of many wheather measurements.\n  \"\"\"\n\n  url = \"https://api.openweathermap.org/data/2.5/weather\"\n\n  #  Use a real API key. You can get a free one from https://openweathermap.org/\n  response = requests.request(\n\t  \"GET\", url, params={\"q\": \"Boston\", \"appid\": \"e5ecbcc49e3debeead24d0fe012fb46e\"}\n  )\n\n  return response.json()\n\n\ndef transform(response: dict) -> float:\n  \"\"\"Process the response and extract windspeed information\n  Args:\n\t  response (dict): Response JSON from extract task\n  Returns:\n\t  float: Current wind speed\n  \"\"\"\n  return response.get(\"wind\", {}).get(\"speed\", 0.0)\n\n\ndef load(speed: float):\n  \"\"\"Append data to file\n  Args:\n\t  speed (float): Windspeed from transform task\n  \"\"\"\n\n  with open(\"windspeed.txt\", \"a\") as f:\n\t  f.write(str(speed) + \"\\n\")\n\n\nif __name__ == \"__main__\":\n  # Execute tasks in the right order.\n  response = extract()\n  windspeed = transform(response)\n  load(windspeed)\n```\n\n## After prefect, turning functions into tasks and making sure they retry and on intervals for success:\n\n```python\nimport requests\n\n# Importing Prefect task, Flow and Python timdelta\nfrom prefect import task, Flow\nfrom datetime import timedelta\n\n# decorater specifying how many times to retry and it's iterval.\n@task(max_retries=3, retry_delay=timedelta(minutes=3))\ndef extract() -> dict:\n  ...\n\n\n@task\ndef transform(response: dict) -> float:\n  ...\n\n@task(max_retries=3, retry_delay=timedelta(5))\ndef load(speed: float):\n  ...\n\n\n# Create a Prefect flow\nwith Flow(\"Windspeed Tracker\") as flow:\n  # Execute tasks in the right order.\n  response = extract()\n  windspeed = transform(response)\n  load(windspeed)\n\nif __name__ == \"__main__\":\n  # Execute the flow\n  flow.run()\n```\n","n":0.069}}},{"i":615,"$":{"0":{"v":"Pre Commit","n":0.707},"1":{"v":"\n\nrun before each `git commit` command\n","n":0.408}}},{"i":616,"$":{"0":{"v":"Polars","n":1},"1":{"v":"\n\n<https://calmcode.io/polars/read-csv.html>\n\n- Related:\n  - [[pandas|import.pandas]]\n  - [[mito|s.l.python.libs.mito]]\n\n","n":0.408}}},{"i":617,"$":{"0":{"v":"Pipe","n":1},"1":{"v":"\n\n```python\narr = [1, 2, 3, 4, 5]\nlist(map(lambda x: x * 2, filter(lambda x: x % 2 == 0, arr)))\n# >>> [4, 8]\n```\n\n```python\nfrom pipe import where, select\narr = [1, 2, 3, 4, 5]\nlist(arr,\n\t | where(lambda x: x % 2 == 0, arr)\n\t | select(lambda x: x * 2))\n# >>> [4, 8]\n```\n\n```python\nfrom pipe import where\narr = [1, 2, 3, 4, 5]\nlist(arr | where(lambda x: x % 2 == 0))\n# >>> [2, 4]\n```\n\n```python\nfrom pipe import where, select\narr = [1, 2, 3, 4, 5]\nlist(arr | select(lambda x: x * 2))\n# >>> [2, 4, 6. 8, 10]\n```\n\n```python\nfrom pipe import chain\nnested = [[1, 2, [3]], [4, 5]]\nlist(nested | chain)\n# >>> [1, 2, [3], 4, 5]\n# OR FOR DEEPLY NESTED:\nfrom pipe import traverse\nnested = [[1, 2, [3]], [4, 5]]\nlist(nested | traverse)\n# >>> [1, 2, 3, 4, 5]\n```\n\n```python\nfrom pipe import traverse, select\nfruits = [\n\t{\"name\": \"apple\", \"price\": [2, 5]},\n\t{\"name\": \"orange\", \"price\": 4},\n\t{\"name\": \"grape\", \"price\": 5},\n]\nlist(fruits\n\t | select(lambda fruit: fruit[\"price\"])\n\t | traverse)\n```\n\n```python\nfrom pipe import groupby, select \nlist( \n\t(1, 2, 3, 4, 5, 6, 7, 8, 9)\n\t| groupby( lambda x: \"Even\" if x % 2 == 0 else \"Odd\") \n\t| select( lambda x: {x[0]: list(x[1])})\n)\n# >>> [{'Even': [2, 4, 6 ,8]}, {\"Odd\": [1, 3, 5, 7, 9]}]\n```\n\n```python\nfrom pipe import groupby, select \nlist( \n\t(1, 2, 3, 4, 5, 6, 7, 8, 9)\n\t| groupby( lambda x: \"Even\" if x % 2 == 0 else \"Odd\") \n\t| select( lambda x: {x[0]: list(x[1] | where(lambda x: x > 2))})\n)\n# >>> [{'Even': [4, 6 ,8]}, {\"Odd\": [3, 5, 7, 9]}]\n```\n\n- Reference:\n  - [[Write Clean Python Code Using Pipes|r.(.2021.11.05.write-clean-python-code-using-pipes]]\n","n":0.063}}},{"i":618,"$":{"0":{"v":"Pathlib","n":1},"1":{"v":"\n\n- Negates the need to combine [[s.l.python.libs.os]] with [[s.l.python.libs.glob]] to find paths that match a given pattern.\n- [[s.l.python.libs.os]] represents paths at their most simple level: strings whereas pathlib represents them as a class \n\n- Reference:\n  - [[r.(.2021.12.16.why-you-should-start-using-pathlib-as-an-alternative-to-the-os-module]]\n","n":0.164}}},{"i":619,"$":{"0":{"v":"Suffix","n":1},"1":{"v":"\n\n`.suffix` : Get the extension of a file\n","n":0.354}}},{"i":620,"$":{"0":{"v":"Remove Suffix","n":0.707},"1":{"v":"\n\n## Remove suffix\n\n![alt](assets/images/Pasted_image_20211224112647.png)\n\n---\n","n":0.577}}},{"i":621,"$":{"0":{"v":"Recursive Globbing","n":0.707},"1":{"v":"\n\n## Recursive globbing\n\n```python\n\nfrom pathlib import Path\n\n# A quite large folder indeed!\npath = Path(\"/Users/ahmed.besbes/anaconda3/\")\n\npython_files = path.rglob(\"**/*.py\")\n\nnext(python_files)\n# PosixPath('/Users/ahmed.besbes/anaconda3/bin/rst2xetex.py')\n\nnext(python_files)\n# PosixPath('/Users/ahmed.besbes/anaconda3/bin/rst2latex.py')\n\nnext(python_files)\n# PosixPath('/Users/ahmed.besbes/anaconda3/bin/rst2odt_prepstyles.py')\n\n...\n\nlen(list(python_files))\n# 67481\n```\n","n":0.229}}},{"i":622,"$":{"0":{"v":"Is_mount","n":1},"1":{"v":"\n\n`.is_mount()` : To check if the path is a mount point\n","n":0.302}}},{"i":623,"$":{"0":{"v":"Is_file","n":1},"1":{"v":"\n\n`.is_file()` : To check if the path corresponds to a file\n","n":0.302}}},{"i":624,"$":{"0":{"v":"Is_dir","n":1},"1":{"v":"\n\n`.is_dir()` : To check if the path corresponds to a directory\n","n":0.302}}},{"i":625,"$":{"0":{"v":"Is_absolute","n":1},"1":{"v":"\n\n`.is_absolute()` : To check if the path is absolute\n","n":0.333}}},{"i":626,"$":{"0":{"v":"Get Common Paths","n":0.577},"1":{"v":"\n\n## Get common paths in a command\n\n```python\nfrom pathlib import Path\n\ncwd = Path.cwd()\nhome = Path.home()\n```\n","n":0.267}}},{"i":627,"$":{"0":{"v":"File Manipulation","n":0.707},"1":{"v":"\n\n## Easy file manipulation\n\n```python\nfrom pathlib import Path\n\nrandom_file = Path(\"random_file.txt\")\n\nrandom_file.exists()\n# False\n\nrandom_file.touch()\n\nrandom_file.exists()\n# True\n```\n","n":0.302}}},{"i":628,"$":{"0":{"v":"Exists","n":1},"1":{"v":"\n\n`.exists()` : To check if the path really exists on the filesystem\n","n":0.289}}},{"i":629,"$":{"0":{"v":"Example","n":1},"1":{"v":"\n\n```python\nfrom pathlib import Path\n\npath = Path('/home/johndoe/Documents/pathlib.md')\npath.touch()\npath.name\n#>>> 'pathlib.md'\npath.stem\n#>>> pathlib\npath.suffix\n#>>> '.md'\npath.parent\n#>>> PosixPath('/home/johndoe/Documents')\npath.parent.parent\n#>>> PosixPath('/home/johndoe')\npath.anchor\n#>>> '/'\n```\n","n":0.289}}},{"i":630,"$":{"0":{"v":"Chmod","n":1},"1":{"v":"\n\n`.chmod()` : To change the file mode and permissions\n","n":0.333}}},{"i":631,"$":{"0":{"v":"Parse","n":1},"1":{"v":"\n\n- [parse library for common string parsing](https://calmcode.io/parse/parse.html)\n\n```python\nfrom parse import parse\n\ngithubs = [\n  \"https://github.com/koaning/justcharts/\",\n  \"https://github.com/koaning/human-learn/\",\n  \"https://github.com/r1chardj0n3s/parse/\",\n]\n\n[parse(\"https://github.com/{owner}/{repo}/\", url).named for url in githubs]\n\n# RESULTS:\n[\n{'owner': 'koaning', 'repo': 'justcharts'},\n{'owner': 'koaning', 'repo': 'human-learn'},\n{'owner': 'r1chardj0n3s', 'repo': 'parse'}\n]\n\n```\n\n```python\n1625696365632\nfrom parse import search\n\nfmt = \"https://github.com/{account}/{project}/\"\ntxt = \"https://github.com/koaning/human-learn/ https://github.com/koaning/scikit-lego/\"\n\n# This only returns one result.\nsearch(fmt, txt)\n```\n\n```python\nfrom parse import findall\n\nfmt = \"https://github.com/{account}/{project}/\"\ntxt = \"https://github.com/koaning/human-learn/ https://github.com/koaning/scikit-lego/\"\nres = findall(fmt, txt)\n\n# This returns two results\nlist(res)\n```\n\n```python\nfrom parse import compile\n\np = compile(\"https://github.com/{account}/{project}/\")\n\ntxt = \"https://github.com/koaning/scikit-lego/\"\np.parse(txt)\n\ntxt = \"foo https://github.com/koaning/scikit-lego/\"\np.search(txt)\n\ntxt = \"https://github.com/koaning/scikit-lego/ https://github.com/koaning/scikit-lego/\"\np.findall(txt)\n```\n","n":0.118}}},{"i":632,"$":{"0":{"v":"Panel","n":1},"1":{"v":"\n\n- <https://panel.holoviz.org/>\n","n":0.707}}},{"i":633,"$":{"0":{"v":"Pandoc","n":1}}},{"i":634,"$":{"0":{"v":"Pandasql","n":1},"1":{"v":"\n\n- [PyPi](https://pypi.org/project/pandasql/)\n- Load data frames and query them with SQL code\n","n":0.302}}},{"i":635,"$":{"0":{"v":"Pandasgui","n":1},"1":{"v":"\n\n- [PyPi page](https://pypi.org/project/pandasgui/)\n- GUI Editing and filtering of data via pandas\n","n":0.302}}},{"i":636,"$":{"0":{"v":"Pandas","n":1}}},{"i":637,"$":{"0":{"v":"Rust Clone","n":0.707},"1":{"v":"\n\n## Pandas Re-done in Rust: Polars\n\n---\n\n- [[s.l.python.libs.polars]]\n","n":0.378}}},{"i":638,"$":{"0":{"v":"Resource","n":1},"1":{"v":"\n\n## Resources\n\n---\n\n- [Calm Code Pandas Pipe](https://calmcode.io/pandas-pipe/pipe.html)\n- [25 Pandas Functions You Didn‚Äôt Know Existed | P(Guarantee) = 0.8](https://towardsdatascience.com/25-pandas-functions-you-didnt-know-existed-p-guarantee-0-8-1a05dcaad5d0)\n- ![[assets/pdfs/Pandas_Cheat_Sheet.pdf]]\n\n---\n","n":0.236}}},{"i":639,"$":{"0":{"v":"Profiling","n":1},"1":{"v":"\n## Profiling\n\n---\n\n```python\npip install pandas-profiling\n#  get the analysis of a data frame and save the analysis in web format we can use\nfrom pandas_profiling import ProfileReport\nreport = ProfileReport(dataframe)\nreport.to_file(output_file=‚Äôoutput.html‚Äô)\n```\n\n---\n","n":0.196}}},{"i":640,"$":{"0":{"v":"Pipe","n":1},"1":{"v":"\n\n## Pandas Pipe\n\n---\n\n```python\nimport pandas as pd\n\ndf = pd.read_csv('https://calmcode.io/datasets/bigmac.csv')\n\ndef set_dtypes(dataf):\n  return (dataf\n\t\t  .assign(date=lambda d: pd.to_datetime(d['date']))\n\t\t  .sort_values(['currency_code', 'date']))\n\ndef remove_outliers(dataf):\n  min_row_country=32\n  countries = (dataf\n\t\t\t  .groupby('currency_code')\n\t\t\t  .agg(n=('name', 'count'))\n\t\t\t  .loc[lambda d: d['n'] >= min_row_country]\n\t\t\t  .index)\n  return (dataf\n\t\t  .loc[lambda d: d['currency_code'].isin(countries)])\n\ndf.pipe(set_dtypes).pipe(remove_outliers)\n```\n\n---\n","n":0.169}}},{"i":641,"$":{"0":{"v":"Modin","n":1},"1":{"v":"\n\n## Faster and more efficient computation with modin\n\n---\n\n```bash\npip install modin\n```\n\n> w, you can install it like this ‚Äî so that you don‚Äôt need to make further changes to your code.\n\n```python\nimport modin.pandas as pd\n```\n\n---\n","n":0.174}}},{"i":642,"$":{"0":{"v":"Excel Files","n":0.707},"1":{"v":"\n## pd.ExcelFile\n\n<https://stackoverflow.com/a/17977609/12339658>\n\n```python\nxl = pd.ExcelFile('foo.xls')\n\nxl.sheet_names  # see all sheet names\n\nxl.parse(sheet_name)  # read a specific sheet to DataFrame\n```\n\n<https://pythoninoffice.com/read-multiple-excel-sheets-with-python-pandas/#:~:text=00%3A00%3A00-,pd.ExcelFile(),-With%20this%20approach>\n\n```python\nf = pd.ExcelFile('users.xlsx')\nf\n# >>> <pandas.io.excel._base.ExcelFile object at 0x00000138DAE66670>\nf.sheet_names\n# >>> ['User_info', 'purchase', 'compound', 'header_row5']\n# To get data from a sheet, we can use the parse() method, and provide the sheet name.\nf.parse(sheet_name = 'User_info')\n# >>>       User Name Country      City Gender  Age\n# >>> 0  Forrest Gump     USA  New York      M   50\n# >>> 1     Mary Jane  CANADA   Tornoto      F   30\n# >>> 2  Harry Porter      UK    London      M   20\n# >>> 3     Jean Grey   CHINA  Shanghai      F   30\n\n```\n\n## pd.read_excel\n\n<https://pythoninoffice.com/read-multiple-excel-sheets-with-python-pandas/>\n\n```python\n# Select sheets to read by index: sheet_name = [0,1,2] means the first three sheets.\n# Select sheets to read by name: sheet_name = ['User_info', 'compound']. This method requires you to know the sheet names in advance.\n# Select all sheets: sheet_name = None.\n\nimport pandas as pd\ndf = pd.read_excel('users.xlsx', sheet_name = [0,1,2])\ndf = pd.read_excel('users.xlsx', sheet_name = ['User_info','compound'])\ndf = pd.read_excel('users.xlsx', sheet_name = None) # read all sheets\n\n# We will read all sheets from the sample Excel file, then use that dataframe for the examples going forward.\n\n# The df returns a dictionary of dataframes. The keys of the dictionary contain sheet names, and values of the dictionary contain sheet content.\ndf.keys()\n# >>> dict_keys(['User_info', 'purchase', 'compound', 'header_row5'])\n\ndf.values()\n# >>> dict_values([      User Name Country      City Gender  Age\n# >>> 0  Forrest Gump     USA  New York      M   50\n# >>> 1     Mary Jane  CANADA   Tornoto      F   30\n# >>> 2  Harry Porter      UK    London      M   20\n# >>> 3     Jean Grey   CHINA  Shanghai      F   30,\n\n# >>> ID      Customer            purchase       Date\n# >>> 0  101  Forrest Gump        Dragon Ball  2020-08-12\n# >>> 1  102     Mary Jane          Evangelion 2020-01-01\n# >>> 2  103  Harry Porter        Kill la Kill 2020-08-01\n# >>> 3  104     Jean Grey        Dragon Ball  1999-01-01\n# >>> 4  105     Mary Jane          Evangelion 2019-12-31\n# >>> 5  106  Harry Porter  Ghost in the Shell 2020-01-01\n# >>> 6  107     Jean Grey          Evangelion 2018-04-01,\n# >>> ])\n\n# To obtain data from a specific sheet, simply reference the key in the dictionary. For example, df['header_row5'] returns the sheet in which data starts from row 5.\ndf['header_row5']\n\n# >>>    Unnamed: 0    Unnamed: 1          Unnamed: 2           Unnamed: 3\n# >>> 0         NaN           NaN                 NaN                  NaN\n# >>> 1         NaN           NaN                 NaN                  NaN\n# >>> 2         NaN           NaN                 NaN                  NaN\n# >>> 3          ID      Customer            purchase                 Date\n# >>> 4         101  Forrest Gump        Dragon Ball   2020-08-12 00:00:00\n# >>> 5         102     Mary Jane          Evangelion  2020-01-01 00:00:00\n# >>> 6         103  Harry Porter        Kill la Kill  2020-08-01 00:00:00\n# >>> 7         104     Jean Grey        Dragon Ball   1999-01-01 00:00:00\n# >>> 8         105     Mary Jane          Evangelion  2019-12-31 00:00:00\n# >>> 9         106  Harry Porter  Ghost in the Shell  2020-01-01 00:00:00\n# >>> 10        107     Jean Grey          Evangelion  2018-04-01 00:00:00\n\n```\n","n":0.049}}},{"i":643,"$":{"0":{"v":"Examples","n":1},"1":{"v":"\n\n## Examples\n\n---\n\n```python\n# Libs\nimport pandas as pd\n\n# Instead of using CSV module this can make a dataframe out of your csv file\ndf = pd.read_csv('data.csv')\n\n# kind of like the skimr function in R to describe the dataset with common statistics\ndf.describe()\n\n# Preview of our data\ndf.head(10)\n\n# Preview of our data\ndf.tail(10)\n\n# Get the shape of the data frame (Rows, Columns)\n# Attribute not a method so no parens needed\ndf.shape\n\n# Get info about the data frame fields\n# This is a method so parens are needed\n# Object types are usually strings\ndf.info()\n\n# makes is so the printed dataframe above with the `df` call cell displays 85 total columns\npd.set_option('display.max_columns',85)\n# makes is so the printed dataframe above with the `df` call cell displays 85 total rows\npd.set_option('display.max_rows',85)\n\n# Load csv schema\nschema_df = pd.read_csv('data_schema.csv')\n\nschema_df\n```\n\n```python\n#!/usr/bin/env python\n# coding: utf-8\n\n# # Pandas tutorial with Stackoverflow data\n# \n# > This tutorial is using data from the stack overflow developer survey that can be found at the following link:\n# [Developer Survey List](https://insights.stackoverflow.com/survey)\n# Libs\nimport pandas as pd\n# Instead of using CSV module this can make a dataframe out of your csv file\ndf = pd.read_csv('data.csv')\n# Preview of our data\ndf.head(10)\n# Preview of our data\ndf.tail(10)\n# Get the shape of the data frame (Rows, Columns)\n# Attribute not a method so no parens needed\ndf.shape\n# Get info about the data frame fields\n# This is a method so parens are needed\n# Object types are usually strings\ndf.info()\n# makes is so the printed dataframe above with the `df` call cell displays 85 total columns\npd.set_option('display.max_columns',85)\n# makes is so the printed dataframe above with the `df` call cell displays 85 total rows\npd.set_option('display.max_rows',85)\n# Load csv schema\nschema_df = pd.read_csv('data_schema.csv')\nschema_df\ndf['Hobbyist']\npeople = {\n  \"first\": [\"Corey\", 'Jane', 'John'], \n  \"last\": [\"Schafer\", 'Doe', 'Doe'], \n  \"email\": [\"CoreyMSchafer@gmail.com\", 'JaneDoe@email.com', 'JohnDoe@email.com']\n}\npeople['email']\npeeps = pd.DataFrame(people)\npeeps\npeeps['email']\npeeps.email\npeeps[['last','email']]\npeeps.columns\n# loc = location\n# iloc = integer location\npeeps.iloc[[0, 1], 2] # return the first and second record and only the 3rd field of those records\ndf['email']\ndf.Hobbyist.value_counts()\n# # Video #3\n# ## Python Pandas Tutorial (Part 3): Indexes - How to Set, Reset, and Use Indexes\n# \n#[video3](https://youtu.be/W9XjRYFkkyw?list=PL-osiE80TeTsWmV9i9c58mdDCSskIFdDS)\n# \npeople = {\n  \"first\": [\"Corey\", 'Jane', 'John'], \n  \"last\": [\"Schafer\", 'Doe', 'Doe'], \n  \"email\": [\"CoreyMSchafer@gmail.com\", 'JaneDoe@email.com', 'JohnDoe@email.com']\n}\ndf = pd.DataFrame(people)\ndf.set_index('email')\ndf\ndf.set_index('email', inplace=True) # make it so changes overwrite the df\ndf\ndf.loc['CoreyMSchafer@gmail.com']\ndf.iloc[0]\nget_ipython().run_line_magic('lsmagic', '')\nget_ipython().run_cell_magic('html', '', '<b>hello there</b>')\nget_ipython().run_cell_magic('bash', '', 'ls -la')\nget_ipython().run_line_magic('ls', '-la')\nget_ipython().run_line_magic('ls', '-la')\nget_ipython().run_line_magic('ls', '-la')\n\n```\n\n---\n","n":0.053}}},{"i":644,"$":{"0":{"v":"Os","n":1}}},{"i":645,"$":{"0":{"v":"Stat","n":1},"1":{"v":"\n```python\nimport os\n\n# get file stats\nstats = os.stat('f:/file.txt')\nprint('Size of file is', stats.st_size, 'bytes')\n```\n","n":0.289}}},{"i":646,"$":{"0":{"v":"Openpyxl","n":1},"1":{"v":"\n\n- **Resources:**\n  - [Automate Excel With Python - Python Excel Tutorial (OpenPyXL)](https://youtu.be/7YS6YDQKFh0)\n- **Example:**\n\n```python\nfrom openpyxl import Workbook, load_workbook\nfrom openpyxl.utils import get_column_letter\nfrom openpyxl.styles import Font\n\ndata = {\n\"Joe\": {\n\t\"math\": 65,\n\t\"science\": 78,\n\t\"english\": 98,\n\t\"gym\": 89\n},\n\"Bill\": {\n\t\"math\": 55,\n\t\"science\": 72,\n\t\"english\": 87,\n\t\"gym\": 95\n},\n\"Tim\": {\n\t\"math\": 100,\n\t\"science\": 45,\n\t\"english\": 75,\n\t\"gym\": 92\n},\n\"Sally\": {\n\t\"math\": 30,\n\t\"science\": 25,\n\t\"english\": 45,\n\t\"gym\": 100\n},\n\"Jane\": {\n\t\"math\": 100,\n\t\"science\": 100,\n\t\"english\": 100,\n\t\"gym\": 60\n}\n}\n\nwb = Workbook()\nws = wb.active\nws.title = \"Grades\"\n\nheadings = ['Name'] + list(data['Joe'].keys())\nws.append(headings)\n\nfor person in data:\ngrades = list(data[person].values())\nws.append([person] + grades)\n\nfor col in range(2, len(data['Joe']) + 2):\nchar = get_column_letter(col)\nws[char + \"7\"] = f\"=SUM({char + '2'}:{char + '6'})/{len(data)}\"\n\nfor col in range(1, 6):\nws[get_column_letter(col) + '1'].font = Font(bold=True, color=\"0099CCFF\")\n\nwb.save(\"NewGrades.xlsx\")\n```\n","n":0.104}}},{"i":647,"$":{"0":{"v":"Numpy","n":1},"1":{"v":"\n\n- [[s.l.python]] [[s.l.python.libs.numpy]] [NumPy Tutorial](https://youtube.com/playlist?list=PLhTjy8cBISEpTyVbZGYUesjpeUXth8rqs)\n","n":0.447}}},{"i":648,"$":{"0":{"v":"Npyscreen","n":1},"1":{"v":"\n\n- **Resources:**\n  - [Create TUI on Python](https://medium.com/@ValTron/create-tui-on-python-71377849879d)\n  - [Read the docs](https://npyscreen.readthedocs.io/introduction.html)\n","n":0.302}}},{"i":649,"$":{"0":{"v":"Multiprocessing","n":1}}},{"i":650,"$":{"0":{"v":"Mkdocs","n":1}}},{"i":651,"$":{"0":{"v":"Mito","n":1},"1":{"v":"\n\n```bash\npython -m pip install mitoinstaller\npython -m mitoinstaller install\n```\n\n```python\nimport mitosheet\nimport pandas as pd\n\ndf = pd.DataFrame.from_dict(\n    {\n        \"col1\": [1,2,3,4,5],\n        \"col2\": [6,7,8,9,10],\n    }\n)\n\nmitosheet.sheet(df)\n```\n\n![alt](assets/images/Pasted_image_20211129113658.png)\n\n- Related:\n  - [[pandas|import.software.language.python.library.pandas]]\n  - [[polars|import.software.language.python.library.polars]]\n","n":0.2}}},{"i":652,"$":{"0":{"v":"Lux","n":1}}},{"i":653,"$":{"0":{"v":"Loguru","n":1},"1":{"v":"\n\n- [GitHub](https://github.com/Delgan/loguru)\n\n- import and send a log message straight to terminal\n\n```python\nfrom loguru import logger\n\nlogger.debug(\"That's it, beautiful and simple logging!\")\n\n```\n\n- want to add a log file as well as sending to stdout? simply pass the path to the file and it will append or create if it doesnt exist\n\n```python\nlogger.add(\"app.log\")\n```\n\n- you can also use variable components:\n\n```python\nlogger.add(\"file_{time}.log\")\n```\n\n- Additionally handlers and criteria once this are filtered through this:\n\n```python\nlogger.add(sys.stderr, format=\"{time} {level} {message}\", filter=\"my_module\", level=\"INFO\")\n```\n\n- catch exceptions\n\n```python\n@logger.catch\ndef my_function(x, y, z):\n  # An error? It's caught anyway!\n  return 1 / (x + y + z)\n```\n\n- back tracing and diagnosis of errors can also be added to a log file with a few additional kwargs:\n\n```python\nlogger.add(\"out.log\", backtrace=True, diagnose=True)\n```\n\n- Add custom fields and bind them to values you desire and want to compute\n\n```python\nlogger.add(\"file.log\", format=\"{extra[ip]} {extra[user]} {message}\")\ncontext_logger = logger.bind(ip=\"192.168.0.1\", user=\"someone\")\ncontext_logger.info(\"Contextualize your logger easily\")\ncontext_logger.bind(user=\"someone_else\").info(\"Inline binding of extra attribute\")\ncontext_logger.info(\"Use kwargs to add context during formatting: {user}\", user=\"anybody\")\n\n```\n","n":0.083}}},{"i":654,"$":{"0":{"v":"Logging","n":1},"1":{"v":"\n\n- [article on logging for a python app](https://towardsdatascience.com/the-reusable-python-logging-template-for-all-your-data-science-apps-551697c8540)\n- [Official Docs](https://docs.python.org/3/library/logging.html#)\n- The level of the logger:\n\n| Level    | Numberic Value |\n| -------- | -------------- |\n| NOTSET   | 0              |\n| DEBUG    | 10             |\n| INFO     | 20             |\n| WARNING  | 30             |\n| ERROR    | 40             |\n| CRITICAL | 50             |\n\n```python\nimport logging\n\ndir(logging)\n# items in all caps are constants\n# capitalized items are classes\n# lowercase are methods\n\n# create an configure logger\nlogging.basicConfig(filename = \"~/py.log\")\nlogger = logging.getLogger()\n\n# Test the logger\nlogger.info(\"our first message.\")\nprint(logger.level) # Defaulted 30 so info and below is not shown\n```\n\n- From [Calm Code Rich Logging](https://calmcode.io/logging/rich.html) only for the stream handler not the file handler\n\n```python\nimport logging\n\nfrom rich.logging import RichHandler\n\nlogger = logging.getLogger(__name__)\n\n# the handler determines where the logs go: stdout/file\nshell_handler = RichHandler()\nfile_handler = logging.FileHandler(\"debug.log\")\n\nlogger.setLevel(logging.DEBUG)\nshell_handler.setLevel(logging.DEBUG)\nfile_handler.setLevel(logging.DEBUG)\n\n# the formatter determines what our logs will look like\nfmt_shell = '%(message)s'\nfmt_file = '%(levelname)s %(asctime)s [%(filename)s:%(funcName)s:%(lineno)d] %(message)s'\n\nshell_formatter = logging.Formatter(fmt_shell)\nfile_formatter = logging.Formatter(fmt_file)\n\n# here we hook everything together\nshell_handler.setFormatter(shell_formatter)\nfile_handler.setFormatter(file_formatter)\n\nlogger.addHandler(shell_handler)\nlogger.addHandler(file_handler)\n```\n\n- To have aesthetic logging output easily:\n","n":0.082}}},{"i":655,"$":{"0":{"v":"Json","n":1},"1":{"v":"\n\n```python\nimport json\n\n# json.load(f) load json from a file or file like object\n# json.loads(s) load json data from a string\n# json.dump(j, f) write json objects to file or file like object\n# json.dumps(j) output json object as string\n\njson_file = open(\"sample.json\", \"r\", encoding=\"utf-8\")\n\nmovie = json.load(json_file)\njson_file.close()\nprint(movie)\n\ntype(movie)\nprint(movie[\"title\"])\n\nvalue = \"\"\"{\n  \"title\":\"Tron: Legacy\",\n  \"release_year\":2010,\n  \"won_oscar\":false,\n  \"actors\": null,\n  \"budget\":170000000,\n  \"composer\":\"Daft Punk\"\n  }\"\"\"\ntron = json.loads(value)\nprint(tron)\n\njson.dumps(movie)\nprint(json.dumps(movie))\n`\n","n":0.134}}},{"i":656,"$":{"0":{"v":"Itertools","n":1},"1":{"v":"\n\n- Reference:\n  - [[r.+.iterators,-iterables,-and-itertools-in-python-python-tutorial-learn-python-programming]]\n","n":0.5}}},{"i":657,"$":{"0":{"v":"Isort","n":1},"1":{"v":"\n\n- sorts the dependencies in your files\n- <https://pypi.org/project/isort/>\n","n":0.354}}},{"i":658,"$":{"0":{"v":"Interrogate","n":1},"1":{"v":"\n\n- [interrogate.py](https://calmcode.io/shorts/interrogate.py.html)\n- add as pre-commit hook to ensure functions have docstrings\n","n":0.302}}},{"i":659,"$":{"0":{"v":"Hvplot","n":1},"1":{"v":"\n\n- <https://hvplot.holoviz.org/>\n","n":0.707}}},{"i":660,"$":{"0":{"v":"Holoviz","n":1},"1":{"v":"\n\n- <https://holoviews.org/>\n","n":0.707}}},{"i":661,"$":{"0":{"v":"Glob","n":1},"1":{"v":"\n\n> glob contains the [[os|import.os]], [[sys|import.sys]], and [[re|import.re]] modules.\n\n```python\nimport glob\nglob.glob('/home/user', '*')\n```\n\n| Wildcard | Matches                                       | Example                                                |\n| -------- | --------------------------------------------- | ------------------------------------------------------ |\n| \\*       | any characters                                | \\*.txt matches all files with the txt extension        |\n| ?        | any one character                             | ??? matches files with 3 characters long               |\n| \\[]      | any character listed in the brackets          | [ABC]\\* matches files starting with A,B or C           |\n| [..]     | any character in the range listed in brackets | [A..Z]\\* matches files starting with capital letters   |\n| [!]      | any character listed in the brackets          | [!ABC]\\* matches files that do not start with A,B or C |\n","n":0.096}}},{"i":662,"$":{"0":{"v":"Getpass","n":1},"1":{"v":"\n\n- python built in just import and:\n\n```python\nimport getpass as gp\ngp.getpass(prompt=\"Give me your password!\")\n```\n","n":0.277}}},{"i":663,"$":{"0":{"v":"Functools","n":1}}},{"i":664,"$":{"0":{"v":"Wrapper Functions","n":0.707},"1":{"v":"\n\nrelated: [[s.l.python.funcs.decorators]]\n\n## Wrapper function\n\n```python\nfrom functools import wraps \n\ndef hello_decorator(func):\n\"\"\"Simple decorator function\"\"\" \n\t@wraps(func)\n\tdef wrapper(*args, **kwargs):\n\t\t\"\"\"Simple decorator wrapper function\"\"\"\n\t\tresult = func(*args, **kwargs)\n\t\treturn result \n\n\treturn wrapper\n\n@hello_decorator\ndef add(a, b):\n\t\"\"\"Simple function that returns sum of two numbers\"\"\"\n\treturn a + b \n\n@hello_decorator\ndef multiply(a, b):\n\t\"\"\"Simple function that returns multiplication of two numbers\"\"\"\n\treturn a * b \n\nif __name__ == '__main__': \n\thelp(add) \n\n\tprint(add.__name__)\n\tprint(add.__doc__) \n\n\toutput1 = add(2, 2)\n\tprint('Result:: ', output1) \n\n\tprint(\"=\" * 25)\n\thelp(multiply)\n\tprint(multiply.__name__)\n\tprint(multiply.__doc__)\n\toutput2 = multiply(4, 2)\n\tprint('Result:: ', output2)\n```\n","n":0.121}}},{"i":665,"$":{"0":{"v":"Cache","n":1},"1":{"v":"\n\n## Cache\n\n- <https://youtu.be/DnKxKFXB4NQ>\n  - [[r.(.python-functools-lru_cache]]\n\n```python\nimport timeit\nfrom functools import cache\nimport sys\nsys.setrecursionlimit(5000)\n@cache\ndef factorial(n):\n    return n * factorial(n-1) if n else 1\n\nif __name__ == '__main__':\n    print(timeit.timeit(\"factorial(100)\", setup=\"from __main__ import factorial\"))\n```\n","n":0.192}}},{"i":666,"$":{"0":{"v":"Flowpy","n":1}}},{"i":667,"$":{"0":{"v":"Flake8","n":1}}},{"i":668,"$":{"0":{"v":"Fastapi","n":1}}},{"i":669,"$":{"0":{"v":"Testing","n":1}}},{"i":670,"$":{"0":{"v":"Testclient","n":1},"1":{"v":"\n\n```python\nfrom fastapi import FastAPI\nfrom fastapi.testclient import TestClient\nfrom app.main import ap\nimport pytest\n\nclient = TestClient(app)\n\ndef test_root():\n    result = client.get('/')\n    print(result.json().get('message'))\n    assert result.json().get('message') == 'Hello World'\n    assert result.status_code == 200\n    # return {\"msg\": \"Hello World\"}\n\ndef test_create_user():\n    result = client.post(\"/users/\", json={\"email\": \"john.doe@gmail.com\",\"password\": \"password123\"})\n    # print(result.json().get('message'))\n    print(result.json())\n    assert result.json().get('email') == \"john.doe@gmail.com\"\n    assert result.status_code == 201\n\n```\n","n":0.141}}},{"i":671,"$":{"0":{"v":"Run and View","n":0.577},"1":{"v":"\n\n## Create and Run in Venv or on server port\n\n```bash\npoetry init &&\npoetry shell &&\npoetry add fastapi[all]\n```\n\nAfter Code is setup and ready to run:\n\n```bash\n# runs the app in the main.py file with the --reload option so that\n# changes when the file is saved are hot loaded into the running API service\n# on the port where the API is listening\n\n# assumes there is a python package\n# . My_Repo_Name\n# ‚îú‚îÄ‚îÄ‚îÄ app/\n# ‚îÇ    ‚îú‚îÄ‚îÄ‚îÄ __init__.py\n# ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ main.py\n# ‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ app()\n\nuvicorn app.main:app --reload\n```\n","n":0.113}}},{"i":672,"$":{"0":{"v":"Path Def API Endpoints","n":0.5},"1":{"v":"\n\n## Path definitions for API End Points\n\n<https://calmcode.io/til/fastapi-two-decorators.html>\n\n> Let's consider a very basic FastAPI app that has a health endpoint.\n\n```python\nfrom fastapi import FastAPI\n\napp = FastAPI()\n\n@app.get(\"/health\")\ndef get_health():\n    return {\"status\": \"alive\"}\n\n```\n\n> This `/health` endpoint has one job: to return a response with status 200. It can serve as a signal that the service is healthy and this is typically used by cloud providers as a indication that a service might need a restart.\n>\n> Some services however, don't use `/health` but `/healthz` instead. So how might you implement this? You could add another route.\n\n```python\nfrom fastapi import FastAPI\n\napp = FastAPI()\n\n@app.get(\"/health\")\ndef get_health():\n    return {\"status\": \"alive\"}\n\n@app.get(\"/healthz\")\ndef get_health():\n    return {\"status\": \"alive\"}\n\n```\n\n> But there's a simpler way, you can also just do this:\n\n```python\nfrom fastapi import FastAPI\n\napp = FastAPI()\n\n@app.get(\"/health\")\n@app.get(\"/healthz\")\ndef get_health():\n    return {\"status\": \"alive\"}\n\n```\n\n> You can totally stack decorators in Python, and FastAPI will just consider it another route that needs to be added.\n>\n> So you only need a single line of code. Neat!\n","n":0.081}}},{"i":673,"$":{"0":{"v":"Root","n":1},"1":{"v":"\n\n### API Root\n\n```python\n# This is a path operation / or also called a route\n@app.get('/') # this actually converts this function into an API end point that the user can access\n#    ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ The path operation, this is what happens when the users goes to the root, it path was `/login` then the user would only get here if they went to our site and `/login`\n#   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ The GET HTTP method is used to retrieve data from a server\nasync def root():\n    return {\"message\": \"Hello from my API\"} # fastapi automatically converts to JSON\n```\n\n#### Root Without Comments\n\n```python\n@app.get('/')\nasync def root():\n    return {\"message\": \"Hello from my API\"}\n```\n","n":0.099}}},{"i":674,"$":{"0":{"v":"Put","n":1},"1":{"v":"\n\n### Put\n\n```python\n@app.put(\"/posts/{id}\")\ndef update_post(id: int, post: Post):\n    index = find_index_post(id)\n    if index == None:\n        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=f\"post with id: {id} does not exist\")\n    post_dict = post.dict()\n    post_dict['id'] = id\n    my_posts[index] = post_dict\n    print(post)\n    return {\"data\": post_dict}\n```\n","n":0.169}}},{"i":675,"$":{"0":{"v":"Post","n":1},"1":{"v":"\n\n### Post\n\n```python\nfrom fastapi.params import Body\nfrom pydantic import BaseModel\n\n @app.post('/posts') # V1\n def create_posts(payLoad: dict = Body(...)): # Take in the body (data) of the POST request and do stuff with it\n     print(payLoad)\n     return {\"new_post\": f\"{payLoad['title'] =} {payLoad['content'] =}\"}\n\n#===========================================================================#\n\n@app.post('/posts') # V2\ndef create_posts(new_post: Post): # Take in the body (data) of the POST request and do stuff with it\n    print(new_post)\n    return {\"new_post\": f\"{new_post.title =} {new_post.content =}\"}\n```\n","n":0.125}}},{"i":676,"$":{"0":{"v":"Get","n":1},"1":{"v":"\n\n### Get\n\n```python\n@app.get('/posts') # in this instance this data gets returned to the user at 127.0.0.1:8000/posts\n# Due to granularity for the paths in the decorators if there are duplicates then the first one that matches is chosen\ndef get_posts():\n    return {\"data\": \"this is your posts\"}\n```\n\n#### Get Without Comments\n\n```python\n@app.get('/posts')\ndef get_posts():\n    return {\"data\": \"this is your posts\"}\n```\n","n":0.137}}},{"i":677,"$":{"0":{"v":"Delete","n":1},"1":{"v":"\n\n### Delete\n\n```python\n@app.delete(\"/posts/{id}\", status_code=status.HTTP_204_NO_CONTENT)\ndef delete_post(id: int):\n    index = find_index_post(id)\n    if index == None:\n        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=f\"post with id: {id} does not exist\")\n    my_posts.pop(index)\n    return Response(status_code=status.HTTP_204_NO_CONTENT)\n```\n","n":0.204}}},{"i":678,"$":{"0":{"v":"Order Matters","n":0.707},"1":{"v":"\n\n## Order matters\n\nIf your API function has a path parameter then your other more specific paths need to come before it so that it doesnt think part of the path is the expected input parameter\n\n```python\n@app.get(\"/posts/latest\")\ndef get_latest_post():\n    post = my_posts[len(my_posts) - 1]\n    return {\"detail\": post}\n\n@app.get(\"/posts/{id}\")\ndef get_post(id: int):\n    post = find_post(id)\n    return {\"post_detail\": post}\n```\n","n":0.139}}},{"i":679,"$":{"0":{"v":"HTTP Status Codes","n":0.577},"1":{"v":"\n\n## Dealing with HTTP status codes\n","n":0.408}}},{"i":680,"$":{"0":{"v":"404","n":1},"1":{"v":"\n\n### 404\n\n```python\nfrom fastapi import FastAPI, Response, status, HTTPException\n\napp = FastAPI()\n\n@app.get(\"/posts/{id}\")\ndef get_post(id: int, response: Response):\n    post = find_post(id)\n    if not post:\n\t\traise HTTPException(status_code=status.HTTP_404_NOT_FOUND,\n\t\t\t\t\t\t\tdetail=f\"post with id: {id} was not found\")\n    return {\"post_detail\": post}\n```\n","n":0.183}}},{"i":681,"$":{"0":{"v":"204","n":1},"1":{"v":"\n\n### 204\n\nCant delete something already deleted or doesnt exist and therefore cannot delete. No data returned\n\n```python\n@app.delete(\"/posts/{id}\", status_code=status.HTTP_204_NO_CONTENT)\ndef delete_post(id: int):\n    index = find_index_post(id)\n    if index == None:\n        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=f\"post with id: {id} does not exist\")\n    my_posts.pop(index)\n    return Response(status_code=status.HTTP_204_NO_CONTENT)\n```\n","n":0.162}}},{"i":682,"$":{"0":{"v":"Funcs","n":1}}},{"i":683,"$":{"0":{"v":"Router","n":1},"1":{"v":"\n```markdown\n.\n‚îî‚îÄ‚îÄ‚îÄapp\n    ‚îÇ   database.py\n    ‚îÇ   utils.py\n    ‚îÇ   __main__.py\n    ‚îÇ\n    ‚îî‚îÄ‚îÄ‚îÄrouters\n            post.py\n            user.py\n```\n\nusing routers you can break apart your API code into separate modules\n\n## In the submodules\n\n```python\nfrom fastapi import APIRouter\n\nrouter = APIRouter()\n\n# change the @app decorator from `@app` to `@router`\n```\n\n## In the main file\n\n```python\nfrom .routers import post, user\n\napp.include_router(post.router)\n```\n\nthis is like a [[s.l.cpp.funcs.header-file]] where all the code gets dumped into\nthat location. So this is a way of separating out the code to separate files\ncleanly.\n","n":0.119}}},{"i":684,"$":{"0":{"v":"Prefixes","n":1},"1":{"v":"\nAdding a prefix to the router object makes it so you can keep the endpoint path\nshort and sweet.\n\npassing this:\n\n```python\nrouter = APIRouter (\n    prefix=\"/posts\"\n)\n```\n\nmakes it so you can take this code:\n\n```python\n@app.get('/posts')\ndef get_posts():\n    ...\n\n@app.get(\"/posts/latest\")\ndef get_latest_post():\n    ...\n\n@app.get(\"/posts/{id}\")\ndef get_post():\n    ...\n```\n\nAnd turn it into this:\n\n```python\n@app.get('')\ndef get_posts():\n    ...\n\n@app.get(\"/latest\")\ndef get_latest_post():\n    ...\n\n@app.get(\"/{id}\")\ndef get_post():\n    ...\n```\n","n":0.147}}},{"i":685,"$":{"0":{"v":"Documentation Tags","n":0.707},"1":{"v":"\nSpecifying tags in the router object makes the documentation for granularly\ndefined and easier to read.\n\n```python\nrouter = APIRouter(\n    prefix='/posts',\n    tags='posts'\n)\n``` \n\nresults in something like this:\n\n![FastAPI tags](/assets/images/2022-01-11-10-22-42.png)\n","n":0.2}}},{"i":686,"$":{"0":{"v":"Documentation","n":1},"1":{"v":"\n\n## Documentation\n\nAuto generated documentation available on the API's port by default and is automatically constructed!\n\n`127.0.0.1:8000/docs`\n","n":0.258}}},{"i":687,"$":{"0":{"v":"Create API","n":0.707},"1":{"v":"\n\n## Create a FastAPI\n\n```python\nfrom fastapi import FastAPI\n\napp = FastAPI()\n```\n","n":0.333}}},{"i":688,"$":{"0":{"v":"Authentication","n":1},"1":{"v":"\n![jwt token](/assets/images/20221-01-11-10-25-47.png)\n","n":0.707}}},{"i":689,"$":{"0":{"v":"Jwt Token","n":0.707}}},{"i":690,"$":{"0":{"v":"Enum","n":1},"1":{"v":"\n\n```python\nfrom enum import Enum\n\nclass Shake(Enum):\n    VANILLA = 7\n    CHOCOLATE = 4\n    COOKIES = 9\n    MINT = 3\n\nfor shake in Shake:\n    print(shake)\n\t\n#>>> Shake.VANILLA\n#>>> Shake.CHOCOLATE\n#>>> Shake.COOKIES\n#>>> Shake.MINT\n```\n","n":0.2}}},{"i":691,"$":{"0":{"v":"Email","n":1},"1":{"v":"\n\n<https://realpython.com/python-send-email>\n","n":1}}},{"i":692,"$":{"0":{"v":"Datetime","n":1},"1":{"v":"\n\n> python will handle dates from january 1st 1 to december 31st 9999\n\n- **Classes**\n  - Date\n    - dates are constructed with 3 args `date(y,m,d)`\n  - Time\n  - Datetime\n- **Timedelta**\n  - use this class to add days to a date:\n\n```python\nfrom datetime import date, timedelta\n\ntoday = date(2020, 2, 19)\n\nprint(today)\nprint(today.year)\nprint(today.month)\nprint(today.day)\n\ntomorrow = timedelta(1)\nprint(\"Tomorrow is: \", today + tomorrow)\n```\n\n- formatting a date that is dropped into a template literal:\n\n```python\nimport datetime\n\ntoday = datetime.date(2020, 2, 19)\n\nprint(today)\nprint(today.year)\nprint(today.month)\nprint(today.day)\n\ntomorrow = datetime.timedelta(1)\nprint(\"Tomorrow is: \", today + tomorrow)\n\n# date time message formatting:\n\nprint(today.strftime(\"%A, %B %d, %Y\"))\nmessage = \"Today is: {:%A, %B %d, %Y}.\"\nprint(message.format(today))\n```\n\n- time delta can also be used to DATEDIFF\n","n":0.101}}},{"i":693,"$":{"0":{"v":"Formatting","n":1},"1":{"v":"\n| Code | Example                  | Description                                                                                                                                                                      |\n|------|--------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| %a   | Sun                      | Weekday as locale‚Äôs abbreviated name.                                                                                                                                            |\n| %A   | Sunday                   | Weekday as locale‚Äôs full name.                                                                                                                                                   |\n| %w   | 0                        | Weekday as a decimal number, where 0 is Sunday and 6 is Saturday.                                                                                                                |\n| %d   | 08                       | Day of the month as a zero-padded decimal number.                                                                                                                                |\n| %-d  | 8                        | Day of the month as a  decimal number. (Platform specific)                                                                                                                       |\n| %b   | Sep                      | Month as locale‚Äôs abbreviated name.                                                                                                                                              |\n| %B   | September                | Month as locale‚Äôs full name.                                                                                                                                                     |\n| %m   | 09                       | Month as a zero-padded decimal number.                                                                                                                                           |\n| %-m  | 9                        | Month as a  decimal number. (Platform specific)                                                                                                                                  |\n| %y   | 13                       | Year without century as a zero-padded decimal number.                                                                                                                            |\n| %Y   | 2013                     | Year with century as a decimal number.                                                                                                                                           |\n| %H   | 07                       | Hour (24-hour clock) as a zero-padded decimal number.                                                                                                                            |\n| %-H  | 7                        | Hour (24-hour clock) as a  decimal number. (Platform specific)                                                                                                                   |\n| %I   | 07                       | Hour (12-hour clock) as a zero-padded decimal number.                                                                                                                            |\n| %-I  | 7                        | Hour (12-hour clock) as a  decimal number. (Platform specific)                                                                                                                   |\n| %p   | AM                       | Locale‚Äôs equivalent of either AM or PM.                                                                                                                                          |\n| %M   | 06                       | Minute as a zero-padded decimal number.                                                                                                                                          |\n| %-M  | 6                        | Minute as a  decimal number. (Platform specific)                                                                                                                                 |\n| %S   | 05                       | Second as a zero-padded decimal number.                                                                                                                                          |\n| %-S  | 5                        | Second as a  decimal number. (Platform specific)                                                                                                                                 |\n| %f   | 000000                   | Microsecond as a decimal number, zero-padded on the left.                                                                                                                        |\n| %z   | +0000                    | UTC offset in the form ¬±HHMM[SS[.ffffff]] (empty string if the object is naive).                                                                                                 |\n| %Z   | UTC                      | Time zone name (empty string if the object is naive).                                                                                                                            |\n| %j   | 251                      | Day of the year as a zero-padded decimal number.                                                                                                                                 |\n| %-j  | 251                      | Day of the year as a  decimal number. (Platform specific)                                                                                                                        |\n| %U   | 36                       | Week number of the year (Sunday as the first day of the week) as a zero padded decimal number. All days in a new year preceding the first Sunday are considered to be in week 0. |\n| %W   | 35                       | Week number of the year (Monday as the first day of the week) as a decimal number. All days in a new year preceding the first Monday are considered to be in week 0.             |\n| %c   | Sun Sep  8 07:06:05 2013 | Locale‚Äôs appropriate date and time representation.                                                                                                                               |\n| %x   | 09/08/13                 | Locale‚Äôs appropriate date representation.                                                                                                                                        |\n| %X   | 07:06:05                 | Locale‚Äôs appropriate time representation.                                                                                                                                        |\n| %%   | %                        | A literal '%' character.                                                                                                                                                         |\n","n":0.047}}},{"i":694,"$":{"0":{"v":"Csv","n":1},"1":{"v":"\n\n- google stock data url [here](https://goo.gl/3zaUlD)\n\n```python\nimport csv\nfrom datetime import datetime\n\npath = \"googleStockData.csv\"\nfile = open(path, newline='')\nreader = csv.reader(file)\n\nheader = next(reader) #the first line is the header\n\n#print(header)\n#print(data[0])\ndata = []\nfor row in reader:\n  # row = [date, open, high, low, close, volume, adj.close]\n  #       date, float, float,float,float,integer,float\n  date = datetime.strptime(row[0], '%m/%d/%Y')\n  open_price = float(row[1]) #rename column as open is a function call\n  high = float(row[2])\n  low = float(row[3])\n  close = float(row[4])\n  volume = int(row[5])\n  adj_close = float(row[6])\n\n  data.append([date, open_price, high, low, close, volume, adj_close])\nprint(data[0])\n\n#compute and store daily stock returns\nreturns_path = \"google_returns.csv\"\nfile = open(returns_path, 'w')\nwriter = csv.writer(file)\nwriter.writerow([\"Date\", \"Return\"])\n\nfor i in range(len(data) - 1):\n  todays_row = data[i]\n  todays_date = todays_row[0]\n  todays_price = todays_row[-1]\n  yesterdays_row = data[i+1]\n  yesterdays_price = yesterdays_row[-1]\n\n  daily_return = (todays_price - yesterdays_price) / yesterdays_price\n  formatted_date = todays_date.strftime('%m/%d/%Y')\n  writer.writerow([formatted_date, daily_return])\n```\n","n":0.089}}},{"i":695,"$":{"0":{"v":"Code2flow","n":1},"1":{"v":"\n\n- build flow call stack charts of [[s.l.python]] programs\n  - use this python module: [code2flow](https://github.com/scottrogowski/code2flow)\n\n## Installation\n\n```bash\npip3 install code2flow\nbrew install graphviz\n```\n\n## Usage\n\n```bash\ncode2flow my_script.py && open out.png\n```\n\nneed graphviz installed **OR** use set `--output` to `file_name.dot`\n\nThen use this vscode extension: `tintinweb.graphviz-interactive-preview` to preview it\n","n":0.156}}},{"i":696,"$":{"0":{"v":"Clockpy","n":1},"1":{"v":"\n\n- [The Dev](https://www.linkedin.com/in/altieres-schincariol-netto-4a44a0106/?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABrEvLwBKwGlQXefpq1h3f3T-R-vhUnLdk4) \n- [The Post](https://www.linkedin.com/feed/update/urn:li:activity:6798152834048114688)\n- [SRC code](https://github.com/altnetto/clockpy)\n","n":0.354}}},{"i":697,"$":{"0":{"v":"Click","n":1},"1":{"v":"\n\n- [Click Docs](https://click.palletsprojects.com/en/8.0.x/)\n","n":0.577}}},{"i":698,"$":{"0":{"v":"Borb","n":1},"1":{"v":"\n\n- [Creating PDF Invoices in Python with borb](https://stackabuse.com/creating-pdf-invoices-in-python-with-borb/)\n","n":0.354}}},{"i":699,"$":{"0":{"v":"Blessed","n":1},"1":{"v":"\n\n- [PyPi - Blessed](https://pypi.org/project/blessed/)\n","n":0.5}}},{"i":700,"$":{"0":{"v":"Black","n":1},"1":{"v":"\n\n- [Calm Code](https://calmcode.io/black/introduction.html)\n- `.pre-commit-config.yaml`\n\n```yml\nrepos:\n-   repo: https://github.com/asottile/seed-isort-config\n\trev: v2.2.0\n\thooks:\n\t- id: seed-isort-config\n-   repo: https://github.com/pre-commit/mirrors-isort\n\trev: v5.8.0\n\thooks:\n\t- id: isort\n- repo: https://github.com/psf/black\n  rev: 21.6b0\n  hooks:\n  - id: black\n\tlanguage_version: python3\n\tdescription: \"Black: The uncompromising Python code formatter\"\n-   repo: https://gitlab.com/pycqa/flake8\n\trev: 3.9.2\n\thooks:\n\t- id: flake8\n-   repo: https://github.com/pre-commit/pre-commit-hooks\n\trev: v4.0.1\n\thooks:\n\t-   id: trailing-whitespace\n\t-   id: end-of-file-fixer\n\t-   id: check-docstring-first\n\t-   id: check-json\n\t\texclude: .vscode/settings.json\n\t-   id: check-added-large-files\n\t-   id: check-yaml\n\t-   id: debug-statements\n\t-   id: name-tests-test\n\t-   id: requirements-txt-fixer\n\n```\n\n- This will run all of the hooks before every commit ensuring code quality\n\n---\n\n- Reference:\n  - [[s.l.python.libs.pre-commit]]\n- Related:\n  - [[s.l.python.libs.venv.vulture]]\n  - [[cli.cmd.git]]\n\n","n":0.114}}},{"i":701,"$":{"0":{"v":"Asyncio","n":1},"1":{"v":"\n\n## Resources\n\n- [Python Asynchronous Programming - AsyncIO & Async/Await](https://youtu.be/t5Bo1Je9EmE)\n\n## Example\n\n```python\nimport asyncio\n\nasync def main():\n    await asyncio.sleep(0.5)\n    print('Bryan')\n    await asyncio.sleep(0.5)\n\nasyncio.run(main())\n\n#>>> Bryan\n```\n\n### async\n\n```python\nimport asyncio\n\nasync def main():\n    print('Bryan')\n\nasyncio.run(main())\n```\n\n### await\n\n```python\nimport asyncio\n\nasync def main():\n    await asyncio.sleep(0.5)\n    print('Bryan')\n    await asyncio.sleep(0.5)\n\nasyncio.run(main())\n\n#>>> Bryan\n```\n\n### gather\n\nRun several functions in parallel\n\n```python\nimport asyncio\n\nasync def main0():\n    print('Bryan')\n\nasync def main1():\n    print('John')\n\nasync def main2():\n    print('Jane')\n\nasync def testing():\n    asyncio.gather(\n            main0(),\n            main1(),\n            main2()\n    )\n\nasyncio.run(testing())\n```\n\n### Structure parallelism and sequential execution elegantly\n\n```python\nimport asyncio\n\nasync def run_sequence(*functions: Awaitable[Any]) -> None:\n    for function in functions:\n        await function\n\nasync def run_parallel(*functions: Awaitable[Any]) -> None:\n    await asyncio.gather(*functions)\n\n```\n\n- Reference:\n  - [[how-to-easily-do-asynchronous-programming-with-asyncio-in-python|r.+.2021.12.21.how-to-easily-do-asynchronous-programming-with-asyncio-in-python]]\n","n":0.109}}},{"i":702,"$":{"0":{"v":"Argparse","n":1},"1":{"v":"\n\n## Information\n\n- <https://realpython.com/command-line-interfaces-python-argparse/>\n- The Python [[argparse|import.argparse]] library:\n  - Allows the use of positional arguments\n  - Allows the customization of the prefix chars\n  - Supports variable numbers of parameters for a single option\n  - Supports subcommands (A main command line parser can use other command line parsers depending on some arguments.)\n\n## Examples\n\n```python\n# myls.py\n# Import the argparse library\nimport argparse\n\nimport os\nimport sys\n\nmy_parser = argparse.ArgumentParser(prog='myls',\n\t\t\t\t\t\t\t\t  usage='%(prog)s [options] path',\n\t\t\t\t\t\t\t\t  description='List the content of a folder')\n\nmy_parser.version = '1.0'\nmy_parser.add_argument('-a',\n\t\t\t\t\t action='store',\n\t\t\t\t\t choices=['head', 'tail'],\n\t\t\t\t\t help='set the user choice to head or tail')\nmy_parser.add_argument('-b',\n\t\t\t\t\t action='store_const',\n\t\t\t\t\t const=42,\n\t\t\t\t\t type=int)\nmy_parser.add_argument('-c', action='store_true')\nmy_parser.add_argument('-d', action='store_false')\nmy_parser.add_argument('-e', action='append')\nmy_parser.add_argument('-f',\n\t\t\t\t\t action='append_const',\n\t\t\t\t\t const=42,\n\t\t\t\t\t type=int)\nmy_parser.add_argument('-g', action='count')\nmy_parser.add_argument('-i', action='help')\nmy_parser.add_argument('-j', action='version')\nmy_parser.add_argument('-k',\n\t\t\t\t\t action='store',\n\t\t\t\t\t type=int,\n\t\t\t\t\t choices=range(1, 5))\n\nmy_group = my_parser.add_mutually_exclusive_group(required=True)\n\nmy_group.add_argument('-v', '--verbose', action='store_true')\nmy_group.add_argument('-s', '--silent', action='store_true')\n\n# Add the arguments\nmy_parser.add_argument('Path',\n\t\t\t\t\t metavar='path',\n\t\t\t\t\t type=str,\n\t\t\t\t\t help='the path to list')\n\n# Execute the parse_args() method\nargs = my_parser.parse_args()\n\ninput_path = args.Path\n\nif not os.path.isdir(input_path):\n  print('The path specified does not exist')\n  sys.exit()\n\nprint('\\n'.join(os.listdir(input_path)))\n```\n","n":0.087}}},{"i":703,"$":{"0":{"v":"Alive Progress","n":0.707},"1":{"v":"\n\n- [GitHub Repo](https://github.com/rsalmei/alive-progress)\n\n","n":0.577}}},{"i":704,"$":{"0":{"v":"Funcs","n":1},"1":{"v":"\n\n## Functions\n\n```python\ndef pow(p):\n\t\"\"\"Calculate the power\"\"\"\n\treturn p*p\n```\n\n\n\n\n","n":0.408}}},{"i":705,"$":{"0":{"v":"Nesting","n":1},"1":{"v":"\n\n## Functions Can Be Nested\n\n```python\ndef func1(a, b): \n\tdef inner_func(x):\n\t\treturn x*x*x \n\treturn inner_func(a) + inner_func(b)\n```\n","n":0.267}}},{"i":706,"$":{"0":{"v":"Map Filter Reduce","n":0.577},"1":{"v":"\n\n## Map Filter Reduce\n\n```python\nimport math\n\ndef area(r):\n\t\"\"\"Area of a circle with radius 'r'.\"\"\"\n\treturn math.pi * (r2)\n\nradii = [2, 5, 7.1, 0.3, 10]\n# Method 1: Direct Method\nareas = []\nfor r in radii:\n\ta = area(r)\n\tareas.append(a)\n\nprint(areas)\nradii = [2, 5, 7.1, 0.3, 10]\n# map(<function>, <list, tuple, or other iterable object>)\nlist(map(area, radii))\nprint(list(map(area, radii)))\n# Celcius to Farenheit with map and lambda\ntemps = [(\"Berlin\",29), (\"Cairo\", 36), (\"Buenos Aires\", 19), (\"Los Angelas\", 26), (\"Tokyo\", 27), (\"New York\", 28), (\"London\", 22), (\"Beijing\", 32)]\n\nc_to_f = lambda data: (data[0], (9/5)*data[1] + 32)\n\nprint(list(map(c_to_f, temps)))\n\nimport statistics\n\ndata = [1.3, 2.7, 0.8, 4.1, 4.3, -0.1]\navg = statistics.mean(data)\nprint(avg)\nprint(list(filter(lambda x: x > avg, data)))\n# Remove Missing Data\ncountries = [\"\", \"Argentina\", \"\", \"Brazil\", \"Chile\", \"\", \"Columbia\", \"\", \"Ecuador\", \"\", \"\", \"Venezuela\"]\n\nprint(list(filter(None, countries)))\n# dont use reduce, just use an explicit for loop\n```\n","n":0.091}}},{"i":707,"$":{"0":{"v":"Decorators","n":1},"1":{"v":"\n\n```python\ndef hello_decorator(func):\n\tdef wrapper(*args, **kwargs):\n\t\tresult = func(*args, **kwargs)\n\t\treturn result\nreturn wrapper\n\n@hello_decorator\ndef add(a, b):\n\treturn a + b \n\nif __name__ == '__main__':\n\toutput = add(2, 2)\n\tprint(output)\n```\n\n![alt](assets/images/Pasted_image_20210916111645.png)\n\n- [Python Decorators in 15 Minutes](https://youtu.be/r7Dtus7N4pI) \\| [Calm Code Decorators](https://calmcode.io/decorators/introduction.html) #üíªÔ∏è/‚≠ê \n- [Decorators 101](https://sureshdsk.dev/python-decorators-101)\n- [Decorators 201](https://sureshdsk.dev/python-decorators-201)\n  - To get the correct doc strings and indicate that wrapping has occurred on the given function we can use the [[s.l.python.libs.functools]] module with the `wraps` function\n- [Decorators with params](https://sureshdsk.dev/python-decorators-with-parameters)\n  - Useful with using Classes so the extra param passing boiler plate can be avoided\n- [3 Essential Decorators in Python You Need To Know](https://betterprogramming.pub/3-essential-decorators-in-python-you-need-to-know-654650bd5c36)\n- Can use logging decorators with [[s.l.python.libs.functools]] to log data changes:\n\n```python\nfrom functools import wraps\nimport datetime as dt\n\ndef log_step(func):\n  @wraps(func)\n  def wrapper(*args, **kwargs):\n\t  tic = dt.datetime.now()\n\t  result = func(*args, **kwargs)\n\t  time_taken = str(dt.datetime.now() - tic)\n\t  print(f\"just ran step {func.__name__} shape={result.shape} took {time_taken}s\")\n\t  return result\n  return wrapper\n```\n","n":0.086}}},{"i":708,"$":{"0":{"v":"__main__","n":1},"1":{"v":"\n\n## The \\_\\_main\\_\\_ Function\n\n```python\nimport time\n\ndef useful_function():\n\tfor i in range(5):\n\t\tprint(\"I sweat I'm useful: {}\".format(i))\n\t\ttime.sleep(1.0)\n\n# This function call if un commented would make it so if the script was run\n# on the CLI then it would execute the function code. However, if we want to \n# Re-use the code as a module import and not have it run immediately on import\n# Then you need the following logical construct\n# useful_function()\n\n# This code checks if the entry point to the current session is this file.\n# i.e. did we run this file like a script? or are we importing from another \n# location that is actually \"__main__\" and we're a sub process declaring\n# variables, functions, and classes? Anything under this construct is ran and \n# defined only if the script is executed as a stand alone script and not imported\nif __name__ == \"__main__\":\n\tuseful_function()\n```\n","n":0.085}}},{"i":709,"$":{"0":{"v":"Flow","n":1}}},{"i":710,"$":{"0":{"v":"Ternary Operator","n":0.707},"1":{"v":"\n\n## Ternary Operator\n\n```python\n#You'll typically see:\nreputation = 30\nif reputation > 25:\n\tname = \"admin\"\nelse:\n\tname = \"visitor\"\n\tprint(name)\n\nreputation = 20\nname = \"admin\" if reputation > 25 else \"visitor\"\nprint(name)\n#>>> admin\n#>>> visitor\n```\n","n":0.196}}},{"i":711,"$":{"0":{"v":"Loops","n":1}}},{"i":712,"$":{"0":{"v":"While","n":1},"1":{"v":"\n\n### While Loop\n\n```python\ni = 1\nwhile i <= 10:\n\tprint(i)\n\ti+=1\n```\n\n\n","n":0.354}}},{"i":713,"$":{"0":{"v":"For","n":1},"1":{"v":"\n\n### For Loop\n\n```python\nfor letter in \"giraffe academy\":\n\tprint(letter)\n\nfriends = [\"Jim\", \"Suzy\", \"Kevin\"]\n\nfor name in friends:\n\tprint(name)\n\nfor index in range(10):\n\tprint(index) # prints 1-9 not including 10 so always increment upwards by 1\n```\n","n":0.186}}},{"i":714,"$":{"0":{"v":"Exception Handling","n":0.707},"1":{"v":"\n\n## Exception Handling\n\n```python\ntry:\n\tnumber = int(input(\"enter a number: \"))\n\tprint(number/0) #divide by zero\nexcept ZeroDivisionError as err:\n\tprint(err)\n\tprint(\"Divided By Zero\")\nexcept ValueError:\n\tprint(\"invalid input\")\n# OUTPUT:\n## ./test.py\n## enter a number: 1\n## integer division or modulo by zero\n## Divided By Zero\n```\n","n":0.174}}},{"i":715,"$":{"0":{"v":"Case Statements","n":0.707},"1":{"v":"\n\n## Case Statement\n\n- Python 3.10 added Match Case statements\n\n```python\nx = \"hello\" \n\nmatch x:\n\tcase \"hello\":\n\t\tprint(\"hello\")\n\tcase \"hi\":\n\t\tprint(\"hi\")\n\tcase _:\n\t\tprint(\"default case\")\n```\n","n":0.243}}},{"i":716,"$":{"0":{"v":"Files","n":1},"1":{"v":"\n\n```python\nwith open(\"employees.txt\",\"r\") as employee_file: # Filename, Mode (r:read a:append w:write)\n\tprint(employee_file.readable()) # returns T/F if we can read the file\n\tprint(employee_file.readline()) # reads the first line of the file\n\tprint(employee_file.readline()) # reads the next line (second) in the file\n\tprint(employee_file.readline()[2]) # reads the (third) in the file\n# always close open files\nemployee_file.close() # not necessary if using a context manager `with`\n\n\n# Python program to illustrate\n# Append vs write mode\nwith open(\"myfile.txt\", \"w\") as file1:\n\tL = [\"This is Delhi \\n\", \"This is Paris \\n\", \"This is London\"]\n\tfile1.writelines(L)\n\t   \n# Append-adds at last\nwith open(\"myfile.txt\", \"a\") as file1:  # append mode \n\tfile1.write(\"Today \\n\")\n\t   \nwith open(\"myfile.txt\", \"r\") as file1:\n\tprint(\"Output of Readlines after appending\")\n\tprint(file1.read())\n\tprint()\n\t   \n# Write-Overwrites\nwith open(\"myfile.txt\", \"w\") as file1:  # write mode \n\tfile1.write(\"Tomorrow \\n\")\n\t   \nwith open(\"myfile.txt\", \"r\") as file1:\n\tprint(\"Output of Readlines after writing\")\n\tprint(file1.read())\n\tprint()\n\t\n# Output:\n\n#> Output of Readlines after appending\n#> This is Delhi\n#> This is Paris\n#> This is LondonToday\n#> \n#> \n#> Output of Readlines after writing\n#> Tomorrow\n```\n","n":0.083}}},{"i":717,"$":{"0":{"v":"Data T","n":0.707}}},{"i":718,"$":{"0":{"v":"Type Hints","n":0.707}}},{"i":719,"$":{"0":{"v":"Union","n":1},"1":{"v":"\n\n![[s.l.python.releases.3.10.union-operator-type-hint]]\n","n":1}}},{"i":720,"$":{"0":{"v":"Tuple","n":1},"1":{"v":"\n\n## Tuple Type:\n\n```python\nfrom typing import Tuple\n\n# This is an error because the tuple can contain items of differing types \n# so you need to specify the type of each item within it\nx: Tuple[int] = (1, 2, 3) \n\nx: Tuple[int, int, int] = (1, 2, 3)\n```\n","n":0.149}}},{"i":721,"$":{"0":{"v":"Sequence","n":1},"1":{"v":"\n\n## Sequence Type\n\n```python\nfrom typing import Sequence\n\ndef foo(seq: Sequence[str]):\npass\nfoo(\"Hello\") # This is fine because a string is a sequence of characters\nfoo((\"a\", \"b\", \"c\")) # a Tuple is an ordered and immutable indexed Object\nfoo([\"a\", \"b\", \"c\"]) # A list is an ordered and indexed object \nfoo({1, 2, 3}) # A set is hashed and not indexed or ordered so it cannot be a sequence\nfoo(1)\n#>>> Last one throws an error because static analysis determines that it is an incompabile type\n```\n","n":0.114}}},{"i":722,"$":{"0":{"v":"Optional","n":1},"1":{"v":"\n\n## Optional typing\n\n```python\nfrom typing import Optional\n\ndef foo(output: Optional[bool]=False):\n\tpass\nfoo()\n```\n","n":0.354}}},{"i":723,"$":{"0":{"v":"Generics","n":1},"1":{"v":"\n\n## Generics:\n\n```python\nfrom typing import TypeVar, List\n\nT = TypeVar('T')\n\ndef get_item(lst: List[T], index: int) -> T:\n\treturn lst[index]\n```\n","n":0.258}}},{"i":724,"$":{"0":{"v":"Custom","n":1},"1":{"v":"\n\n- Using the `typing` library you can import types for data structures and custom types more than just the standard primitive types\n\n## Custom Typing\n\n```python\nfrom typing import List\n\nVector = List[float]\t\n\ndef foo(v: Vector) -> Vector:\n\tprint(v)\n```\n\n![alt](assets/images/Pasted_image_20211215085306.png)\n\n### Can also use our own custom types like this:\n\n```python\nfrom typing import List\n\nVector = List[float]\nVectors = List[Vector]\n\ndef foo(v: Vectors) -> Vectors:\n\tprint(v)\n```\n","n":0.137}}},{"i":725,"$":{"0":{"v":"Callable","n":1},"1":{"v":"\n\n## Callable Type:\n\n```python\nfrom typing import callable, Optional\n\ndef foo(func: Callable[[int, int, Optional[int]], int]) -> None:\n\tfunc(1, 2)\n\ndef add(x: int, y: int) -> int:\n\treturn x + y\n\nfoo(add)\n\n#=================================================================#\n\ndef foo() -> Callable[[int, int, Optional[int]], int]):\n\tdef add(x: int, y: int) -> int:\n\t\treturn x + y\n\treturn add\n\nfoo()\n\n#=================================================================#\n\ndef foo() -> Callable[[int, int], int]):\n\tfunc: Callable[[int, int], int]) = Lambda x, y: x + y\n\treturn func\n\nfoo()\n```\n","n":0.134}}},{"i":726,"$":{"0":{"v":"Any","n":1},"1":{"v":"\n\n## Any Type\n\nAny Type is the same as not adding an annotation but more explicit\n\n```python\nfrom typing import Any\n\ndef foo(output: Any):\n\tpass\n```\n","n":0.224}}},{"i":727,"$":{"0":{"v":"Strings","n":1},"1":{"v":"\n\n### Strings\n\n```python\n# This is an ordinary string\nprint(\"This is a string\")\n\n# This is a function Doc string\ndef function(x):\n\t\"\"\"This is a doc string explaining\n\tthe inner workings of this function\n\t\"\"\"\n\ty = x * 7\n\treutrn(y)\n\nx = 17\nprinter = \"hewlet packard\"\n\n# This is a template literal \"F string\"\nprint(f\"I just printed {x} pages to the printer {printer}\")\n# or for less elegence\nprint(\"I just printed\" + x + \"pages to the printer\" + printer)\n```\n","n":0.123}}},{"i":728,"$":{"0":{"v":"Fstrings","n":1},"1":{"v":"\n- [Python 3's f-Strings: An Improved String Formatting Syntax (Guide)](https://realpython.com/python-f-strings/)\n- F String format specifications\n\n!!! **DO NOT USE F-STRINGS FOR SQL STATEMENTS** use the `.format` syntax as this santizes a lot of malicious input\n","n":0.174}}},{"i":729,"$":{"0":{"v":"Variable Name Reuse","n":0.577},"1":{"v":"\n## Reuse variable name\n\n- f strings that have a trailing `=` will print a statement like this:\n\n```python\nx=7\nprint(f'{x=}')\n# >>> x=7\nprint(f'{x =}')\n# >>> x =7\nprint(f'{x = }')\n# >>> x = 7\n```\n","n":0.186}}},{"i":730,"$":{"0":{"v":"Printing Ascii","n":0.707},"1":{"v":"\n## Printing Ascii\n\n- to print the repr of the value end the fstring with a `!r`:\n\n```python\nx = \"hello ‚úÖ\"\nprint(f'{x!r}')\n# >>> \"hello ‚úÖ\"\n```\n\n- to print only ascii values end the fstring with a `!a`:\n\n```python\nx = \"hello ‚úÖ\"\nprint(f'{x!a}')\n# >>> \"hello \\u2705\"\n```\n\n- to print string values without quotes end the fstring with a `!s`:\n\n```python\nx = \"hello ‚úÖ\"\nprint(f'{x!a}')\n# >>> hello ‚úÖ\n```\n","n":0.132}}},{"i":731,"$":{"0":{"v":"Number Formatting","n":0.707},"1":{"v":"\n## Number Formatting\n\n### Floats\n\n```python\n\npi = 3.1415926\nprint(f'Pi is approximately equal to {pi:.2f}')\n# Pi is approximately equal to 3.14\n```\n\n### Integer\n\n```python\nid = 1  # need to print a 3-digit number\nprint(f\"The id is {id:03d}\")\n# The id is 001\n```\n\n### Number separator\n\n```python\nN = 1000000000  # need to add separator\nprint(f'His networth is ${N:,d}')\n# His networth is $1,000,000,000\n```\n","n":0.141}}},{"i":732,"$":{"0":{"v":"Nested Formatting Conditions","n":0.577},"1":{"v":"\n```python\nnum_value = 123.456\nnested_format = \".2f\"\nprint(f'{num_value:{nested_format}}')\n# >>> 123.46\n```\n","n":0.378}}},{"i":733,"$":{"0":{"v":"Date Formatting","n":0.707},"1":{"v":"\n## Date and number formatting\n\n```python\nimport datetime\nfrom datetime import datetime\ntoday = datetime.today()\nprint(f'{datetime.datetime.utcnow():%Y-%m-%d}')\nprint(f\"Today is {today}\")\n# Today is 2021-07-31 18:20:48.956829\nprint(f\"Today is {today:%B %d, %Y}\")\n# Today is July 31, 2021\nprint(f\"Today is {today:%m-%d-%Y}\")\n# Today is 07-31-2021\n\nprint(f\"Today is {datetime.today()}\")\n# Today is 2021-07-31 18:20:48.956829\n```\n","n":0.164}}},{"i":734,"$":{"0":{"v":"Integers","n":1},"1":{"v":"\n\n```python\n# Integer whole numbers\na = 496\nprint(type(a)) # int for integer\n\n# Float for floating point number\na = 496\nprint(type(a)) # float\n\n# Complex Numbers (in math i is used for imaginary numbers, in programming and python it is 'j')\na = 496 - 6.1j #the j is the complex part\nprint(type(a)) # complex\nprint(a.real) # view the real part of the number\nprint(a.imag) # view the imaginary part of the number\n```\n","n":0.125}}},{"i":735,"$":{"0":{"v":"Generators","n":1},"1":{"v":"\n\n```python\n# Instead of holding values in memory:\n\nx = range(1_000_000)\n\n# Use a generator that only spits out values as needed\n\nx = (i for i in range(1_000_000))\n\n#  ================================================ #\n\n# Using functions as a generator\n\ndef gen(n):\n\tfor i in range(n):\n\t\tyield i\n\nfor i in gen(5):\n\tprint(i)\n\t\n# V.S.\n\nx = range(5)\n\nfor i in x:\n\tprint(i)\n\t\t\n```\n","n":0.147}}},{"i":736,"$":{"0":{"v":"Booleans","n":1},"1":{"v":"\n\n```python\nTrue & False # these ARE the operators\ntrue & false # These are NOT the operators\nTRUE & FALSE # These are NOT the operators\n\nbool(\" \") # True\nbool(\"\")  # False\nbool(1)   # True\nbool(0)   # False\n```\n","n":0.174}}},{"i":737,"$":{"0":{"v":"Data S","n":0.707}}},{"i":738,"$":{"0":{"v":"Tuple","n":1},"1":{"v":"\n\n### Tuple\n\n```python\n# can be created just by assigning values encapsulated in parens\n# or for a single value leaving a trailing comma\n\na = (1, 2, 3, 4)\n# or\nb = ('a',)\n# or\nc = 1, 2, 3, 4,\n\n# tuples are immutable, they are smaller in memory than lists, have less methods available to them, and are faster that lists.\n\nsurvey = (27, \"vietnam\", True)\nage, country, knows_python = survey # this works\nprint(age)\nprint(country)\nprint(knows_python)\n```\n","n":0.122}}},{"i":739,"$":{"0":{"v":"Set","n":1},"1":{"v":"\n\n### Set\n\n```python\n# a set is like a hashtable, the order is not important and they are not ordered like an array\n# sets cannot contain duplicate values\na = set([1,2,3,4])\na = (1, 2, 3, 4)\n\n# methods\na.add() # adds an item to the set\na.remove() # removes an existing item from the set\na.discard() # acts like remove but if item is not a part of the set, do nothing and throw no errors (remove quietly)\na.clear() # removes all items from the set and it becomes empty\nlen(a) # lets you see how many items are in the set\n# faster way of making a set is to pass an `[]` array to the set() function\n\na = set([1,3,5,7,9])\nb = set([2,4,6,8,10])\nc = set([2, 3, 5 ,7])\na.union(b) # = 1, 2, 3, 4, 5, 6, 7, 8, 9, 10\na.intersection(c) # = 3, 5, 7\n\n2 in b # result is True\n9 not in a # Result is False 9 IS in the set of odd numbers\n```\n","n":0.08}}},{"i":740,"$":{"0":{"v":"Frozen","n":1},"1":{"v":"\n\n### Frozen Set\n\n```python\n# less methods than sets\n# immutable\n```\n","n":0.354}}},{"i":741,"$":{"0":{"v":"Scoping","n":1},"1":{"v":"\n\n### Data Structures do not even need to be passed to class \\_\\_init\\_\\_ functions\n\n```python\n# Data structures like lists and dictionaries dont even need to be passed into the classes init function.\n# The data lives at global scope, is mutated by reference not value.\n\n\nclass Mutator:\n\n    def mutate(self):\n        data.append(3)  # >>> [0, 1, 2, 3]\n        def add_four(data):\n            data.append(4)\n        add_four(data)  # >>> [0, 1, 2, 3, 4]\n\n\nif __name__ == \"__main__\":\n    data = [0, 1, 2]\n    print(data)  # >>> [0, 1, 2]\n    m = Mutator()\n    m.mutate()\n    print(data)  # >>> [0, 1, 2, 3, 4]\n\n```\n","n":0.105}}},{"i":742,"$":{"0":{"v":"Pass by Ref","n":0.577},"1":{"v":"\n\n### Data Structures are passed by reference not value\n\n```python\n# Data structures are passed by reference, not by value.\n# So the dictionary can be passed into a class instance, operated upon, and then when the class is over the data itself is mutated\n# making it so classes dont need to play hot potato with data. and just just be called and manipulate data at the global state level.\n\nclass Mutator:\n    def __init__(self, data) -> None:\n        self.data = data  # Grab a reference to the data for the class to use internally\n\n    def mutate(self):\n        self.data[\"fname\"] = \"John\"  # Manipulate the data in the class\n        print(F\"After function call within class instance:\\n\\t{data}\")  # Show result of manipulation\n\n\nif __name__ == \"__main__\":\n    data = {\n        \"fname\": \"Bryan\",\n        \"lname\": \"Jenks\",\n        \"age\": 29,\n    }\n    print(F\"Before function call and at global scope:\\n\\t{data}\")  # show original data in before manipulation\n    m = Mutator(data)  # Pass the data into the class\n    m.mutate()  # Manipulate the data\n    print(F\"After class instance, and at global scope:\\n\\t{data}\")  # Show result of manipulation at global scope level (not in class)\n```\n","n":0.076}}},{"i":743,"$":{"0":{"v":"List","n":1},"1":{"v":"\n\n### List\n\n```python\n# basically an array as you understand them\n\na = [1, 2, 3, 4, 5]\na.append(17) # adds a new item to the end of the list\na.append(19) # adds a new item to the end of the list\na = [1, 2, 3, 4, 5, 17, 19]\n\na[-1] # shows the item at the end of the list by wrapping around\n# you can only wrap around completely, once, otherwise you will get an error.\n\na[2:5] # this slices out a smaller list. the starting index number element is included and the ending index number is not included so indexes returned will be 2, 3, 4 but not 5\n\nb = ['a', 'b', 'c']\na + b # = [1, 2, 3, 4, 5, 17, 19, 'a', 'b', 'c']\n# adding lists together causes concatenation\n```\n","n":0.089}}},{"i":744,"$":{"0":{"v":"Dictionary","n":1},"1":{"v":"\n\n### Dictionary\n\n```python\n# key value pairs, basically an object in javascript\nmy_dictionary = {\"key\":\"my_key\", \"value\":666}\nmy_dictionary.keys()\nmy_dictionary.values()\n\n# to add more key value pairs after initialization to the dictionary use object name and brackets around the key and set equal to the value:\nmy_dictionary[\"name\"] = \"Bryan Jenks\"\n# with bracket method the key needs quotes around it but in the constructor function you DONT need quotes on the key names:\ndict(message=\"test\", language=\"english\")\n\nfor key, value in my_dictionary.items():\n\tprint(key, \"=\", value)\n```\n","n":0.12}}},{"i":745,"$":{"0":{"v":"Conventions","n":1},"1":{"v":"\n\n- Classes: Proper Snake Case\n- Constants: Upper Snake Case\n- Functions: Lower Snake Case\n- Variables: Lower Snake Case\n- Spaces > Tabs\n","n":0.224}}},{"i":746,"$":{"0":{"v":"Build","n":1}}},{"i":747,"$":{"0":{"v":"Poetry","n":1},"1":{"v":"\n\n**Using Poetry**\n\n- 1. [Installation](https://python-poetry.org/docs/#windows-powershell-install-instructions)\n  - 1.1 Configuration: `poetry completions bash > /etc/bash_completion.d/poetry.bash-completion`\n- 2. Usage `poetry new poetry-demo` to make a new directory project or `poetry init` in current project\n- 3. Activate venv in the project `poetry shell`\n- 4. Add dependencies `poetry add pandas` add developer dependencies with `poetry add --dev pytest`\n  - 4.1 get latest versions of all dependencies `poetry update` or list which to update `poetry update pandas`\n- 5. Build the source and wheel archives `poetry build`\n- 6. deactivate venv `exit`\n- 7. [publish to PyPi](https://python-poetry.org/docs/libraries/#publishing-to-pypi) `poetry publish`\n- Opening a poetry project and installing them `poetry install`\n- update poetry `poetry self update`\n- poetry help pages easy to access `poetry help <command>`\n","n":0.095}}},{"i":748,"$":{"0":{"v":"Powershell","n":1},"1":{"v":"\n\n- <https://docs.microsoft.com/en-us/powershell/module/microsoft.powershell.core/about/about_special_characters?view=powershell-7.1#escape-e>\n- powershell setups\n  - <https://codeandkeep.com/PowerShell-And-Vim/>\n","n":0.408}}},{"i":749,"$":{"0":{"v":"Doc","n":1},"1":{"v":"\n\nBlock comment syntax for power shell starts with `<#`\n","n":0.333}}},{"i":750,"$":{"0":{"v":"Lisp","n":1}}},{"i":751,"$":{"0":{"v":"Syntax","n":1},"1":{"v":"\n\n- One of the hallmarks of lisp is that the data resembles the code.\n- Lisp is dynamically typed\n- Parens. Parens everywhere.\n\n```lisp\n(+ 1 2)\n;; 3\n```\n\n```lisp\n;; VARIABLES\n(setf foo \"hello world\")\n(pprint foo)\n;; hello world\n```\n\n```lisp\n(pprint (string-upcase foo))\n;; HELLO WORLD\n```\n","n":0.169}}},{"i":752,"$":{"0":{"v":"Setup","n":1},"1":{"v":"\n\n- vscode Extensions\n  - `ailisp.strict-paredit`\n  - `ailisp.commonlisp-vscode`\n    - `mattn.lisp`\n    - `ailisp.commonlisp-vscode`\n    - `ailisp.strict-paredit`\n  - `ailisp.commonlisp-vscode`\n    - `mattn.lisp`\n  - MacOS Boostrap\n\n```bash\nbrew install clisp\nbrew install roswell\nros install ailisp/linedit\nros install ailisp/prepl\nros install ailisp/cl-lsp\nros install sbcl\nros use sbcl\n```\n","n":0.171}}},{"i":753,"$":{"0":{"v":"Resources","n":1},"1":{"v":"\n\n- <https://opensource.com/article/21/5/learn-lisp>\n- <https://learnxinyminutes.com/docs/common-lisp/>\n","n":0.577}}},{"i":754,"$":{"0":{"v":"Functions","n":1},"1":{"v":"\n\n- Using functions\n  - pretty print function:\n\n```lisp\n(pprint \"hello world\")\n```\n\n- Create Functions\n\n```lisp\n(defun myPrinter (s) (pprint s))\n(myPrinter \"Hello World\")\n;; Hello World\n```\n","n":0.229}}},{"i":755,"$":{"0":{"v":"Data Types & Structs","n":0.5},"1":{"v":"\n\n- Type checking\n\n```lisp\n(typep foo 'string)\n;; NIL\n(typep foo 'integer)\n;; T\n```\n\n- The `'` is just short hand for: `(typep foo (quote string))`\n  - the `quote` escapes the data to be literal text like:\n\n```lisp\n(quote (+ 1 2))\n;; (+ 1 2)\n\n'(+ 1 2)\n;; (+ 1 2)\n```\n","n":0.154}}},{"i":756,"$":{"0":{"v":"JavaScript","n":1},"1":{"v":"\n## Resources\n\n- [[s.l.javascript.learning-roadmap]]\n- [Algorithms](https://github.com/trekhleb/javascript-algorithms)\n- [unminify code](https://unminify.com/)\n","n":0.408}}},{"i":757,"$":{"0":{"v":"Variable Assignment","n":0.707},"1":{"v":"\n\nThere are 3 methods of variable assignment in JavaScript\n\n| Assignment Keyword                                        | Scope  | Mutable |\n| --------------------------------------------------------- | ------ | ------- |\n| [[s.l.javascript.the-var-keyword]]   | global | Yes     |\n| [[s.l.javascript.the-let-keyword]]   | local  | Yes     |\n| [[s.l.javascript.the-const-keyword]] | local  | No      |\n","n":0.158}}},{"i":758,"$":{"0":{"v":"Tools","n":1}}},{"i":759,"$":{"0":{"v":"Npm","n":1}}},{"i":760,"$":{"0":{"v":"The Var Keyword","n":0.577},"1":{"v":"\n\nThe `VAR` Keyword is a variable assignment declaration that is available globally in scope no matter where it is declared.\n\n```js\nvar x = 10;\n// Here x is 10\n{\n  let x = 2;\n  // Here x is 2\n}\n// Here x is 10\n```\n","n":0.158}}},{"i":761,"$":{"0":{"v":"The Let Keyword","n":0.577},"1":{"v":"\n\nThe `let` keyword is a way to assign a value to a mutable variable that respects local scoping. \n\n```js\nvar x = 10;\n// Here x is 10\n{\n  let x = 2;\n  // Here x is 2\n}\n// Here x is 10\n```\n","n":0.16}}},{"i":762,"$":{"0":{"v":"The Const Keyword","n":0.577},"1":{"v":"\n\nThe `CONST` keyword is a way to assign a value to an immutable variable that respects local scoping.\n\n```js\nvar x = 10;\n// Here x is 10\n{\n  const x = 2;\n  // Here x is 2\n  x = 5;\n  // ERROR: value cannot be re-assigned\t\n}\n// Here x is 10\n```\n","n":0.146}}},{"i":763,"$":{"0":{"v":"Template Literals","n":0.707},"1":{"v":"\n\n## Template Literals\n\nTemplate literals provide an easy and clean way create multi-line strings and perform string interpolation. Now we can embed variables or expressions into a string at any spot without any hassle.\n\nTemplate literals are created using back-tick (`` ` ` ``) (grave accent) character instead of the usual double or single quotes. Variables or expressions can be placed inside the string using the `${...}` syntax. Compare the following examples and see how much useful it is:\n\n```js\n// Simple multi-line string\nlet str = `The quick brown fox\n\tjumps over the lazy dog.`;\n\ndocument.write(`<pre>${str}</pre>`);\n\n// String with embedded variables and expression\nlet a = 10;\nlet b = 20;\nlet result = `The sum of ${a} and ${b} is ${a+b}.`;\ndocument.write(result); // The sum of 10 and 20 is 30.\n```\n","n":0.091}}},{"i":764,"$":{"0":{"v":"Template Cloning","n":0.707},"1":{"v":"\n\n## [[import.software.language.javascript.template-cloning]]\n\n---\n\nThis is a method of a [[s.m.html.tags.body.template-tag]] element to copy the content of the template into a new variable for manipulation. Such as several new list items to be appended to a list.\n","n":0.171}}},{"i":765,"$":{"0":{"v":"Symbol Type","n":0.707},"1":{"v":"\n\nA JavaScript `Symbol` is a primitive datatype just like Number, String, or Boolean.\n\nIt represents a unique \"_hidden_\" identifier that no other code can accidentally access.\n\nFor instance, if different coders want to add a `person.id` property to a person object belonging to a third-party code, they could mix each others values.\n\nUsing `Symbol()` to create a unique identifiers, solves this problem:\n\n```js\nconst person = {  \n firstName: \"John\",  \n lastName: \"Doe\",  \n age: 50,  \n eyeColor: \"blue\"  \n};  \n  \nlet id = Symbol('id');  \nperson.id = 140353;\n```\n\nSymbols are always unique.\n\nIf you create two symbols with the same description they will have different values.\n\n```js\nSymbol(\"id\") == Symbol(\"id\") // false\n```\n","n":0.099}}},{"i":766,"$":{"0":{"v":"String Padding","n":0.707},"1":{"v":"\n\n## JavaScript String Padding\n\nECMAScript 2017 added two String methods: `padStart` and `padEnd` to support padding at the beginning and at the end of a string.\n\n### Example\n\n```js\nlet str = \"5\";  \nstr = str.padStart(4,0);  \n// result is 0005\n//========================//\nlet str = \"5\";  \nstr = str.padEnd(4,0);  \n// result is 5000\n```\n","n":0.147}}},{"i":767,"$":{"0":{"v":"Releases","n":1}}},{"i":768,"$":{"0":{"v":"Ecmascript 2020","n":0.707},"1":{"v":"\n\n![[s.l.javascript.modules]]\n","n":1}}},{"i":769,"$":{"0":{"v":"Ecmascript 2017","n":0.707},"1":{"v":"\n\n## [[import.software.language.javascript.ecmascript-2017]]\n\n---\n\n- [[s.l.javascript.string-padding]]\n- [[s.l.javascript.object-entries]]\n- [[s.l.javascript.object-values]]\n- [[s.l.javascript.async-and-defer]]\n","n":0.408}}},{"i":770,"$":{"0":{"v":"Ecmascript 2016","n":0.707},"1":{"v":"\n\n- [[s.l.javascript.exponentation]]\n- [[s.l.javascript.arrays.prototype-includes]]\n","n":0.577}}},{"i":771,"$":{"0":{"v":"Ecmascript 2015","n":0.707},"1":{"v":"\n\nECMAScript 6, also known as ES6 and ECMAScript 2015, was the second major revision to JavaScript.\n\nList of `ES6` Changes:\n\n- [[JavaScript Variable Assignment|s.l.javascript.variable-assignment]]\n- [[JavaScript Arrow Functions|s.l.javascript.arrow-functions]]\n  - [[JavaScript Function Rest Parameter|s.l.javascript.function-rest-parameter]]\n- [[JavaScript Classes|s.l.javascript.classes]]\n- [[JavaScript Promises|s.l.javascript.promises]]\n- [[JavaScript Symbol Type|s.l.javascript.symbol-type]]\n- [[JavaScript Object Destructuring|s.l.javascript.object-destructuring]]\n- [[JavaScript Array Destructuring|s.l.javascript.arrays.destructuring]]\n- [[JavaScript For..of Loop|s.l.javascript.for-of-loop]]\n- [[JavaScript Template Literals|s.l.javascript.template-literals]]\n- [[JavaScript Modules|s.l.javascript.modules]]\n","n":0.14}}},{"i":772,"$":{"0":{"v":"Promises","n":1},"1":{"v":"\n\n## Promises\n\n> \"Im going to give you the best video on promises\"\n\n---\n\n```js\nlet p = new Promise((resolve, reject) => {\n    let a = 1 + 1\n    if (a == 2) {\n        resolve('Success')\n    } else {\n        reject('Failed')\n    }\n}) \n```\n\n1+1 will always = 2 so the `resolve()` method is called.\n\nso if the promise is going to be resolved and we keep our promise of delivering a great video, **THEN** we resolve the promise.\n\nthis is also basically a try catch block but without the finally\n\n```js\np.then((message) => {\n    console.log('This is in the then' + message)\n}).catch((message) => {\n    console.log('This is in the catch' + message)\n})\n```\n\nPromises are things you want to happen in the background but that take a long time.\nlike downloading an image in a server and not making other things wait for it.\n\n---\n","n":0.088}}},{"i":773,"$":{"0":{"v":"Return Quickest Completed Item","n":0.5},"1":{"v":"\n\n## Return the Quickest Completed item\n\n`promise.all` waits for all of the promises to finish execution before returning results \nwhere as \n`promise.race` returns as soon as anything finishes and will return that first completed item in the `.then` so that an array isnt returned only a single result value of the quickest item because its a `.race`\n\n```js\nPromise.race([\n    recordVideoOne,\n    recordVideoTwo,\n    recordVideoThree\n]).then((message) => {\n    console.log(message)\n})\n```\n","n":0.127}}},{"i":774,"$":{"0":{"v":"Callbacks","n":1},"1":{"v":"\n\n## Callbacks (superceded by promises)\n\n```js\nconst userLeft = false\nconst userWatchingCatMeme = false\n\nfunction watchTutorialCallback(callback, errorCallback) {\n    if (userLeft) {\n        errorCallback({\n            name: 'User Left',\n            message: ':('\n        })\n    } else if (userWatchingCatMeme) {\n        errorCallback({\n            name: 'User Watching Cat Meme',\n            message: 'WebDevSimplified < Cat'\n        })\n    } else {\n        callback('Thumbs up and Subscribe')\n    }\n}\n\nwatchTutorialCallback((message) => {\n    console.log('Success ' + message)\n}, (error) => {\n    console.log(error.name + ' ' + error.message)\n}\n```\n\nPromises were meant to supercede callbacks and now the same code can be put into a promise:\n\n```js\nfunction watchTutorialPromise() {\n    return new Promise((resolve, reject) => {\n        if (userLeft) {\n            reject({\n                name: 'User Left',\n                message: ':('\n            })\n        } else if (userWatchingCatMeme) {\n            reject({\n                name: 'User Watching Cat Meme',\n                message: 'WebDevSimplified < Cat'\n            })\n        } else {\n            resolve('Thumbs up and Subscribe')\n        }\n    })\n}\n\nwatchTutorialPromise.then((message) => {\n    console.log('Success ' + message)\n}).catch((error) => {\n    console.log(error.name + ' ' + error.message)\n})\n```\n\nThe code looks cleaner and to avoid lots of nested callbacks and \"callback hell\" you can just use this syntax to deal with multiple then actions\n\n```js\nwatchTutorialPromise.then((message) => {\n    console.log('Success ' + message)\n}).then((message) => {\n    console.log('Success ' + message)\n}).catch((error) => {\n    console.log(error.name + ' ' + error.message)\n})\n```\n","n":0.074}}},{"i":775,"$":{"0":{"v":"Batching Promise Execution","n":0.577},"1":{"v":"\n\n## Batching Promise Execution\n\n```js\nconst recordVideoOne = new Promise((resolve, reject) => {\n    resolve('Video 1 Recorded')\n})\nconst recordVideoTwo = new Promise((resolve, reject) => {\n    resolve('Video 2 Recorded')\n})\nconst recordVideoThree = new Promise((resolve, reject) => {\n    resolve('Video 3 Recorded')\n})\n```\n\nrun a bunch of promises all at once in parallel instead of sequentially. \nthese promises all resolve and dont reject. \n\n```js\nPromise.all([\n    recordVideoOne,\n    recordVideoTwo,\n    recordVideoThree\n]).then((messages) => {\n    console.log(messages)\n})\n```\n\nso once the promises resolve the `.then` will then return an array of messages from the promises that we can then log\n","n":0.111}}},{"i":776,"$":{"0":{"v":"Object Values","n":0.707},"1":{"v":"\n\n## JavaScript Object Values\n\n`Object.values` are similar to `Object.entries`, but returns a single dimension array of the object values:\n\n### Example\n\n```js\nconst person = {  \n¬† firstName : \"John\",  \n¬† lastName : \"Doe\",  \n¬† age : 50,  \n¬† eyeColor : \"blue\"  \n};  \ndocument.getElementById(\"demo\").innerHTML = Object.values(person);\n```\n","n":0.154}}},{"i":777,"$":{"0":{"v":"Object Entries","n":0.707},"1":{"v":"\n\n## JavaScript Object Entries\n\nECMAScript 2017 adds a new `Object.entries` method to objects:\n\n### Example\n\n```js\nconst person = {  \n¬† firstName : \"John\",  \n¬† lastName : \"Doe\",  \n¬† age : 50,  \n¬† eyeColor : \"blue\"  \n};  \ndocument.getElementById(\"demo\").innerHTML = Object.entries(person);\n```\n","n":0.167}}},{"i":778,"$":{"0":{"v":"Object Destructuring","n":0.707},"1":{"v":"\n\n## The object destructuring assignment\n\nIn ES5 to extract the property values of an object we need to write something like this:\n\n```js\n// ES5 syntax\nvar person = {name: \"Peter\", age: 28};\n\nvar name = person.name;\nvar age = person.age;\n\ndocument.write(name); // Peter\ndocument.write(\"<br>\");\ndocument.write(age); // 28\n```\n\nBut in ES6, you can extract object's property values and assign them to the variables easily like this:\n\n```js\n// ES6 syntax\nlet person = {name: \"Peter\", age: 28};\n\nlet {name, age} = person; // Object destructuring assignment\n\ndocument.write(name); // Peter\ndocument.write(\"<br>\");\ndocument.write(age); // 28\n```\n\n---\n\n- Reference:\n  - <https://www.tutorialrepublic.com/javascript-tutorial/javascript-es6-features.php>\n","n":0.113}}},{"i":779,"$":{"0":{"v":"Modules","n":1},"1":{"v":"\n\n## Modules\n\nPrior to ES6, there were no native support for modules in JavaScript. Everything inside a JavaScript application, for example variables across different JavaScript files, shared the same scope.\n\nES6 introduces file based module, in which each module is represented by a separate `.js` file. Now, you can use the `export` or `import` statement in a module to export or import variables, functions, classes or any other entity to/from other modules or files.\n\nThis works in conjunction with [[JavaScript Variable Assignment|s.l.javascript.variable-assignment]] options that came with ES6 to constrain variables to local scopes and not a global scope as well.\n\nLet's create a module i.e. a JavaScript file \"`main.js`\" and place the following code in it:\n\n```js\nlet greet = \"Hello World!\"; \nconst PI = 3.14; \nfunction multiplyNumbers(a, b) {\n\treturn a \\* b; \n} \n// Exporting variables and functions \nexport { greet, PI, multiplyNumbers };\n```\n\nNow create another JavaScript file \"app.js\" with the following code:\n\n```js\nimport { greet, PI, multiplyNumbers } from './main.js'; \nalert(greet); \n// Hello World! \nalert(PI); \n// 3.14 \nalert(multiplyNumbers(6, 15)); // 90\n```\n","n":0.078}}},{"i":780,"$":{"0":{"v":"Import Non Default Things","n":0.5},"1":{"v":"\n\n### To import non-default things\n\nif we want the functions we defined in the `user.js` file and also exported, we can also import them with the following syntax:\n\n```js\nimport U, { printName, printAge } from '/user.js'\n```\n\nbasically, the default import can just be declared as `U` in this instance, where as non default imports have to be imported with the brace syntax. We can also change the name of those items too in this following was: \n\n```js\nimport U, { printName as printUsername, printAge as printUserAge } from '/user.js'\n```\n\nFor more browser support a common method of dealing with imports is to use the `babel` tool to convert these newer features into older and supported javascript code\n","n":0.094}}},{"i":781,"$":{"0":{"v":"Es6 Modules","n":0.707},"1":{"v":"\n\n### ES6 Modules\n\n[source](https://youtu.be/cRHQNNcYf6s?list=PLZlA0Gpn_vH-0FlQnruw2rd1HuiYJHHkm)\n\nImporting sections of code so that files can be broken out into more modular files\n\n---\n\n2 types of exports, the default is the following at the end of a file:\n\n`export default User`\n\nthis exports the User object as our default thing for the user.js file\n\nthe normal way of exports is:\n\n`export { printName, printAge }`\n\nwhich will export those two functions\n\nan even better way would be inline like the example below for both the `User` class and functions: \n\n```javascript\nexport default class User {\n    constructor(name, age) {\n        this.name = name\n        this.age = age\n    }\n}\n\nexport function printName(user) {\n    console.log(`User's name is ${user.name}`)\n}\n\nexport function printAge(user) {\n    console.log(`User's is ${user.age} years old`)\n}\n```\n\nFinally create a HTML file \"`test.html`\" and with the following code and open this HTML file in your browser using HTTP protocol (or use localhost). Also notice the `type=\"module\"` on script tag.\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"utf-8\">\n    <title>JavaScript ES6 Modules Demo</title>\n</head>\n<body>\n    <script type=\"module\" src=\"/examples/js/app.js\"></script>\n</body>\n</html>\n```\n","n":0.082}}},{"i":782,"$":{"0":{"v":"Es2020 Modules","n":0.707},"1":{"v":"\n\n### [[s.l.javascript.releases.ecmascript-2020]]\n\n#### Hot loading modules\n\n```js\nconst baseModulePath = \"./modules\";\nconst btnBooks = document.getElementById(\"btnBooks\");\nlet bookList = [];\n\nbtnBooks.addEventListener(\"click\", async e => {\n  const bookModule = await import(`${baseModulePath}/books.js`);\n\n  bookList = bookModule.loadList();\n});\n```\n\nSo this code will only load the module on a particular click event, instead of a static declaration at the top of a file.\n","n":0.143}}},{"i":783,"$":{"0":{"v":"Default Imports","n":0.707},"1":{"v":"\n\n## You can only default export one thing so it will likely be the class you are defining if you are defining a class in your file\n\nNow in a new file we can `import` your `exported` items paying attention to your file paths in the import statements\n\n`import User from '/user.js'`\n\nthis alone will throw an error, in your HTML where you source your javascript files you need to change the `script` tag to use ES6 modules:\n\n`<script src=\"main.js\"></script>`\n\n`<script type=\"module\" src=\"main.js\"></script>`\n\na tip for the module import `<script>` tag was the `defer` keyword. Child issue: #6 \n\nso now in a `*.js` file that does not have the User class declared in it, i can make and use the User class: \n\n```js\nconst user = new User('Bryan Jenks', 999)\nconsole.log('user')\n```\n\n**Result:**\n\n> User {name: \"Bryan Jenks\", age: 999}\n> age: 999\n> name: \"Bryan Jenks\"\n> **proto**: Object\n","n":0.086}}},{"i":784,"$":{"0":{"v":"Changing Names of Default Import","n":0.447},"1":{"v":"\n\n### Changing the names of the default import\n\nso if you have a User [[JavaScript Classes|class]] you're importing but in the new file you import that into you want to import that class but call it something different, then what you can do is basically treat it like a base class (which it is) and say:\n\n`import U from '/user.js'`\n\nbecause the User class is the default export its assuming we're saying something like this if we were in python\n\n```python\nimport pandas as pd\n```\n\nexcept that its `import User as U`\n","n":0.108}}},{"i":785,"$":{"0":{"v":"Libs","n":1}}},{"i":786,"$":{"0":{"v":"Node","n":1}}},{"i":787,"$":{"0":{"v":"Learning Roadmap","n":0.707},"1":{"v":"\n\n## Learning Path\n\n![[assets/pdfs/Web_Development_2021_Roadmap.pdf]]\n\n## How the internet works\n\n‚ùåÔ∏è <https://www.youtube.com/watch?v=7_LPdttKXPc>\n‚ùåÔ∏è <https://www.youtube.com/watch?v=Dxcc6ycZ73M>\n‚ùåÔ∏è Hosting\n‚ùåÔ∏è DNS\n‚ùåÔ∏è HTTP\n‚ùåÔ∏è Browsers\n‚ùåÔ∏è Domain Names\n\n## Basic Tools\n\n### Text Editor\n\n‚ùåÔ∏è <https://www.youtube.com/playlist?list=PLkwxH9e_vrAJshxiMo6gIavTr5kYsjPs7>\n‚ùåÔ∏è <https://vscodehero.com/>\n\n### Design\n\n‚ùåÔ∏è <https://www.youtube.com/channel/UCVyRiMvfUNMA1UPlDPzG5Ow>\n‚ùåÔ∏è <https://www.youtube.com/channel/UCvM5YYWwfLwpcQgbRr68JLQ>\n\n## HTML\n\n‚ùåÔ∏è <https://www.youtube.com/watch?v=XiQ9rjaa2Ow>\n‚ùåÔ∏è Best Practices\n‚ùåÔ∏è Semantic HTML\n‚ùåÔ∏è Forms and Validations\n‚ùåÔ∏è Accessibility\n‚ùåÔ∏è SEO\n\n## CSS\n\n‚ùåÔ∏è [Basics](https://www.youtube.com/watch?v=Tfjd5yzCaxk)\n‚ùåÔ∏è _pros and cons of these_\n  ‚ùåÔ∏è [flexbox](https://www.youtube.com/watch?v=qqDH0T6K5gY)\n  ‚ùåÔ∏è [css grid](https://www.youtube.com/watch?v=BDOzg4lXcSg)\n‚ùåÔ∏è custom properties\n\n### transitions/animations\n\n‚ùåÔ∏è plain CSS\n‚ùåÔ∏è [GSAP](https://greensock.com/gsap/) and [GSAP typing animation](https://www.youtube.com/watch?v=ZT66N5hBiCE)\n‚ùåÔ∏è [anime.js](https://animejs.com/)\n\n### Responsive Design\n\n‚ùåÔ∏è Mobile first\n‚ùåÔ∏è rem units\n‚ùåÔ∏è viewport\n‚ùåÔ∏è fluid widths\n‚ùåÔ∏è media queries\n‚ùåÔ∏è [kevin powell](https://www.youtube.com/channel/UCJZv4d5rbIKd4QHMPkcABCw)\n\n### CSS Preprocessorts\n\n‚ùåÔ∏è [SASS](https://www.youtube.com/watch?v=BDOzg4lXcSg)\n‚ùåÔ∏è postCSS\n\n### Modern CSS\n\n‚ùåÔ∏è [styled components](https://styled-components.com/)\n‚ùåÔ∏è [CSS Modules](https://github.com/css-modules/css-modules)\n\n### CSS Prameworks\n\n‚ùåÔ∏è [tailwind CSS](https://tailwindcss.com/)\n‚ùåÔ∏è [bootstrap](https://getbootstrap.com/)\n\n## Paths\n\n### Desktop Applications\n\n‚ùåÔ∏è Electron\n\n### Mobile Apps\n\n‚ùåÔ∏è React Native \n  ‚ùåÔ∏è <https://www.youtube.com/channel/UC806fwFWpiLQV5y-qifzHnA>\n‚ùåÔ∏è Flutter\n  ‚ùåÔ∏è <https://www.youtube.com/user/Lionranger>\n  ‚ùåÔ∏è <https://www.youtube.com/c/TadasPetra>\n  ‚ùåÔ∏è <https://www.youtube.com/c/RobertBrunhage/>\n‚ùåÔ∏è NativeScript\n‚ùåÔ∏è Ionic\n\n### front end\n\n#### Javascript\n\n‚ùåÔ∏è [Basic Syntax ](https://www.youtube.com/watch?v=d5ob3WAGeZE)\n‚ùåÔ∏è DOM Manipulation \n‚ùåÔ∏è [Fetch API](https://www.youtube.com/watch?v=djCuFrLLjVk)\n‚ùåÔ∏è [JSON](https://www.youtube.com/watch?v=s6OIOL9OMYA)\n‚ùåÔ∏è ES6+\n‚ùåÔ∏è <https://www.youtube.com/playlist?list=PLkwxH9e_vrALRJKu7wfXby3MKeflhTu6B>\n‚ùåÔ∏è <https://www.youtube.com/watch?v=bGDK1rpykOQ&list=PLkwxH9e_vrALlH7D0XLDn2td-uoHqHFxq>\n‚ùåÔ∏è [typescript](https://www.youtube.com/watch?v=ahCwqrYpIuM)\n\n##### More Tools\n\n‚ùåÔ∏è Browser dev tools\n‚ùåÔ∏è [VSCode extentions](https://www.youtube.com/watch?v=c5GAS_PMXDs)\n‚ùåÔ∏è [emmet](https://www.youtube.com/watch?v=EzGWXTASWWo)\n  ‚ùåÔ∏è [[HTML Emmet Shortcuts in VSCode|html-emmet-shortcuts-in-vscode]]\n‚ùåÔ∏è [axios](https://www.youtube.com/watch?v=6LyagkoRWYA)\n\n###### version control\n\n‚ùåÔ∏è [git](https://www.youtube.com/watch?v=N_bMCff8q6A)\n- [x] github\n\n###### Build Tools\n\n‚ùåÔ∏è **Task Runners**\n  ‚ùåÔ∏è NPM Scripts\n  ‚ùåÔ∏è [GULP](https://www.youtube.com/watch?v=-lG0kDeuSJk)\n‚ùåÔ∏è **Linters / Formatters**\n  ‚ùåÔ∏è [Prettier](https://prettier.io/)\n  ‚ùåÔ∏è [ESLint](https://eslint.org/)\n‚ùåÔ∏è **Module Bundlers**\n  ‚ùåÔ∏è [webpack](https://www.youtube.com/watch?v=MpGLUVbqoYQ)\n  ‚ùåÔ∏è [parcel](https://www.youtube.com/watch?v=ONwotPEpinI)\n  ‚ùåÔ∏è [Rollup](https://rollupjs.org/guide/en/)\n\n##### Preogressive web apps\n\n‚ùåÔ∏è [PWA's](https://www.youtube.com/playlist?list=PL4cUxeGkcC9gTxqJBcDmoi5Q2pzDusSL7)\n‚ùåÔ∏è <https://www.youtube.com/watch?v=ppwagkhrZJs>\n\n##### Graph-QL\n\n‚ùåÔ∏è [Apollo](https://www.youtube.com/watch?v=ed8SzALpx1Q)\n\n##### Package Managers\n\n‚ùåÔ∏è [NPM](https://nodejs.org/en/)\n‚ùåÔ∏è [yarn](https://classic.yarnpkg.com/en/docs/install)\n\n##### Jam Stack\n\n‚ùåÔ∏è Javascript\n  ‚ùåÔ∏è <https://www.youtube.com/watch?v=ySJGjo3_EX4>\n  ‚ùåÔ∏è <https://www.youtube.com/watch?v=73b1ZbmB96I>\n‚ùåÔ∏è [API](https://developer.mozilla.org/en-US/docs/Web/API/Web_Speech_API)\n‚ùåÔ∏è Markup\n\n##### Front End Framework\n\n‚ùåÔ∏è [React](https://www.youtube.com/watch?v=UGcALH8kPC0&list=PLkwxH9e_vrAK4TdffpxKY3QGyHCpxFcQ0)\n‚ùåÔ∏è Vue\n  ‚ùåÔ∏è <https://www.youtube.com/channel/UCshZ3rdoCLjDYuTR_RBubzw>\n  ‚ùåÔ∏è <https://www.youtube.com/channel/UCxA99Yr6P_tZF9_BgtMGAWA>\n\n###### State Management\n\n‚ùåÔ∏è [Context API (React)](https://www.youtube.com/watch?v=35lXWvCuM8o)\n‚ùåÔ∏è [Redux (React)](https://www.youtube.com/watch?v=CVpUuw9XSjY)\n‚ùåÔ∏è [Vuex (Vue)](https://www.youtube.com/watch?v=oxUyIzDbZts)\n\n###### Server Side Rendering (SSR)\n\n‚ùåÔ∏è [Nuxt.js (Vue)](https://www.youtube.com/watch?v=ltzlhAxJr74)\n‚ùåÔ∏è [Next.js (React)](https://www.youtube.com/channel/UC7Wpv0Aft4NPNhHWW_JC4GQ)\n\n###### Static Site Generators\n\n‚ùåÔ∏è [Gatsby (React)](https://www.youtube.com/user/Weibenfalk)\n‚ùåÔ∏è Next.js (React)\n‚ùåÔ∏è [Gridsome (Vue)](https://www.youtube.com/watch?v=vB6rmWCmANA)\n‚ùåÔ∏è Nuxt.js (Vue) \n‚ùåÔ∏è 11ty\n","n":0.067}}},{"i":788,"$":{"0":{"v":"Innertext Method","n":0.707}}},{"i":789,"$":{"0":{"v":"If Statements","n":0.707},"1":{"v":"\n\n## Efficient Usage\n\nThe most classic form of the if-else statement looks really simple.\n\n```js\nif (someCondition) {\n   // 10 lines of code\n} else {\n   // More code..\n}\n```\n\nThis is how we could use a return in order to get rid of the else block:\n\n```js\nif (someCondition) {\n   // 10 lines of code\n   return;\n} \n// More code..\n```\n\nIf-else statements get used a lot to assign variables\n\n```js\nif (someCondition) {\n   number = someNumber * 2\n} else {\n   number = 1\n}\n```\n\nWhen you spot code like this, change it. The way to get rid of the else block is by assigning a default value.\n\n```js\nnumber = 1\nif (someCondition) {\n   number = someNumber * 2\n}\n```\n\nThere‚Äôs a way to optimize this code even more. We could make this piece of code a one-liner by using the conditional operator:\n\n```js\nnumber = someCondition ? someNumber * 2 : 1;\n```\n\n[[theory.guard-clauses]] are also known as early-returns.\n\n![[theory.guard-clauses]]\n\n---\n\n- Reference:\n  - <https://levelup.gitconnected.com/how-you-can-avoid-using-else-in-your-code-871197a1adbc> \n","n":0.084}}},{"i":790,"$":{"0":{"v":"Function Rest Parameter","n":0.577}}},{"i":791,"$":{"0":{"v":"Spread Operator","n":0.707},"1":{"v":"\n\n## The Spread Operator\n\nThe spread operator, which is also denoted by (`...`), performs the exact opposite function of the rest operator. The spread operator spreads out (i.e. splits up) an array and passes the values into the specified function, as shown in the following example:\n\n```js\nfunction addNumbers(a, b, c) {\n\treturn a + b + c;\n}\n\nlet numbers = [5, 12, 8];\n\n// ES5 way of passing array as an argument of a function\ndocument.write(addNumbers.apply(null, numbers)); // 25\ndocument.write(\"<br>\");\n\n// ES6 spread operator\ndocument.write(addNumbers(...numbers)); // 25\n```\n\nThe spread operator can also be used to insert the elements of an array into another array without using the array methods like `push()`, `unshift()` `concat()`, etc.\n\n```js\nlet pets = [\"Cat\", \"Dog\", \"Parrot\"];\nlet bugs = [\"Ant\", \"Bee\"];\n\n// Creating an array by inserting elements from other arrays\nlet animals = [...pets, \"Tiger\", \"Wolf\", \"Zebra\", ...bugs];\n\ndocument.write(animals); // Cat,Dog,Parrot,Tiger,Wolf,Zebra,Ant,Bee\n```\n","n":0.087}}},{"i":792,"$":{"0":{"v":"Rest Parameters","n":0.707},"1":{"v":"\n\n## The Rest Parameters\n\nThis is similar to the function ellipsis parameter in [[R|r]] where the number of inputs in variable and you want to accept them all as a variable size [[Python Data Structures|python-data-structures#List]]/Array.\n\nThe rest parameter (`...`) allows a function to treat an indefinite number of arguments as an array:\n\n```js\nfunction sum(...args) {  \n let sum = 0;  \n for (let arg of args) sum += arg;  \n return sum;  \n}  \n  \nlet x = sum(4, 9, 16, 25, 29, 100, 66, 77);\n```\n","n":0.11}}},{"i":793,"$":{"0":{"v":"For of Loop","n":0.577},"1":{"v":"\n\n## The `for...of` Loop\n\nThe new `for...of` loop allows us to iterate over arrays or other iterable objects very easily. \n\nAlso, the code inside the loop is executed for each element of the iterable object. Here's an example:\n\n```js\n// Iterating over array \nlet letters = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"]; \n\nfor(let letter of letters) { \n\tconsole.log(letter); // a,b,c,d,e,f \n}\n// Iterating over string \nlet greet = \"Hello World!\"; \n\nfor(let character of greet) { \n\tconsole.log(character); // H,e,l,l,o, ,W,o,r,l,d,! \n}\n```\n\n---\n\n- Reference:\n  - <https://www.tutorialrepublic.com/javascript-tutorial/javascript-es6-features.php>\n\n","n":0.113}}},{"i":794,"$":{"0":{"v":"Exponentation","n":1},"1":{"v":"\n\n```js\nlet base = 3;\nlet exponent = 4;\n\n// old way Math.pow()\nconsole.log(Math.pow(base ,exponent)) //81\n\n// new way\nconsole.log(base**exponent); //81\n```\n\n## Exponentiation Assignment\n\nThe **exponentiation assignment** operator (`**=`) raises the value of a variable to the power of the right operand.\n\n### Example\n\n```js\nlet x = 5;  \nx **= 2; // result 25\n```\n","n":0.151}}},{"i":795,"$":{"0":{"v":"Event Listeners","n":0.707},"1":{"v":"\n\n`target.addEventListener( type, listener );`\n\n[event types](https://developer.mozilla.org/en-US/docs/Web/Events)\n\nthe Listener is what receives notification. I.E. trigger the event type, then activate the listener code. So if the listener is an [[JavaScript Arrow Functions|arrow-function]] then you can run an entire anonymous function.\n\n## Click event\n\n<https://developer.mozilla.org/en-US/docs/Web/API/Element/click_event>\n","n":0.16}}},{"i":796,"$":{"0":{"v":"Es6","n":1}}},{"i":797,"$":{"0":{"v":"Numbers","n":1}}},{"i":798,"$":{"0":{"v":"New Properties","n":0.707},"1":{"v":"\n\n## New Number Properties\n\nES6 added the following properties to the Number object:\n\n- `EPSILON`\n- `MIN_SAFE_INTEGER`\n- `MAX_SAFE_INTEGER`\n\n```js\nvar x = Number.EPSILON;\nconsole.log(x);\n// 2.220446049250313e-16\nvar x = Number.MIN_SAFE_INTEGER;\nconsole.log(x);\n// 4 -9007199254740991\nvar x = Number.MAX_SAFE_INTEGER;\nconsole.log(x);\n// 6 9007199254740991\n```\n","n":0.186}}},{"i":799,"$":{"0":{"v":"Is Safe Integer","n":0.577},"1":{"v":"\n\n## The Number.isSafeInteger() Method\n\nA safe integer is an integer that can be exactly represented as a _double precision number_.\n\nThe `Number.isSafeInteger()` method returns `true` if the argument is a safe integer.\n\n### Example\n\n```js\nNumber.isSafeInteger(10);¬†¬†¬†¬†// returns true  \nNumber.isSafeInteger(12345678901234567890);¬† // returns false\n```\n\nSafe integers are all integers from \n\n**$-(2^{53} - 1)$** to **$+(2^{53} - 1)$**\n\nThis is safe: _9007199254740991_\n\nThis is not safe: _9007199254740992_\n","n":0.134}}},{"i":800,"$":{"0":{"v":"Is Nan","n":0.707},"1":{"v":"\n\n## The isNaN() Method\n\nThe global `isNaN()` method returns `true` if the argument is `NaN`. Otherwise it returns `false`:\n\n### Example\n\n```js\nisNaN(\"Hello\");¬†¬†¬†¬†¬†¬† // returns true\n```\n","n":0.213}}},{"i":801,"$":{"0":{"v":"Is Integer","n":0.707},"1":{"v":"\n\n## The Number.isInteger() Method\n\nThe `Number.isInteger()` method returns `true` if the argument is an integer.\n\n### Example\n\n```js\nNumber.isInteger(10);¬†¬†¬†¬†¬†¬†¬† // returns true  \nNumber.isInteger(10.5);¬†¬†¬†¬†¬† // returns false\n```\n","n":0.213}}},{"i":802,"$":{"0":{"v":"Is Finite","n":0.707},"1":{"v":"\n\n## The isFinite() Method\n\nThe global `isFinite()` method returns `false` if the argument is `Infinity` or `NaN`.\n\nOtherwise it returns `true`:\n\n### Example\n\n```js\nisFinite(10/0);¬†¬†¬†¬†¬†¬† // returns false  \nisFinite(10/1);¬†¬†¬†¬†¬†¬† // returns true \n```\n\n[Try it Yourself ¬ª](https://www.w3schools.com/Js/tryit.asp?filename=tryjs_es6_isfinite)\n","n":0.18}}},{"i":803,"$":{"0":{"v":"Array Methods","n":0.707}}},{"i":804,"$":{"0":{"v":"Findindex","n":1},"1":{"v":"\n\n## Array.findIndex()\n\nThe `findIndex()` method returns the **index** of the first array element that passes a test function.\n\nThis example finds the index of the first element that is larger than 18:\n\n### Example\n\n```js\nvar numbers = [4, 9, 16, 25, 29];  \nvar first = numbers.findIndex(myFunction);  \n  \nfunction myFunction(value, index, array) {  \n¬† return value > 18;  \n}\n\nmyFunction(25,3,numbers);\n```\n","n":0.136}}},{"i":805,"$":{"0":{"v":"Find","n":1},"1":{"v":"\n\n## Array.find()\n\nThe `find()` method returns the **value** of the first array element that passes a test function.\n\nThis example finds (returns the value of ) the first element that is larger than 18:\n\n### Example\n\n```js\nvar numbers = [4, 9, 16, 25, 29];  \nvar first = numbers.find(myFunction);  \n  \nfunction myFunction(value, index, array) {  \n return value > 18;  \n}\n\nmyFunction(25,3,numbers); // TRUE\n```\n\n```js\nconst items = [\n    { name: 'Bike',     price: 100  },\n    { name: 'TV',       price: 200  },\n    { name: 'Album',    price: 10   },\n    { name: 'Book',     price: 5    },\n    { name: 'Phone',    price: 500  },\n    { name: 'Computer', price: 1000 },\n    { name: 'Keyboard', price: 25   }\n]\n\nconst foundItem = items.find((item) => {\n    return item.name === 'Book'\n})\n\nconsole.log(foundItem)\n```\n\n> {name: \"Book\", price: 5}\n>\n> name: \"Book\"\n>\n> price: 5\n>\n> **proto**: Object\n>\n","n":0.091}}},{"i":806,"$":{"0":{"v":"Dom Manipulation","n":0.707},"1":{"v":"\n\nThe way of accessing the DOM tree. \n\n|     |                             |\n| --- | --------------------------- |\n| DOM | `D`ocument `O`bject `M`odel |\n\n---\n\n- Reference:\n  - <https://developer.mozilla.org/en-US/docs/Web/API/Document>\n","n":0.209}}},{"i":807,"$":{"0":{"v":"Queryselector","n":1},"1":{"v":"\n\nreturns the first Element within the document that matches the specified selector, or group of selectors. If no matches are found, `null` is returned.\n\n## Finding the first element matching a class\n\nIn this example, the first element in the document with the class \"`myclass`\" is returned:\n\n```javascript\nvar el = document.querySelector(\".myclass\");\n```\n\n## A more complex selector\n\nSelectors can also be really powerful, as demonstrated in the following example. Here, the first `<input>` element with the name \"_login_\" (`<input name=\"login\"/>`) located inside a `<div>` whose class is \"user-panel main\" (`<div class=\"user-panel main\">`) in the document is returned:\n\n```javascript\nvar el = document.querySelector(\"div.user-panel.main input[name='login']\");\n```\n\n## Negation\n\nAs all CSS selector strings are valid, you can also negate selectors:\n\n```javascript\nvar el = document.querySelector(\"div.user-panel:not(.main) input[name='login']\");\n```\n\nThis will select an input with a parent div with the user-panel class but not the main class.\n\n---\n\n- Reference:\n  - [MDN](https://developer.mozilla.org/en-US/docs/Web/API/Document/querySelector)\n","n":0.087}}},{"i":808,"$":{"0":{"v":"Getelementbyid","n":1}}},{"i":809,"$":{"0":{"v":"Conditional Logic and Control Flow","n":0.447},"1":{"v":"\n- [[s.l.javascript.if-statements]]\n\n<https://www.w3schools.com/Js/js_json.asp>\n","n":0.707}}},{"i":810,"$":{"0":{"v":"Classes","n":1},"1":{"v":"\n\nJavaScript Classes are templates for JavaScript Objects.\n\nUse the keyword `class` to create a class.\n\nAlways add a method named `constructor()`:\n\n```js\nclass Car \n{  \n\tconstructor(name, year) \n\t{  \n\t\tthis.name \\= name;  \n\t\tthis.year \\= year;  \n\t}  \n}\n```\n\nA JavaScript class is **not** an object.\n\nIt is a **template** for JavaScript objects.\n\n```js\nlet myCar1 = new Car(\"Ford\", 2014);  \nlet myCar2 = new Car(\"Audi\", 2019);\n```\n","n":0.135}}},{"i":811,"$":{"0":{"v":"Async and Defer","n":0.577},"1":{"v":"\n\n## Async and Defer\n\n<center>\n\t<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/BMuFBYw91UQ\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n</center>\n\nNormal DOC parsing is that is parses synchronously, so as soon as it hits a `<script>` tag it stops and downloads that content first and then executes it and only THEN continues with the HTML download/parsing.\n","n":0.143}}},{"i":812,"$":{"0":{"v":"Defer","n":1},"1":{"v":"\n\n### Defer\n\nwith defer it will defer javascript execution until all the parsing is done, this way all the content is loaded and prepared before javascript begins to act upon them\n\n![[95397383-e9d4b200-08b7-11eb-9075-2acd110eb0a1.png)\n\ndefer will run your deferred code before the document `onReady()` event. and it will stay in order and run when the page is done being parsed.\n\nTo imitate the behavior of `defer` people commonly put their script tags in the end of the `</body>` tag, with the `defer` keyword now though we can put the javascript files back in the `<head>` so they are easier to find but still have the same behavior as leaving them at the bottom.\n\n---\n\nDefer is more reliable as it is ordered and you know when it will run. Async can be useful if you have small files that don't depend on anything that you want to have loaded whenever.\n\n---\n\n```html\n// Normal\n<script src=\"file.js\"></script>\n// Async\n<script async src=\"file.js\"></script>\n// Defer\n<script defer src=\"file.js\"></script>\n```\n","n":0.082}}},{"i":813,"$":{"0":{"v":"Async","n":1},"1":{"v":"\n\n### Async\n\nwith `Async` the downloads happen concurrently and only the Javascript execution is treat synchronously \n\n![[95397297-b4c85f80-08b7-11eb-8a63-068446b52032.png)\n\n`Async` will allow the javascript to also run after the document `onReady()` event maybe this is not what you want. `Async` will also vary when it is run as it can be variable based on network speeds. if order matters this will throw a wrench in the works as it can be executed whenever dependent on the users network conditions.\n","n":0.115}}},{"i":814,"$":{"0":{"v":"Arrow Functions","n":0.707},"1":{"v":"\n\nArrow functions do not have their own `this`. They are not well suited for defining **object methods**.\n\nArrow functions are not hoisted. They must be defined **before** they are used.\n\nUsing `const` is safer than using `var`, because a function expression is always a constant value.\n\nYou can only omit the `return` keyword and the curly brackets if the function is a single statement. Because of this, it might be a good habit to always keep them:\n\n```javascript\n/*\n    Source: https://youtu.be/h33Srr5J9nY?list=PLZlA0Gpn_vH-0FlQnruw2rd1HuiYJHHkm\n*/\n\n// Normal function\nfunction sum(a, b) {\n    return a + b\n}\n\n// if it can fit on 1 line these make the code more concise and legible\nlet sum2 = (a, b) => a + b\n\n/**************************************************************************************/\nfunction isPositive(number) {\n    return number >= 0 \n}\n\n// Single parameter functions dont need parens on their args\nlet isPositive = number => number >= 0\n\n/**************************************************************************************/\n\nfunction randomNumber() {\n    return Math.random\n}\n\n// No parameter functions need the parens to exist though\nlet randomNumber = () => Math.random\n\n/**************************************************************************************/\n\n// arrow functions really useful for anonymous functions\ndocument.addEventListener('click', function(){\n    console.log('click')\n})\n\n// is exactly the same as \n\ndocument.addEventListener('click', () => console.log('click'))\n\n/**************************************************************************************/\n/* \n    The real power of arrow functions is the redeffinition of the the 'this' keyword\n    within them\n*/\n\nclass Person {\n    constructor(name) {\n        this.name = name\n    }\n    printNameArrow() {\n        setTimeout(() => {\n            console.log('Arrow: ' + this.name)\n        }, 100)\n    }\n    \n    printNameFunction() {\n        setTimeout(function() {\n            console.log('Arrow: ' + this.name)\n        }, 100)\n    }\n}\n\nlet person = new Person('Bob')\nperson.printNameArrow() // acts like most other programming langs\nperson.printNameFunction() // prints nothing because in normal functions the 'this' is defined based on WHERE the function is called\nconsole.log(this.name) // also returns nothing as 'this' is not defined in the global scope\n\n/*\n    Normal functions redefine 'this' to what ever scope you function in and that is the global scope in this instance\n    Arrow functions treat the scoping of the 'this' keyword like most other programming language now \n    its preferable now to use arrow function over normal functions unless explicitly necessary to use normal functions\n*/\n```\n\n### Default Parameter Values\n\n```js\nfunction myFunction(x, y = 10) {  \n  // y is 10 if not passed or undefined  \n  return x + y;  \n}  \nmyFunction(5); // will return 15\n```\n","n":0.054}}},{"i":815,"$":{"0":{"v":"Arrays","n":1}}},{"i":816,"$":{"0":{"v":"Some()","n":1},"1":{"v":"\n\n<center>\n\t<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/R8rmfD9Y5-c\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n</center>\n\nGiven data:\n\n```javascript\nconst items = [\n    { name: 'Bike',     price: 100  },\n    { name: 'TV',       price: 200  },\n    { name: 'Album',    price: 10   },\n    { name: 'Book',     price: 5    },\n    { name: 'Phone',    price: 500  },\n    { name: 'Computer', price: 1000 },\n    { name: 'Keyboard', price: 25   }\n]\n```\n\n## Some method\n\nthis method returns a boolean value and is great for asking a question of your data and getting simple response in return.\n\n---\n\n```javascript\nconst hasInexpensiveItems = items.some((item) => {\n    return item.price <= 100\n})\n```\n\n**Result:**\n\n> true\n\nfor each item in items, is there at least 1 item that is less than or equal to 100? if so return true, otherwise false. \n","n":0.093}}},{"i":817,"$":{"0":{"v":"Reduce()","n":1},"1":{"v":"\n\n<center>\n\t<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/R8rmfD9Y5-c\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n</center>\n\nGiven data:\n\n```javascript\nconst items = [\n    { name: 'Bike',     price: 100  },\n    { name: 'TV',       price: 200  },\n    { name: 'Album',    price: 10   },\n    { name: 'Book',     price: 5    },\n    { name: 'Phone',    price: 500  },\n    { name: 'Computer', price: 1000 },\n    { name: 'Keyboard', price: 25   }\n]\n```\n\n## Reduce method\n\nThis is like wanting to get a sum of all the prices of your items that meet certain conditions.\n\nUnlike the other methods the `reduce` method has 2 arguments and the first of which has to be the aggregate value holder\n\n---\n\n```javascript\nconst total = items.reduce((currentTotal, item) => {\n    return item.price + currentTotal\n}, 0)\n\nconsole.log(total)\n```\n\n**Result:**\n\n> 1840\n\nwe want to get a sum of all prices so we run the array method and  for each item in items we pass the item and a local variable in the arrow function to the function body.\n\nat then end of the arrow function is a second argument for the `reduce` method which is where the `currentTotal` value should start. We probably want a total to start at 0 so that's where it is set to.\n\nthis is like a for loop using `item = item + newItem` \n\nso for each item passed to the function body, you also have the current running total passed as well. The items iteratively get returned and added to the `currentTotal` and then ultimately the `currentTotal` variable is returned giving you the sum of the array object's prices\n","n":0.064}}},{"i":818,"$":{"0":{"v":"Prototype Includes","n":0.707},"1":{"v":"\n\n## JavaScript Array.prototype.includes\n\nECMAScript 2016 introduced `Array.prototype.includes` to arrays. This allows us to check if an element is present in an array:\n\n### Example\n\n```js\nconst fruits = [\"Banana\", \"Orange\", \"Apple\", \"Mango\"];  \n  \nfruits.includes(\"Mango\"); // is true\n```\n","n":0.174}}},{"i":819,"$":{"0":{"v":"Map()","n":1},"1":{"v":"\n\n<center>\n\t<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/R8rmfD9Y5-c\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n</center>\n\nGiven data:\n\n```javascript\nconst items = [\n    { name: 'Bike',     price: 100  },\n    { name: 'TV',       price: 200  },\n    { name: 'Album',    price: 10   },\n    { name: 'Book',     price: 5    },\n    { name: 'Phone',    price: 500  },\n    { name: 'Computer', price: 1000 },\n    { name: 'Keyboard', price: 25   }\n]\n```\n\n## Map\n\nMap will let you take an array and turn it into an entirely new array while also allowing you to perform operations upon it\n\n---\n\n```js\nconst itemPrice = items.map((item) => {\n    return item.price + 100\n})\n```\n\nin other languages map always reminded me of applying a function to each item in an array/vector so in this case it is\n\n- take each item in items\n- pass to arrow functions (the surgical table)\n- operate upon it (add 100 to the item)\n- build the return array\n- assign the return array to the `itemPrices` constant which consists of the original array with each element having had its prices increased by 100\n","n":0.079}}},{"i":820,"$":{"0":{"v":"Includes()","n":1},"1":{"v":"\n\n<center>\n\t<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/R8rmfD9Y5-c\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n</center>\n\nGiven data:\n\n```javascript\nconst items = [\n    { name: 'Bike',     price: 100  },\n    { name: 'TV',       price: 200  },\n    { name: 'Album',    price: 10   },\n    { name: 'Book',     price: 5    },\n    { name: 'Phone',    price: 500  },\n    { name: 'Computer', price: 1000 },\n    { name: 'Keyboard', price: 25   }\n]\n```\n\n## Includes Method\n\nWhen you have a simple array and you just want to find out where a value is contained within it. Simple question, simple answer.\n\n---\n\n```js\nconst items = [1, 2, 3, 4, 5]\n\nconst includesTwo = items.includes(2)\nconsole.log(includesTwo)\n```\n\n**Result:**\n\n> true\n","n":0.104}}},{"i":821,"$":{"0":{"v":"Foreach()","n":1},"1":{"v":"\n\n<center>\n\t<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/R8rmfD9Y5-c\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n</center>\n\nGiven data:\n\n```javascript\nconst items = [\n    { name: 'Bike',     price: 100  },\n    { name: 'TV',       price: 200  },\n    { name: 'Album',    price: 10   },\n    { name: 'Book',     price: 5    },\n    { name: 'Phone',    price: 500  },\n    { name: 'Computer', price: 1000 },\n    { name: 'Keyboard', price: 25   }\n]\n```\n\n## For Each\n\ndoes not return anything, basically acts like a for loop and takes a function as an argument as what you will be doing with each value\n\n> \"for each item in items, do the thing\"\n\n```js\nitems.forEach((item) => {\n    console.log(item.name)\n})\n```\n\n**Result:**\n\nReading like English:\n\n- for each item in the array object, pass it to the arrow function #2 \n- for each item i receive, log it\n- next item\n\nno returned objects just pure action\n","n":0.089}}},{"i":822,"$":{"0":{"v":"Filter()","n":1},"1":{"v":"\n\n<center>\n\t<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/R8rmfD9Y5-c\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n</center>\n\nGiven data:\n\n```javascript\nconst items = [\n    { name: 'Bike',     price: 100  },\n    { name: 'TV',       price: 200  },\n    { name: 'Album',    price: 10   },\n    { name: 'Book',     price: 5    },\n    { name: 'Phone',    price: 500  },\n    { name: 'Computer', price: 1000 },\n    { name: 'Keyboard', price: 25   }\n]\n```\n\n## Filtering items\n\n```js\nconst filteredItems = items.filter((item) => {\n    return item.price <= 100\n})\n\nconsole.log(filteredItems)\n```\n\n**Result:**\n\n> .\n> (3) [\"Video 1 Recorded\", \"Video 2 Recorded\", \"Video 3 Recorded\"]\n> 0: \"Video 1 Recorded\"\n> 1: \"Video 2 Recorded\"\n> 2: \"Video 3 Recorded\"\n> length: 3\n> **proto**: Array(0)\n\nReading this like English, \n\n- The immutable variable `filteredItems` receives the following value(s). \n- The array of objects has the filter method applied\n  - The filter uses an arrow function #2 that takes a single parameter `(item)`\n  - The arrow function says \"for each item in items, pass each item into my function body and operate upon it\"\n  - Inside the function body the items price attribute is operated on with basic arithmetic to determine if it meets the condition `<=` \n  - If true, the data is returned with all other valid data that met the condition as the `.filter` method is an array method and likely returns an array as a result\n  - Each item that met the condition is then added to the resulting returned array \n- The returned array is then assigned to the constant variable `filteredItems`\n","n":0.065}}},{"i":823,"$":{"0":{"v":"Every()","n":1},"1":{"v":"\n\n<center>\n\t<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/R8rmfD9Y5-c\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n</center>\n\nGiven data:\n\n```javascript\nconst items = [\n    { name: 'Bike',     price: 100  },\n    { name: 'TV',       price: 200  },\n    { name: 'Album',    price: 10   },\n    { name: 'Book',     price: 5    },\n    { name: 'Phone',    price: 500  },\n    { name: 'Computer', price: 1000 },\n    { name: 'Keyboard', price: 25   }\n]\n```\n\n## Every method\n\nthis method returns a boolean value and is great for asking a question of your data and getting simple response in return. where as `some` just returns true as soon as it finds a single positive case, `every` reviews every value and only returns its result after every value has passed its check.\n\n---\n\n```js\nconst hasExpensiveItems = items.every((item) => {\n    return item.price <= 100\n})\n```\n\n**Result:**\n\n> false\n\nfor each item in items, iare all items less than or equal to 100? if so return true, otherwise false. \n","n":0.084}}},{"i":824,"$":{"0":{"v":"Destructuring","n":1},"1":{"v":"\n\n```js\n// Before:\nvar width = 200;\nvar height = 400;\n\n// After:\nlet [width, height] = [200, 400];\n\n// before: \nconst calculateArea = (areaParameters) => areaParameters[0] * areaParameters[1]\ncalculateArea([200, 400]);\n\n// or for better naming in older functions:\nconst calculateArea = ([width, height]) => width * height\ncalculateArea([200, 400]);\n```\n","n":0.158}}},{"i":825,"$":{"0":{"v":"Go","n":1}}},{"i":826,"$":{"0":{"v":"Csharp","n":1},"1":{"v":"\n\n- [Extract Fields from PDF][0]\n- [Coderr automated exception handling][1]\n\n[0]: https://www.codeproject.com/Articles/5140785/Extract-User-Data-Fields-From-Fillable-PDF-Document\n[1]: https://www.codeproject.com/Articles/1126297/Skip-Logfiles-Try-Automated-Exception-Handling\n","n":0.302}}},{"i":827,"$":{"0":{"v":"Cpp","n":1}}},{"i":828,"$":{"0":{"v":"Vars","n":1},"1":{"v":"\n\n## Data Types\n\nNormal variables are usually camel case with first letter lower case `likeThis`\n\nvariables must have their data types declared before the name of the variable\n","n":0.196}}},{"i":829,"$":{"0":{"v":"Tools","n":1}}},{"i":830,"$":{"0":{"v":"Ctags","n":1},"1":{"v":"\n\n## Resources\n\n- <https://www.youtube.com/4f3AENLrdYo>\n\nGenerate tags so that you can jump to function definitions\nin a file or in a group of files. tags will also find their\ndefinitions in other files in the director(ies) it was generated in\n\nTo generate tags: `ctags -R .`\n\nthis generates a `tags` file and now in your documents you can use\nthe following keybindings:\n\n`ctrl-]` jump to definition\n`ctrl-o` go back to prior position\n`ctrl-i` Jump forward\n\n`:h tag-stack` for more info on tags\n","n":0.12}}},{"i":831,"$":{"0":{"v":"Test","n":1}}},{"i":832,"$":{"0":{"v":"Functions","n":1},"1":{"v":"\n\n## Unit Testing\n\nTesting the behavior of your functions to ensure that they are working correctly and have no aberrant behavior.\n\n```cpp\n#include <iostream>\n#include <cassert>\nusing namespace std;\n\ndouble HrMinToMin(int origHours, int origMinutes) {\n   int totMinutes = 0;  // Resulting minutes\n   \n   totMinutes = (origHours * 60) + origMinutes;\n   \n   return origMinutes;\n}\n\nint main() {\n   \n   cout << \"Testing started\" << endl;\n   \n   assert(HrMinToMin(0, 0)  == 0);\n   assert(HrMinToMin(0, 1)  == 1);\n   assert(HrMinToMin(0, 99) == 99);\n   assert(HrMinToMin(1, 0)  == 60);\n   assert(HrMinToMin(5, 0)  == 300);\n   assert(HrMinToMin(2, 30) == 150);\n   // Many more test vectors would be typical...\n   \n   cout << \"Testing completed\" << endl;\n   \n   return 0;\n}\n```\n","n":0.101}}},{"i":833,"$":{"0":{"v":"Streams","n":1}}},{"i":834,"$":{"0":{"v":"String","n":1},"1":{"v":"\n\n### String Streams\n\n#### Input Stream\n\n> Sometimes a programmer wishes to read input data from a string rather than from the keyboard (standard input). A new input string stream variable of type `istringstream` can be created that is associated with a string rather than with the keyboard (standard input). `istringstream` is derived from `istream`. Such a stream can be used just like the `cin` stream. The following program illustrates.\n\n```cpp\n#include <iostream>\n#include <sstream>\n#include <string>\nusing namespace std;\n\nint main() {\n   string  userInfo = \"Amy Smith 19\"; // Input string\n   istringstream inSS(userInfo);      // Input string stream\n   string firstName;                  // First name\n   string lastName;                   // Last name\n   int userAge = 0;                   // Age\n   \n   // Parse name and age values from input string\n   inSS >> firstName;\n   inSS >> lastName;\n   inSS >> userAge;\n   \n   // Output parsed values\n   cout << \"First name: \" << firstName << endl;\n   cout << \"Last  name: \" << lastName << endl;\n   cout << \"Age: \"        << userAge << endl;\n   \n   return 0;\n}\n\n//#> First name: Amy\n//#> Last  name: Smith\n//#> Age: 19\n```\n\n> The program uses `#include <sstream>` for access to the string stream class, which is in `namespace std`. The line `istringstream inSS(userInfo);` declares a new stream variable and initializes its buffer to a copy of `userInfo`. Then, the program can extract data from stream `inSS` using `>>` similar to extracting from `cin`.\n> .\n> A common use of string streams is to process user input line-by-line. The following program reads in the line as a string, and then extracts individual data items from that string.\n\n```cpp\n#include <iostream>\n#include <string>\n#include <sstream>\nusing namespace std;\n\nint main() {\n   istringstream inSS;       // Input string stream\n   string lineString;        // Holds line of text\n   string firstName;         // First name\n   string lastName;          // Last name\n   int    userAge = 0;       // Age\n   bool   inputDone = false; // Flag to indicate next iteration\n   \n   // Prompt user for input\n   cout << \"Enter \\\"firstname lastname age\\\" on each line\" << endl;\n   cout << \"(\\\"Exit\\\" as firstname exits).\" << endl << endl;\n   \n   // Grab data as long as \"Exit\" is not entered\n   while (!inputDone) {\n      \n      // Entire line into lineString\n      getline(cin, lineString);\n      \n      // Copies to inSS's string buffer\n      inSS.clear();\n      inSS.str(lineString);\n      \n      // Now process the line\n      inSS >> firstName;\n      \n      // Output parsed values\n      if (firstName == \"Exit\") {\n         cout << \"   Exiting.\" << endl;\n         \n         inputDone = true;\n      }\n      else {\n         inSS >> lastName;\n         inSS >> userAge;\n         \n         cout << \"   First name: \" << firstName << endl;\n         cout << \"   Last  name: \" << lastName << endl;\n         cout << \"   Age:        \" << userAge   << endl;\n         cout << endl;\n      }\n   }\n   \n   return 0;\n}\n\n//#> Enter \"firstname lastname age\" on each line\n//#> (\"Exit\" as firstname exits).\n//#> \n//#> Mary Jones 22\n//#>    First name: Mary\n//#>    Last  name: Jones\n//#>    Age:        22\n//#> \n//#> Sally Smith 14\n//#>    First name: Sally\n//#>    Last  name: Smith\n//#>    Age:        14\n//#> \n//#> Exit\n//#>    Exiting.\n```\n\n#### Output Stream\n\n> The program uses `getline` to read an input line into a string. The line `inSS.str(lineString);` uses the `str(s)` function to initialize the stream's buffer to string `s`. Afterwards, the program extracts input from that stream using `>>.` The statement `inSS.clear();` is necessary to reset the state of the stream so that subsequent extractions start from the beginning; the clear resets the stream's state.\n> .\n> Similarly, a new output string stream variable of type **ostringstream** can be created that is associated with a string rather than with the screen (standard output). **ostringstream** is a special kind of (i.e., is derived from) `ostream`. Once created, a program can insert characters into that stream using `<<`, as follows.\n\n```cpp\n#include <iostream>\n#include <string>\n#include <sstream>\nusing namespace std;\n\nint main() {\n   ostringstream fullNameOSS; // Output string stream\n   ostringstream ageOSS;      // Output string stream\n   string firstName;          // First name\n   string lastName;           // Last name\n   string fullName;           // Full name (first and last)\n   string ageStr;             // Age (string)\n   int userAge = 0;           // Age\n   \n   // Prompt user for input\n   cout << \"Enter \\\"firstname lastname age\\\": \" << endl;\n   cin >> firstName;\n   cin >> lastName;\n   cin >> userAge;\n   \n   // Writes to buffer, then copies from buffer into string\n   fullNameOSS << lastName << \", \" << firstName;\n   fullName = fullNameOSS.str();\n   \n   // Output parsed input\n   cout << endl << \"   Full name: \" << fullName << endl;\n   \n   // Writes int age as chars to buffer\n   ageOSS << userAge;\n   \n   // Appends (minor) to buffer if less than 21, then\n   // copies buffer into string\n   if (userAge < 21) {\n      ageOSS << \" (minor)\";\n   }\n   \n   ageStr = ageOSS.str();\n   \n   // Output string\n   cout << \"   Age: \" << ageStr << endl;\n   \n   return 0;\n}\n```\n","n":0.036}}},{"i":835,"$":{"0":{"v":"Output Fotmatting","n":0.707}}},{"i":836,"$":{"0":{"v":"Text","n":1},"1":{"v":"\n\n#### Text Formatting\n\n| Manipulator | Description                                                                                                                                                                                             | Example (for item \"Amy\")    |   |\n| :---------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | :-------------------------- | - |\n| setw(n)     | Sets the number of characters for the next output item only (does not persist, in contrast to other manipulators). By default, the item will be right-aligned, and filled with spaces. From `<iomanip>` | For n=7: \"Amy\"              |   |\n| setfill(c)  | Sets the fill to character c. From `<iomanip>`                                                                                                                                                          | For c='\\*': \"\"\\*\\*\\*\\*Amy\"\" | \" |\n| left        | Changes to left alignment. From `<ios>`                                                                                                                                                                 | \"Amy \"                      |   |\n| right       | Changes to right alignment. From `<ios>`                                                                                                                                                                | \" Amy\"                      |   |\n\n```cpp\n#include <iostream>\n#include <ios>\n#include <iomanip>\nusing namespace std;\n\nint main() {\n   cout << \"Dog age in human years (dogyears.com)\" << endl << endl;\n   \n   // set num char for each column, set alignment\n   cout << setw(10) << left  << \"Dog age\" << \"|\";\n   cout << setw(12) << right << \"Human age\" << endl;\n   cout << \"------------------------------\" << endl;\n   cout << setw(10) << left  << \"2 months\" << \"|\";\n   cout << setw(12) << right << \"14 months\" << endl;\n   cout << setw(10) << left  << \"6 months\" << \"|\";\n   cout << setw(12) << right << \"5 years\" << endl;\n   \n   // set fill character, num char for each column, set alignment\n   cout << setfill('-');\n   cout << setw(10) << left  << \"8 months\" << \"|\";\n   cout << setw(12) << right << \"9 years\" << endl;\n   cout << setw(10) << left  << \"1 year\" << \"|\";\n   \n   // change fill character, num char for each column, set alignment\n   cout << setfill('.');\n   cout << setw(12) << right << \"15 years\" << endl;\n\n   // change fill character, num char for each column\n   cout << setfill('*') << setw(30) << \"\" << endl;\n   \n   return 0;\n}\n```\n\n> Of particular interest is how the `setw()` and `setfill()` manipulators are used in the last few lines. Note how they are used to create a line of 30 asterisks, without having to type 30 asterisks.\n> .\n> Most manipulators are persistent, meaning they change the state of the stream for all subsequent output. The exception is `setw()`, which <u>only affects the next output item</u>, defined that way likely because programmers usually only want to set the width of the next item and not all subsequent items.\n\n| Manipulator | Description                                                                                           |                   |\n| :---------: | :---------------------------------------------------------------------------------------------------- | ----------------- |\n|    `endl`   | Inserts a newline character '\\\\n' into the output buffer, and informs the system to flush the buffer. | From `<iostream>` |\n|   `flush`   | Informs the system to flush the buffer. From `<iostream>`                                             |                   |\n","n":0.049}}},{"i":837,"$":{"0":{"v":"Number","n":1},"1":{"v":"\n\n#### Number Formatting\n\n> A programmer can adjust the way that output appears, a task known as output formatting. The main formatting approach uses manipulators. A manipulator is an item designed to be used with the insertion operator `<<` or extraction operator `>>` to adjust the way output appears, and is available via `#include <iomanip>; `or `#include <ios>;` in namespace std. For example, `cout << setprecision(3) << myFloat;` causes the floating-point variable `myFloat` to be output with only 3 digits; if `myFloat` was 12.34, the output would be 12.3.\n> .\n> <u>Most manipulators change the state of the stream such that the manipulation affects all subsequent output, not just the next output.</u>\n\n| Manipulator     | Description                                                                                                                                   | Example                                                                            |\n| :-------------- | :-------------------------------------------------------------------------------------------------------------------------------------------- | :--------------------------------------------------------------------------------- |\n| fixed           | Use fixed-point notation. `From <ios>`                                                                                                        | 12.34                                                                              |\n| scientific      | Use scientific notation. `From <ios>`                                                                                                         | 12.3E+01                                                                           |\n| setprecision(p) | If stream has not been manipulated to fixed or scientific: Sets max number of digits in number                                                | p=3 yields 12.3 p=5 yields 12.34                                                   |\n|                 | If stream has been manipulated to fixed or scientific: Sets max number of digits in fraction only (after the decimal point). From `<iomanip>` | fixed: p=1 yields 12.3 scientific: p=1 yields 1.2e+01                              |\n| showpoint       | Even if fraction is 0, show decimal point and trailing 0s. Opposite is noshowpoint. `From <ios>`                                              | For 99.0 with precision=2 and fixed: 99 (default or noshowpoint) 99.00 (showpoint) |\n\n```cpp\n#include <iostream>\n#include <ios>\n#include <iomanip>\nusing namespace std;\n\nint main() {\n   \n   double milesTrvld = 765.4321;\n   \n   cout << \"setprecision(p) -- Sets # digits\" << endl;\n   cout << milesTrvld << \" (default p is 6)\" << endl;\n   cout << setprecision(8) << milesTrvld << \" (p = 8)\" << endl;\n   cout << setprecision(5) << milesTrvld << \" (p = 5)\" << endl;\n   cout << setprecision(2) << milesTrvld << \" (p = 2)\"\n        << \" (note rounding)\" << endl;\n   cout << milesTrvld << \" (manipulator persists)\" << endl << endl;\n   \n   cout << setprecision(2);\n   cout << \"(For following, p = 2 applies to fraction only)\" << endl;\n   \n   // fixed -- uses fixed point notation\n   cout << fixed;\n   cout << \"fixed: \" << milesTrvld << endl;\n   \n   // scientific -- uses scientific notation\n   cout << scientific;\n   cout << \"scientific: \" << milesTrvld << endl;\n   \n   return 0;\n}\n```\n","n":0.052}}},{"i":838,"$":{"0":{"v":"Input and Output","n":0.577},"1":{"v":"\n\n### Input / Output\n\n#### Output Stream\n\nor `ostream` for short is a class that supports output. It is included from [[s.l.cpp.libs.iostream]]\n\n`<iostream>` provides the `<<` operator known as the **insertion operator**.\n\n`cout` is a predefined `ostream` object (e.g., you can think of it as declared as `ostream cout;`\n\n> The `<<` operator is overloaded with functions to support the various standard data types, such as int, bool, float, etc., each function converting that data type to a sequence of characters. The operator may be further overloaded by the string library from `#include <string>` or by the programmer for programmer-created classes.\n> .\n> The `<<` operator returns a reference to the `ostream` that called it, and is evaluated from left to right like most operators, so `<<` operators can appear in series.\n\n```cpp\ncout << \"Num\" << myInt;\n\n// can be thought of as:\n\n( cout.operator<<(\"Num\") ).operator<<(myInt);\n```\n\n#### Input Stream\n\nOr `istream`, provides the `>>` operator known as the **extraction operator**. To extract data from a data buffer and write the data into different types of variables.\n\n> `cin` is a predefined istream pre-associated with a system's standard input, usually a computer keyboard. The system automatically puts the standard input into a data buffer associated with `cin`. The `>>` operator <u>skips leading whitespace</u>, extracts as many characters as possible consistent with the target variable's type and <u>stopping at the next whitespace</u>, converts the extracted characters to the target variable's type, and stores the result into the variable.\n","n":0.065}}},{"i":839,"$":{"0":{"v":"Basic Input Output","n":0.577},"1":{"v":"\n\n```cpp\n/*\n\tBasic input output\n\tSend to STDOUT\n\tendl is like \"\\n\" but better\n*/\n\nstd::cout << \"What are you ending to the terminal?\" << std::endl;\n//#> What are you ending to the terminal?\n\nstd::cin >> myVariable; // \"Hello World\"\n\nstd::cout << \"this goes to terminal: \" << myVariable << std::endl;\n//#> this goes to terminal: Hello World\n```\n","n":0.144}}},{"i":840,"$":{"0":{"v":"Resources","n":1},"1":{"v":"\n\n- [Assembly Code Breakdown of your code](https://godbolt.org/)\n- [cplusplus.com](http://cplusplus.com/reference/)\n- [Cherno C++ Tutorial Series](https://www.youtube.com/playlist?list=PLlrATfBNZ98dudnM48yfGUldqGD0S4FFb)\n","n":0.289}}},{"i":841,"$":{"0":{"v":"Preprocessor Directives","n":0.707},"1":{"v":"\n\n> The **preprocessor** is a tool that scans the file from top to bottom looking for any lines that begin with #, known as a **hash symbol**. Each such line is not a program statement, but rather directs the **preprocessor** to modify the file in some way before compilation continues, each such line being known as a **preprocessor directive**. The directive ends at the end of the line, no semicolon is used at the end of the line.\n\n## Include\n\n> Perhaps the most commonly-used preprocessor directive is **#include**, known as an include directive. **#include** directs the compiler to replace that line by the contents of the given filename.\n\n```cpp\n#include \"filename\"\n#include <filename>\n```\n\n## Header Files\n\nHeader files are included through Pre-Processor Directives.\n\nHeader files contain code such as groups of related functions & their [[C++ Functions|c++-functions#Declaration]]'s and [[C++ Functions|c++-functions#Definition]]'s', as well as [[C++ Classes|c++-classes]]. \n\nWhen you input a header file with an `#include` statement its basically like copy/pasting all the code where the file is included. sometimes this can lead to duplication and errors if included multiple times so to prevent this we use [[import.software.language.cpp.preprocessor-directives#Header File Guards]].\n\n### Header File Guards\n\nThese guards look like this:\n\n```cpp\n#ifndef FILENAME_H\n#define FILENAME_H\n\n// Header file contents\n\n#endif\n```\n\n> `#define FILENAME_H` defines the symbol `FILENAME_H` to the preprocessor. The `#ifndef FILENAME_H` and `#endif` form a pair that instructs the preprocessor to process the code between the pair only if FILENAME_H is not defined (\"ifndef\" is short for \"if not defined\"). Thus, if the preprocessor includes encounter the header more than once, the code in the file during the second and any subsequent encounters will be skipped because `FILENAME_H` was already defined.\n> .\n> <u>Good practice</u> is to guard every header file. The following shows the `threeintsfcts.h` file with the guarding code added:\n\n```cpp\n#ifndef THREEINTSFCT_H\n#define THREEINTSFCT_H\n\nint ThreeIntsSum(int num1, int num2, int num3);\nint ThreeIntsAvg(int num1, int num2, int num3);\n\n#endif\n```\n\nAnother example from [This video by The Cherno](https://youtu.be/9RJTQmK0YPI?list=PLlrATfBNZ98dudnM48yfGUldqGD0S4FFb) is instead of `ifndef` and all that, using instead `#pragma once` which says to include the file only once per translation unit. \n\nTo be safe and make sure all compilers will support portability and the use the fastest option you can use both:\n\n```cpp\n#pragma once\n#ifndef _HEADER_H_\n#define _HEADER_H_\n\n...\n\n#endif\n```\n","n":0.053}}},{"i":842,"$":{"0":{"v":"Precedence Rules for Logical and Relational Operators","n":0.378},"1":{"v":"\n\n| Convention  | Description                                                                            | Explanation                                                                                                                |\n| ----------- | -------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------- |\n| `( )`       | Items within parentheses are evaluated first.                                          | In¬†!(age > 16), age > 16 is evaluated first, then the logical NOT.                                                         |\n| `!`         | Next to be evaluated is¬†!.                                                             |                                                                                                                            |\n| `* / % + -` | Arithmetic operator are then evaluated using the precedence rules for those operators. | z - 45 &lt; 53¬†is evaluated as¬†(z - 45) &lt; 53.                                                                           |\n| `< <= > >=` | Then, relational operators¬†&lt; &lt;= > >=¬†are evaluated.                              | x &lt; 2 \\|\\| x >= 10¬†is evaluated as¬†(x &lt; 2) \\|\\| (x >= 10)¬†because &lt; and >= have precedence over \\|\\|.             |\n| `== ¬† !=`   | Then, the equality and inequality operators¬†== !=¬†are evaluated.                       | x == 0 && x >= 10¬†is evaluated as¬†(x == 0) && (x >= 10)¬†because &lt; and >= have precedence over &&lt;.                    |\n| `&`         | Then, the bitwise AND operator is evaluated.                                           | x == 5 \\| y == 10 & z != 10¬†is evaluated as¬†(x == 5) \\| ((y == 10) & (z != 10))¬†because & has precedence over \\|.          |\n| \\|          | Then, the bitwise OR operator is evaluated.                                            | x == 5 \\| y == 10 && z != 10¬†is evaluated as¬†((x == 5) \\| (y == 10)) && (z != 10))¬†because \\| has precedence over &&.      |\n| `&&`        | Then, the logical AND operator is evaluated.                                           | x == 5 \\|\\| y == 10 && z != 10¬†is evaluated as¬†(x == 5) \\|\\| ((y == 10) && (z != 10))¬†because && has precedence over \\|\\|. |\n| \\|\\|        | Finally, the logical OR operator is evaluated.                                         |                                                                                                                            |\n","n":0.06}}},{"i":843,"$":{"0":{"v":"Polymorphism","n":1},"1":{"v":"\n\n## Function Name Overloading\n\n> Sometimes a program has two functions with the same name but differing in the number or types of parameters, known as **function name overloading** or just **function overloading**.\n\n```cpp\n#include <iostream>\n#include <string>\nusing namespace std;\n\t\t\t// int\t\t\tint\t\t\t   int\nvoid DatePrint(int currDay, int currMonth, int currYear) {\n\n   cout << currMonth << \"/\" << currDay << \"/\" << currYear;\n   return;\n}\n\t\t\t// int\t\t\tstring\t\t\t  int\nvoid DatePrint(int currDay, string currMonth, int currYear) {\n\n   cout << currMonth << \" \" << currDay << \", \" << currYear;\n   return;\n}\n\nint main() {\n   \n   DatePrint(30, 7, 2012);\n   cout << endl;\n   \n   DatePrint(30, \"July\", 2012);\n   cout << endl;\n   \n   return 0;\n}\n```\n","n":0.101}}},{"i":844,"$":{"0":{"v":"Oop","n":1},"1":{"v":"\n\n> The **class** construct defines a new type that can group data and functions to form an object\n","n":0.236}}},{"i":845,"$":{"0":{"v":"Unit Testing","n":0.707},"1":{"v":"\n\nRelated: [[C++ Unit Testing Functions|s.l.cpp.test.functions]]\n\n> A goal of testing is to achieve complete **code coverage**, meaning all code is executed at least once. Minimally for a class, that means every public function is called at least once. Of course, the programmer of a class knows about a class' implementation and thus will want to also ensure that every private helper function is called, and that every line of code within every function is executed at least once, which may require multiple calls with different input values for a function with branches.\n","n":0.105}}},{"i":846,"$":{"0":{"v":"Test Bench","n":0.707},"1":{"v":"\n\n## Test Bench\n\n```cpp\nint main() {\n   StatsInfo testData;\n\n   // Typical testbench tests more thoroughly \n\n   cout << \"Beginning tests.\" << endl;\n\n   // Check set/get num1\n   testData.SetNum1(100);\n   if (testData.GetNum1() != 100) {\n      cout << \"   FAILED set/get num1\" << endl;\n   }\n\n   // Check set/get num2\n   testData.SetNum2(50);\n   if (testData.GetNum2() != 50) {\n      cout << \"   FAILED set/get num2\" << endl;\n   }\n\n   // Check GetAverage()\n   testData.SetNum1(10);\n   testData.SetNum2(20);\n   if (testData.GetAverage() != 15) {\n      cout << \"   FAILED GetAverage for 10, 20\" << endl;\n   }\n\n   testData.SetNum1(-10);\n   testData.SetNum2(0);\n   if (testData.GetAverage() != -5) {\n      cout << \"   FAILED GetAverage for -10, 0\" << endl;\n   }\n\n   cout << \"Tests complete.\" << endl;\n\n   return 0;\n}\n```\n","n":0.098}}},{"i":847,"$":{"0":{"v":"Class to Tes","n":0.577},"1":{"v":"\n\n## Class to Test\n\n```cpp\n#include <iostream>\nusing namespace std;\n\n// Note: This class intentionally has errors\n\nclass StatsInfo {\npublic:\n   void SetNum1(int numVal);\n   void SetNum2(int numVal);\n   int  GetNum1() const;\n   int  GetNum2() const;\n   int  GetAverage() const;\n   void PrintNums()  const;\n   \nprivate:\n   int num1;\n   int num2;\n};\n\nvoid StatsInfo::SetNum1(int numVal) {\n   num1 = numVal;\n}\n\nvoid StatsInfo::SetNum2(int numVal) {\n   num2 = numVal;\n}\n\nint StatsInfo::GetNum1() const {\n   return num1;\n}\n\nint StatsInfo::GetNum2() const {\n   return num1;\n}\n\nint StatsInfo::GetAverage() const {\n   return num1 + num2 / 2;\n}\n```\n","n":0.12}}},{"i":848,"$":{"0":{"v":"This Implicit Parameter","n":0.577},"1":{"v":"\n\n> Within a member function, the implicitly-passed object pointer is accessible via the name this. In particular, a member can be accessed as `this->member`. The `->` is the member access operator for a pointer, similar to the `.` operator for non-pointers.\n\n```cpp\n#include <iostream>\nusing namespace std;\n\nclass ShapeSquare {\n   public:\n      void   SetSideLength(double sideLength);\n      double GetArea() const;\n   private:\n      double sideLength;\n};\n\nvoid ShapeSquare::SetSideLength(double sideLength) {\n   this->sideLength = sideLength; // Refer to data member with same\n   // Data member      Parameter  // name as the passed in parameter\n   return;\n}\n\ndouble ShapeSquare::GetArea() const{\n   return sideLength * sideLength; // Both refer to data member\n}\n\nint main() {\n   ShapeSquare square1;\n\n   square1.SetSideLength(1.2);\n   cout << \"Square's area: \" << square1.GetArea() << endl;\n\n   return 0;\n}\n```\n","n":0.096}}},{"i":849,"$":{"0":{"v":"The Big Three","n":0.577},"1":{"v":"\n\n> The **rule of three** describes a practice that if a programmer explicitly defines any one of those three special member functions (destructor, copy constructor, copy assignment operator), then the programmer should explicitly define all three. For this reason, those three special member functions are sometimes called the **big three**.\n> .\n> A <u>good practice</u> is to always follow the rule of three and define the big three (_destructor, copy constructor, copy assignment operator_) if any one of these functions are defined.\n","n":0.111}}},{"i":850,"$":{"0":{"v":"Deconstructors","n":1},"1":{"v":"\n\n## Deconstructors\n\n> A destructor has no parameters and no return value (_not even void_)\n\nJust like [[s.l.cpp.oop.the-big-three#Constructors]] Deconstructors share the same name as the class  albeit prepended with a tilde `~` so this is a class with its constructor and destructor:\n\n```cpp\nclass SampleClass {\n   public:\n      SampleClass(); // Constructor\n      ~SampleClass(); // Destructor\n   private:\n};\n```\n","n":0.141}}},{"i":851,"$":{"0":{"v":"Implementation","n":1},"1":{"v":"\n\n### Implementation\n\n```cpp\n#include <iostream>\nusing namespace std;\n\nclass MyClass {\n   public:\n      MyClass();\n      ~MyClass();\n   private:\n      int* subObj;\n};\n\nMyClass::MyClass() {\n   cout << \"Constructor called.\" << endl;\n   subObj = new int; // Allocate mem for data\n   *subObj = 0;\n   return;\n}\n\nMyClass::~MyClass() {\n   cout << \"Destructor called.\" << endl;\n   delete subObj;\n   return;\n}\n\nint main() {\n   MyClass* tempClassObj;      // Create object of type MyClass\n\n   tempClassObj = new MyClass; // Allocate mem for object\n   delete tempClassObj;        // No more memory leak\n                               // Freed obj's mem, including subObj\n   // Rest of program ...\n   return 0;\n}\n```\n","n":0.11}}},{"i":852,"$":{"0":{"v":"Copy Assignment Operator","n":0.577},"1":{"v":"\n\n## Copy Assignment Operator\n\n> The problem is that the assignment of `classObj2 = classObj1;` merely copied the pointer for `dataObj`, resulting in `classObj1's dataObj` and `classObj2's dataObj` members both pointing to the same memory location. Printing `classObj2` prints 9 but for the wrong reason, and if `classObj1's dataObj` value was later changed, `classObj2's dataObj` value would seemingly magically change too. Additionally, destroying `classObj1` frees that `dataObj's` memory; destroying `classObj2` then tries to free that same memory, causing a program crash. Furthermore, a memory leak has occurred because neither `dataObj` is pointing at location 81.\n> .\n> The solution is to overload the \"`=`\" operator by defining a new function, known as the `copy assignment operator` or sometimes just the `assignment operator`, that copies one class object to another. Such a function is typically defined as:\n\n```cpp\nclass MyClass {\n   public:\n      ...\n      MyClass& operator=(const MyClass& objToCopy);\n      ...\n};\n```\n","n":0.084}}},{"i":853,"$":{"0":{"v":"Implementation","n":1},"1":{"v":"\n\n### Implementation\n\n```cpp\n#include <iostream>\nusing namespace std;\n\nclass MyClass {\npublic:\n   MyClass();\n   ~MyClass();\n   MyClass& operator=(const MyClass& objToCopy);\n   \n   // Set member value dataObj\n   void SetDataObj(const int setVal) {\n      *dataObj = setVal;\n   }\n   \n   // Return member value dataObj\n   int GetDataObj() const {\n      return *dataObj;\n   }\nprivate:\n   int* dataObj;// Data member\n};\n\n// Default constructor\nMyClass::MyClass() {\n   cout << \"Constructor called.\" << endl;\n   dataObj = new int; // Allocate mem for data\n   *dataObj = 0;\n\n   return;\n}\n\n// Destructor\nMyClass::~MyClass() {\n   cout << \"Destructor called.\" << endl;\n   delete dataObj;\n\n   return;\n}\n\nMyClass& MyClass::operator=(const MyClass& objToCopy) {\n   cout << \"Assignment op called.\" << endl;\n   \n   if (this != &objToCopy) {           // 1. Don't self-assign\n      delete dataObj;                  // 2. Delete old dataObj\n      dataObj = new int;               // 3. Allocate new dataObj\n      *dataObj = *(objToCopy.dataObj); // 4. Copy dataObj\n   }\n   \n   return *this;\n}\n\nint main() {\n   MyClass tempClassObj1; // Create object of type MyClass\n   MyClass tempClassObj2; // Create object of type MyClass\n   \n   // Set and print object 1 data member value\n   tempClassObj1.SetDataObj(9);\n   \n   // Copy class object using copy assignment operator\n   tempClassObj2 = tempClassObj1;\n   \n   // Set object 1 data member value\n   tempClassObj1.SetDataObj(1);\n   \n   // Print data values for each object\n   cout << \"obj1:\" << tempClassObj1.GetDataObj() << endl;\n   cout << \"obj2:\" << tempClassObj2.GetDataObj() << endl;\n   \n   return 0;\n}\n```\n","n":0.071}}},{"i":854,"$":{"0":{"v":"Class Copy Constructor","n":0.577},"1":{"v":"\n\n## Class Copy Constructors\n\nIf a class has a constructor that allocates memory for a variable with a pointer:\n\n```cpp\nclass MyClass {\npublic:\n   MyClass();\n   ~MyClass();\n   \n   // Set member value dataObj\n   void SetDataObj(const int setVal) {\n      *dataObj = setVal;\n   }\n   \n   // Return member value dataObj\n   int GetDataObj() const {\n      return *dataObj;\n   }\nprivate:\n   int* dataObj;// Data member\n};\n```\n\nAnd a new class is instantiated, and then passed by **value** to a function:\n\n```cpp\nvoid SomeFunction(MyClass localObj) {\n   // Do something with localObj\n}\n\nint main() {\n   MyClass tempClassObj; // Create object of type MyClass\n   \n   // Set and print data member value\n   tempClassObj.SetDataObj(9);\n   cout << \"Before: \" << tempClassObj.GetDataObj() << endl;\n   \n   // Calls SomeFunction(), tempClassObj is passed by value\n   SomeFunction(tempClassObj);\n   \n   // Print data member value\n   cout << \"After: \" << tempClassObj.GetDataObj() << endl; // ERROR\n   \n   return 0;\n}\n\n```\n\nYou get an error because the pass by value acts as a member wise copy.:\n\n- newA = oldA\n- newB = oldB\n\nIf your class doesn't have pointers then you wont have this issue. But with pointers we need to take a special approach. We need a copy constructor so that when passed by value to a function, when the class is copied locally we don't mess with the pointers. This copy constructor creates a new copy of the original class called a **deep copy**. \n\n> The **copy constructor** can be called with a single pass by reference argument of the class type, representing an original object to be copied to the newly-created object:\n\n```cpp\nclass MyClass {\n   public:\n      ...\n      MyClass(const MyClass& origClass);\n      ...\n};\n```\n\n```cpp\n/*\n\tA class's copy constructor will be called automatically when an object of the class type \n\tis passed by value to a function, and also when an object is initialized by copying another \n\tobject during declaration, as in: \n*/\nMyClass classObj2 = classObj1; \n// or \nobj2Ptr = new MyClass(classObj1);.\n```\n","n":0.058}}},{"i":855,"$":{"0":{"v":"Implementation","n":1},"1":{"v":"\n\n### Implementation\n\n```cpp\n#include <iostream>\nusing namespace std;\n\nclass MyClass {\npublic:\n   MyClass();\n   MyClass(const MyClass& origClass); // Copy constructor\n   ~MyClass();\n   \n   // Set member value dataObj\n   void SetDataObj(const int setVal) {\n      *dataObj = setVal;\n   }\n   \n   // Return member value dataObj\n   int GetDataObj() const {\n      return *dataObj;\n   }\nprivate:\n   int* dataObj;// Data member\n};\n\n// Default constructor\nMyClass::MyClass() {\n   cout << \"Constructor called.\" << endl;\n   dataObj = new int; // Allocate mem for data\n   *dataObj = 0;\n   \n   return;\n}\n\n// Copy constructor\nMyClass::MyClass(const MyClass& origClass) {\n   cout << \"Copy constructor called.\" << endl;\n   dataObj = new int; // Allocate sub-object\n   *dataObj = *(origClass.dataObj);\n   \n   return;\n}\n\n// Destructor\nMyClass::~MyClass() {\n   cout << \"Destructor called.\" << endl;\n   delete dataObj;\n\n   return;\n}\n\nvoid SomeFunction(MyClass localObj) {\n   // Do something with localObj\n   return;\n}\n\nint main() {\n   MyClass tempClassObj; // Create object of type MyClass\n   \n   // Set and print data member value\n   tempClassObj.SetDataObj(9);\n   cout << \"Before: \" << tempClassObj.GetDataObj() << endl;\n   \n   // Calls SomeFunction(), tempClassObj is passed by value\n   SomeFunction(tempClassObj);\n   \n   // Print data member value\n   cout << \"After: \" << tempClassObj.GetDataObj() << endl;\n   \n   return 0;\n}\n```\n","n":0.077}}},{"i":856,"$":{"0":{"v":"Separation of Concerns","n":0.577},"1":{"v":"\n\n## Class Code Separation of Concerns\n\nTypically 2 files are used to separate class code:\n\n`ClassName.h` **--** _Contains the class definition, including data members and member function declarations._\n\n`ClassName.cpp` **--**\t_Contains member function definitions._\n\n> Sometimes multiple small related classes are grouped into a single file, to avoid a proliferation of files. But for typical classes, good practice is to create a unique `.cpp` and `.h` file for each class.\n","n":0.124}}},{"i":857,"$":{"0":{"v":"Example","n":1},"1":{"v":"\n\n### Example\n\n`StoreItem.h`\n\n```cpp\n#ifndef STOREITEM_H\n#define STOREITEM_H\n\nclass StoreItem {\n   public:\n      void SetWeightOunces(int ounces);\n      void Print() const;\n   private:\n      int weightOunces;\n};\n\n#endif\n```\n\n`StoreItem.cpp`\n\n```cpp\n#include <iostream>\nusing namespace std;\n\n#include \"StoreItem.h\"\n\nvoid StoreItem::SetWeightOunces(int ounces) {\n   weightOunces = ounces;\n   return;\n}\n\nvoid StoreItem::Print() const {\n   cout << \"Weight (ounces): \" << weightOunces << endl;\n   return;\n}\n```\n\n`main.cpp`\n\n```cpp\n#include <iostream>\nusing namespace std;\n\n#include \"StoreItem.h\"\n\nint main() {\n   StoreItem item1;\n\n   item1.SetWeightOunces(16);\n   item1.Print();\n\n   return 0;\n}\n```\n","n":0.139}}},{"i":858,"$":{"0":{"v":"Classes within Classes","n":0.577},"1":{"v":"\n\n### Classes Within Classes\n\n`TeamPerson.h`\n\n```cpp\n#ifndef TEAMPERSON_H\n#define TEAMPERSON_H\n\n#include <string>\nusing namespace std;\n\nclass TeamPerson {\n   public:\n      void   SetFullName(string firstAndLastName);\n      void   SetAgeYears(int ageInYears);\n      string GetFullName() const;\n      int    GetAgeYears() const;\n      void   Print() const;\n\n   private:\n      string fullName;\n      int    ageYears;\n};\n\n#endif\n```\n\n`TeamPerson.cpp`\n\n```cpp\n#include <iostream>\n#include <string>\nusing namespace std;\n\n#include \"TeamPerson.h\"\n\nvoid TeamPerson::SetFullName(string firstAndLastName) {\n   fullName = firstAndLastName;\n   return;\n}\n\nvoid TeamPerson::SetAgeYears(int ageInYears) {\n   ageYears = ageInYears;\n   return;\n}\n\nstring TeamPerson::GetFullName() const {\n   return fullName;\n}\n\nint TeamPerson::GetAgeYears() const {\n   return ageYears;\n}\n\nvoid TeamPerson::Print() const {\n   cout << \"Full name: \"   << fullName << endl;\n   cout << \"Age (years): \" << ageYears << endl;\n}\n```\n\n`SoccerTeam.h`\n\n```cpp\n#ifndef SOCCERTEAM_H\n#define SOCCERTEAM_H\n\n#include \"TeamPerson.h\"\n\nclass SoccerTeam {\n   public:\n      void SetHeadCoach(TeamPerson teamPerson);\n      void SetAssistantCoach (TeamPerson teamPerson);\n\n      TeamPerson GetHeadCoach() const;\n      TeamPerson GetAssistantCoach() const;\n\n      void Print() const;\n\n   private:\n      TeamPerson headCoach;\n      TeamPerson assistantCoach;\n      // Players omitted for brevity\n};\n\n#endif\n```\n\n`SoccerTeam.cpp`\n\n```cpp\n#include <iostream>\nusing namespace std;\n\n#include \"TeamPerson.h\"\n#include \"SoccerTeam.h\"\n\nvoid SoccerTeam::SetHeadCoach(TeamPerson teamPerson) {\n   headCoach = teamPerson;\n   return;\n}\n\nvoid SoccerTeam::SetAssistantCoach(TeamPerson teamPerson) {\n   assistantCoach = teamPerson;\n   return;\n}\n\nTeamPerson SoccerTeam::GetHeadCoach() const {\n   return headCoach;\n}\n\nTeamPerson SoccerTeam::GetAssistantCoach() const {\n   return assistantCoach;\n}\n\nvoid SoccerTeam::Print() const {\n   cout << \"HEAD COACH: \" << endl;\n   headCoach.Print();\n   cout << endl;\n\n   cout << \"ASSISTANT COACH: \" << endl;\n   assistantCoach.Print();\n   cout << endl;\n   return;\n}\n```\n\n`main.cpp`\n\n```cpp\n#include <iostream>\nusing namespace std;\n\n#include \"SoccerTeam.h\"\n#include \"TeamPerson.h\"\n\nint main() {\n   SoccerTeam teamCalifornia;\n   TeamPerson headCoach;\n   TeamPerson asstCoach;\n\n   headCoach.SetFullName(\"Mark Miwerds\");\n   headCoach.SetAgeYears(42);\n   teamCalifornia.SetHeadCoach(headCoach);\n\n   asstCoach.SetFullName(\"Stanley Lee\");\n   asstCoach.SetAgeYears(30);\n   teamCalifornia.SetAssistantCoach(asstCoach);\n\n   teamCalifornia.Print();\n\n   return 0;\n}\n```\n","n":0.072}}},{"i":859,"$":{"0":{"v":"Operator Overloading","n":0.707},"1":{"v":"\n\n## Operator Overloading\n\nRelated:\n\n- [[s.l.cpp.polymorphism]]\n\nIf you have 2 integers and you add them with `+` then you used the `+` operator. If you want to add 2 private data members that are part of a class that are comprised of multiple parts, the `+` operator is not able to handle this unless we overload it:\n\n```cpp\nTimeHrMn time1(3, 22);\nTimeHrMn time2(2, 50);\nTimeHrMn timeTot;\n\ntimeTot = time1 + time2;\ntimeTot.Print();\n\n//#> H:5, M:72\n```\n\n> The + operator was somehow redefined to add TimeHrMn objects' hours and minutes fields separately (3 + 2 is 5, 22 + 50 is 72), leading to simple readable code.\n> .\n> Although `+` requires left and right operands as in `time1 + time2`, the member function only requires the <u>right operand</u> (rhs: right-hand-side) as the parameter, <u>because the left operand is the calling object</u>. In other words, `time1 + time2` is equivalent to the function call `time1.operator+(time2)`, which is valid syntax but almost never used.\n\n```cpp\n\n#include <iostream>\nusing namespace std;\n\nclass TimeHrMn {\npublic:\n   TimeHrMn(int timeHours = 0, int timeMinutes = 0);\n   void Print() const;\n   TimeHrMn operator+(TimeHrMn rhs) ; // Overloaded `+` operator\nprivate:\n   int hours;\n   int minutes;\n};\n\n// Overload + operator for TimeHrMn\nTimeHrMn TimeHrMn::operator+(TimeHrMn rhs) { // Definition of overload\n   TimeHrMn timeTotal;\n   \n   timeTotal.hours   = hours   + rhs.hours;\n   timeTotal.minutes = minutes + rhs.minutes;\n   \n   return timeTotal;\n}\n\nTimeHrMn::TimeHrMn(int timeHours, int timeMinutes) {\n   hours  = timeHours;\n   minutes = timeMinutes;\n   \n   return;\n}\n\nvoid TimeHrMn::Print() const {\n   cout << \"H:\" << hours << \", \" << \"M:\" << minutes << endl;\n   \n   return;\n}\n\nint main() {\n   TimeHrMn time1(3, 22);\n   TimeHrMn time2(2, 50);\n   TimeHrMn timeTot;\n   \n   timeTot = time1 + time2; // Implementation of overloaded operator\n   timeTot.Print();\n   \n   return 0;\n}\n```\n\n> When an operator like `+` has been overloaded, the compiler determines which `+` operation to invoke based on the operand types. In `4 + 9`, the compiler sees two integer operands and thus applies the built-in `+` operation. In `time1 + time2`, where `time1` and `time2` are `TimeHrMn` objects, the compiler sees two `TimeHrMn` operands and thus invokes the programmer-defined function.\n> .\n> A programmer can define several functions that overload the same operator, as long as each involves different types so that the compiler can determine which to invoke.\n\n```cpp\n#include <iostream>\nusing namespace std;\n\nclass TimeHrMn {\npublic:\n   TimeHrMn(int timeHours = 0, int timeMinutes = 0);\n   void Print() const;\n   TimeHrMn operator+(TimeHrMn rhs);\n   TimeHrMn operator+(int rhsHours);\nprivate:\n   int hours;\n   int minutes;\n};\n\n// Operands: TimeHrMn, TimeHrMn. Call this \"A\"\nTimeHrMn TimeHrMn::operator+(TimeHrMn rhs) {\n   TimeHrMn timeTotal;\n   \n   timeTotal.hours   = hours   + rhs.hours;\n   timeTotal.minutes = minutes + rhs.minutes;\n   \n   return timeTotal;\n}\n\n// Operands: TimeHrMn, int. Call this \"B\"\nTimeHrMn TimeHrMn::operator+(int rhsHours) {\n   TimeHrMn timeTotal;\n   \n   timeTotal.hours = hours + rhsHours;\n   timeTotal.minutes = minutes; // Stays same\n   \n   return timeTotal;\n}\n\nTimeHrMn::TimeHrMn(int timeHours, int timeMinutes) {\n   hours  = timeHours;\n   minutes = timeMinutes;\n   \n   return;\n}\n\nvoid TimeHrMn::Print() const {\n   cout << \"H:\" << hours << \", \" << \"M:\" << minutes << endl;\n   \n   return;\n}\n\nint main() {\n   TimeHrMn time1(3, 22);\n   TimeHrMn time2(2, 50);\n   TimeHrMn timeTot;\n   int num = 91;\n   \n   timeTot = time1 + time2; // Invokes \"A\"\n   timeTot.Print();\n   \n   timeTot = time1 + 10;    // Invokes \"B\"\n   timeTot.Print();\n   \n   cout << num + 8 << endl; // Invokes built-in add\n   \n   // timeTot = 10 + time1; // ERROR: No (int, TimeHrMn)\n   \n   return 0;\n}\n```\n","n":0.044}}},{"i":860,"$":{"0":{"v":"Member Functions","n":0.707},"1":{"v":"\n\nA member function is a [[C++ Functions|s.l.cpp.funcs]] that is a _member_ of a class.\n\nTypically these are `public` functions so that the user can call them as methods of the class instances. There are however private member functions that do some work in the background that the user doesn't even know exist.\n","n":0.14}}},{"i":861,"$":{"0":{"v":"Scope Resolution Operator","n":0.577},"1":{"v":"\n\n## Scope Resolution Operator\n\nin the class we may declare member functions but if there is a lot of logic we don't want to crowd the class so we may take advantage of the `Scope Resolution Operator`: `::`. Similar to how `R` code uses `::` to access functions from specific packages. We do this by putting a Functions in the class declaration and then the Functions below which houses all the logic:\n\n```cpp\nvoid   SetTime(int timeRunSecs);       // Time run in seconds\n\n}; // end of the class declaration\n\n// \"RunnerInfo::\" means SetTime is a RunnerInfo member function\nvoid RunnerInfo::SetTime(int timeRunSecs) {\n   timeRun = timeRunSecs;  // timeRun refers to data member\n   return;\n}\n```\n\nIf a member function has the word `const` after its declaration like: \n\n```cpp\ndouble GetSpeedMph() const;            // Speed in miles/hour\n```\n\nfrom the Example above, then this means that this member function cannot change the value of any data member or else an error is thrown.\n","n":0.082}}},{"i":862,"$":{"0":{"v":"Mutators Accessors and Private Helpers","n":0.447},"1":{"v":"\n\n## Mutators, Accessors, and Private Helpers\n\n> Commonly, a data member has a pair of associated functions: a mutator for setting its value, and an accessor for getting its value, as above. Those functions are also known as a **setter** and **getter** functions, respectively, and typically have names that start with set or get.\n","n":0.137}}},{"i":863,"$":{"0":{"v":"Private Helpers","n":0.707},"1":{"v":"\n\n### Private Helpers\n\nThese are private functions that are used in the background to carry out tasks. The user will not be able access the functions at all, to the users these functions do not exist.\n\n```cpp\nprivate:\n\tint MaxOfPair(int num1, int num2) const; // Private helper fct\n```\n","n":0.151}}},{"i":864,"$":{"0":{"v":"Mutators","n":1},"1":{"v":"\n\n### Mutators\n\nModify / 'Mutate' the data members of a class (a setter, it sets the value of a data member by changing it)\n\n```cpp\n// Public member function. Setter / Mutator\npublic:\n\tvoid SetPlayer1PlayA(int playScore); // Mutator\n\n// Private data member that users cant access\nprivate:\n\tint player1PlayA;\n\n// Function definition, get input value and set private data member\n// value equal to that input\nvoid GameInfo::SetPlayer1PlayA(int playScore) {\n   player1PlayA = playScore;\n}\n```\n","n":0.127}}},{"i":865,"$":{"0":{"v":"Example","n":1},"1":{"v":"\n\n### Example\n\n```cpp\n#include <iostream>\nusing namespace std;\n\nclass GameInfo {\n   public:\n      void SetPlayer1PlayA(int playScore); // Mutator\n      void SetPlayer1PlayB(int playScore); // Mutator\n      void SetPlayer2PlayA(int playScore); // Mutator\n      void SetPlayer2PlayB(int playScore); // Mutator\n\n      int  GetPlayer1PlayA() const;        // Accessor\n      int  GetPlayer1PlayB() const;        // Accessor\n      int  GetPlayer2PlayA() const;        // Accessor\n      int  GetPlayer2PlayB() const;        // Accessor\n\n      int  GetPlayer1HighScore() const;    // Accessor\n      int  GetPlayer2HighScore() const;    // Accessor\n\n   private:\n      int player1PlayA;\n      int player1PlayB;\n      int player2PlayA;\n      int player2PlayB;\n      int MaxOfPair(int num1, int num2) const; // Private helper fct\n};\n\nvoid GameInfo::SetPlayer1PlayA(int playScore) {\n   player1PlayA = playScore;\n}\n\nvoid GameInfo::SetPlayer1PlayB(int playScore) {\n   player1PlayB = playScore;\n}\n\nvoid GameInfo::SetPlayer2PlayA(int playScore) {\n   player2PlayA = playScore;\n}\n\nvoid GameInfo::SetPlayer2PlayB(int playScore) {\n   player2PlayB = playScore;\n}\n\nint  GameInfo::GetPlayer1PlayA() const {\n   return player1PlayA;\n}\n\nint  GameInfo::GetPlayer1PlayB() const {\n   return player1PlayB;\n}\n\nint  GameInfo::GetPlayer2PlayA() const {\n   return player2PlayA;\n}\n\nint  GameInfo::GetPlayer2PlayB() const {\n   return player2PlayB;\n}\n\nint GameInfo::GetPlayer1HighScore() const {\n   return MaxOfPair(player1PlayA, player1PlayB);\n}\n\nint GameInfo::GetPlayer2HighScore() const {\n   return MaxOfPair(player2PlayA, player2PlayB);\n}\n\nint GameInfo::MaxOfPair(int num1, int num2) const {\n   if (num1 > num2) {\n      return num1;\n   }\n   else {\n      return num2;\n   }\n}\n\nint main() {\n   GameInfo funGame;\n\n   funGame.SetPlayer1PlayA(88);\n   funGame.SetPlayer1PlayB(97);\n   funGame.SetPlayer2PlayA(74);\n   funGame.SetPlayer2PlayB(40);\n\n   cout << \"Player1 playA: \" << funGame.GetPlayer1PlayA() << endl;\n\n   cout << \"Player1 max: \" << funGame.GetPlayer1HighScore() << endl;\n   cout << \"Player2 max: \" << funGame.GetPlayer2HighScore() << endl;\n\n   return 0;\n}\n```\n","n":0.073}}},{"i":866,"$":{"0":{"v":"Accessors","n":1},"1":{"v":"\n\n### Accessors\n\nAccessors can let the user access the values of the private data members:\n\n> Accessor functions usually are defined as const, to enforce that they do not change data members. The keyword **const** after a member function's declaration and definition causes the compiler to report an error if the function modifies a data member. **<u>If a const member function calls another member function, that function must also be const.</u>**\n\n```cpp\nint  GetPlayer1PlayA() const;        // Accessor\nint  GameInfo::GetPlayer1PlayA() const {\n   return player1PlayA;\n}\n```\n","n":0.113}}},{"i":867,"$":{"0":{"v":"Member Access Operator","n":0.577},"1":{"v":"\n\n## Member Access Operator\n\nThese function use the `.` operator known as the `Member Access Operator` which is typical dot notation of `class.method();`\n\nTypically the class will have `getter` and `setter` functions some to set the values of the private data members to the value of inputted data, and others to output that data for the user to use.\n","n":0.132}}},{"i":868,"$":{"0":{"v":"Inline Member Function","n":0.577},"1":{"v":"\n\n## Inline Member Functions\n\nUnlike the example you can put all the code for a member function in the class declaration. this is called an Inline Member Function, because the function is in the class declaration.\n\n```cpp\nclass RunnerInfo {\n   public:\n      void   SetTime(int timeRunSecs) { // Here is the inline function\n         timeRun = timeRunSecs;\n      }\n      void   SetDist(double distRunMiles);\n      double GetSpeedMph() const;\n   private:\n      int    timeRun;\n      double distRun;\n};\n\nvoid RunnerInfo::SetDist(double distRunMiles) {\n   distRun = distRunMiles;\n\n   return;\n}\n```\n","n":0.12}}},{"i":869,"$":{"0":{"v":"Example","n":1},"1":{"v":"\n\n# Example\n\n```cpp\n#include <iostream>\nusing namespace std;\n\nclass RunnerInfo {\n   public:                                // The class' public functions\n      void   SetTime(int timeRunSecs);       // Time run in seconds\n      void   SetDist(double distRunMiles);   // Distance run in miles\n      double GetSpeedMph() const;            // Speed in miles/hour\n   private:  // The class' private internal data members\n      int    timeRun;\n      double distRun;\n};\n\n// \"RunnerInfo::\" means SetTime is a RunnerInfo member function\nvoid RunnerInfo::SetTime(int timeRunSecs) {\n   timeRun = timeRunSecs;  // timeRun refers to data member\n   return;\n}\n\nvoid RunnerInfo::SetDist(double distRunMiles) {\n   distRun = distRunMiles;\n   return;\n}\n\ndouble RunnerInfo::GetSpeedMph() const {\n   return distRun / (timeRun / 3600.0); // miles / (secs / (hrs / 3600 secs))\n}\n\nint main() {\n   RunnerInfo runner1; // User-created object of class type RunnerInfo\n   RunnerInfo runner2; // A second object\n\n   runner1.SetTime(360);\n   runner1.SetDist(1.2);\n\n   runner2.SetTime(200);\n   runner2.SetDist(0.5);\n\n   cout << \"Runner1's speed in MPH: \" << runner1.GetSpeedMph() << endl;\n   cout << \"Runner2's speed in MPH: \" << runner2.GetSpeedMph() << endl;\n\n   return 0;\n}\n```\n\n```cpp\nclass ClassName {\n  public:\n      // Public member functions\n   private:\n      // Private data members\n};\n```\n","n":0.081}}},{"i":870,"$":{"0":{"v":"Derived Classes","n":0.707},"1":{"v":"\n\n> Commonly, one class is similar to another class but with some additions or variations. For example, a store inventory system might use a class called GenericItem having itemName and itemQuantity members. But for produce (fruits and vegetables), a class ProduceItem having itemName, itemQuantity, and expirationDate members may be desired. Note that ProduceItem is really a GenericItem with an additional feature, so ideally a program could define the ProduceItem class as being the same as the GenericItem class but with the addition of an expirationDate member.\n","n":0.108}}},{"i":871,"$":{"0":{"v":"Data Management","n":0.707},"1":{"v":"\n\n## Data management best practices\n\nThe best practice is to make all data members in a class private.\n\nif a data member is declared but is not under a specific label of `public:` or `private:` then the default is **private**. The opposite is true in [[Structs|s.l.cpp.data-s.structs]].\n","n":0.151}}},{"i":872,"$":{"0":{"v":"Constructors","n":1},"1":{"v":"\n\nConstructors initialize instances of a class. A best practice is to initialize all variables when declared (likely to keep them in the same memory location on the stack). \n\nConstructors share the same name as the class name:\n\n```cpp\n#include <iostream>\n#include <string>\nusing namespace std;\n\n/*** ShopItem class definition ***/\nclass ShopItem {\npublic:\n   void SetNameAndPrice(string itemName, int itemPrice);\n   void Print() const;\n   ShopItem();  // Default constructor\n   \nprivate:\n   string name;  // Ex: \"Bag of salad\"\n   int    price; // Price in cents. Ex: 199\n};\n\nShopItem::ShopItem() {  // Default constructor\n   name  = \"NoName\";    // Default name\n   price = -1;          // Default price\n   \n   return;\n}\n\nvoid ShopItem::SetNameAndPrice(string itemName, int itemPrice) {\n   name  = itemName;\n   price = itemPrice;\n   \n   return;\n}\n\nvoid ShopItem::Print() const {\n   cout << \"Name: \"  << name  << \", \";\n   cout << \"Price: \" << price << endl;\n   \n   return;\n}\n\n/*** End definitions for ShopItem class ***/\n\nint main() {\n   ShopItem item1;  // Auto-calls default constructor\n   \n   item1.Print();\n   \n   item1.SetNameAndPrice(\"Soap\", 385);\n   item1.Print();\n   \n   return 0;\n}\n```\n","n":0.081}}},{"i":873,"$":{"0":{"v":"Member Initialization","n":0.707},"1":{"v":"\n\n## Constructor Member Initialization\n\n```cpp\n// Given\n\nclass SampleClass {\n   public:\n      SampleClass();\n      void Print() const;\n\n   private:\n      int field1;\n      int field2;\n};\n\n// Instead of this:\n\nSampleClass::SampleClass() {\n   field1 = 100;\n   field2 = 200;\n\n   return;\n}\n\n// You can do this:\n\nSampleClass::SampleClass() : field1(100), field2(200) {\n   return;\n}\n```\n\nThis is not particularly useful for members of basic types, but for data members like [[C++ Arrays and Vectors|vectors]] that need to be explicitly constructed with a size, this can be very useful:\n\n```cpp\nclass SampleClass {\n   public:\n      SampleClass();\n      void Print() const;\n\n   private:\n      vector<int> itemList; \n      // vector<int> itemList(2);  not allowed\n};\n\nSampleClass::SampleClass() : itemList(2) {\n   // itemList gets constructed with size 2\n   return;\n}\n```\n","n":0.102}}},{"i":874,"$":{"0":{"v":"Constructor Overloading","n":0.707},"1":{"v":"\n\n## Constructor Overloading\n\nJust like with  [[C++ Polymorphism|c++-polymorphism#Function Name Overloading]] you can overload a constructor to instantiate the same object (class) with different initialization values based on the parameters passed to the constructor:\n\n```cpp\nclass Seat {\n   public:\n      ...\n   Seat(); // Default constructor\n   Seat(string resfirstName, string resLastName, int resAmountPaid); // Second constructor\n      ...\n};\n\nSeat::Seat() { // Default constructor\n   firstName  = \"none\";\n   lastName   = \"none\";\n   amountPaid = -1;\n}\n\nSeat::Seat(string resfirstName, string resLastName, int resAmountPaid) { // Second constructor\n   firstName  = resfirstName;\n   lastName   = resLastName;\n   amountPaid = resAmountPaid;\n}\n```\n","n":0.111}}},{"i":875,"$":{"0":{"v":"Classes with Vectors","n":0.577},"1":{"v":"\n\n## Classes with vectors\n\n### Example\n\n```cpp\n#include <iostream>\n#include <vector>\n#include <string>\nusing namespace std;\n\n/*** Seat class definition ***/\nclass Seat {\npublic:\n   void Reserve(string resfirstName, string resLastName, int resAmountPaid);\n   void MakeEmpty();\n   bool IsEmpty() const;\n   void Print() const;\n   \nprivate:\n   string firstName;\n   string lastName;\n   int    amountPaid;\n};\n\nvoid Seat::Reserve(string resfirstName, string resLastName, int resAmountPaid) {\n   firstName  = resfirstName;\n   lastName   = resLastName;\n   amountPaid = resAmountPaid;\n   \n   return;\n}\n\nvoid Seat::MakeEmpty() {\n   firstName  = \"empty\";\n   lastName   = \"empty\";\n   amountPaid = 0;\n   \n   return;\n}\n\nbool Seat::IsEmpty() const {\n   return(firstName == \"empty\");\n}\n\nvoid Seat::Print() const {\n   cout << firstName << \" \" << lastName  << \", \";\n   cout << \"Paid: \"  << amountPaid << endl;\n   \n   return;\n}\n/*** End definitions for Seat class ***/\n\n\n/*** Functions for vector of Seat objects ***/\nvoid SeatsMakeEmpty(vector<Seat>& seats) {\n   unsigned int i = 0;\n   \n   for (i = 0; i < seats.size(); ++i) {\n      seats.at(i).MakeEmpty();\n   }\n   \n   return;\n}\n\nvoid SeatsPrint(vector<Seat> seats) {\n   unsigned int i = 0;\n   \n   for (i = 0; i < seats.size(); ++i) {\n      cout << i << \": \";\n      seats.at(i).Print();\n   }\n   \n   return;\n}\n\nvoid SeatsCreateReservation(vector<Seat>& seats) {\n   string firstName, lastName;\n   int amountPaid = 0;\n   unsigned int seatNum = 0;\n   Seat seat;\n   \n   cout << \"Enter seat number (0..\";\n   cout << seats.size() - 1 << \"): \";\n   cin  >> seatNum;\n   \n   if (seatNum > (seats.size() - 1)) {\n      cout << \"Seat number too large.\" << endl;\n   }\n   else if ( !(seats.at(seatNum).IsEmpty()) ) {\n      cout << \"Seat already occupied.\" << endl;\n   }\n   else {\n      cout << \"Enter first name: \";\n      cin >> firstName;\n      cout << \"Enter last name: \";\n      cin >> lastName;\n      cout << \"Enter amount paid: \";\n      cin >> amountPaid;\n      \n      seat.Reserve(firstName, lastName, amountPaid);\n      seats.at(seatNum) = seat;\n      \n      cout << \"Completed.\" << endl;\n   }\n   \n   return;\n}\n/*** End functions for vector of Seat objs ***/\n\nint main() {\n   char   userKey = '-';\n   vector<Seat> seats(5);\n   \n   SeatsMakeEmpty(seats);\n   \n   while (userKey != 'q') {\n      cout << endl << \"Enter command (p/r/q): \";\n      cin >> userKey;\n      \n      if (userKey == 'p') { // Print seats\n         SeatsPrint(seats);\n      }\n      else if (userKey == 'r') { // Reserve seat\n         SeatsCreateReservation(seats);\n      }\n      else if (userKey == 'q') { // Quit\n         cout << \"Quitting.\" << endl;\n      }\n      else {\n         cout << \"Invalid command.\" << endl;\n      }\n   }\n   \n   return 0;\n}\n```\n","n":0.053}}},{"i":876,"$":{"0":{"v":"Mem Mgmt","n":0.707}}},{"i":877,"$":{"0":{"v":"Pointers","n":1},"1":{"v":"\n\n## Pointers in C++\n\n> A **pointer** is a variable that contains a memory address, rather than containing data like most variables\n\n## Example\n\n```cpp\n#include <iostream>\nusing namespace std;\n\nint main() {\n   int usrInt = 0; // User defined int value\n   int* myPtr = nullptr; // Pointer to the user defined int value\n   \n   // Prompt user for input\n   cout << \"Enter any number: \";\n   cin >> usrInt;\n   \n   // Output int value and address\n   cout << \"We wrote your number into variable usrInt.\" << endl;\n   cout << \"The content of usrInt is: \" << usrInt << \".\" << endl;\n   cout << \"usrInt's memory address is: \" << &usrInt << \".\" << endl;\n   cout << endl << \"We can store that address into pointer variable myPtr.\"\n        << endl;\n   \n   // Grab address storing user value\n   myPtr = &usrInt;\n   \n   // Output pointer value and value at pointer address\n   cout << \"The content of myPtr is: \" << myPtr << \".\" << endl;\n   cout << \"The content of what myPtr points to is: \"\n        << *myPtr << \".\" << endl;\n   \n   return 0;\n}\n```\n","n":0.075}}},{"i":878,"$":{"0":{"v":"Using Pointers","n":0.707},"1":{"v":"\n\n## Using Pointers Example\n\n```cpp\n#include <iostream>\nusing namespace std;\n\nint main() {\n   double vehicleMpg = 0.0;\n   double* valPtr = nullptr;\n   \n   valPtr = &vehicleMpg;\n   \n   *valPtr = 29.6; // Assigns the number to the variable\n                   // POINTED TO by valPtr.\n   \n   // vehicleMpg = 40;   // Uncomment this later\n   \n   cout << \"Vehicle MPG = \" << vehicleMpg << endl;\n   cout << \"Vehicle MPG = \" << *valPtr << endl;\n   \n   return 0;\n}\n```\n","n":0.12}}},{"i":879,"$":{"0":{"v":"Symbol Usage","n":0.707}}},{"i":880,"$":{"0":{"v":"Pointer Variables","n":0.707},"1":{"v":"\n\n### Pointer Variables\n\n> Appending `*` after a data type in a variable declaration declares a pointer variable, as in `int* myPtr`. One might imagine that the programming language would have a type like address in addition to types like int, char, etc., but instead the language requires each pointer variable to indicate the type of data to which the address points. So valid pointer variable declarations are `int* myPtr1`, `char* myPtr2`, `double* myPtr3`, and even `Seat* myPtr4;` (where Seat is a class type); all such variables will contain memory addresses.\n\n```cpp\nint* myInt;\n```\n","n":0.105}}},{"i":881,"$":{"0":{"v":"Null Pointer","n":0.707},"1":{"v":"\n\n### Null Pointer\n\n> The pointer was initialized to **`nullptr`**. The `nullptr` keyword is a literal indicating a pointer points to nothing. A pointer assigned with `nullptr` is said to be null.\n","n":0.18}}},{"i":882,"$":{"0":{"v":"Get Memory Address","n":0.577},"1":{"v":"\n\n### Get Memory Address\n\n> Prepending `&` to any variable's name gets the variable's address. `&` is the reference operator that returns a pointer to a variable using the following form:\n\n```cpp\n&myInt;\n```\n","n":0.183}}},{"i":883,"$":{"0":{"v":"Dereferencing a Pointer","n":0.577},"1":{"v":"\n\n### Dereferencing a Pointer\n\n> Prepending `*` to a pointer variable's name in an expression gets the data to which the variable points, as in `*myPtr1`, an act known as **dereferencing** a pointer variable. `*` is the dereference operator that allows the program to access the value pointed to by the pointer using the form:\n\n```cpp\n*myInt;\n```\n","n":0.136}}},{"i":884,"$":{"0":{"v":"Operators","n":1}}},{"i":885,"$":{"0":{"v":"New","n":1},"1":{"v":"\n\n### The 'New' Operator\n\n> Sometimes memory should be allocated while a program is running and should persist independently of any particular function. The **new** operator allocates memory for the given type and returns a pointer (i.e., the address) to that allocated memory.\n\n```cpp\n\n#include <iostream>\nusing namespace std;\n\nint main() {\n   int* myPtr = nullptr;\n   cout << \"myPtr: \"  << myPtr << endl;\n   \n   // Next line would cause error because myPtr is null\n   // cout << \"*myPtr: \" << *myPtr << endl; // ERROR\n   \n   // new allocates int, returns pointer\n   myPtr = new int; \n   cout << \"myPtr: \"  << myPtr << endl;\n   cout << \"*myPtr: \" << *myPtr << endl;\n   \n   *myPtr = 555;\n   cout << \"*myPtr: \" << *myPtr << endl;\n   \n   return 0;\n}\n```\n\n> The new operator is commonly used with class types, as in `new SimpleItem;` where `SimpleItem` is a class name. After new allocates memory for a class object, the object's constructor is called. Arguments may be provided after the class name to call a non-default constructor.\n\n```cpp\n#include <iostream>\nusing namespace std;\n\nclass SimpleItem {\npublic:\n   void PrintNums();\n   SimpleItem(int initVa1 = -1, int initVal2 = -1);\nprivate:\n   int num1;\n   int num2;\n};\n\nSimpleItem::SimpleItem(int initVal1, int initVal2) {\n   num1 = initVal1;\n   num2 = initVal2;\n\n   return;\n}\n\nvoid SimpleItem::PrintNums() {\n   cout << \"num1: \" << num1 << endl;\n   cout << \"num2: \" << num2 << endl;\n\n   return;\n}\n\nint main() {\n   SimpleItem* myItemPtr1 = nullptr;\n   SimpleItem* myItemPtr2 = nullptr;\n   \n   myItemPtr1 = new SimpleItem;\n   (*myItemPtr1).PrintNums();\n   cout << endl;\n   \n   myItemPtr2 = new SimpleItem(8, 9);\n   (*myItemPtr2).PrintNums();\n   \n   return 0;\n}\n```\n","n":0.064}}},{"i":886,"$":{"0":{"v":"Delete","n":1},"1":{"v":"\n\n### The 'delete' Operator\n\n> The **delete** operator does the opposite of the new operator. The statement `delete pointerVariable`; deallocates a memory block pointed to by pointerVariable, which must have been previously allocated by new. If pointerVariable is null, delete has no effect.\n\n```cpp\nnew pointerVariable;\ndelete pointerVariable;\n```\n","n":0.151}}},{"i":887,"$":{"0":{"v":"Memory Regions","n":0.707},"1":{"v":"\n\n## Static Memory\n\n> The region where global variables (_variables declared outside any function_) as well as static local variables (_variables declared inside functions starting with the keyword \"static\"_) are allocated. The name \"static\" comes from these variables not changing (_static means not changing_); they are allocated once and last for the duration of a program's execution, their addresses staying the same.\n\n## The Stack\n\n> The region where a function's local variables are allocated <u>during a function call</u>. A function call adds local variables to the stack, and a return removes them, like adding and removing dishes from a pile; hence the term \"_stack_.\" Because this memory is automatically allocated and deallocated, it is also called **automatic memory**.\n\n## The Heap\n\n> The region where the \"_new_\" operator allocates memory, and where the \"_delete_\" operator deallocates memory. The region is also called **free store**.\n","n":0.085}}},{"i":888,"$":{"0":{"v":"Libs","n":1}}},{"i":889,"$":{"0":{"v":"Vector","n":1},"1":{"v":"\n\n## Site Definition\n\n[vector](http://cplusplus.com/reference/vector/vector/)\n\n> Vectors are sequence containers representing arrays that can change in size. \n> .\n> Just like arrays, vectors use contiguous storage locations for their elements, which means that their elements can also be accessed using offsets on regular pointers to its elements, and just as efficiently as in arrays. But unlike arrays, their size can change dynamically, with their storage being handled automatically by the container.\n","n":0.121}}},{"i":890,"$":{"0":{"v":"Modification","n":1}}},{"i":891,"$":{"0":{"v":"Vector Equality","n":0.707},"1":{"v":"\n\n### Vector Equality\n\nin the above example in [[import.software.language.cpp.include-vector#Vector copying]], if one were to change the values in some of the elements in `salePrices` and then perform an equality check `==` then the vector will compare element to element through the whole vector and return a boolean result.\n\n```cpp\n// Update salePrices. Note: does not affect origPrices\nsalePrices.at(2) = 27;\nsalePrices.at(3) = 35;\n\nsalePrices == origPrices; // because of above they are no longer equal\n\t\t\t\t\t\t  // or identical, result is false\n```\n","n":0.115}}},{"i":892,"$":{"0":{"v":"Vector Copying","n":0.707},"1":{"v":"\n\n### Vector copying\n\nIn this example `salePrices = origPrices;`\n\n```cpp\n\nconst int   NUM_ELEMENTS = 4;         // Number of elements\nvector<int> origPrices(NUM_ELEMENTS); // Original prices\nvector<int> salePrices(NUM_ELEMENTS); // Sale prices\nint i = 0;                            // Loop index\n\n// Assign original prices\norigPrices.at(0) = 10;\norigPrices.at(1) = 20;\norigPrices.at(2) = 30;\norigPrices.at(3) = 40;\n\n// Copy original prices to sales prices\n\nsalePrices = origPrices;\n```\n\nvector `salePrices` is empty and of size 0 until it copies every element in `origPrices`. This is a complete duplication and takes up twice the memory.\n","n":0.116}}},{"i":893,"$":{"0":{"v":"Member Functions","n":0.707},"1":{"v":"\n\n## Vector Member Functions\n","n":0.5}}},{"i":894,"$":{"0":{"v":"Modifiers","n":1}}},{"i":895,"$":{"0":{"v":"Push Back","n":0.707},"1":{"v":"\n\n#### push_back()\n\njust like `push()` in Javascript for vectors you are adding a new element to the vector and therefore creating a single new index. \n\n```cpp\n// playersList initially 55, 99, 44      (size is 3)\n\nplayersList.push_back(77); // Appends new element, sets value to 77 \n\n// playersList is now    55, 99, 44, 77  (size is 4)\n```\n","n":0.139}}},{"i":896,"$":{"0":{"v":"Pop Back","n":0.707},"1":{"v":"\n\n#### pop_back()\n\nJust like `pop()` in Javascript, this removes the last element from the vector. \n\n```cpp\n// playersList is 55, 99, 44 (size 3)\n\nplayersList.pop_back();     // Removes last element\n\n// playersList now 55, 99    (size 2)\n\ncout << playersList.back(); // Common combination of back() \n\nplayersList.pop_back();     // followed by pop_back()\n\n// Prints 99. playersList becomes just 55\n\ncout << playersList.pop_back(); // Common error \n                                // pop_back() returns void\n```\n","n":0.129}}},{"i":897,"$":{"0":{"v":"Element Access","n":0.707}}},{"i":898,"$":{"0":{"v":"Back","n":1},"1":{"v":"\n\n#### back()\n\nBasically asks _\"Hey, whats the item at the end? i don't know the index but that's the last value??\"_\n\n```cpp\n// playersList initially 55, 99, 44\n\ncout << playersList.back(); // Prints 44 \n\n// playersList is still  55, 99, 44\n```\n","n":0.164}}},{"i":899,"$":{"0":{"v":"At","n":1},"1":{"v":"\n\n#### at()\n\nReturns the value at the index number given like the traditional array syntax:\n\n```cpp\nvector.at(1) == array[1]; // True\n```\n\nyou can even use the array syntax on the vector although `.at()` is recommended due to superior error checking just like strings:\n","n":0.16}}},{"i":900,"$":{"0":{"v":"Capacity","n":1},"1":{"v":"\n\n### Capacity\n\n","n":0.707}}},{"i":901,"$":{"0":{"v":"Resize","n":1},"1":{"v":"\n\n#### resize()\n\nTo dynamically resize a vector while program is executing and size is not known during compile time.\n\n```cpp\nvctr.resize(N);  // Allocates N elements for vector vctr.\n```\n\nresize is now adding new slots on top of existing elements, rather it just states that _\"THIS is how many elements are in this vector\"_. If the resize value is smaller than the vectors current size, all elements in indexes larger than `N` are destroyed and `N` is now the size of the vector.\n","n":0.113}}},{"i":902,"$":{"0":{"v":"Time","n":1},"1":{"v":"\n\n## C Time Library\n\n[\\\\&lt;ctime>](http://cplusplus.com/reference/ctime/)\n\n## Time Manipulation\n\n### time\n\n[time()](http://cplusplus.com/reference/ctime/time/)\n\n> The value returned generally represents the number of seconds since 00:00 hours, Jan 1, 1970 UTC (i.e., the current unix timestamp). Although libraries may use a different representation of time: Portable programs should not use the value returned by this function directly, but always rely on calls to other elements of the standard library to translate them to portable types (such as `localtime`, `gmtime` or `difftime`).\n\n```cpp\ntime(0)\n```\n","n":0.117}}},{"i":903,"$":{"0":{"v":"String","n":1},"1":{"v":"\n\n## The String Library\n\n[\\\\&lt;string>](http://cplusplus.com/reference/string/string/)\n\n> Strings are objects that represent sequences of characters.\n\nThis library include the `string` class and this class has various methods that allow us to perform string manipulation.\n","n":0.183}}},{"i":904,"$":{"0":{"v":"String Operations","n":0.707}}},{"i":905,"$":{"0":{"v":"Sub String","n":0.707},"1":{"v":"\n\n### substr( index, len )\n\nReturns substring starting at index and having len characters.\n\n```cpp\n// userText is \"http://google.com\"\nuserText.substr(0, 7)                     // Returns \"http://\"\nuserText.substr(13, 4)                    // Returns \".com\"\nuserText.substr(userText.length() - 4, 4) // Last 4: \".com\"\n```\n","n":0.18}}},{"i":906,"$":{"0":{"v":"Find","n":1},"1":{"v":"\n\n### find( item, index )\n\nStarts at a 0 index and returns index position of your input. Optional 2nd argument can tell you which index to start at so as to skip the first occurrence of something.\n\n```cpp\n// userText is \"Help me!\"\nuserText.find('p')    // Returns 3 \nuserText.find('e')    // Returns 1 (first occurrence of e only) \nuserText.find('z')    // Returns string::npos \nuserText.find(\"me\")   // Returns 5\nuserText.find('e', 2) // Returns 6 (starts at index 2)\n```\n","n":0.121}}},{"i":907,"$":{"0":{"v":"Modifiers","n":1}}},{"i":908,"$":{"0":{"v":"Replace","n":1},"1":{"v":"\n\n### replace( index, num, subStr )\n\nReplaces characters at indices `index` to `index + num - 1` with a copy of `subStr`.\n\n```cpp\n// userText is \"You have many gifts\"\nuserText.replace(9, 4, \"a plethora of\"); \n// Now \"You have a plethora of gifts\"\n```\n","n":0.16}}},{"i":909,"$":{"0":{"v":"Push Back","n":0.707},"1":{"v":"\n\nAppends `newChar` to the end.\n\n_NOTE_ that the char has to be wrapped in single quotes as mentioned in [[C++ Variables and Datatypes#Character|char-data-type]]\n\n```cpp\n// userText is \"Hello\"\nuserText.push_back('?'); // Now \"Hello?\" \nuserText.length();       // Returns 6\n```\n","n":0.177}}},{"i":910,"$":{"0":{"v":"Insert","n":1},"1":{"v":"\n\n### insert( index, subStr )\n\nInserts string `subStr` starting at `index`.\n\n```cpp\n// userText is \"Goodbye\"\nuserText.insert(0, \"Well \"); // Now \"Well Goodbye\" \n// userText is \"Goodbye\"\nuserText.insert(4, \"---\");   // Now \"Good---bye\"\n```\n","n":0.192}}},{"i":911,"$":{"0":{"v":"Append","n":1},"1":{"v":"\n\n### append( moreString )\n\nAppends a copy of string `moreString`.\n\n```cpp\n// userText is \"Hi\"\nuserText.append(\" friend\"); // Now \"Hi friend\" \nuserText.length();          // Returns 9\n```\n","n":0.218}}},{"i":912,"$":{"0":{"v":"Element Access","n":0.707}}},{"i":913,"$":{"0":{"v":"At","n":1},"1":{"v":"\n\n> C++ also supports C-style access of a string using brackets \\[] rather than .at(), as in: someString[0]. However, such C-style access does not provide such error checking. Good practice is to use .at() rather than brackets for accessing a string's characters, due to .at()'s error checking.\n>\n> \\-- zybooks\n\n```cpp\nstring name = \"bryan\";\ncout << name.at(1) << endl;\n//#> r\n```\n","n":0.132}}},{"i":914,"$":{"0":{"v":"Capacity","n":1}}},{"i":915,"$":{"0":{"v":"Resize","n":1},"1":{"v":"\n\n### resize( num )\n\nResize string to have num characters. \nIf decrease, drops extra chars. \nIf increase, sets new chars to null ('\\\\0', ASCII value 0).\n\n```cpp\n// userText is \"Help me!\"\nuserText.resize(4); // Now \"Help\" \nuserText.size();    // Returns 4\n```\n","n":0.167}}},{"i":916,"$":{"0":{"v":"Length and Size","n":0.577},"1":{"v":"\n\n### length() & size()\n\nSame idea as `len()`\n\n```cpp\n// userText is \"Help me!\"\nuserText.length()  // Returns 8 \nuserText.size()    // Returns 8 \n// userText is \"\"\nuserText.length()  // Returns 0\n```\n","n":0.2}}},{"i":917,"$":{"0":{"v":"Empty","n":1},"1":{"v":"\n\n### empty()\n\nTrue is length is 0\n\n```cpp\n// userText is \"Help me!\"\nuserText.empty()   // Returns false\n// userText is \"\"\nuserText.empty()   // Returns true\n```\n","n":0.229}}},{"i":918,"$":{"0":{"v":"Clear","n":1},"1":{"v":"\n\n### clear()\n\nDeletes characters, sets size to 0.\n\n```cpp\n// userText is \"Help me!\"\nuserText.clear(); // Clears string \nuserText.size();  // Returns 0 \nuserText.at(0);   // Generates exception\n```\n","n":0.213}}},{"i":919,"$":{"0":{"v":"Iostream","n":1},"1":{"v":"\n\n## Streams\n\n- Refer to: [[s.l.cpp.streams]]\n- And Also: [[s.l.cpp.files]]\n","n":0.354}}},{"i":920,"$":{"0":{"v":"Cstring","n":1}}},{"i":921,"$":{"0":{"v":"Searching","n":1}}},{"i":922,"$":{"0":{"v":"Strchr","n":1},"1":{"v":"\n\n## strchr()\n\n`size_t strlen(sourceStr)`\n\nReturns number of characters in `sourceStr` up to, but not including, first null character. `size_t` is integer type.\n\n```cpp\n// Given:\nchar orgName[100] = \"United Nations\"; \nchar userText[20] = \"UNICEF\"; \nchar targetText[10];\n\nx = strlen(orgName);    // Assigns 14 to x \nx = strlen(userText);   // Assigns 6 to x\nx = strlen(targetText); // Error: targetText may lack null char\n```\n","n":0.135}}},{"i":923,"$":{"0":{"v":"Othe","n":1}}},{"i":924,"$":{"0":{"v":"Strlen","n":1},"1":{"v":"\n\n## strlen()\n\n`int strcmp(str1, str2)`\n\nReturns 0 if `str1` and `str2` are equal, non-zero if they differ.\n\n```cpp\n// Given:\nchar orgName[100] = \"United Nations\"; \nchar userText[20] = \"UNICEF\"; \nchar targetText[10];\n\nif (strcmp(orgName, \"United Nations\") == 0) {\n   ... // Equal, branch taken\n}\nif (strcmp(orgName, userText) == 0) {\n   ... // Not equal, branch not taken\n}\n```\n","n":0.143}}},{"i":925,"$":{"0":{"v":"Copying","n":1}}},{"i":926,"$":{"0":{"v":"Strncopy","n":1},"1":{"v":"\n\n## strncpy()\n\n`strncpy(destStr, sourceStr, numChars)`\n\n> Copies up to numChars characters.\t\n\n```cpp\nstrncpy(orgName, userText, 6); // orgName is \"UNICEF Nations\"\n```\n","n":0.25}}},{"i":927,"$":{"0":{"v":"Strcopy","n":1},"1":{"v":"\n\n## strcpy()\n\n`strcpy(destStr, sourceStr)`\n\n> Copies sourceStr (up to and including null character) to destStr.\t\n\n```cpp\nstrcpy(targetText, userText); // Copies \"UNICEF\" + null char \n                              // to targetText \nstrcpy(targetText, orgName);  // Error: \"United Nations\" \n                              // has > 10 chars\ntargetText = orgName;         // Error: Strings can't be \n                              // copied this way\n```\n","n":0.144}}},{"i":928,"$":{"0":{"v":"Concatenation","n":1}}},{"i":929,"$":{"0":{"v":"Strncat","n":1},"1":{"v":"\n\n## strncat()\n\n`strncat(destStr, sourceStr, numChars)`\n\n> Copies up to numChars characters to destStr's end, then appends null character.\t\n\n```cpp\nstrcpy(targetText, \"abc\"); \t\t\t // targetText is \"abc\"\nstrncat(targetText, \"123456789\", 3); // targetText is \"abc123\"\n```\n","n":0.189}}},{"i":930,"$":{"0":{"v":"Strcat","n":1},"1":{"v":"\n\n## strcat()\n\n`strcat(destStr, sourceStr)`\n\n> Copies sourceStr (up to and including null character) to end of destStr (starting at destStr's null character).\t\n\n```cpp\nstrcat(orgName, userText); // orgName is \"United NationsUNICEF\"\n```\n","n":0.196}}},{"i":931,"$":{"0":{"v":"Comparison","n":1}}},{"i":932,"$":{"0":{"v":"Strcmp","n":1},"1":{"v":"\n\n## strcmp()\n\n`strchr(sourceStr, searchChar)`\n\nReturns `NULL` if `searchChar` does not exist in `sourceStr`. (Else, returns address of first occurrence, discussed elsewhere).\n`NULL` is defined in the cstring library.\n\n```cpp\n// Given:\nchar orgName[100] = \"United Nations\"; \nchar userText[20] = \"UNICEF\"; \nchar targetText[10];\n\nif (strchr(orgName, 'U') != NULL) { // 'U' exists in orgName?\n   ...  // 'U' exists in \"United Nations\", branch taken\n}  \nif (strchr(orgName, 'u') != NULL) { // 'u' exists in orgName?\n   ...  // 'u' doesn't exist (case matters), branch not taken\n}\n```\n","n":0.115}}},{"i":933,"$":{"0":{"v":"Cstdlib","n":1},"1":{"v":"\n\n## C Standard Library\n\nThe [C Standard Library](http://cplusplus.com/reference/cstdlib/) contains many standard general utilities for `C`.\n\n```cpp\n#include <cstdlib>\n```\n","n":0.258}}},{"i":934,"$":{"0":{"v":"Srand","n":1},"1":{"v":"\n\n## srand\n\nThe pseudo-random number generator is initialized using the argument passed as seed.\n\nFor every different seed value used in a call to `srand`, the pseudo-random number generator can be expected to generate a different succession of results in the subsequent calls to `rand`.\n\nTwo different initializations with the same seed will generate the same succession of results in subsequent calls to `rand`.\n\nIf seed is set to 1, the generator is reinitialized to its initial value and produces the same values as before any call to rand or `srand`.\n\nIn order to generate random-like numbers, `srand` is usually initialized to some distinctive runtime value, like the value returned by function time (declared in header `<ctime>`). This is distinctive enough for most trivial randomization needs.\n\n```cpp\n#include <iostream>\n#include <cstdlib>\n#include <ctime>\n\nint main(int argc, const char * argv[]) {\n     printf (\"First number: %d\\n\", rand()%100);\n    \n     srand (time(0));\n    \n     printf (\"Random number: %d\\n\", rand()%100);\n     srand (1);\n     printf (\"Again the first number: %d\\n\", rand()%100);\n\n    return 0;\n}\n```\n","n":0.08}}},{"i":935,"$":{"0":{"v":"Rand","n":1},"1":{"v":"\n\n## rand\n\nReturns a pseudo-random integral number in the range between 0 and `RAND_MAX`.\n\nThis number is generated by an algorithm that returns a sequence of apparently non-related numbers each time it is called. This algorithm uses a seed to generate the series, which should be initialized to some distinctive value using function `srand`.\n\n`RAND_MAX` is a constant defined in `<cstdlib>`.\n\nA typical way to generate trivial pseudo-random numbers in a determined range using rand is to use the modulo of the returned value by the range span and add the initial value of the range:\n\n```cpp\nv1 = rand() % 100;         // v1 in the range 0 to 99\nv2 = rand() % 100 + 1;     // v2 in the range 1 to 100\nv3 = rand() % 30 + 1985;   // v3 in the range 1985-2014\n```\n","n":0.088}}},{"i":936,"$":{"0":{"v":"Cmath","n":1}}},{"i":937,"$":{"0":{"v":"Fabs","n":1},"1":{"v":"\n\n## fabs()\n\n```cpp\ndouble bodyTemp = 0.0;\n\ncout << \"Enter body temperature in Fahrenheit: \";\ncin >> bodyTemp;\n\nif (fabs(bodyTemp - 98.6) < 0.0001) {\n  cout << \"Temperature is exactly normal.\" << endl;\n} else if (bodyTemp > 98.6) {\n  cout << \"Temperature is above normal.\" << endl;\n} else {\n  cout << \"Temperature is below normal.\" << endl;\n}\n```\n","n":0.139}}},{"i":938,"$":{"0":{"v":"Cctype","n":1},"1":{"v":"\nüíªÔ∏è/C++\npublish: true\naliases:\n\n- null\n  cssclass: null\n  created: 2021-12-31 1945\n  updated: 2022-01-01 2151\n\n---\n\n---\n\n## The C Character Type Library\n\n> This header declares a set of functions to classify and transform individual characters.\n\n### isalpha( c )\n\ntrue if alphabetic: a-z or A-Z\n\n```cpp\nisalpha('x') // true\nisalpha('6') // false\nisalpha('!') // false\n```\n\n### isdigit( c )\n\ntrue if digit: 0-9.\n\n```cpp\nisdigit('x') // false\nisdigit('6') // true\n```\n\n### isalnum( c )\n\nReturns true if c is alphabetic or a numeric digit. Thus, returns true if either [[import.software.language.cpp.include-cctype#isalpha c]] or [[import.software.language.cpp.include-cctype#isdigit c]] would return true.\n\n### isspace( c )\n\ntrue if whitespace.\n\n```cpp\nisspace(' ')  // true\nisspace('\\n') // true\nisspace('x')  // false\n```\n\n### toupper( c )\n\nUppercase version\n\n```cpp\ntoupper('a')  // A\ntoupper('A')  // A\ntoupper('3')  // 3\n```\n\n### tolower( c )\n\nLowercase version \n\n```cpp\ntolower('A')  // a\ntolower('a')  // a\ntolower('3')  // 3\n```\n\n### isblank()\n\nReturns true if character c is a blank character. Blank characters include spaces and tabs.\n\n```cpp\nisblank(myString[5]); // Returns true because that character is a space ' '.\nisblank(myString[0]); // Returns false because 'H' is not blank.\n```\n\n### isxdigit()\n\nReturns true if c is a hexadecimal digit: 0-9, a-f, A-F.\n\n```cpp\nisxdigit(myString[3]); // Returns true because '9' is a hexadecimal digit.\nisxdigit(myString[1]); // Returns true because 'e' is a hexadecimal digit.\nisxdigit(myString[6]); // Returns false because 'G' is not a hexadecimal digit.\n```\n\n### ispunct()\n\nReturns true if c is a punctuation character. Punctuation characters include: `!\"#$%&'()*+,-./:;<=>?@[\\]^_{|}~`\n\n```cpp\nispunct(myString[4]); // Returns true because '!' is a punctuation character.\nispunct(myString[6]); // Returns false because 'G' is not a punctuation character.\n```\n\n### isprint()\n\nReturns true if c is a printable character. Printable characters include alphanumeric, punctuation, and space characters.\n\n### iscntrl()\n\n Returns true if c is a control character. Control characters are all characters that are not printable.\n\n---\n\n- ## Tags:\n- ## Reference:\n- ## Related:\n\n","n":0.063}}},{"i":939,"$":{"0":{"v":"Cassert","n":1},"1":{"v":"\n\n## cassert for Unit Testing\n\n`assert.h` defines one macro function that can be used as a standard debugging tool:\n\nSee: [[s.l.cpp.test.functions]]\n","n":0.229}}},{"i":940,"$":{"0":{"v":"Funcs","n":1}}},{"i":941,"$":{"0":{"v":"Return Type","n":0.707},"1":{"v":"\n\n### Return type\n\nBefore each function [[s.l.cpp.funcs#Declaration]] you must have a return type for that function. The return type is the data type for what is returned by the function. Most of the data types you will use are in [[C++ Variables and Datatypes|c++-variables-and-datatypes]] but one you will also use is `void` this is when the function will return nothing to you, but it may perform actions such as mutate data, or log things to the console, but no value is returned.\n\n```cpp\nvoid SayHello() {\n\tstd::cout << \"hello world!\" << std::endl;\n}\n\nint main() {\n\tSayHello();\n}\n\n//#> \"hello world!\"\n```\n","n":0.104}}},{"i":942,"$":{"0":{"v":"Return Statement","n":0.707},"1":{"v":"\n\n### Return Statement\n\nA function can only return one item, no more. The return statement is what value you want the function to return to you.\n\nIf your function [[s.l.cpp.funcs#Return type]] is `void` then you are returning nothing and you will just use the keyword by itself: `return;`\n\n```cpp\nint Square ( int num1, int num2 ) {\n\treturn num1 * num2;\n}\n\nint main() {\n\tint myNum = 7;\n\t\n\tstd::cout << Square(myNum) << std::endl;\n}\n\n//#> 49\n```\n","n":0.122}}},{"i":943,"$":{"0":{"v":"Pass by Reference Vs Pass by Value","n":0.378}}},{"i":944,"$":{"0":{"v":"Pass by Value","n":0.577},"1":{"v":"\n\n#### Pass By Value\n\n[[s.l.cpp.funcs.parameters]] are pass by value, meaning the argument's value is copied into a local variable for the parameter. This duplication is expensive with large items like [[s.l.cpp.libs.vector]].\n","n":0.183}}},{"i":945,"$":{"0":{"v":"Pass by Reference","n":0.577},"1":{"v":"\n\n#### Pass By References\n\n> A **pass by reference** parameter does not create a local copy of the argument, but rather the parameter refers directly to the argument variable's memory location. Appending & to a parameter's data type makes the parameter pass by reference type.\n\n```cpp\nvoid MyFunction( vector<int>& inputVector ) {\n\t// References my vector but doesnt copy it into the function\n\t// body scope taking up an identical amount of memory.\n\tcout << inputVector.at(16345) << endl;\n}\n\nint main() {\n\tvector<int> myVector(785746353);\n\t\n\tMyFunction(myVector);\n}\n```\n\n\n","n":0.115}}},{"i":946,"$":{"0":{"v":"With Const","n":0.707},"1":{"v":"\n\n##### Pass By References with Const\n\nIn [[s.l.cpp.funcs#Pass By References]] the `inputVector` was passed by reference which means any changes made to the vector inside the function body would result in mutation of the original vector as we referred to the original vector.\n\nTo prevent mutation of the original vector but take advantage of a pass by reference for efficiency we can prepend `const` to our input parameter so that we wont accidentally be able to mutate that pass by reference value.\n\n```cpp\nvoid MyFunction( const vector<int>& inputVector ) {\n\t// References my vector but doesnt copy it into the function\n\t// body scope taking up an identical amount of memory.\n\tcout << inputVector.at(16345) << endl;\n}\n\nint main() {\n\tvector<int> myVector(785746353);\n\t\n\tMyFunction(myVector);\n}\n```\n","n":0.094}}},{"i":947,"$":{"0":{"v":"Parameters","n":1},"1":{"v":"\n\n### Parameters\n\nParameters passed to a function need to have their data types explicitly declared as well so the function knows what type of data it is receiving:\n\n```cpp\n#include <string>\n\nvoid SayHello ( string name, int age ) {\n\tstd::cout << \"Hello \" << name \n\t<< \" you are: \" << age << \" years old!\" << std::endl;\t\n}\n\nint main () {\n\tstring myName = \"Bryan\";\n\tint myAge = 28;\n\t\n\tSayHello( myName, myAge );\n}\n\n//#> \"Hello Bryan you are: 28 years old!\"\n```\n\n\n","n":0.117}}},{"i":948,"$":{"0":{"v":"Default Parameters","n":0.707},"1":{"v":"\n\n#### Default Parameters\n\n> Sometimes a function's last parameter (or last few) should be optional. A function call could then omit the last argument, and instead the program would use a default value for that parameter. A function can have a **default parameter value** for the last parameter(s), meaning a call can optionally omit a corresponding argument.\n\n```cpp\n#include <iostream>\nusing namespace std;\n\n// Function prints date in two styles (0: American (default), 1: European)\nvoid DatePrint(int currDay, int currMonth, int currYear, int printStyle = 0) {\n\n   if (printStyle == 0) {      // American\n      cout << currMonth << \"/\" << currDay << \"/\" << currYear;\n   }\n   else if (printStyle == 1) { // European\n      cout << currDay << \"/\" << currMonth << \"/\" << currYear;\n   }\n   else {\n      cout << \"(invalid style)\";\n   }\n   \n   return;\n}\n\nint main() {\n   \n   // Print dates given various style settings\n   DatePrint(30, 7, 2012, 0);\n   cout << endl;\n   \n   DatePrint(30, 7, 2012, 1);\n   cout << endl;\n   \n   DatePrint(30, 7, 2012); // Uses default value for printStyle\n   cout << endl;\n   \n   return 0;\n}\n```\n","n":0.077}}},{"i":949,"$":{"0":{"v":"Header File","n":0.707},"1":{"v":"\n![[s.l.cpp.preprocessor-directives]]\n","n":1}}},{"i":950,"$":{"0":{"v":"Definition","n":1},"1":{"v":"\n\n### Definition\n\nThe meat of your function. This is where all the body code goes and where you actually perform your coded actions. These are the fleshed out versions of function [[s.l.cpp.funcs#Declaration]]'s.\n\n```cpp\nvoid Hello( string firstName, string lastName ) {\n\tcout << \"Hello \" << firstName << \" \" << lastName << endl;\n}\n```\n","n":0.141}}},{"i":951,"$":{"0":{"v":"Declaration","n":1},"1":{"v":"\n\n### Declaration\n\n> A **function declaration** specifies the function's return type, name, and parameters, ending with a semicolon where the opening brace would have gone\n\n```cpp\nvoid Hello( string firstName, string lastName );\n```\n","n":0.183}}},{"i":952,"$":{"0":{"v":"Flow","n":1}}},{"i":953,"$":{"0":{"v":"Loops","n":1}}},{"i":954,"$":{"0":{"v":"While","n":1},"1":{"v":"\n\n## While Loops\n\n### Eval First While Loop\n\nThe condition is **evaluated first** before running any body code of the loop.\n\n```cpp\nwhile (expression) { // <-- Loop expression\n\n    // Loop body: Sub-statements that execute if the \n    // expression evaluats to true \n}\n\n// Statements that execute after the expression evaluates to false\n// Or loop concludes\n```\n\n### Execute Then Eval Do-While Loop\n\nThis condition will always **execute the body** code once before testing the expression for `true`. You can use this if you want the code executed at least once before the loop has a chance to break itself on its tested condition.\n\n```cpp\ndo {\n   // Loop body\n} while (loopExpression);\n```\n","n":0.099}}},{"i":955,"$":{"0":{"v":"For","n":1},"1":{"v":"\n\nFor Loops Are Cleaner Than [[C++ While Loops|s.l.cpp.flow.loops.while]]\n\nA real benefit of For loops is that they can clean up a lot of the syntax of while loops when while loops are used for iterations that can be calculated before the initiation of the loop, rather than _\"Run this while loop until a condition is met sometime at some point\"_.\n","n":0.13}}},{"i":956,"$":{"0":{"v":"When to Use","n":0.577},"1":{"v":"\n\n## When to use For loops v.s. While Loops\n\n|    Loop   | Usage                                                                                                                                             |\n| :-------: | :------------------------------------------------------------------------------------------------------------------------------------------------ |\n|  **For**  | _Use when the number of iterations is computable before entering the loop, as when counting down from X to 0, printing a character N times, etc._ |\n| **While** | _Use when the number of iterations is not computable before entering the loop, as when iterating until a user enters a particular character._     |\n","n":0.118}}},{"i":957,"$":{"0":{"v":"Syntax","n":1},"1":{"v":"\n\n## For Loop Syntax\n\n```cpp\nfor (initialExpression; conditionExpression; updateExpression) {\n  // Loop body: Sub-statements to execute if the\n  // conditionExpression evaluates to true\n}\n// Statements to execute after the expression evaluates to false\n```\n","n":0.183}}},{"i":958,"$":{"0":{"v":"Continue Statement","n":0.707},"1":{"v":"\n\n## The continue Statement\n\n```cpp\nfor ( int i = 0; i <= 19; i++ ) {\n\tif ( ( i % 10 ) == 0 ) {\n\t\tcontinue;\n\t}\n\tcout << i << endl;\n}\n```\n\nThe `continue;` statement will skip everything else in the loop and go to the next iteration of the loop.\n\nIn this case it will not send 10 to cout because it was told to continue on.\nwhen the if condition found that the 10 was divisible by 10 with modulus division: `%`, it then ran `continue;` and said _\"skip the printing of this value\"_.\n","n":0.105}}},{"i":959,"$":{"0":{"v":"Break Statement","n":0.707},"1":{"v":"\n\n## The break statement\n\nJust like [[C++ Case Statements|s.l.cpp.flow.case-statements]] the `break;` keyword will cause the loop to end, just like the case statement will run, executing all code on the flow down until it hits a `break;` statement:\n\n![[s.l.cpp.flow.case-statements]]\n","n":0.164}}},{"i":960,"$":{"0":{"v":"If Else","n":0.707},"1":{"v":"\n\n## Single-Branch\n\n```cpp\n// Statements that execute before the branches\n\nif (expression) {\n   // Statements to execute when the expression is true (first branch)\n} else {\n   // Statements to execute when the expression is false (second branch)\n}\n\n// Statements that execute after the branches\n```\n\n## Multi-Branch\n\nThe more branches you add to an If-Statement the more it becomes advantageous to just use a case statement^\\[[[C++ Case Statements|c++-case-statements]]]\n\n```cpp\nif (expr1) {\n\t\n} else if (expr2) {\n\t\n} else if (exprN) {\n\t\n} else {\n\n}\n```\n\n## Short Circuit Evaluation\n\n> A logical operator evaluates operands from left to right. **Short circuit evaluation** skips evaluating later operands if the result of the logical operator can already be determined.\n\n| Operator               | Example            | Short Circuit Evaluation                                                                                                |\n| ---------------------- | ------------------ | ----------------------------------------------------------------------------------------------------------------------- |\n| operand1 && operand2   | true && operand2   | If the first operand evaluates to true, operand2 is evaluated.                                                          |\n| operand1 && operand2   | false && operand2  | If the first operand evaluates to false, the result of the AND operation is always false, so operand2 is not evaluated. |\n| operand1 \\|\\| operand2 | true \\|\\| operand2 | If the first operand evaluates to true, the result of the OR operation is always true, so operand2 is not evaluated.    |\n| operand1 \\|\\| operand2 | false \\|\\|operand2 | If the first operand evaluates to false, operand2 is evaluated.                                                         |\n","n":0.068}}},{"i":961,"$":{"0":{"v":"Case Statements","n":0.707},"1":{"v":"\n\n## Syntax\n\n```cpp\nint main() {\n    int num = 0;\n\n    cout << \"Enter a number (1,2, or 3: \";\n    cin  >> num;\n\n    switch (num) {\n       case 1:\n          cout << \"You Chose 1!\" << endl;\n          break;\n\n       case 2:\n          cout << \"You Chose 2!\" << endl;\n          break;\n\n       case 3:\n          cout << \"You Chose 3!\" << endl;\n          break;\n\n       default:\n          cout << \"WUT\" << endl;\n          break;\n    }\n\n   return 0;\n}\n```\n\n## Multi-Case Flows\n\nIf you line up a bunch of cases like this:\n\n```cpp\nint main() {\n   int dogAgeYears  = 0;\n   int dogAgeMonths = 0;\n\n   cout << \"Enter dog's age (in years): \";\n   cin >> dogAgeYears;\n\n   if (dogAgeYears == 0) {\n      cout << \"Enter dog's age in months: \";\n      cin  >> dogAgeMonths;\n\n      switch (dogAgeMonths) {\n         case 0:\n         case 1:\n         case 2:\n            cout << \"That's 0..14 human months.\" << endl;\n            break;\n\n         case 3:\n         case 4:\n         case 5:\n         case 6:\n            cout << \"That's 1..5 human years.\" << endl;\n            break;\n\n         case 7:\n         case 8:\n            cout << \"That's 5..9 human years.\" << endl;\n            break;\n\n         case 9:\n         case 10:\n         case 11:\n         case 12:\n            cout << \"That's 9..15 human years.\" << endl;\n            break;\n\n         default:\n            cout << \"Invalid input.\" << endl;\n            break;\n      }\n   }\n   else {\n      cout << \"FIXME: Do earlier dog year cases.\" << endl;\n      switch (dogAgeYears) {\n      }\n   }\n\n   return 0;\n}\n```\n\nThe cases for 3,4,5, and 6 will all cause the same result, i.e. the result for case 6. The other cases will hit and then flow down executing all code until they finally hit a `break;` statement. This can be useful shorthand for grouping multiple inputs to the same output code. 723541\n","n":0.063}}},{"i":962,"$":{"0":{"v":"Files","n":1}}},{"i":963,"$":{"0":{"v":"Stream Errors","n":0.707},"1":{"v":"\n\n### Stream Errors\n\n> A **stream error** occurs when insertion or extraction fails, causing the stream to enter an error state.\n\n```cpp\n#include <iostream>\nusing namespace std;\n\nint main() {\n   int num1 = -1; // Initial value -1 for demo purposes.\n   int num2 = -1;\n   \n   cout << \"Enter a number: \" << endl;\n   cin  >> num1; // Stream error state entered here.\n   \n   cout << \"Enter a second number:\" << endl;\n   cin  >> num2; // Stream already in error state, so extraction skipped.\n   \n   cout << \"num1: \" << num1 << endl;\n   cout << \"num2: \" << num2 << endl;\n   \n   return 0;\n}\n\n/*\n\tEnter a number:\n\tsix\n\tEnter a second number:\n\tnum1: 0\n\tnum2: -1\n*/\n\n```\n\n> A stream's error state can be checked with a function. Ex: `cin.good() `returns true if `cin` is not in an error state. Otherwise, false is returned. A stream internally uses several 1-bit error flags to track the state of the stream.\n\n| Flag      | Meaning                                                                                                                       | Function                                                                                                         |\n| :-------- | :---------------------------------------------------------------------------------------------------------------------------- | :--------------------------------------------------------------------------------------------------------------- |\n| `goodbit` | Indicates no error flags are set and the stream is good.                                                                      | `good()`¬†returns true if no stream errors have occurred.                                                         |\n| `eofbit`  | Indicates if end-of-file reached on extraction.                                                                               | `eof()`¬†returns value of eofbit, if end-of-file reached on extraction.                                           |\n| `failbit` | Indicates a logical error for the previous extraction or insertion operation.                                                 | `fail()`¬†returns true if either failbit or badbit is set, indicating an error for the previous stream operation. |\n| `badbit`  | Indicates an error occurred reading or writing the stream, and the stream is bad. Further operations on the stream will fail. | `bad()`¬†returns true if badbit is set, indicating the stream is bad.                                             |\n\n> A stream's error state is cleared using `clear()`. Ex: `cin.clear()` clears the error state from `cin`.\n> .\n> The function `ignore(maxToIgnore, stopChar)` ignores characters in the stream buffer. Ex: `cin.ignore(10, '\\n') `ignores up to 10 characters in the stream buffer, or until a '`\\n`' character is encountered.\n> .\n> Commonly, a program needs to wait until a '`\\n`' character is found, in which case set `maxToIgnore` to the maximum size of a stream: `numeric_limits<streamsize>::max()`.\n\n```cpp\n// Read user input until a number is entered\n#include <iostream>\n#include <limits>\nusing namespace std;\n\nint main() {\n   int number = 0;\n   \n   cout << \"Enter a number: \" << endl;\n   cin >> number;\n   \n   while (cin.fail()) {\n      // Clear error state\n      cin.clear();\n\n      // Ignore characters in stream until newline\n      cin.ignore(numeric_limits<streamsize>::max(), '\\n');\n      \n      cout << \"Try again: \" << endl;\n      cin  >> number;\n   }\n   \n   cout << \"You entered: \" << number << endl;\n   \n   return 0;\n}\n```\n\n> A program may need to check for errors during file reading. \n> One approach is to check whether end-of-file was reached after the file reading ends. If end-of-file was not reached, then an error in file reading occurred.\n\n```cpp\n/* Given:\n\tmyfile.txt:\n\t5\n\t8\n\tsix\n\t4\n\t6\n*/\n\n#include <iostream>\n#include <fstream>\nusing namespace std;\n\nint main() {\n   ifstream inFS;\n   int fileNumber = 0; // Number in file\n   \n   inFS.open(\"myfile.txt\");\n   \n   if (!inFS.is_open()) {\n      cout << \"Could not open file myfile.txt.\" << endl;\n      \n      return 1;\n   }\n   \n   // Read file until end-of-file or an error\n   while (inFS.good()) {\n       inFS >> fileNumber;\n       cout << \"File number: \" << fileNumber << endl;\n   }\n   \n   // If end-of-file not reached, then an error occurred\n   if (!inFS.eof()) {\n      cout << \"Error reading myfile.txt\" << endl;\n      \n      return 1;\n   }\n   \n   inFS.close();\n   \n   return 0;\n}\n\n/*\n\tFile number: 5\n\tFile number: 8\n\tFile number: 0\n\tError reading myfile.txt\n*/\n```\n","n":0.043}}},{"i":964,"$":{"0":{"v":"Output","n":1},"1":{"v":"\n\n### Output\n\n`ofstream` = Output File Stream\n\n```cpp\n#include <iostream>\n#include <fstream>\nusing namespace std;\n\nint main() {\n   ofstream outFS; // Output file stream\n   \n   // Open file\n   outFS.open(\"myoutfile.txt\");\n   \n   if (!outFS.is_open()) {\n      cout << \"Could not open file myoutfile.txt.\" << endl;\n      return 1;\n   }\n   \n   // Write to file\n   outFS << \"Hello\" << endl;\n   outFS << \"1 2 3\" << endl;\n   \n   // Done with file, so close it\n   outFS.close();\n   \n   return 0;\n}\n```\n","n":0.121}}},{"i":965,"$":{"0":{"v":"Input","n":1},"1":{"v":"\n\n### Input\n\n> Sometimes a program should get input from a file rather than from a user typing on a keyboard. To achieve this, a programmer can create a new input stream that comes from a file, rather than the predefined input stream `cin` that comes from the standard input (keyboard). That new input stream can then be used just like `cin`, as the following program illustrates. Assume a text file exists named _myfile.txt_ with the contents shown (created for example using Notepad on a Windows computer or using TextEdit on a Mac computer).\n\n```\nmyfile.txt with two integers:\n5\n10\n```\n\n```cpp\n#include <iostream>\n#include <fstream>\nusing namespace std;\n\nint main() {\n   ifstream inFS;     // Input file stream\n   int fileNum1 = 0;  // Data value from file\n   int fileNum2 = 0;  // Data value from file\n   \n   // Try to open file\n   cout << \"Opening file myfile.txt.\" << endl;\n   \n   inFS.open(\"myfile.txt\");\n   if (!inFS.is_open()) {\n      cout << \"Could not open file myfile.txt.\" << endl;\n      return 1; // 1 indicates error\n   }\n   \n   // Can now use inFS stream like cin stream\n   // myfile.txt should contain two integers, else problems\n   cout << \"Reading two integers.\" << endl;\n   inFS >> fileNum1;\n   inFS >> fileNum2;\n   cout << \"Closing file myfile.txt.\" << endl;\n   inFS.close(); // Done with file, so close it\n   \n   // Ouput values read from file\n   cout << \"num1: \" << fileNum1 << endl;\n   cout << \"num2: \" << fileNum2 << endl;\n   cout << \"num1 + num2: \" << (fileNum1 + fileNum2) << endl;\n   \n   return 0;\n}\n```\n\n> **Five** lines are needed for the new input stream, highlighted above.\n> .\n>\n> - The `#include <fstream>` (for \"_file stream_\") enables use of the file stream class.\n> - A new stream variable has been declared: `ifstream inFS;`. `ifstream` is short for _input file stream_, and is derived from `istream`.\n> - The line `inFS.open(\"myfile.txt\");` opens the file for reading and associates the file with the `inFS` stream. Because of the high likelihood that the open fails, usually because the file does not exist or is in use by another program, the program checks whether the open was successful using `if (!inFS.is_open())`.\n> - The successfully opened input stream can then be used just like the `cin` stream, e.g., using `inFS >> num1;` to read an integer into `num1`.\n> - Finally, when done using the stream, the program closes the file using `inFS.close()`.\n> - A common error is to type `cin >> num1;` when actually intending to get data from a file as in `inFS >> num1`. Another common error is a mismatch between the variable data type and the file data, e.g., if the data type is int but the file data is \"Hello\".\n\n> The `inFS.open(str)` function has a string parameter str, which can be a C++ string or a null-terminated C string. A program often uses a user-entered string as the filename, such as using `cin >> filename;`.\n\n```cpp\n/* Given\n\ndatafile.txt with two integers:\n72\n68\n\n*/\n\n#include <iostream>\n#include <fstream>\n#include <string>\nusing namespace std;\n\nint main() {\n   ifstream inFS;        // Input file stream\n   int fileNum1 = 0;     // File data\n   int fileNum2 = 0;     // File data\n   string filename = \"\"; // Input filename\n   \n   // Prompt user for filename\n   cout << \"Enter filename: \" << endl;\n   cin >> filename;\n   \n   // Try to open file\n   inFS.open(filename);\n   \n   if (!inFS.is_open()) {\n      cout << \"Could not open file \" << filename << endl;\n      return 1;\n   }\n   \n   // Get numbers. If too few, may encounter problems\n   inFS >> fileNum1;\n   inFS >> fileNum2;\n   \n   // Done with file, close it\n   inFS.close();\n   \n   // Ouput values read from file\n   cout << \"num1: \" << fileNum1 << endl;\n   cout << \"num2: \" << fileNum2 << endl;\n   cout << \"num1 + num2: \" << (fileNum1 + fileNum2) << endl;\n   \n   return 0;\n}\n\n/*\n\tEnter filename: \n\tdatafile.txt\n\tnum1: 72\n\tnum2: 68\n\tnum1 + num2: 140\n*/\n```\n\n> A program can read varying amounts of data in a file by using a loop that reads until the end of the file has been reached, as follows.\n> .\n> The `eof()` function returns true if the previous stream operation reached the end of the file. Errors may be encountered while attempting to read from a file, including end-of-file, corrupt data, etc. So, a program should check that each read was successful before using the variable to which the data read was assigned. The `good()` function returns true if the previous stream operation had no problems. Ex:  `if( inFS.good() ) {...} `checks that the previous read operation was successful.\n\n```cpp\n/* Given:\n\tmyfile.txt with variable number of integers:\n\t111\n\t222\n\t333\n\t444\n\t555\n*/\n\n#include <iostream>\n#include <fstream>\nusing namespace std;\n\nint main() {\n   ifstream inFS;   // Input file stream\n   int fileNum = 0; // File data\n   \n   // Open file\n   cout << \"Opening file myfile.txt.\" << endl;\n   inFS.open(\"myfile.txt\");\n   \n   if (!inFS.is_open()) {\n      cout << \"Could not open file myfile.txt.\" << endl;      \n      return 1;\n   }\n   \n   // Print read numbers to output\n   cout << \"Reading and printing numbers.\" << endl;\n   \n   while (!inFS.eof()) {\n      inFS >> fileNum;\n      if( inFS.good() ) {\n         cout << \"num: \" << fileNum << endl;\n      }\n   }\n   \n   cout << \"Closing file myfile.txt.\" << endl;\n   \n   // Done with file, so close it\n   inFS.close();\n   \n   return 0;\n}\n\n/*\n\tOpening file myfile.txt.\n\tReading and printing numbers.\n\tnum: 111\n\tnum: 222\n\tnum: 333\n\tnum: 444\n\tnum: 555\n\tClosing file myfile.txt.\n*/\n```\n","n":0.034}}},{"i":966,"$":{"0":{"v":"Extraction before Getline","n":0.577},"1":{"v":"\n\n### Extraction Before Getline\n\n> The `getline()` function and the extraction operator `>>` handle a trailing newline differently, which can lead to a problem.\n>\n> - The `getline()` function reads a line of text from a buffer, **discarding the ending newline character**.\n> - The extraction operator `>>` skips <u>whitespace</u>, then reads the next item such as an integer or string which is said to end at the next <u>whitespace</u>, leaving that ending whitespace character in the buffer (an exception being for reading a single character).\n\n> The problem is that code like `cin >> myInt;` and `getline(cin, nextLine);` may not behave as expected if the integer is ended with a newline. The `getline()` function will read that single remaining newline character, returning an empty string, rather than proceeding to the next line.\n> .\n> A simple solution is to not mix the two approaches to reading an input buffer, either only using extraction, or only using `getline()`.\n> .\n> If one must mix the two approaches, then after an extraction operation, the trailing newline should be discarded from the buffer before calling the `getline()`, by inserting some statement in between. One possible solution inserts `cin.ignore()`, which discards the next character in the input buffer. Another possible approach inserts another `getline()` call, ignoring its blank string.\n","n":0.069}}},{"i":967,"$":{"0":{"v":"Data T","n":0.707}}},{"i":968,"$":{"0":{"v":"Strings","n":1},"1":{"v":"\n\n### Strings\n\n_Strings make use of the [[C++ Include string|string]] library to represent an array of characters (a word or more) in a single datatype with minimal headache on management and more options and functionality than C-style strings_\n\n```cpp\nstring firstName = \"bryan\";\n```\n\nIf you are reading in^\\[[[C++ Basic Input Output|c++-basic-input-output]]] a string value into a variable, any spaces will be considered the termination of the string.\n\nTo get the entire input string you need to use `getline()`\n\n```cpp\nstring firstName;\nstring lastName;\ncout << \"Enter first name:\" << endl;\ngetline(cin, firstName); // Gets entire line up to ENTER\ncout << \"Enter last name:\" << endl;\ngetline(cin, lastName); // Gets entire line up to ENTER\ncout << endl;\ncout << \"Welcome \" << firstName << \" \" << lastName << \"!\" << endl;\ncout << \"May I call you \" << firstName << \"?\" << endl;\n```\n\n","n":0.087}}},{"i":969,"$":{"0":{"v":"Cstrings","n":1},"1":{"v":"\n\n#### C Strings\n\nchar arrays were the only type of strings that existed in `C` such as:\n\n```cpp\nchar movieTitle[20] = \"Star Wars\";\n```\n\n> Because a string can be shorter than the character array, a string in a char array must end with a special character known as a null character, written as '\\\\0'. Given a string literal like \"Star Wars\", the compiler automatically appends a null character.\n> .\n> A char array of size 20 can store strings of lengths 0 to 19. The longest string is 19, not 20, since the null character must be stored.\n\n`C` strings can be in legacy code and are included with:\n\n```cpp\n#include <cstring>\n```\n","n":0.098}}},{"i":970,"$":{"0":{"v":"Mutability","n":1},"1":{"v":"\n\n## Mutability\n\n`const` variables are traditionally upper snake case `LIKE_THIS`\n\nTo declare something as `const` is to make it immutable and unable to be reassigned to a new value.\n\n```cpp\nconst int CENTIMETERS_PER_INCH = 3; // will forever be 3\n```\n","n":0.167}}},{"i":971,"$":{"0":{"v":"Integers","n":1},"1":{"v":"\n\n### Integer\n\n_Whole numbers only._\n\n```cpp\nint age = 28;\n```\n\n","n":0.378}}},{"i":972,"$":{"0":{"v":"Unsigned","n":1},"1":{"v":"\n\n#### Unsigned Integers\n\nIf you know an integer will always be positive then you can double the range of the positive value limit as the negative value limit will be reduced to zero in favor of expanding the positive limit.\n\n| Declaration                 | Size    | Supported number range           | Standard-defined minimum size |\n| --------------------------- | ------- | -------------------------------- | ----------------------------- |\n| `unsigned char myVar;`      | 8 bits  | 0 to 255                         | 8 bits                        |\n| `unsigned short myVar;`     | 16 bits | 0 to 65,535                      | 16 bits                       |\n| `unsigned long myVar;`      | 32 bits | 0 to 4,294,967,295               | 32 bits                       |\n| `unsigned long long myVar;` | 64 bits | 0 to 184,467,440,737,095,551,615 | 64 bits                       |\n| `unsigned int myVar;`       | 32 bits | 0 to 4,294,967,295               | 16 bits                       |\n","n":0.088}}},{"i":973,"$":{"0":{"v":"Other","n":1},"1":{"v":"\n\n#### Other types of Integers\n\n| Declaration        | Size    | Supported number range                                  | Standard-defined minimum size |\n| ------------------ | ------- | ------------------------------------------------------- | ----------------------------- |\n| `char myVar;`      | 8 bits  | -128 to 127                                             | 8 bits                        |\n| `short myVar;`     | 16 bits | -32,768 to 32,767                                       | 16 bits                       |\n| `long myVar;`      | 32 bits | -2,147,483,648 to 2,147,483,647                         | 32 bits                       |\n| `long long myVar;` | 64 bits | -9,223,372,036,854,775,808 to 9,223,372,036,854,775,807 | 64 bits                       |\n| `int myVar;`       | 32 bits | -2,147,483,648 to 2,147,483,647                         | 16 bits                       |\n","n":0.105}}},{"i":974,"$":{"0":{"v":"Float","n":1},"1":{"v":"\n\n### Double / Float\n\n_Floating point numbers \"They have a decimal point\", can be 1.0 like an integer but can also be 1.1._\n\n```cpp\ndouble heightInCentimeters = 198.7;\n```\n","n":0.2}}},{"i":975,"$":{"0":{"v":"Floating Point Comparison","n":0.577},"1":{"v":"\n\n## 'Good Enough' Equality\n\n> Floating-point numbers should not be compared using `==`. Ex: Avoid float1 `==` float2. \n> .\n> Reason: Some floating-point numbers cannot be exactly represented in the limited available memory bits like 64 bits. Floating-point numbers expected to be equal may be close but not exactly equal.\n> .\n> Floating-point numbers should be compared for _\"close enough\"_ rather than exact equality. \n> Ex: If `( x - y ) < 0.0001`, x and y are deemed equal.\n> Because the difference may be negative, the absolute value is used: `fabs(x - y) < 0.0001`.\n> .\n> The difference threshold indicating that floating-point numbers are equal is often called the `epsilon`. Epsilon's value depends on the program's expected values, but 0.0001 is common.\n","n":0.091}}},{"i":976,"$":{"0":{"v":"Conversion","n":1},"1":{"v":"\n\nIf you do not want to make a new variable or refactor an existing variable due to the need for it to be a `double` and not an `int` any longer.\n\nLike when finding the average of integers and the returned value is floating point\n\nthis will work like `cast()` in SQL\n\n```cpp\n#include <iostream>\nusing namespace std;\n\nint main() {\n   int kidsInFamily1 = 3; // Should be int, not double\n   int kidsInFamily2 = 4; // (know anyone with 2.3 kids?)\n   int numFamilies   = 2; // Should be int, not double\n\n   double avgKidsPerFamily = 0.0; // Expect fraction, so double\n\n   avgKidsPerFamily = static_cast<double>(kidsInFamily1 + kidsInFamily2) \n                      / static_cast<double>(numFamilies);\n\n   cout << \"Average kids per family: \" << avgKidsPerFamily << endl;\n\n   return 0;\n}\n```\n","n":0.093}}},{"i":977,"$":{"0":{"v":"Char","n":1},"1":{"v":"\n\n### Character\n\n_Character are a single character only, and in the assignment the character must be wrapped in single quotes._\n\n```cpp\nchar arrowBody = '-'\n```\n","n":0.213}}},{"i":978,"$":{"0":{"v":"Bool","n":1},"1":{"v":"\n\n### Boolean\n\n_booleans can hold the values `true` and `false` that is all._\n\nA great practice for boolean variables would be to name them something beginning with the word _is_ like `isTall` the answer to their question is `true` or `false`. This makes code easier to understand.\n\n```cpp\nbool isLarge = true;\nbool isNeg   = false;\n```\n","n":0.14}}},{"i":979,"$":{"0":{"v":"Auto","n":1},"1":{"v":"\n\n### Auto\n\nThe `auto` specifier is a way of detecting the data type based on assignment value. \n\n```cpp\nauto i = 5;   // causes i to be of type int\n\t\t\t  // and\nauto j = 5.0; // causes j to be of type double.\n```\n","n":0.156}}},{"i":980,"$":{"0":{"v":"Data S","n":0.707}}},{"i":981,"$":{"0":{"v":"Structs","n":1},"1":{"v":"\n\n## Structs\n\n> a **struct** is nearly identical to a [[C++ Classes|class]]. The difference is that if a [[C++ Classes#Class Member Function|member]] appears before a label of private or public, then by default, in a struct the member is public while in a class the member is private. Some programmers suggest a good practice is to use struct for simple data grouping with that data being public, while using class for objects (having data and functions, with data private). \n> .\n> However, some C++ programmers argue that good practice is to only use class, abandoning struct entirely\n\n<https://www.guru99.com/cpp-structures.html>\n\n```cpp\n// Declaration\n\nstruct Person  \n{  \n    char name[30];  \n     int citizenship;  \n     int age;  \n}\n\n// Instantiation\nPerson p;\n```\n","n":0.095}}},{"i":982,"$":{"0":{"v":"Enumerations","n":1},"1":{"v":"\n\nenums are basically just numbers. In this instance \n\n`FICTION = 0` and `NONFICTION = 1`\n\n```cpp\nenum BookType {FICTION,NONFICTION};\n```\n\n`bookTypeStrings` are really just [[C++ Include string|string]] labels for the `BookType` enum as the enum in really is just numbers.\n\n```cpp\nstatic const std::string bookTypeStrings[] = {\"FICTION\",\"NONFICTION\"};\n```\n\nThe enumumerated values are being used as an index for the label values:\n\n```cpp\nbookTypeStrings[FICTION] // returns the string: \"FICTION\"\nbookTypeStrings[NONFICTION] // returns the string: \"NONFICTION\"\n```\n\nThe order of the strings does matter in this instance as the values default to a normal 0..1..n indexing unless manually set to specific values:\n\n```cpp\nenum light { RED = 2, YELLOW = 5, GREEN = 7 };\n```\n","n":0.101}}},{"i":983,"$":{"0":{"v":"Arrays and Vectors","n":0.577},"1":{"v":"\n\n## Vectors are Array++\n\nA vector is an ordered list of items of a given data type. \n\nEach item in a vector is called an **element**.\n\n```cpp\n#include <vector>\n// vector<dataType> identifier(numElements);\nvector<int> myVector(5); // an integer vector with 5 elements\n/*\n\tThough if you assign a vector a size of 5 the true size is still using the 0..n array indexing. so if you say:\n*/\nvector<int> myVector(5);\n/*\n\tand then try to access element 5:\n*/\nmyVector.at(5); // <-- ERROR! 5 elements at index 0..4\n```\n\n### Iterating Through a Vector\n\nUsing [[C++ For Loops|c++-for-loops]] on a vector can be a little irritating at first with the  size declaration but usage of array indexing:\n\n```cpp\n// These give a variable to reference the size of the vector\nconst int NUM_ELEMENTS = 3;\nvector<int> userVals(NUM_ELEMENTS);\n\n// test case\nuserVals.at(0) = 2;\nuserVals.at(1) = 7;\nuserVals.at(2) = 4;\n\n/*\n\twhere i < NUM_ELEMENTS is to say it quits if it is larger than 2\n\ti.e. 3. NUM_ELEMENTS goes up to 3, but because of the array indexing\n\tthe true values are 0, 1, & 2 as shown above in the test case\n*/\nfor (int i = 0; i < NUM_ELEMENTS; ++i) {\n  cout << userVals.at(i) << endl;\n}\n\n//#> 2, 7, 4\n```\n\nAn even easier way of doing the same thing without an unnecessary `const` variable is to use `.size()`\n\n```cpp\nvector<int> userVals(3);\n\n// test case\nuserVals.at(0) = 2;\nuserVals.at(1) = 7;\nuserVals.at(2) = 4;\n\n/*\n\tthe size is 3 so if i < 3 which is what the prior example also showed\n*/\nfor (int i = 0; i < userVals.size(); ++i) {\n  cout << userVals.at(i) << endl;\n}\n\n//#> 2, 7, 4\n```\n\n### Reversing a vector\n\n```cpp\nconst int NUM_ELEMENTS = 8;        // Number of elements\nvector<int> revVctr(NUM_ELEMENTS); // User values\nunsigned int i;                    // Loop index\nint tmpValue;                      // Placeholder\n\n// User populates the vector\ncout << \"Enter \" << NUM_ELEMENTS << \" integer values...\" << endl;\nfor (i = 0; i < revVctr.size(); ++i) {\n  cout << \"Value: \";\n  cin >> revVctr.at(i);\n}\n\n// Reverse the vector (this doesnt take into account an odd # of vals)\n// Size returns the amount of values in a vector, the exact number of\n// indexes is really -1 but to rever a vector we really only need to\n// pivot around a mid point or in this case a middle value or half of\n// the vector's size hence .size() / 2 below\nfor (i = 0; i < (revVctr.size() / 2); ++i) {\n  // temp value holds the values one by one starting from the left i=1\n  tmpValue = revVctr.at(i);  \n  // .size() - 1 as that is the true last index of the vector and -i\n  // so we can begin to move towards the center values right to left\n  // i starts off at 0 so the first iteration is in reality swapping\n  // the first and last elements of a vector\n  revVctr.at(i) = revVctr.at(revVctr.size() - 1 - i);\n  // Referring again to the true last element of the vector receiving \n  // the true last index of the vector receiving the value of the first \n  // this is the end of the swap\n  revVctr.at(revVctr.size() - 1 - i) = tmpValue;\n}\n```\n","n":0.045}}},{"i":984,"$":{"0":{"v":"Clang","n":1},"1":{"v":"\n\n> C: God's programming language\n","n":0.447}}},{"i":985,"$":{"0":{"v":"Batch","n":1},"1":{"v":"\n\n- <https://www.robvanderwoude.com/battech.php>\n\n","n":0.707}}},{"i":986,"$":{"0":{"v":"Bash","n":1},"1":{"v":"\n\n> Glue for [[C|s.l.clang]]\n","n":0.5}}},{"i":987,"$":{"0":{"v":"Vars","n":1},"1":{"v":"\n\n### Variables\n\nVariables in bash are assigned with a single `=`\nNo spacing between the variable name, the `=` and the assigned value\nYou can specify the variables scope with either `export` or `local` or\nan environmental variable with no explicit scope.\n\nOnce declared in your script or environment etc, you can reference your\nvariables by matching the exact casing of the variable name and pre-pending\na `$` so my path variable for binaries to execute would be `$PATH`.\n\nWhen referencing your variables always quote them because of:\n\"General rule: quote it if it can either be empty or contain spaces\"\n\"`$?` doesn't need quotes since it's a numeric value.\"\n\n```shell\n## Variables\n\n### Local vars\nlocal var=2\n\n### Global Vars\nvar=2\n\n### Environment\nexport var=2\n\necho \"$var\"\n```\n\n\"In short, quote everything where you do not require the shell to perform token\nsplitting and wild card expansion.\"\n\n```shell\n\n## Token Splitting\nwords=\"foo bar baz\"\nfor word in $words; do\n  echo \"$word\"\ndone\n#> foo\n#> bar\n#> baz\n\n```\n\nDouble quotes are suitable when variable interpolation is\nrequired. With suitable adaptations, it is also a good workaround when you need\nsingle quotes in the string. (There is no straightforward way to escape a\nsingle quote between single quotes, because there is no escape mechanism inside\nsingle quotes -- if there was, they would not quote completely verbatim.)\n\nNo quotes are suitable when you specifically require the shell to perform token\nsplitting and/or wild card expansion.\n\n```shell\n## Wildcard Expansion\n\n### Literal Strings\npattern='file*.txt'\nls $pattern\n# > file1.txt      file_other.txt\n\n### Double Quotes\nls \"$pattern\"\n#> ls: cannot access file*.txt: No such file or directory\n# (There is no file named literally file*.txt.)\n\nls '$pattern'\n#> ls: cannot access $pattern: No such file or directory\n# (There is no file named $pattern, either!)\n```\n\nIn more concrete terms, anything containing a filename should usually be quoted\n(because filenames can contain whitespace and other shell meta characters).\nAnything containing a URL should usually be quoted (because many URL's contain\nshell meta characters like `?` and `&`). Anything containing a regex should usually\nbe quoted (ditto ditto). Anything containing significant whitespace other than\nsingle spaces between non-whitespace characters needs to be quoted (because\notherwise, the shell will munge the whitespace into, effectively, single\nspaces, and trim any leading or trailing whitespace).\n\nWhen you know that a variable can only contain a value which contains no shell\nmeta characters, quoting is optional. Thus, an unquoted `$?` is basically fine,\nbecause this variable can only ever contain a single number. However, `\"$?\"` is\nalso correct, and recommended for general consistency and correctness (though\nthis is my personal recommendation, not a widely recognized policy).\n\nValues which are not variables basically follow the same rules, though you\ncould then also escape any meta characters instead of quoting them. For a common\nexample, a URL with a & in it will be parsed by the shell as a background\ncommand unless the meta character is escaped or quoted.\n\n\n\n#### Meta characters with variables\n\nThe braces, in addition to delimiting a variable name are used for parameter expansion so you can do things like:\n\nTruncate the contents of a variable\n\n```shell\nvar=\"abcde\"; echo ${var%d*}\n#> abc\n```\n\nMake substitutions similar to sed\n\n```shell\nvar=\"abcde\"; echo ${var/de/12}\n#> abc12\n```\n\nUse a default value\n\n```shell\ndefault=\"hello\"; unset var; echo ${var:-$default}\n#> hello\n```\n\nand several more\n\nAlso, brace expansions create lists of strings which are typically iterated over in loops:\n\n```shell\necho f{oo,ee,a}d\n#> food feed fad\n\nmv error.log{,.OLD}\n# (error.log is renamed to error.log.OLD because the brace expression\n# expands to \"mv error.log error.log.OLD\")\n\nfor num in {000..2}; do echo \"$num\"; done\n#> 000\n#> 001\n#> 002\n\necho {00..8..2}\n#> 00 02 04 06 08\n\necho {D..T..4}\n#> D H L P T\n```\n\n#### Exporting variables\n\nExport variables for other programs to use in your shell environment with\n\n```shell\nexport var=myvar\n```\n\nvariable with\n\n```shell\nunset myvar\n```\n\nExport copies variables to the environment, `declare -x` also does the same as export?\n\nExport functions with\n\n```shell\nexport -f myfunc\n```\n\nJust printing export will list all current environment variables\n\nFunctions don‚Äôt get a copy of the variables in the environment, they share them and therefor can mutate them\n\nTo see built-ins use\n\n```shell\nenable\n```\n\nTo see keywords use\n\n```shell\ncompgen -k\n```\n","n":0.041}}},{"i":988,"$":{"0":{"v":"Tips Tricks","n":0.707},"1":{"v":"\n![[r.(.2022.03.16.five-powerful-tips-for-bash-scripting#error-proof-your-variables]]\n","n":1}}},{"i":989,"$":{"0":{"v":"Track Content of File","n":0.5},"1":{"v":"\n\n### Track the content of a log file\n\n> See the contents of a file in real time\n\n```bash\nwatch cat log.txt\n```\n\n> Although this command does the job, it is not the best option. You can use the tail command with the -f option to track only the new lines that are appended to the file,\n","n":0.137}}},{"i":990,"$":{"0":{"v":"Stdin as Arg","n":0.577},"1":{"v":"\n\n### Stdin as a file argument\n\n```bash\n# Command expects a file:\nwc file1 file2\n# Instead of making a temp file to read in a little text use this to pass in\n# text as a temp file to STDIN\nwc file1 - file2 # waits for you to type input and you complete this process by using `CTRL+D` which inserts the EOF character\n```\n","n":0.13}}},{"i":991,"$":{"0":{"v":"Shorten If Statements","n":0.577},"1":{"v":"\n![[r.(.2022.03.16.five-powerful-tips-for-bash-scripting#skip-the-long-if-else-statements]]\n","n":1}}},{"i":992,"$":{"0":{"v":"Redirect Stout and Stderr Each to Separate Files and Print Both to the Screen","n":0.267},"1":{"v":"\n```bash\n(some_command 2>&1 1>&3 | tee errorlog ) 3>&1 1>&2 | tee stdoutlog\n```\n","n":0.289}}},{"i":993,"$":{"0":{"v":"Re Use Cmd Args","n":0.5},"1":{"v":"\n\n### Re-use command arguments\n\n```bash\nmkdir very-large-directory-name\ncd very-large-directory-name\n# Instead of duplicating the argument of the mkdir command, you can use !$ for retrieve the last argument of the last command, the result is:\nmkdir very-large-directory-name\ncd !$ # == cd very-large-directory-name\n```\n","n":0.164}}},{"i":994,"$":{"0":{"v":"Re Run Cmds","n":0.577},"1":{"v":"\n\n### Re-run commands\n\n```bash\n# of course there's\nsudo !!\n# but you can also do\n!-N # where N is the Nth command (Relative)\n# or\n!N # for the N command in your history (Absolute)\n```\n","n":0.183}}},{"i":995,"$":{"0":{"v":"Quickly Truncate a File","n":0.5},"1":{"v":"\n```bash\n>filename\n```\n","n":1}}},{"i":996,"$":{"0":{"v":"Pipe Stdout and Stderr to Separate Commands","n":0.378},"1":{"v":"\n```bash\nsome_command > >(/bin/cmd_for_stdout) 2> >(/bin/cmd_for_stderr)\n```\n","n":0.447}}},{"i":997,"$":{"0":{"v":"Output as File Arg","n":0.5},"1":{"v":"\n\n### Use the output of another command as a file argument\n\n```bash\nwc file1 <(echo ‚Äúhello world‚Äù) file2\n```\n\n> When you wrap a command with `<(...)` bash generate a temporal file in a path like `/dev/fd/64`, then execute your wrapped command, put the output in this temporal file, and finally replace `<(...)` with the filename of the temporal file, in this case, `/dev/fd/64`\n","n":0.129}}},{"i":998,"$":{"0":{"v":"Multiprocessing in Bash Scripts","n":0.5},"1":{"v":"\n```bash\n#!/bin/bash\nfunction task1() {\n    echo \"Running task1...\"\n    sleep 5\n}\nfunction task2() {\n    echo \"Running task2...\"\n    sleep 5\n}\ntask1 &\ntask2 &\nwait\necho \"All done!\"\n```\n\nthe `wait` builtin makes sure that all background processes have completed before carrying on\n","n":0.177}}},{"i":999,"$":{"0":{"v":"Ignore First N Lines","n":0.5},"1":{"v":"\n\n### Ignore the first N lines\n\n> By default, the tail command will show the last n rows, but if you specified the option -n with a number that starts with the + symbol, like +5 , the first 5 lines are going to be skipped.\n\n```bash\n# In this example, the tail command is going to skip the first 10 lines and print the rest of the file content.\ntail -n +10 dataset.csv\n```\n","n":0.12}}},{"i":1000,"$":{"0":{"v":"Globbing Vs Ls","n":0.577},"1":{"v":"\n\n##### Use globbing instead of  ls\n\nInstead of using `ls -l <pattern>` to return a wildcard glob, use the wildcard as it is and avoid `ls`\n\n```bash\n#  Documentation\npattern=\"ex*\"\n\nprintf '%s\\n' $pattern   # not ``ls -1 $pattern''\n# > file1.txt\n# > file_other.txt\n\nfor file in $pattern; do  # definitely, definitely not ``for file in $(ls $pattern)''\n\tprintf 'Found file: %s\\n' \"$file\"\ndone\n# > Found file: file1.txt\n# > Found file: file_other.txt\n```\n\n###### Documentation\n\n- [parsing file globs with ls](https://mywiki.wooledge.org/ParsingLs)\n- <https://superuser.com/questions/31464/looping-through-ls-results-in-bash-shell-script#31466>\n","n":0.12}}},{"i":1001,"$":{"0":{"v":"Error Proof Your Variables","n":0.5}}},{"i":1002,"$":{"0":{"v":"Dont Rely on Positional Args","n":0.447},"1":{"v":"\n![[r.(.2022.03.16.five-powerful-tips-for-bash-scripting#dont-rely-on-passing-arguments]]\n","n":1}}},{"i":1003,"$":{"0":{"v":"Displaying Native Gui Notifications from Bash","n":0.408},"1":{"v":"\n## Linux\n\n```bash\n#!/bin/bash\nsleep 10\nnotify-send \"notify.sh\" \"Task #1 was completed successfully\"\n```\n\nOSX\n\n```bash\n#!/bin/bash\nsleep 10\nosascript -e \"display notification \\\"Task #1 was completed successfully\\\" with title \\\"notify.sh\\\"\"\n```\n","n":0.218}}},{"i":1004,"$":{"0":{"v":"Delete All Files in a Folder That Don't Match a Certain File Extension","n":0.277},"1":{"v":"\n```bash\nrm !(*.foo|*.bar|*.baz)\n```\n","n":0.707}}},{"i":1005,"$":{"0":{"v":"Create Loading Animations","n":0.577},"1":{"v":"\n```bash\n#!/bin/bash\nwhile true;\ndo\n    # Frame #1\n    printf \"\\r< Loading...\" \n    sleep 0.5\n    # Frame #2 \n    printf \"\\r> Loading...\" \n    sleep 0.5 \ndone\n```\n\nor\n\n```bash\n#!/bin/bash\nsleep 5 &\npid=$!\nframes=\"/ | \\\\ -\"\nwhile kill -0 $pid 2&>1 > /dev/null;\ndo\n    for frame in $frames;\n    do\n        printf \"\\r$frame Loading...\" \n        sleep 0.5\n    done\ndone\nprintf \"\\n\"\n```\n","n":0.147}}},{"i":1006,"$":{"0":{"v":"Create Default Variable Values","n":0.5},"1":{"v":"\n![[r.(.2022.03.16.five-powerful-tips-for-bash-scripting#create-a-default-value-for-a-variable]]\n","n":1}}},{"i":1007,"$":{"0":{"v":"Create a Directory and Change into It at the Same Time","n":0.302},"1":{"v":"\n```bash\nmkd() { mkdir -p \"$@\" && cd \"$@\"; }\n```\n","n":0.333}}},{"i":1008,"$":{"0":{"v":"Color Output","n":0.707},"1":{"v":"\n\n##### Colorized Output In Bash\n\n- Using ANSI escape codes you can make your terminal display colored output\n\n|     Color    |      Code      |     Color    |      Code      |\n| :----------: | :------------: | :----------: | :------------: |\n|     Black    | '\\\\033\\[0;30m' |   Dark Gray  | '\\\\033\\[1;30m' |\n|      Red     | '\\\\033\\[0;31m' |   Light Red  | '\\\\033\\[1;31m' |\n|     Green    | '\\\\033\\[0;32m' |  Light Green | '\\\\033\\[1;32m' |\n| Brown/Orange | '\\\\033\\[0;33m' |    Yellow    | '\\\\033\\[1;33m' |\n|     Blue     | '\\\\033\\[0;34m' |  Light Blue  | '\\\\033\\[1;34m' |\n|    Purple    | '\\\\033\\[0;35m' | Light Purple | '\\\\033\\[1;35m' |\n|     Cyan     | '\\\\033\\[0;36m' |  Light Cyan  | '\\\\033\\[1;36m' |\n|  Light Gray  | '\\\\033\\[0;37m' |     White    | '\\\\033\\[1;37m' |\n\n- `RED='\\033[0;31m'`\n- 30-37 sets foreground color\n- 40-47 sets background color\n\n```bash\nRED='\\033[0;31m'\nNC='\\033[0m'\n\necho -e \"${LRED}Hard${NC} [1]   ${RED}Difficult${NC} [2]   ${YELLOW}Normal${NC} [3]   ${GREEN}Mild${NC} [4]   ${LGREEN}Easy${NC} [5]\"\n```\n\n###### Documentation\n\n- [SO answer](https://stackoverflow.com/questions/5947742/how-to-change-the-output-color-of-echo-in-linux#5947802)\n- [more documentation](https://misc.flogisoft.com/bash/tip_colors_and_formatting)\n","n":0.088}}},{"i":1009,"$":{"0":{"v":"Text Manip","n":0.707},"1":{"v":"\n\n### Text String Manipulation\n","n":0.5}}},{"i":1010,"$":{"0":{"v":"Text Repl","n":0.707},"1":{"v":"\n\n#### Text Replacement In Bash\n\n- Bash tip: instead of spawning an instance of `sed`, you can do text replacement in \"pure\" Bash like `status=\"${status//,/}\"`. Breaking that down:\n- `status=`   # assign a new value to the Bash variable `status`.\n- `status=\"${ ‚Ä¶ }\"` # I just always use double quotes when doing parameter (and command) substitution.\n- `status=\"${status ‚Ä¶ }\"` # the new value I am assigning to `status` is the expansion of (value of) `status`, BUT first we alter that value‚Ä¶\n- `status=\"${status//PATTERN/STRING}\"` # the `//` means \"globally replace\" (a single `/` would replace the first occurrence of PATTERN)\n\n```shell\nstatus=\"${status//,/}\"\nstatus=\"${status//PATTERN/STRING}\"\n\nfirstString=\"I love Suzi and Marry, but Suzi Most\"\nsecondString=\"Sara\"\necho \"${firstString/Suzi/$secondString}\"    # prints 'I love Sara and Marry'\n```\n\n","n":0.095}}},{"i":1011,"$":{"0":{"v":"Doc","n":1},"1":{"v":"\n\n##### Documentation\n\n- [pure bash bible](https://github.com/dylanaraps/pure-bash-bible)\n","n":0.447}}},{"i":1012,"$":{"0":{"v":"Text Blocks","n":0.707},"1":{"v":"\n\n#### Text Blocks In Bash\n\n- You can have blocks of formatted text in a script for use such as a help menu If you want some of the text to be dynamic you will need to wrap it in double quote. Also echo CAN work for this but its just better to use `cat` or `printf`\n\n```shell\ncat <<EOF\nHello world\nHow's it going?\nEOF\n# Or use printf (also efficient, printf is built-in):\nprintf %s \"\\\nHello world\nHow's it going?\n\"\n```\n\n","n":0.117}}},{"i":1013,"$":{"0":{"v":"Doc","n":1},"1":{"v":"\n\n##### Documentation\n\n- <https://mywiki.wooledge.org/BashPitfalls>\n","n":0.577}}},{"i":1014,"$":{"0":{"v":"Substring Removal","n":0.707},"1":{"v":"\n\n#### Sub-String Removal In Bash\n\nRemoving substrings without `awk`/`cut` function calls\n\n```shell\nstring=\"hello-world\"\nprefix=\"hell\"\nsuffix=\"ld\"\n\nfoo=${string#\"$prefix\"}\nfoo=${foo%\"$suffix\"}\necho \"${foo}\"\n#===#===#===#===#===#===#===#\nstring=\"hello-world\"\nprefix=\"hell\"\nsuffix=\"ld\"\n\n#remove \"hell\" from \"hello-world\" if \"hell\" is found at the beginning.\nprefix_removed_string=${string/#$prefix}\n\n#remove \"ld\" from \"o-world\" if \"ld\" is found at the end.\nsuffix_removed_String=${prefix_removed_string/%$suffix}\necho $suffix_removed_String\n#> o-wor\n\n# NOTES:\n# `#$prefix` : adding `#` makes sure that substring \"hell\" is removed only if\n# it is found in beginning.\n# `%$suffix` : adding `%` makes sure that substring \"ld\" is removed only if it\n# is found in end.\n\n# Without these, the substrings \"hell\" and \"ld\" will get removed everywhere,\n# even it is found in the middle.\n\nvar=\"apple orange\"\n# this command will print 'apple'\necho \"${var%% *}\"\n\n# This command will print 'orange'\necho \"${var##* }\"\n```\n\n\n","n":0.099}}},{"i":1015,"$":{"0":{"v":"Doc","n":1},"1":{"v":"\n\n##### Documentation\n\n- [SO Answer](https://stackoverflow.com/questions/16623835/remove-a-fixed-prefix-suffix-from-a-string-in-bash#16623897)\n- [puse bash bible](https://github.com/dylanaraps/pure-bash-bible)\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/QXineadwG4E\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n","n":0.243}}},{"i":1016,"$":{"0":{"v":"Param","n":1},"1":{"v":"\n\n#### Parameter What does it do?\n\n```shell\n${VAR^}     # Uppercase first character.\n${VAR==}    # Uppercase all characters.\n${VAR,}     # Lowercase first character.\n${VAR,,}    # Lowercase all characters.\n${VAR~}     # Reverse case of first character.\n${VAR~~}    # Reverse case of all characters.\n```\n\n```shell\n#!/usr/bin/env bash\n\nfoo() {\n\tlocal value=\"The Quick Brown FOX Jumped over The Lazy Dog.\"\n\n\tlocal -i loopCount=1000\n\tlocal -i i=0\n\tfor (( i = 0; i < loopCount; ++i )); do\n\t\tlocal newVal=\"\"\n\t\tnewVal=\"${value,}\"\n\t\tprintf \"%s\\n\" \"$newVal\"\n\tdone\n}\n\n\nbar() {\n\tlocal value=\"The Quick Brown FOX Jumped over The Lazy Dog.\"\n\n\tlocal -i loopCount=1000\n\tlocal -i i=0\n\tfor (( i = 0; i < loopCount; ++i )); do\n\t\t# shellcheck disable=SC2155\n\t\tlocal newVal=$(echo \"$value\" | tr '[:upper:]' '[:lower:]')\n\t\tprintf \"%s\\n\" \"$newVal\"\n\tdone\n}\n\nbaz() {\n\tlocal value=\"$*\"\n\n\tprintf \"%s\\n\" \"${value,,}\"\n}\n\nfoo\nbar\nbaz\n\n# Lower Case Conversion\nlower() {\n\t# Usage: lower \"string\"\n\tprintf '%s\\n' \"${1,,}\"\n}\n# Upper Case Conversion\nupper() {\n\t# Usage: upper \"string\"\n\tprintf '%s\\n' \"${1==}\"\n}\n# Reverse Case Conversion\nreverse_case() {\n\t# Usage: reverse_case \"string\"\n\tprintf '%s\\n' \"${1~~}\"\n}\n```\n","n":0.089}}},{"i":1017,"$":{"0":{"v":"Case Modify","n":0.707},"1":{"v":"\n\n#### Text Case Modification In Bash\n\n- I realize that this is beside your point, but‚Ä¶don't shell out to `tr` like you did. It's really slow and Bash has built-in facilities for manipulating strings‚Äîespecially case. Equivalent to your code `input=$(echo \"$value\" | tr '[:upper:]' '[:lower:]')` would be something like:\n- input=\"$\\*\"\n- input=\"${input,,}\"\n- We are assigning a new value to the `bash` variable `input`.  The right-hand-side of the `=` is the new value. If we used `${input}`, that would just be the value already in variable `input` The magic is in those two commas `,,`. A `,` operator after the variable name downcases the first letter of the variable and leaves the rest of the value unchanged. The double-comma `,,` operator after the variable downcases every character in the value.\n- You can use `^` and `==` for uppercasing.\n- You could have done the same in a single line with `input=\"${*,,}\"`\n- I ran the `tr` version as written above 1000 times and a \"pure\" Bash equivalent The `tr` version took 4.1 sec versus \"pure\" Bash's 0.04 sec (100 X faster).\n\n","n":0.075}}},{"i":1018,"$":{"0":{"v":"Doc","n":1},"1":{"v":"\n\n##### Documentation\n\n- See: <https://gist.github.com/cfraizer/8f17c375837f6d904bcafd3adaa8466d> for the code.\n","n":0.378}}},{"i":1019,"$":{"0":{"v":"Resources","n":1},"1":{"v":"\n\n## Resources\n\n- [BashGuide](https://mywiki.wooledge.org/BashGuide)\n- [bash cheat sheet](https://mywiki.wooledge.org/BashSheet)\n- [pure bash bible](https://github.com/dylanaraps/pure-bash-bible)\n- [Cronjobs](https://crontab.guru/)\n","n":0.316}}},{"i":1020,"$":{"0":{"v":"Redirections","n":1},"1":{"v":"\n\n### Bash Redirections\n\nWhen Bash starts, normally, 3 file descriptors are opened, 0, 1 and 2 also known as standard input (`stdin`), standard output (`stdout`) and standard error (`stderr`).\n\n| num | val      |\n| --- | -------- |\n| 0   | `stdin`  |\n| 1   | `stdout` |\n| 2   | `stderr` |\n\n```shell\n2>/dev/null\n```\n\n#### Documentation\n\n- <https://wiki.bash-hackers.org/howto/redirection_tutorial>\n","n":0.141}}},{"i":1021,"$":{"0":{"v":"Proj","n":1}}},{"i":1022,"$":{"0":{"v":"Question Extractor","n":0.707},"1":{"v":"\n\n## Projects\n\n**Question Extractor Written In Bash**\n\n```shell\nif [[ -e $1 ]]\nthen\nfilename=\"Questions $1\"\ncount=$(grep -Fc '**Q**' \"$1\")\nreport=\"$count Questions extracted from $filename\"\nprintf \"# $report \\n \\n\" > \"./$filename\"\ngrep -Fn '**Q**' \"$1\" | sed -e 's/\\*\\*Q:*\\*\\*:*//g' | sed -e 's/^/- /' >> \"$filename\"\necho $report\nelse\necho Provide a file as an argument\nfi\n```\n\nThis script will take a file as an input argument and then any lines it finds the text `**Q**` on it will extract into a list of questions in a new file called `questions_<input file name>` and also report in the CLI how many questions were extracted\n","n":0.105}}},{"i":1023,"$":{"0":{"v":"Math","n":1},"1":{"v":"\n\n#### Arithmetic Expansion\n\n- `(( [arithmetic expression] ))`\n- Evaluates the given expression in an arithmetic context.\n- That means, strings are considered names of integer variables, all operators are considered arithmetic operators (such as ++, \\\\=\\\\=, >, &lt;=, etc..) ==You should always use this for performing tests on numbers!==\n- `$(( [arithmetic expression] ))`\n- Expands the result of the given expression in an arithmetic context.\n- This syntax is similar to the previous, but expands into the result of the expansion. We use it inside other commands when we want the result of the arithmetic expression to become part of another command.\n","n":0.101}}},{"i":1024,"$":{"0":{"v":"Interpolation","n":1},"1":{"v":"\n\n### Interpolation In Bash\n\n- [Variable Interpolation](https://en.wikipedia.org/wiki/String_interpolation)\n\nIn computer programming, string interpolation is the process of evaluating a string literal containing one or more placeholders, yielding a result in which the placeholders are replaced with their corresponding values. It is a form of simple template processing or, in formal terms, a form of quasi-quotation.\n\n```shell\n#  Documentation\nvar=\"theres no place like '$HOME'\"\necho \"$var\"\n#> theres no place like /Users/bryanjenks\n```\n","n":0.126}}},{"i":1025,"$":{"0":{"v":"Ifs","n":1},"1":{"v":"\n\n### Internal Field Separator - IFS\n\n`IFS` = Internal Field Separator.\n\nUnbelievable as it may seem, [[POSIX|posix]] requires the treatment of IFS as a field terminator, rather than a field separator. What this means in our example is that if there's an empty field at the end of the input line, it will be discarded:\n\n```shell\n\nIFS=, read -ra fields <<< \"a,b,\"\ndeclare -p fields\n#> declare -a fields='([0]=\"a\" [1]=\"b\")'\n\n```\n\nWhere did the empty field go? It was eaten for historical reasons (\"because it's always been that way\"). This behavior is not unique to bash; all conforming shells do it. A non-empty field is properly scanned:\n\n```shell\n\nIFS=, read -ra fields <<< \"a,b,c\"\ndeclare -p fields\n#> declare -a fields='([0]=\"a\" [1]=\"b\" [2]=\"c\")'\n\n```\n\nSo, how do we work around this nonsense? As it turns out, appending an `IFS` character to the end of the input string will force the scanning to work. If there was a trailing empty field, the extra `IFS` character \"terminates\" it so that it gets scanned. If there was a trailing non-empty field, the `IFS` &lt;character creates a new, empty field that gets dropped.\n\n```shell\n\ninput=\"a,b,\"\nIFS=, read -ra fields <<< \"$input,\"\ndeclare -p fields\n#> declare -a fields='([0]=\"a\" [1]=\"b\" [2]=\"\")'\n\n```\n\n<https://mywiki.wooledge.org/BashPitfalls>\n<https://mywiki.wooledge.org/IFS>\n","n":0.073}}},{"i":1026,"$":{"0":{"v":"Get Opts","n":0.707},"1":{"v":"\n\n##### Get Opts In Bash\n\nhow to get flag options in a bash script\n\n```bash\n#  Documentation\na_flag=''\nb_flag=''\nfiles=''\nverbose='false'\n\nprint_usage() {\n\tprintf \"Usage: ...\"\n}\n\nwhile getopts 'abf:v' flag; do\n\tcase \"${flag}\" in\n\t\ta) a_flag='true' ;;\n\t\tb) b_flag='true' ;;\n\t\tf) files=\"${OPTARG}\" ;;\n\t\tv) verbose='true' ;;\n\t\t*) print_usage\n\t\t   exit 1 ;;\n\tesac\ndone\n```\n\n###### Documentation\n\n- [SO Article](https://stackoverflow.com/questions/7069682/how-to-get-arguments-with-flags-in-bash#21128172)\n","n":0.162}}},{"i":1027,"$":{"0":{"v":"Funcs","n":1},"1":{"v":"\n\n#### Functions In Bash\n\n- [[s.l.bash.vars]] assigned outside of functions can be overwritten in functions and display aberrant results if local isn't used.\n\n```bash\nfoo=\"bar\"\necho \"top level: $foo\"\n\nmain(){\n\tfoo=\"func bar\"\n\techo \"func $foo\"\n}\nmain\necho \"end $foo\"\n\n# OUTPUT:\n#> top level: bar\n#> func func bar\n#> end func bar\n\n#===#===#===#===#===#===#\n\nfoo=\"bar\"\necho \"top level: $foo\"\n\nmain(){\n\tlocal foo=\"func bar\"\n\techo \"func $foo\"\n}\nmain\necho \"end $foo\"\n\n# OUTPUT:\n#> top level: bar\n#> func func bar\n#> end bar\n```\n\n- Do not use the function keyword, it reduces compatibility with older versions of bash.\n\n```bash\n# Right.\ndo_something() {\n\t# ...\n}\n\n# Wrong.\nfunction do_something() {\n\t# ...\n}\n```\n\n```bash\n# Current function.\n\"${FUNCNAME[0]}\"\n\n# Parent function.\n\"${FUNCNAME[1]}\"\n\n# So on and so forth.\n\"${FUNCNAME[2]}\"\n\"${FUNCNAME[3]}\"\n\n# All functions including parents.\n\"${FUNCNAME[@]}\"\n```\n","n":0.104}}},{"i":1028,"$":{"0":{"v":"Flow","n":1},"1":{"v":"\n\n##### Bash Test Conditionals\n\n- Testing conditions is down to using square bracket syntax:\n\n```bash\nif [ 1 = 3 ] || [ 2 = 2 ]; then\necho \"yes!\"\nfi\n```\n\n- To note, double brackets are a BASH-ism and not POSIX compliant.\n  To test multiple conditions for the same evaluation do not use the\n  internal `-a` for and or the `-o` for or like:\n\n```bash\nif [ 1 = 3 -o 2 = 2 ]; then\necho \"yes!\"\nfi\n```\n\n- Instead separate the tests into separate commands with the `&&` operator.\n  This way it will run each test as a separate command, AND it will only\n  continue forward if the condition is true:\n- `<this has to be true> && \"AND\" <this has to be true, to continue>`.\n- Double quote [[Bash Variables|variables]] use in the test condition unless you\n  explicitly know and understand why they should be unquoted.\n","n":0.085}}},{"i":1029,"$":{"0":{"v":"Ternary Test","n":0.707},"1":{"v":"\n\n##### Ternary Tests\n\n- [pure bash bible](https://github.com/dylanaraps/pure-bash-bible)\n\n```bash\n# Ternary Tests\n## Set the value of var to var2 if var2 is greater than var.\n## var: variable to set.\n## var2>var: Condition to test.\n## ?var2: If the test succeeds.\n## :var: If the test fails.\n((var=var2>var?var2:var))\n```\n","n":0.16}}},{"i":1030,"$":{"0":{"v":"Loops","n":1},"1":{"v":"\n\n##### Loops In Bash\n\n- For looping over all positional arguments / words sent to the command you can use the following:\n\n```bash\nfor arg in \"$@\"\n# Or simply:\nfor arg\n```\n\n- Since looping over the positional parameters is such a common thing to do in\n  scripts, for arg defaults to for arg in `\"$@\"`. The double-quoted `\"$@\"` is\n  special magic that causes each parameter to be used as a single word (or a\n  single loop iteration). It's what you should be using at least 99% of the time.\n\n```bash\n# Correct version\n\nfor x in \"$@\"; do\n\techo \"parameter: '$x'\"\ndone\n\n# or better:\n\nfor x do\n\techo \"parameter: '$x'\"\ndone\n\n$ ./myscript 'arg 1' arg2 arg3\n\n#> parameter: 'arg 1'\n#> parameter: 'arg2'\n#> parameter: 'arg3'\n```\n\n```bash\ndo [command list]; done\n```\n\n- This constitutes the actual loop that is used by the next few commands.\n  The list of commands between the do and done are the commands that will be executed in every iteration of the loop.\n\n```bash\nfor [name] in [words]\n```\n\n- The next loop will iterate over each WORD after the in keyword.\n  The loop's commands will be executed with the value of the variable denoted by name set to the word.\n\n```bash\nfor (( [arithmetic expression]; [arithmetic expression]; [arithmetic expression] ))\n```\n\n- The next loop will run as long as the second arithmetic expression remains true.\n  The first arithmetic expression will be run before the loop starts. The third arithmetic expression will be run after the last command in each iteration has been executed.\n\n```bash\nwhile [command list]\n```\n\n- The next loop will be repeated for as long as the last command ran in the command list exits successfully.\n\n```bash\nuntil [command list]\n```\n\n- The next loop will be repeated for as long as the last command ran in the command list exits unsuccessfully (\"fails\").\n\n```bash\nselect [name] in [words]\n```\n\n- The next loop will repeat forever, letting the user choose between the given words.\n- The iteration's commands are executed with the variable denoted by name's value set to the word chosen by the user. Naturally, you can use break to end this loop.\n","n":0.056}}},{"i":1031,"$":{"0":{"v":"For","n":1},"1":{"v":"\n\n```bash\nfor filename in *; do echo \"put ${filename}\"; done\n\nfor file in *; do \n    if [ -f \"$file\" ]; then \n        echo \"$file\" \n    fi \n```\n","n":0.196}}},{"i":1032,"$":{"0":{"v":"If Else","n":0.707},"1":{"v":"\n\n##### Bash IF Statements\n\n- Many beginners have an incorrect intuition about `if` statements brought about by seeing the very common pattern of an if keyword followed immediately by a `[` or `[[`. This convinces people that the `[` is somehow part of the `if` statement's syntax, just like parentheses used in C's if statement.\n- This is not the case! `if` takes a command. `[` is a command, not a syntax marker for the if statement. It's equivalent to the test command, except that the final argument must be a `]`. For example:\n\n```bash\n# POSIX\nif [ false ]; then echo \"HELP\"; fi\nif test false; then echo \"HELP\"; fi\n```\n\n- Are equivalent -- both checking that the argument \"false\" is non-empty. In both cases HELP will always be printed, to the surprise of programmers from other languages guessing about shell syntax.\n- The syntax of an if statement is:\n\n```bash\nif COMMANDS\nthen <COMMANDS>\nelif <COMMANDS> # optional\nthen <COMMANDS>\nelse <COMMANDS> # optional\nfi # required\n```\n","n":0.08}}},{"i":1033,"$":{"0":{"v":"Case","n":1},"1":{"v":"\n\n##### Bash Case Statements\n\n- Case statement syntax in bash is a little strange but also really easy and they are very friendly and nice.\n- case will look for a value in a list of options, each option is appended with a paren then the commands that this option will run. these options can also expand with wild cards. To have a final catch all statement for anything that didnt meet a prior condition use `*` as the final case option.\n\n```bash\ncase \"$RESPONSE\" in\nn) exit ;;\nN) exit ;;\nq) exit ;;\nQ) exit ;;\ny) mkdir $DIR && touch $TEMPLATE_DECK && echo \"category1:question1:answer1\" >> $TEMPLATE_DECK && echo \"category2:question2:answer2\" >> $TEMPLATE_DECK && echo \"category3:question3:answer3\" >> $TEMPLATE_DECK && echo \"$DIR_MADE_MSG\" ;;\nY) mkdir $DIR && touch $TEMPLATE_DECK && echo \"category1:question1:answer1\" >> $TEMPLATE_DECK && echo \"category2:question2:answer2\" >> $TEMPLATE_DECK && echo \"category3:question3:answer3\" >> $TEMPLATE_DECK && echo \"$DIR_MADE_MSG\" ;;\n*) echo \"invalid choice, please select either 'y' or 'n'\" ;;\nesac\n```\n","n":0.082}}},{"i":1034,"$":{"0":{"v":"Files","n":1},"1":{"v":"\n\n### File Handling\n\n#### Using Temp Files With Bash\n\n- Temp files are stored in the `/tmp/` directory and will need to be removed upon script completion. Why use a temp file or directory? Because it will make it easier to have a storing place of a file that holds some information you want to be read, or just act as an intermediary file/directory.\n\n```bash\n#  Documentation\n# All temp files need those X's for randomization\n# check out `man mktemp` for more details\ntmpfile=$(mktemp /tmp/abc-script.XXXXXX)\n\n# <CODE>\n\nrm \"$tmpfile\"\n```\n\n##### Documentation\n\n- [SO answer](https://unix.stackexchange.com/questions/181937/how-create-a-temporary-file-in-shell-script)\n","n":0.109}}},{"i":1035,"$":{"0":{"v":"Avoid Name Conflicts","n":0.577},"1":{"v":"\n\n### Avoid conflicts with filenames that start with a dash\n\n```bash\n# -- indicates the end of the options section\n# -myFile.txt uses a dash after the options section to avoid conflicts\ncat -- -myFile.txt\n```\n","n":0.18}}},{"i":1036,"$":{"0":{"v":"Fencing","n":1},"1":{"v":"\n\n### Brace, Bracket, & Paren Notation\n","n":0.408}}},{"i":1037,"$":{"0":{"v":"Square Brackets","n":0.707},"1":{"v":"\n\n#### Brackets\n\n<http://wiki.bash-hackers.org/scripting/obsolete>\n\n```shell\nif [ CONDITION ]    # Test construct\nif [[ CONDITION ]]  # Extended test construct\nArray[1]=element1   # Array initialization\n[a-z]               # Range of characters within a Regular Expression\n$[ expression ]     # A non-standard & obsolete version of $(( expression )) \n```\n\nSingle brackets are also used for array indices:\n\n```shell\narray[4]=\"hello\"\n\nelement=${array[index]}\n```\n","n":0.147}}},{"i":1038,"$":{"0":{"v":"Parens","n":1},"1":{"v":"\n\n#### Parentheses\n\n```shell\n( command1; command2 )             # Command group executed within a subshell\nArray=(element1 element2 element3) # Array initialization\nresult=$(COMMAND)                  # Command substitution, new style\n>(COMMAND)                         # Process substitution\n<(COMMAND)                         # Process substitution\n```\n\n#### Double Parentheses\n\n```shell\n(( var = 78 ))            # Integer arithmetic\nvar=$(( 20 + 5 ))         # Integer arithmetic, with variable assignment\n(( var++ ))               # C-style variable increment\n(( var-- ))               # C-style variable decrement\n(( var0 = var1<98?9:21 )) # C-style ternary operation\n```\n\n```shell\n((a++))\n\n((meaning = 42))\n\nfor ((i=0; i<10; i++))\n\necho $((a + b + (14 * c)))\n```\n\nand they enable you to omit the dollar signs on integer and array variables and include spaces around operators for readability.\n","n":0.101}}},{"i":1039,"$":{"0":{"v":"Braces","n":1},"1":{"v":"\n\n#### Curly Braces\n\n```shell\n${variable}                             # Parameter substitution\n${!variable}                            # Indirect variable reference\n{ command1; command2; . . . commandN; } # Block of code\n{string1,string2,string3,...}           # Brace expansion\n{a..z}                                  # Extended brace expansion\n{}                                      # Text replacement, after find and xargs\n```\n","n":0.169}}},{"i":1040,"$":{"0":{"v":"Exist Status","n":0.707},"1":{"v":"\n\n### Exit Status In Bash\n\n- You can check the exit status with the exit status variable:\n\n```shell\necho \"My script's exit status is '$?'\"\n```\n\n- `$?` is only required if you need to retrieve the exact status of the previous command. If you only need to test for success or failure (any non-zero status), just test the command directly. e.g.:\n\n```shell\nif cmd; then\n...\nfi\n```\n\n#### Documentation\n\n- <https://mywiki.wooledge.org/BashPitfalls>\n","n":0.128}}},{"i":1041,"$":{"0":{"v":"Doc","n":1},"1":{"v":"\n\n#### Documentation\n\n- [bashtips](https://drawings.jvns.ca/bashtips/)\n- [quoting variables SO](https://stackoverflow.com/questions/10067266/when-to-wrap-quotes-around-a-shell-variable#10067297)\n","n":0.408}}},{"i":1042,"$":{"0":{"v":"Cmd Sub","n":0.707},"1":{"v":"\n\n#### Command Substitution\n\n- `( [command list] )`\n- Execute the list of commands in a subshell.\n- This is exactly the same thing as the command grouping above, only, the commands are executed in a subshell. Any code that affects the environment such as variable assignments, cd, export, etc. do not affect the main script's environment but are scoped within the brackets.\n- **\\*Note:** You do not need a `;` before the closing `)`.\n","n":0.119}}},{"i":1043,"$":{"0":{"v":"Cmd List","n":0.707},"1":{"v":"\n\n#### Command Lists\n\n- `{ [command list]; }`\n- Execute the list of commands in the current shell as though they were one command.\n- Command grouping on its own isn't very useful. However, it comes into play wherever Bash syntax accepts only one command while you need to execute multiple.\n- For example, you may want to pass output of multiple commands via a pipe to another command's input:\n-\n\n```bash\n{ ls .; ls ..; } | grep file-name\n```\n\n- Or you may want to execute multiple commands after a || operator:\n\n```bash\nrm file || { echo \"Removal failed, aborting.\"; exit 1; }\n```\n\n- It is also used for [[s.l.bash.funcs]] bodies. Technically, this can also be used for loop bodies though this is undocumented, not portable and we normally prefer `do ...; done` for this):\n\n```bash\nfor digit in 1 9 7; { echo \"$digit\"; }       # non-portable, undocumented, unsupported\n- for digit in 1 9 7; do echo \"$digit\"; done   # preferred\n```\n\n- **\\*Note**: You need a `;` before the closing `}` (or it must be on a new line).\n- Command Lists are similar but not identical to\n","n":0.075}}},{"i":1044,"$":{"0":{"v":"Cdpath","n":1},"1":{"v":"\n\n##### CDPATH\n\n- `CDPATH` is an environmental variable that makes it so that when using the `cd` command it will list items in your current directory\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/4-Nun5c3qeA\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n","n":0.16}}},{"i":1045,"$":{"0":{"v":"Awk","n":1},"1":{"v":"\n## Resources\n\n- [Built in functions](https://www.gnu.org/software/gawk/manual/html_node/Built_002din.html#Built_002din)\n","n":0.447}}},{"i":1046,"$":{"0":{"v":"Example","n":1},"1":{"v":"\n```bash\n#!/usr/bin/env bash\n\n#===#===#===#===#===#===#===#===#===#===#===#===#===#===#===#===#===#===#===#===#\necho \"=====Grab a field=====\"\nread\necho \"hello world this is Bryan\" | awk '{print $1,$5}'\nread\n#===#===#===#===#===#===#===#===#===#===#===#===#===#===#===#===#===#===#===#===#\necho \"=====Grab a column=====\"\nread\n\necho \"ajay manager account 45000\nsunil clerk account 25000\nvarun manager sales 50000\namit manager account 47000\ntarun peon sales 15000\ndeepak clerk sales 23000\nsunil peon sales 13000\nsatvik director purchase 80000\" | awk '{print}' \nread\n\necho \"ajay manager account 45000\nsunil clerk account 25000\nvarun manager sales 50000\namit manager account 47000\ntarun peon sales 15000\ndeepak clerk sales 23000\nsunil peon sales 13000\nsatvik director purchase 80000\" | awk '{print $4}' \nread\n\n#===#===#===#===#===#===#===#===#===#===#===#===#===#===#===#===#===#===#===#===#\necho \"=====Selectively output fields=====\"\nread\n\necho \"ajay manager account 45000\nsunil clerk account 25000\nvarun manager sales 50000\namit manager account 47000\ntarun peon sales 15000\ndeepak clerk sales 23000\nsunil peon sales 13000\nsatvik director purchase 80000\" | awk '/manager/ {print}'\nread\n\n#===#===#===#===#===#===#===#===#===#===#===#===#===#===#===#===#===#===#===#===#\necho \"=====Variables=====\"\necho \"\\$0 -- The whole line\"\nread\necho \"Hello World\" | awk '{print $0}'\nread\necho \"NR -- The Number of Records\"\nread\n\necho \"ajay manager account 45000\nsunil clerk account 25000\nvarun manager sales 50000\namit manager account 47000\ntarun peon sales 15000\ndeepak clerk sales 23000\nsunil peon sales 13000\nsatvik director purchase 80000\" | awk '{print NR}'\nread\n\necho \"ajay manager account 45000\nsunil clerk account 25000\nvarun manager sales 50000\namit manager account 47000\ntarun peon sales 15000\ndeepak clerk sales 23000\nsunil peon sales 13000\nsatvik director purchase 80000\" | awk '{print $NR}'\nread\n\necho \"ajay manager account 45000\nsunil clerk account 25000\nvarun manager sales 50000\namit manager account 47000\ntarun peon sales 15000\ndeepak clerk sales 23000\nsunil peon sales 13000\nsatvik director purchase 80000\" | awk '{print $0}'\nread\n\necho \"NF -- Number of Fields\"\nread\n\necho \"ajay manager account 45000\nsunil clerk account 25000\nvarun manager sales 50000\namit manager account 47000\ntarun peon sales 15000\ndeepak clerk sales 23000\nsunil peon sales 13000\nsatvik director purchase 80000\" | awk '{print NF}'\nread\n\necho \"ajay manager account 45000\nsunil clerk account 25000\nvarun manager sales 50000\namit manager account 47000\ntarun peon sales 15000\ndeepak clerk sales 23000\nsunil peon sales 13000\nsatvik director purchase 80000\" | awk '{print $NF}' \nread\n\necho \"ajay manager account 45000\nsunil clerk account 25000\nvarun manager sales 50000\namit manager account 47000\ntarun peon sales 15000\ndeepak clerk sales 23000\nsunil peon sales 13000\nsatvik director purchase 80000\" | awk '{print $1,NF}' \nread\n\n#===#===#===#===#===#===#===#===#===#===#===#===#===#===#===#===#===#===#===#===#\necho \"=====Format some output=====\"\nread\n\necho \"ajay manager account 45000\nsunil clerk account 25000\nvarun manager sales 50000\namit manager account 47000\ntarun peon sales 15000\ndeepak clerk sales 23000\nsunil peon sales 13000\nsatvik director purchase 80000\" | awk '{print NR \" - \" $1}'\nread\n\n#===#===#===#===#===#===#===#===#===#===#===#===#===#===#===#===#===#===#===#===#\necho \"=====BEGIN and END=====\n\nBEGIN and END are special conditions that only get triggered once per run\n\nBEGIN gets triggered before processing any line\nEND gets triggered after all lines have been processed\"\nread\n\necho \"Using BEGIN on the data set:\n\najay manager account 45000\nsunil clerk account 25000\nvarun manager sales 50000\namit manager account 47000\ntarun peon sales 15000\ndeepak clerk sales 23000\nsunil peon sales 13000\nsatvik director purchase 80000\"\nread\n\necho \"ajay manager account 45000\nsunil clerk account 25000\nvarun manager sales 50000\namit manager account 47000\ntarun peon sales 15000\ndeepak clerk sales 23000\nsunil peon sales 13000\nsatvik director purchase 80000\" | awk 'BEGIN {print NR}' \nread\n\necho \"Using END on the data set:\"\nread\n\necho \"ajay manager account 45000\nsunil clerk account 25000\nvarun manager sales 50000\namit manager account 47000\ntarun peon sales 15000\ndeepak clerk sales 23000\nsunil peon sales 13000\nsatvik director purchase 80000\" | awk 'END {print NR}'\nread\n\n#===#===#===#===#===#===#===#===#===#===#===#===#===#===#===#===#===#===#===#===#\necho \"=====Setting a delimiter=====\"\nread\n\necho \"ajay/manager/account/45000\nsunil/clerk/account/25000\nvarun/manager/sales/50000\namit/manager/account/47000\ntarun/peon/sales/15000\ndeepak/clerk/sales/23000\nsunil/peon/sales/13000\nsatvik/director/purchase/80000\" | awk -F/ '{print $1,$4}' \n# -F can take regex '[,-/]' to determine the delimiter, a `/` in this case\nread\n```\n","n":0.045}}},{"i":1047,"$":{"0":{"v":"Infrastructure As Code","n":0.577}}},{"i":1048,"$":{"0":{"v":"Ansible","n":1},"1":{"v":"\nREVISIT <https://youtu.be/w9eCU4bGgjQ>\n","n":0.707}}},{"i":1049,"$":{"0":{"v":"Data Formats","n":0.707}}},{"i":1050,"$":{"0":{"v":"Yaml","n":1},"1":{"v":"\n\n- [This is the wikipedia page for YAML](https://en.wikipedia.org/wiki/YAML)\n- [YAML validator tool](https://yamlvalidator.com/)\n","n":0.302}}},{"i":1051,"$":{"0":{"v":"Tips Tricks","n":0.707}}},{"i":1052,"$":{"0":{"v":"Multiple Docs in Single File","n":0.447},"1":{"v":"\n\n## Multiple YAML Docs in a single file\n\nIn YAML the compile sees `---` as a separator between 2 different YAML documents\n\n```yaml\nname: \"File one\"\nage: \"one day\"\nplanet: \"earth\"\n---\nname: \"File two\"\nage: \"two billion light years\"\nplanet: \"Jupiter\"\n```\n","n":0.174}}},{"i":1053,"$":{"0":{"v":"Multi Line Strings","n":0.577},"1":{"v":"\n\n## Multi-line strings\n\n### Literal Block\n\nThis preserves the `\\n` character at the end of each line, such as in a list of executed CLI commands\n\n```yaml\nscript: |\n    echo \"hello world\" > file.txt\n    cat file.txt\n    sed s/hello/Hello/g file.txt > file2.txt\n    mv file2.txt file.txt\n```\n\n### Folded Block Approach\n\nThis treats the text as a single run on sentance with no new lines akin to: \n\n`script: Hello there This is some text but will be on the same line as the previous text`\n\n```yaml\nscript: >\n    Hello there\n    This is some text\n    but will be on the same line as the previous text\n```\n","n":0.103}}},{"i":1054,"$":{"0":{"v":"Explicit Tags","n":0.707},"1":{"v":"\n\n## Explicit Tags\n\nFor data type casting\n\n```yaml\nnumbers:\n    num1: !!int 1.0 # converted to 1\n    num2: !!float 100 # converted to 100.0\n    num3: !!str 150 # converted to \"150\"\n```\n","n":0.192}}},{"i":1055,"$":{"0":{"v":"Anchors","n":1},"1":{"v":"\n\n## Anchors\n\n```yaml\nman:\n  name: Utibe\n  age: 1000\n  galaxy: milky-way\n  dinosaursExist: no\nalien:\n  name: kal-el\n  age: 10000000\n  galaxy: milky-way\n  dinosaursExist: no\nnames:\n  - Utibe\n  - kal-el\n```\n\n> As you can see, we have a names key that lists the `names` of both `man` and `alien`.\n> However, this is not ideal as we are writing out the names multiple times and if the name changes we have to change each reference to it.\n> YAML has a feature known as anchors that allows us to reference a value. Here‚Äôs how it works\n\n```yaml\nman:\n  name: &man Utibe\n  age: 1000\n  galaxy: milky-way\n  dinosaursExist: no\nalien:\n  name: &alien kal-el\n  age: 10000000\n  galaxy: milky-way\n  dinosaursExist: no\nnames:\n  - *man\n  - *alien\n```\n\n### Remove Redundancy With Anchors\n\n```yaml\nmetadata: &metadata\n  galaxy: milky-way\n  dinosaursExist: no\nman:\n  name: &man Utibe\n  age: 1000\n  <<: *metadata\nalien:\n  name: &alien kal-el\n  age: 10000000\n  <<: *metadata\nnames:\n  - *man\n  - *alien\n```\n\nAnd to overide standard template metadata in this example with specific values simply overwrite at the end as if the last thing read is what happens like in [[s.m.css]]\n\n```yaml\nman:\n  name: &man Utibe\n  age: 1000\n  <<: *metadata\n  galaxy: another-galaxy\n```\n","n":0.076}}},{"i":1056,"$":{"0":{"v":"Xml","n":1},"1":{"v":"\n\n- <https://docs.python.org/3/library/xml.html>\n- [Socratica Video XML Walkthrough](https://youtu.be/j0xr0-IAqyk)\n","n":0.408}}},{"i":1057,"$":{"0":{"v":"Json","n":1}}},{"i":1058,"$":{"0":{"v":"Hl7","n":1},"1":{"v":"\n\n- HL7\n  - HL7 terms to better understand what is HL7. There are four primary HL7 standard message types:\n  - Patient Administration ([ADT](http://www.corepointhealth.com/resource-center/hl7-resources/hl7-adt))\n  - Orders ([ORM](http://www.corepointhealth.com/resource-center/hl7-resources/hl7-orm-message)'s)\n  - Results ([ORU](http://www.corepointhealth.com/resource-center/hl7-resources/hl7-oru-message)'s)\n  - Charges ([DFT](http://www.corepointhealth.com/resource-center/hl7-resources/hl7-dft-detail-financial-transaction)'s)\n  - Most commonly used HL7 message types include:\n    - [ACK](https://corepointhealth.com/resource-center/hl7-resources/hl7-acknowledgement-ack) ‚Äì General acknowledgement\n    - [ADT](https://corepointhealth.com/resource-center/hl7-resources/hl7-adt) ‚Äì Admit, Discharge, Tranfser\n    - BAR ‚Äì Add/change billing account\n    - [DFT](https://corepointhealth.com/resource-center/hl7-resources/hl7-dft-detail-financial-transaction)¬†‚Äì Detailed financial transaction\n    - [MDM](https://corepointhealth.com/resource-center/hl7-resources/hl7-mdm-message) ‚Äì Medical document management\n    - MFN ‚Äì Master files notification\n    - [ORM](https://corepointhealth.com/resource-center/hl7-resources/hl7-orm-message) ‚Äì Order (Pharmacy/treatment)\n    - [ORU](https://corepointhealth.com/resource-center/hl7-resources/hl7-oru-message) ‚Äì Observation result (unsolicited)\n    - QRY ‚Äì Query, original mode\n    - RAS ‚Äì Pharmacy/treatment administration\n    - [RDE](https://corepointhealth.com/resource-center/hl7-resources/hl7-rde-message-pharmacy) ‚Äì Pharmacy/treatment encoded order\n    - RGV ‚Äì Pharmacy/treatment give\n    - [SIU](https://corepointhealth.com/resource-center/hl7-resources/hl7-siu-message) ‚Äì Scheduling information unsolicited\n","n":0.094}}},{"i":1059,"$":{"0":{"v":"Csv","n":1}}},{"i":1060,"$":{"0":{"v":"Database","n":1}}},{"i":1061,"$":{"0":{"v":"Postgres","n":1}}},{"i":1062,"$":{"0":{"v":"Neo4j","n":1},"1":{"v":"\nREVISIT\n","n":1}}},{"i":1063,"$":{"0":{"v":"Ms Sql Server","n":0.577}}},{"i":1064,"$":{"0":{"v":"Tools","n":1}}},{"i":1065,"$":{"0":{"v":"Ssms","n":1}}},{"i":1066,"$":{"0":{"v":"Sqlcmd","n":1},"1":{"v":"\n\nSQL Server CLI client in [[s.l.powershell]]\n\nNot a part of SQL Server directly, but SQL Server includes an extension to Powershell called a `powershell provider`\n","n":0.204}}},{"i":1067,"$":{"0":{"v":"Server Profiler","n":0.707},"1":{"v":"\n\n- SQL Server Profiler\n  - Allows a trace of all commands being sent to SQL Server\n    - Every single thing that requires a command to be sent to SQL Server to do something\n    - Can save log to a file or a table\n    - Also useful when you want to optimize performance of SQL Server and queries\n","n":0.132}}},{"i":1068,"$":{"0":{"v":"Database Projects","n":0.707},"1":{"v":"\n<https://docs.microsoft.com/en-us/sql/azure-data-studio/extensions/sql-database-project-extension?view=sql-server-ver16>\n","n":1}}},{"i":1069,"$":{"0":{"v":"Database Engine Tuning Advisor","n":0.5},"1":{"v":"\n- Database Engine Tuning Advisor\n  - Optimizes performance of SQL Server\n  - Does this by analyzing the commands it sees being sent to SQL Server and figuring out the best place to put indexes and that sort of thing\n  - Typically you complete a trace using Profiler (above) then feed it into the Tuning Advisor\n","n":0.135}}},{"i":1070,"$":{"0":{"v":"Default Ports","n":0.707},"1":{"v":"\n\n| Port number    | Type        | Use                                                                |\n|----------------|-------------|--------------------------------------------------------------------|\n| 135            | TCP         | WMI, MSDTC, Agent file copy, T-SQL debugging                       |\n| [[n.port.80]]             | TCP         | To publish SQL Server Reporting Services (SSRS) reports using HTTP |\n| [[n.port.443]]           | TCP         | To publish SSRS reports using HTTPS                                |\n| 500            | UDP         | IPSec to encrypt connections                                       |\n| 1024 to 5000   | TCP         | Dynamic ports for named instances                                  |\n| [[n.port.1433]]          | TCP         | Database engine default instance                                   |\n| 1434           | TCP and UDP | DAC and the SQL Browse                                             |\n| 2382           | UDP         | SQL Server Analysis Services with dynamic ports                    |\n| 2383           | TCP         | SQL Server Analysis Services (SSAS)                                |\n| 2725           | TCP         | SQL Server Analysis Services (SSAS)                                |\n| 3343           | UDP         | Cluster network driver                                             |\n| 3882           | TCP         | SQL Server Integration Services (SSIS)                             |\n| 4022           | TCP         | SQL Broker Service                                                 |\n| 4500           | UDP         | IPSec                                                              |\n| 5000 to 5099   | UDP         | Clusters                                                           |\n| 5022           | TCP         | AlwaysOn                                                           |\n| 7022           | TCP         | Database Mirroring                                                 |\n| 8011 to 8031   | UDP         | Cluster internode                                                  |\n| 49152 to 65535 | TCP         | More dynamic ports for named instances                             |\n","n":0.072}}},{"i":1071,"$":{"0":{"v":"Mongodb","n":1}}},{"i":1072,"$":{"0":{"v":"Containers","n":1}}},{"i":1073,"$":{"0":{"v":"Kubernetes","n":1},"1":{"v":"\n\nREVISIT <https://youtu.be/SC7lLm6QAb8>\n","n":0.707}}},{"i":1074,"$":{"0":{"v":"Kuber","n":1},"1":{"v":"\n\n[[r.+.kubernetes-course-full-beginners-tutorial-containerize-your-apps]]\n","n":1}}},{"i":1075,"$":{"0":{"v":"Docker","n":1}}},{"i":1076,"$":{"0":{"v":"Tools","n":1}}},{"i":1077,"$":{"0":{"v":"Portainer","n":1},"1":{"v":"\n![portainer](/assets/images/2022-01-27-10-42-50.png)\n","n":1}}},{"i":1078,"$":{"0":{"v":"Tips and Tricks","n":0.577}}},{"i":1079,"$":{"0":{"v":"Modify Container Filesystem","n":0.577},"1":{"v":"\n## Modifying a Docker Container's Filesystem\n\n```bash\ndocker exec-it container bash\n```\n\n> From here, you are free to use normal Linux commands. If you want to do this remotely, you can [install an SSH server in your container][1], and bind port 22 to another port on the host.\n\n[1]: https://www.cloudsavvyit.com/13937/how-to-ssh-into-a-docker-container/\n","n":0.147}}},{"i":1080,"$":{"0":{"v":"Docker File","n":0.707},"1":{"v":"\n## Tips\n\n- consider each line of the docker a layer of the abstraction this comes into play in the next example.\n- Docker files MUST start with `FROM` but after that you can also add data like:\n\n```docker\nFROM python:3.9.7\nMAINTAINER Bryan Jenks bryan@bryanjenks.dev\n```\n\n- When you build your docker image from a docker file with [[s.containers.docker.cmd.build]] each command in the file create a new image and the layers are plastered on top, but each layer is cached so when you change things iteratively, only the changed items onward get re-ran. Essentially lazy loading.\n\n## Base example of having to install all your dependencies and everything\n\nNegates the utility of docker if the image is not just \"good to go\" but here's how to do this\n\n---\n\n```docker\nFROM python:3.9.7\nWORKDIR /usr/src/app\nCOPY requirements.txt ./\nRUN pip install --no-cache-dir -r requirements.txt\nCOPY . .\nCMD [\"uvicorn\", \"app.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n```\n\n---\n\n- `FROM python:3.9.7`\n  - Specify what python version to run in the base image\n  - \"python\" is the image\n  - \"3.9.7\" is the version of that image\n- `WORKDIR /usr/src/app`\n  - \"/usr/src\" is a valid path in the image\n  - \"/app\" is the path we want to tack on and create for our app code\n- `COPY requirements.txt ./`\n  - Grab the requirements file into the image\n- `RUN pip install --no-cache-dir -r requirements.txt`\n  - Install dependencies\n- `COPY . .`\n  - \".\" first dot is current directory, second \".\" is `WORKDIR`\n  - Move our source code into the image\n  - This is where layering comes into play, when you change source code files\n    - The only thing that changed was source code so this step and below is what gets re-ran\n  - Each layers results are cached, so when you change something it only re-runs steps where something has changed compared to the cached image layers.\n    - Only changed source code? then only re-run the step where we copy over source code files\n- `CMD [\"uvicorn\", \"app.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]`\n  - The array of commands to run once the image is spun up\n  - each array items is either a switch or a param\n  - essentially any time you have a space between anything in the command that is when you make a separate item in the array for it.\n\nAt this point you can now create the image using [[s.containers.docker.cmd.build]]\n\n## Security\n\nSpecify a `USER` in the docker file like `USER 1000` so that processes do not run as root and prevent potential security risk\n\n## Multi-Stage\n\nReduce container size by not building on top of a big image\n\n```docker\nFROM golang:1.14.2-alpine3.11 AS builder\nENV GOPATH /go\nWORKDIR /$GOPATH/src/croc-hunter/\nCOPY croc-hunter.go /go/src/croc-hunter/\nRUN go get -d -v\nRUN go build -o /go/bin/croc-hunter\n\nFROM alpine:3.11 AS runtime\nUSER 1000\nWORKDIR /app\nCOPY static/ static/\nCOPY --from=builder /go/bin/croc-hunter /app/croc-hunter\nEXPOSE 8080\nCMD [ \"/app/croc-hunter\" ]\n```\n\n## Dynamic Port exposure\n\nyou can set the docker file to use `EXPOSE ${PORT}` in the docker file and then pass in that value during the `docker run` command. It also helps to have the deployed code rely on the environmental variable as well so everything is dynamic based on the arguments fed to the container:\n\n```bash\ndocker run -e PORT=3000 -p 3000:3000 --name croc-hunter croc-hunter-port:1\n```\n\n\n","n":0.045}}},{"i":1081,"$":{"0":{"v":"Docker Compose","n":0.707},"1":{"v":"\n## Configuration File\n\n`docker-compose.yml`\n\n```yml\nversion: \"3\"\nservices:\n  api:\n    image: tallguyjneks/<hub-repo-name>:<optional-tag-name> # instead of build if this was a production env\n    build: . # where is the thing im building\n    depends_on: # builds dependencies before main containers\n      - postgres\n    ports:\n      - 8000:8000 # <port on localhost>:<port on container\n    volumes:\n      - ./app:/usr/src/app:ro # makes it so docker can be aware of changes between a linked directory and `ro` means read only so docker cant change the files\n    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload # overrides default command for the image when ran\n    env_file:\n      - ./.env\n    # ^^^ OR vvv\n    environment:\n      - DATABASE_HOSTNAME=postgres # docker compose uses its own network dns so you can specify a name of another container instead of the ip address\n      - DATABASE_PORT=5432 # you can either list them out or point docker to a .env file\n  postgres:\n    image: postgres\n    environment:\n      - POSTGRES_PASSWORD=password123\n      - POSTGRES_DB=fastapi\n    volumes: # data is transient in the image so you need to have a place to have permanently stored data\n      - postgre-db: /var/lib/postgresql/data\nvolumes:\n  postgres-db:\n```\n\n## Tips\n\n- having 2 files for a **dev** and a **prod** environment\n- no using `--reload` in production code because the code shouldn't be changing\n- port [[n.port.80]] on local host so that you can view in web browser\n- on linux the `environment:` values can use linux variable accessors `${DATABASE_HOSTNAME}`\n","n":0.068}}},{"i":1082,"$":{"0":{"v":"Cmd","n":1}}},{"i":1083,"$":{"0":{"v":"Up","n":1},"1":{"v":"\n## Command to run\n\n```bash\ndocker-compose up -d\n```\n\n`-d` detaches the process to run it in the background\n\n## To use a specific configuration file\n\n```bash\ndocker-compose -f docker-compose-dev.yml up -d\n```\n","n":0.2}}},{"i":1084,"$":{"0":{"v":"Down","n":1},"1":{"v":"\n## Command to teardown existing image\n\nIt reads from the compose file so it knows what image we're referring to\n\n```bash\ndocker-compse down\n```\n","n":0.224}}},{"i":1085,"$":{"0":{"v":"Cmd","n":1}}},{"i":1086,"$":{"0":{"v":"Push","n":1},"1":{"v":"\nlike git push this will push a docker image to <https://www.dockerhub.com> after authenticating with [[s.containers.docker.cmd.login]]\n\n```bash\ndocker push tallguyjenks/<hub-repo-name>:<local-tag-name>\n```\n\nTo rename an existing image for this purpose of pushing use [[s.containers.docker.cmd.image.tag]]\n","n":0.189}}},{"i":1087,"$":{"0":{"v":"Logs","n":1},"1":{"v":"\n```bash\ndocker logs <image name>\n```\n\nShow the logs from the image\n","n":0.333}}},{"i":1088,"$":{"0":{"v":"Login","n":1},"1":{"v":"\n```bash\ndocker login\n```\n\nopens interactive session prompt for your <https://www.dockerhub.com> username and password\n","n":0.302}}},{"i":1089,"$":{"0":{"v":"Inspect","n":1},"1":{"v":"\n```bash\ndocker inspect <containerID>\n```\n\nGive you [[s.df.json]] output of the container's data\n","n":0.316}}},{"i":1090,"$":{"0":{"v":"Image","n":1}}},{"i":1091,"$":{"0":{"v":"Tag","n":1},"1":{"v":"\n```bash\ndocker image tag <image name> tallguyjenks/<hub-repo-name>:<optional tag>\n```\n\nOptional tag if not stated just defaults to `latest` but you can also put a custom tag there\n","n":0.204}}},{"i":1092,"$":{"0":{"v":"Prune","n":1},"1":{"v":"\n## Prunes containers that do not have a reference\n\n```bash\ndocker image prune\n```\n\n## To prune all old images not used by existing containers\n\nrun it with the -a flag:\n\n```bash\ndocker image prune -a\n```\n","n":0.186}}},{"i":1093,"$":{"0":{"v":"ls","n":1},"1":{"v":"\n```bash\ndocker image ls\n# OR\ndocker images\n```\n\n## Example Output\n\n```markdown\nREPOSITORY                       TAG           IMAGE ID       CREATED        SIZE\nmcr.microsoft.com/mssql/server   2019-latest   6db3c5ebc331   2 months ago   1.55GB\n```\n","n":0.236}}},{"i":1094,"$":{"0":{"v":"Exec","n":1},"1":{"v":"\n```bash\ndocker exec -it fastapi_api bash\n```\n\n- Enters `docker` interactive mode (`-it`) on image named `fastapi_api` and runs the command `bash` for the interactive session\n- `bash` overrides the defaul command of the docker file with is usually the `CMD` to start the image\n","n":0.156}}},{"i":1095,"$":{"0":{"v":"Build","n":1},"1":{"v":"\n```bash\ndocker build -t fastapi .\n```\n\n- `docker build`\n  - build the image\n- `-t fastapi `\n  - an optional tag for the image\n- `.`\n  - where to place the built image\n","n":0.186}}},{"i":1096,"$":{"0":{"v":"Best Practices","n":0.707},"1":{"v":"\n1. Use official and verified Docker Images as Base Image\n2. Use Specific Docker Image Versions\n3. Use Small-Sized Official Images\n4. Optimize Caching Image Layers\n5. Use .dockerignore file\n6. Make use of Multi-Stage Builds\n7. Use the Least Privileged User\n8. Scan your Images for Security Vulnerabilities\n","n":0.154}}},{"i":1097,"$":{"0":{"v":"Azure Deployment","n":0.707},"1":{"v":"\nREVISIT <https://youtu.be/tQJq4Tx1n0Y>\n","n":0.707}}},{"i":1098,"$":{"0":{"v":"Command Line Interfaces","n":0.577},"1":{"v":"\n- REVISIT <https://clig.dev/>\n","n":0.577}}},{"i":1099,"$":{"0":{"v":"Apps","n":1}}},{"i":1100,"$":{"0":{"v":"Vscode","n":1},"1":{"v":"\n\n- Manually add code folding markers\n    - with comments:\n\n```\n//#region\n  fold me\n//#endregion\n```\n","n":0.302}}},{"i":1101,"$":{"0":{"v":"Extensions","n":1}}},{"i":1102,"$":{"0":{"v":"Todotree","n":1},"1":{"v":"\n\n- [Icons][1]\n- [Docs][2]\n- [Gruvbox][3]\n\n[1]: https://primer.style/octicons/\n[2]: https://marketplace.visualstudio.com/items?itemName=Gruntfuggly.todo-tree\n[3]: https://github.com/morhetz/gruvbox\n","n":0.378}}},{"i":1103,"$":{"0":{"v":"Visual Studio","n":0.707}}},{"i":1104,"$":{"0":{"v":"Tableau","n":1},"1":{"v":"\n- Worksheets: A single visualization\n- Dashboards: A collection of Worksheets\n- Stories: A combination of Dashboards and worksheets to depict your data and tie it in with key data points\n","n":0.186}}},{"i":1105,"$":{"0":{"v":"Snyk","n":1}}},{"i":1106,"$":{"0":{"v":"Obsidian","n":1}}},{"i":1107,"$":{"0":{"v":"Microsoft Orchestrator","n":0.707},"1":{"v":"\n\n## Make a New Run Books\n\n### SC 2016 Service Manager\n\n- ==Monitor Object==:\n  - Monitoring For new or updated items\n  - **Connection:** `SCSM PROD`\n  - **Class:** `service request` or `incident`\n    - One monitor for each class type\n  - **Trigger:** Keep trigger to _New_ because _Update_ will do a biiiig pull\n  - **Filters:** To match your criteria Title works with [[Regex|regex]]\n- ==Update Object==\n- ==Create Relationship==\n\n## Utilities\n\n- ==Write To Database==\n\n## Text File Management\n\n- ==Append Line==\n\n## Tips\n\n- **Data Fields:**\n  - For input areas _right click_ to get `subscribe data` or `variables`\n- **Data Connectors:** To connect nodes together and have data flow between nodes hover over an icon and it's arrow until the cursor changes to a black cross hairs then click and drag to another node. no visual indication of the operation will occur until the drag and drop is complete\n  - The connector lines also have additional options you can access with double clicking\n\n---\n\n- Never just change ticket status to `Closed`\n  - Change to `Completed` the `Closed` status is auto\n  - Make sure to update comments or description with `implementation status` and `notes` so tickets are not just closed with no user communication\n- ADM account doesnt have access to file location? then for \n  **Security** pass your normal credentials and the path to the location that your normal account has access to\n  Best to have a service account own this though\n  - Service account would need:\n    - ADM Account\n    - Access to @IT\n    - Access to the SCORTCH AD group\n","n":0.064}}},{"i":1108,"$":{"0":{"v":"Gns3","n":1}}},{"i":1109,"$":{"0":{"v":"Excel","n":1},"1":{"v":"\n\n- [Create Power Query formulas in Excel](https://support.microsoft.com/en-us/office/create-power-query-formulas-in-excel-6bc50988-022b-4799-a709-f8aafdee2b2f?ocmsassetid=ha104003958&correlationid=e82699ce-de1e-4581-ab48-b7791c569c13&ui=en-us&rs=en-us&ad=us)\n- [e90e50charts](https://sites.google.com/site/e90e50charts/)\n\n- Related:\n  - [[vba|s.l.vba]]\n\n","n":0.302}}},{"i":1110,"$":{"0":{"v":"Azure","n":1}}},{"i":1111,"$":{"0":{"v":"Test Plans","n":0.707}}},{"i":1112,"$":{"0":{"v":"Pipelines","n":1},"1":{"v":"\n\n- [[focus.azure.pipelines]]\n  - [YAML Schema Reference for pipelines](https://docs.microsoft.com/en-us/azure/devops/pipelines/yaml-schema?tabs=schema%2Cparameter-schema&view=azure-devops)\n  - [Pipelines Documentation](https://docs.microsoft.com/en-us/azure/devops/pipelines/?view=azure-devops)\n  - Pushing successful Job outputs to [dev](https://docs.microsoft.com/en-us/learn/modules/create-multi-stage-pipeline/4-promote-dev) environment and then [test](https://docs.microsoft.com/en-us/learn/modules/create-multi-stage-pipeline/5-promote-test) environments\n    - Leading to [staging](https://docs.microsoft.com/en-us/learn/modules/create-multi-stage-pipeline/6-promote-staging)\n","n":0.192}}},{"i":1113,"$":{"0":{"v":"Devops","n":1},"1":{"v":"\n\n- Related: [Pivotal Tracker](https://www.pivotaltracker.com/dashboard)\n- naming branches in the repo's using forward slashes in the names groups them under folders:\n  - `project/user/branch`\n- [[focus.azure.devops]] Extension for [Automatic Release Notes](https://marketplace.visualstudio.com/items?itemName=richardfennellBM.BM-VSTS-XplatGenerateReleaseNotes&ssr=false#overview)\n\n","n":0.192}}},{"i":1114,"$":{"0":{"v":"Research","n":1}}},{"i":1115,"$":{"0":{"v":"Book","n":1}}},{"i":1116,"$":{"0":{"v":"Refactoring Improving the Design of Existing Code","n":0.378},"1":{"v":"\n\n## Metadata\n\n- `Author:` Martin Fowler\n  - `Notable Authors:` Kent Beck\n- `ISBN:` 978-0-13-475759-9\n- `Publish Date:` 1999-06-28\n","n":0.258}}},{"i":1117,"$":{"0":{"v":"Refactorings","n":1}}},{"i":1118,"$":{"0":{"v":"362 Replace Type Code with Subclasses","n":0.408},"1":{"v":"\n```javascript\n//FROM\nfunction createEmployee(name, type) {\n    return new Employee(name, type);\n}\n\n//TO\nfunction createEmployee(name, type) {\n    switch (type) {\n        case \"engineer\": return new Engineer(name);\n        case \"salesman\": return new Salesman(name);\n        case \"manager\":  return new Manager (name);\n    }\n```\n","n":0.18}}},{"i":1119,"$":{"0":{"v":"334 Replace Constructor with Factory Function","n":0.408},"1":{"v":"\n```javascript\n//FROM\nleadEngineer = new Employee(document.leadEngineer, 'E');\n\n//TO\nleadEngineer = createEngineer(document.leadEngineer);\n```\n","n":0.378}}},{"i":1120,"$":{"0":{"v":"310 Parameterize Function","n":0.577},"1":{"v":"\n```javascript\n//FROM\nfunction tenPercentRaise(aPerson) {\n  aPerson.salary = aPerson.salary.multiply(1.1);\n}\nfunction fivePercentRaise(aPerson) {\n  aPerson.salary = aPerson.salary.multiply(1.05);\n}\n\n\n//TO\nfunction raise(aPerson, factor) {\n  aPerson.salary = aPerson.salary.multiply(1 + factor);\n}\n```\n","n":0.229}}},{"i":1121,"$":{"0":{"v":"272 Replace Conditional with Polymorphism","n":0.447},"1":{"v":"\n```javascript\n//FROM\nswitch (bird.type) {\n    case 'EuropeanSwallow':\n        return \"average\";\n    case 'AfricanSwallow':\n        return (bird.numberOfCoconuts > 2) ? \"tired\" : \"average\";\n    case 'NorwegianBlueParrot':\n        return (bird.voltage > 100) ? \"scorched\" : \"beautiful\";\n    default:\n        return \"unknown\";\n}\n\n//TO\nclass EuropeanSwallow {\n    get plumage() {\n        return \"average\";\n    }}\nclass AfricanSwallow {\n    get plumage() {\n        return (this.numberOfCoconuts > 2) ? \"tired\" : \"average\";\n    }\n)\nclass NorwegianBlueParrot {\n    get plumage() {\n        return (this.voltage > 100) ? \"scorched\" : \"beautiful\";\n    }\n}\n```\n","n":0.123}}},{"i":1122,"$":{"0":{"v":"Rename Field","n":0.707},"1":{"v":"\n```javascript\n// BEFORE\nclass Organization {\n  get name() {...}\n}\n// AFTER\nclass Organization {\n  get title() {...}\n}\n```\n\n- If the record has limited scope, rename all accesses to the field and test; no need to do the rest of the mechanics.\n- If the record isn't already encapsulated, apply [[r.{.refactoring-improving-the-design-of-existing-code.refactorings.162-encapsulate-record]]\n- Rename the private field inside the object, adjust internal methods to fit.\n- If the constructor uses the name, apply [[r.{.refactoring-improving-the-design-of-existing-code.refactorings.124-change-function-declaration]] to rename it.\n- Apply [[r.{.refactoring-improving-the-design-of-existing-code.refactorings.124-change-function-declaration]] to the accessors.\n","n":0.118}}},{"i":1123,"$":{"0":{"v":"231 Replace Loop with Pipeline","n":0.447},"1":{"v":"\n```javascript\n//FROM\nconst names = [];\nfor (const i of input) {\n    if (i.job === \"programmer\")\n        names.push(i.name);\n}\n\n//TO\nconst names = input\n    .filter(i => i.job === \"programmer\")\n    .map(i => i.name)\n;\n```\n","n":0.2}}},{"i":1124,"$":{"0":{"v":"227 Split Loop","n":0.577},"1":{"v":"\n```javascript\n//FROM\nlet averageAge = 0;\nlet totalSalary = 0;\nfor (const p of people) {\n    averageAge += p.age;\n    totalSalary += p.salary;\n}\naverageAge = averageAge / people.length;\n\n//TO\nlet totalSalary = 0;\nfor (const p of people) {\n    totalSalary += p.salary;\n}\n\nlet averageAge = 0;\nfor (const p of people) {\n    averageAge += p.age;\n}\naverageAge = averageAge / people.length;\n```\n","n":0.144}}},{"i":1125,"$":{"0":{"v":"223 Slide Statements","n":0.577},"1":{"v":"\n```javascript\n//FROM\nconst pricingPlan = retrievePricingPlan();\nconst order = retreiveOrder();\nlet charge;\nconst chargePerUnit = pricingPlan.unit;\n\n//TO\nconst pricingPlan = retrievePricingPlan();\nconst chargePerUnit = pricingPlan.unit;\nconst order = retreiveOrder();\nlet charge;\n```\n\n> Code is easier to understand when things that are related to each other appear together. If several lines of code access the same data structure, it's best for them to be together rather than intermingled with code accessing other data structures. At its simplest, I use Slide Statements to keep such code together. A very common case of this is declaring and using variables. Some people like to declare all their variables at the top of a function. I prefer to declare the variable just before I first use it.\n","n":0.095}}},{"i":1126,"$":{"0":{"v":"198 Move Function","n":0.577},"1":{"v":"\n```javascript\n//FROM\nclass Account {\n    get overdraftCharge() {...}\n\n//TO\nclass AccountType {\n    get overdraftCharge() {...}\n```\n","n":0.302}}},{"i":1127,"$":{"0":{"v":"178 Replace Temp with Query","n":0.447},"1":{"v":"\n```javascript\n//FROM\nconst basePrice = this._quantity * this._itemPrice;\nif (basePrice > 1000)\n    return basePrice * 0.95;\nelse\n    return basePrice * 0.98;\n\n//TO\nget basePrice() {this._quantity * this._itemPrice;}\n\n...\n\nif (this.basePrice > 1000)\n    return this.basePrice * 0.95;\nelse\n    return this.basePrice * 0.98;\n```\n","n":0.177}}},{"i":1128,"$":{"0":{"v":"Encapsulate Record","n":0.707},"1":{"v":"\n```javascript\n// BEFORE\norganization = {name: \"Acme Gooseberries\", country: \"GB\"};\n// AFTER\nclass Organization {\n    constructor(data) {\n        this._name = data.name;\n        this._country = data.country;\n    }\n    get name()    {return this._name;}\n    set name(arg) {this._name = arg;}\n\n    get country()    {return this._country;}\n    set country(arg) {this._country = arg;}\n}\n```\n","n":0.162}}},{"i":1129,"$":{"0":{"v":"154 Split Phase","n":0.577},"1":{"v":"\n```javascript\n//FROM\nconst orderDate = orderString.split(/\\s+/);\nconst productPrice = priceList[orderData[0].split(\"-\")[1]];\nconst orderPrice = parseInt(orderData[1]) * productPrice;\n\n//TO\nconst orderRecord = parseOrder(order);\nconst orderPrice = price(orderRecord, priceList);\n\nfunction parseOrder(aString) {\n    const values =  aString.split(/\\s+/);\n    return ({\n        productID: values[0].split(\"-\")[1],\n        quantity: parseInt(values[1]),\n    });\n}\nfunction price(order, priceList) {\n    return order.quantity * priceList[order.productID];\n}\n```\n","n":0.16}}},{"i":1130,"$":{"0":{"v":"Rename Variable","n":0.707},"1":{"v":"\n```javascript\n// BEFORE\nlet a = height * width;\n// AFTER\nlet area = height * width;\n```\n\n- Single line lambda functions where the variable is easy to track are fine with single letters\n- variables that live in functions are also likely fine to be terse\n- Variables used throughout should be descriptive and if the variable is used widely, consider [[r.{.refactoring-improving-the-design-of-existing-code.refactorings.132-encapsulate-variable]]\n","n":0.134}}},{"i":1131,"$":{"0":{"v":"Encapsulate Variable","n":0.707},"1":{"v":"\n```javascript\n// BEFORE\nlet defaultOwner = {firstName: \"Martin\", lastName: \"Fowler\"};\n// AFTER\nlet defaultOwnerData = {firstName: \"Martin\", lastName: \"Fowler\"};\nexport function defaultOwner()       {return defaultOwnerData;}\nexport function setDefaultOwner(arg) {defaultOwnerData = arg;}\n```\n\nAccess your data through functions so that updating the variable is as simple as changing a single function rather than every instance of a variable used.\n\nvariables encapsulated by functinos are also testable\n","n":0.135}}},{"i":1132,"$":{"0":{"v":"124 Change Function Declaration","n":0.5},"1":{"v":"\n```javascript\n//FROM\nfunction circum(radius) {...}\n\n//TO\nfunction circumference(radius) {...}\n```\n\nIf deprecating something like API code a useful way of accomplishing that easily might be to do something like this:\n\n```javascript\n//FROM\nfunction circum(radius) {\n\treturn Math.PI * 2 * radius;\n}\n\n//TO\nfunction circum(radius) {\n\tconsole.log(\"This function is deprecated, please use circumference()\");\n\treturn circumference(radius);\n}\n\nfunction circumference(radius) {\n\treturn Math.PI * 2 * radius;\n}\n```\n\nThis also makes it easy to refactor in place and only change small things like what the contents are of `circum()` this way if it breaks code we can just handle it in our new function body and all references to `circum()` are intact until we're able to migrate everything to the new function declaration.\n","n":0.1}}},{"i":1133,"$":{"0":{"v":"123 Inline Variable","n":0.577},"1":{"v":"\n```javascript\n//FROM\nlet basePrice = anOrder.basePrice;\nreturn (basePrice > 1000);\n\n//TO\nreturn anOrder.basePrice > 1000;\n```\n","n":0.316}}},{"i":1134,"$":{"0":{"v":"106 Extract Function","n":0.577},"1":{"v":"\n```javascript\n// FROM\nfunction printOwing(invoice) {\n\tprintBanner();\n\tlet outstanding = calculateOutstanding();\n\n\t//print details\n\tconsole.log(`name: ${invoice.customer}`);\n\tconsole.log(`amount: ${outstanding}`);\n}\n\n// TO\nfunction printOwing(invoice) {\n\tprintBanner();\n\tlet outstanding = calculateOutstanding();\n\tprintDetails(outstanding);\n\n\tfunction printDetails(outstanding) {\n\t\tconsole.log(`name: ${invoice.customer}`);\n\t\tconsole.log(`amount: ${outstanding}`);\n\t}\n}\n```\n","n":0.224}}},{"i":1135,"$":{"0":{"v":"Notes","n":1},"1":{"v":"\n\n## Notes\n\n---\n\n- Notes like this: `Extract Function (106)`\n  - mean that on `Page 106` there is a better example of that concept\n\n---\n","n":0.213}}},{"i":1136,"$":{"0":{"v":"Bad Smells In Code","n":0.5},"1":{"v":"\n- Mysterious Name\n  - [[r.{.refactoring-improving-the-design-of-existing-code.refactorings.124-change-function-declaration]\n  - [[r.{.refactoring-improving-the-design-of-existing-code.refactorings.123-inline-variable]]\n  - [[r.{.refactoring-improving-the-design-of-existing-code.refactorings.137-rename-variable]]\n  - [[r.{.refactoring-improving-the-design-of-existing-code.refactorings.244-rename-field]]\n- Duplicated Code\n- Long Function\n- Long Parameter List\n- Global Data\n- Mutable Data\n- Divergent Change\n- Shotgun Surgery\n- Feature Envy\n- Data Clumps\n- Primitive Obsession\n- Repeated Switches\n- Loops\n- Lazy Element\n- Speculative Generality\n- Temporary Field\n- Message Chains\n- Middle Man\n- Insider Trading\n- Large Class\n- Alternative Classes with Different Interfaces\n- Data Class\n- Refused Bequest\n- Comments\n","n":0.13}}},{"i":1137,"$":{"0":{"v":"Principles In Refactoring","n":0.577},"1":{"v":"\n\n## Chapter 2\n\n---\n\n- Refactoring is for when i need to understand the code base\n  - If the code is a hot mess but i dont need to interact with it beyond treating it like an API black box then i can ignore the code for now. It's when i need to care that i refactor\n  - If the code is easier to re-write than refactor that is also a valid edge case to not refactor\n- Client boundries can get in the way such as the published public interface\n  - If we want people to avoid using the `circum()` function in favor of the `circumference()` function then like the example in [[r.{.refactoring-improving-the-design-of-existing-code.refactorings.124-change-function-declaration]] leave the old declaration as a pass through with a deprecation warning and phase out over time. This is just the cost and fact of life for public interfaces and code ownership boundries.\n- reduce the complexity of large branch feature merges with things like feature toggles to turn off \"in-progress\" work that is unable to be broken into smaller parts in a [[terms.ci-cd]] environment.\n\n---\n","n":0.076}}},{"i":1138,"$":{"0":{"v":"Refactoring A First Example","n":0.5},"1":{"v":"\n## Chapter 1 Refactoring: A First Example\n\n---\n\n- First step in refactoring is to ensure that there is a solid set of tests for the section of code to ensure that functionality is not altered\n- Immediately compile/run the code after a change along with the test quite to check for unintended changes\n- Incrementally save and commit to VCS to easily return to prior state, squash merge later for the actual merge of the refactoring into [[cli.cmd.git]]\n- Even if the result of a refactor is more loops and more loop iterations and what \"appears\" to be more inefficient code\n  - sometimes the increased inefficiency is negligible or justifiably worth it for cleaner, simpler, more legible code.\n  - If performance takes a big hit then it may warrant performance tuning after the refactor to try and speed it back up or even a revert of the refactor\n\n---\n","n":0.083}}},{"i":1139,"$":{"0":{"v":"Clean Code","n":0.707}}},{"i":1140,"$":{"0":{"v":"The Single Responsibility Principle","n":0.5},"1":{"v":"\n\n> ‚ÄúA class should have one, and only one, reason to change‚Äù\n\n```python\nimport numpy as np\n\ndef math_operations(list_):\n    # Compute Average\n    print(f\"the mean is {np.mean(list_)}\")\n    # Compute Max\n    print(f\"the max is {np.max(list_)}\") \n\nmath_operations(list_ = [1,2,3,4,5])\n# the mean is 3.0\n# the max is 5\n```\n\nHaving a single function do all the work is a bad approach\n\nsplit the function `math_operations` into atomic functions\n\nMake a single function (or class), generically named, \"main\". This will call all the other functions one-by-one in a step-to-step process.\n\n```python\ndef get_mean(list_):\n    '''Compute Mean'''\n    print(f\"the mean is {np.mean(list_)}\") \n\ndef get_max(list_):\n    '''Compute Max'''\n    print(f\"the max is {np.max(list_)}\") \n\ndef main(list_): \n    # Compute Average\n    get_mean(list_)\n    # Compute Max\n    get_max(list_)\n\nmain([1,2,3,4,5])\n# the mean is 3.0\n# the max is 5\n```\n\nThe result of this simple action is that now:\n\n- It is easier to localize errors. Any error in execution will point out to a smaller section of your code, accelerating your debug phase.\n- Any part of the code is reusable in other section of your code.\n- Moreover and, often overlooked, is that it is easier to create testing for each function of your code. \n  - _Side note on testing:_ You should write tests before you actually write the script. But, this is often ignored in favor of creating some nice result to be shown to the stakeholders instead.\n\n---\n\n- Reference:\n  - [[SOLID Coding in Python|r.(.2021.11.10.solid-coding-in-python]]\n\n","n":0.068}}},{"i":1141,"$":{"0":{"v":"The Open Closed Principle","n":0.5},"1":{"v":"\n\n> ‚ÄúSoftware entities ‚Ä¶ should be open for extension but closed for modification‚Äù\n\nIn other words: You should not need to modify the code you have already written to accommodate new functionality, but simply add what you now need.\n\nIntention: Add a `Median` function\n\n```python\nimport numpy as np\nfrom abc import ABC, abstractmethod\n\nclass Operations(ABC):\n    '''Operations'''\n    @abstractmethod\n    def operation():\n        pass\n\nclass Mean(Operations):\n    '''Compute Max'''\n    def operation(list_):\n        print(f\"The mean is {np.mean(list_)}\") \n\nclass Max(Operations):\n    '''Compute Max'''\n    def operation(list_):\n        print(f\"The max is {np.max(list_)}\") \n\nclass Main:\n    '''Main'''\n    @abstractmethod\n    def get_operations(list_):\n        # __subclasses__ will found all classes inheriting from Operations\n        for operation in Operations.__subclasses__():\n            operation.operation(list_)\n\n\nif __name__ == \"__main__\":\n    Main.get_operations([1,2,3,4,5])\n# The mean is 3.0\n# The max is 5\n```\n\n---\n\n- Reference:\n  - [[SOLID Coding in Python|r.(.2021.11.10.solid-coding-in-python]]\n- Related:\n  - [[Python Abstract Base Classes|s.l.python.oop.abstract-base-classes]]\n\n","n":0.092}}},{"i":1142,"$":{"0":{"v":"The Liskov Substitution Principle","n":0.5},"1":{"v":"\n\n> ‚ÄúFunctions that use pointers or references to base classes must be able to use objects of derived classes without knowing it‚Äù\n\nAlternatively, this can be expressed as ‚ÄúDerived classes must be substitutable for their base classes‚Äù\n\n> For example, the sub-class ‚ÄúPlatypus‚Äù, of the base class ‚ÄúMammals‚Äù, would have the exception that these mammals lay eggs. The LSP, tell us that it would create a function called ‚Äúgive_birth‚Äù, this function will have different behavior for the sub-class Platypus and the sub-class Dog. Therefore, we should have had a more abstract base class than Mammals that accommodate this.\n>\n> If this sounds very confusing, do not worry, the application of this latter aspect of the LSP is rarely fully implemented, and it rarely leaves the theoretical textbooks.\n\n---\n\n- Reference:\n  - [[SOLID Coding in Python|r.(.2021.11.10.solid-coding-in-python]]\n\n","n":0.088}}},{"i":1143,"$":{"0":{"v":"The Interface Segregation Principle","n":0.5},"1":{"v":"\n\n> ‚ÄúMany client-specific interfaces are better than one general-purpose interface‚Äù\n> <br>\n> In the contest of classes, an interface is considered, all the methods and properties ‚Äú**exposed**‚Äù, thus, everything that a user can interact with that belongs to that class.\n> <br>\n> In this sense, the The Interface Segregation Principle tell us that a class should only have the interface needed ([[the-single-responsibility-principle|r.{.clean-code.the-single-responsibility-principle]]) and avoid methods that won‚Äôt work or that have no reason to be part of that class.\n> <br>\n> This problem arises, primarily, when, a subclass inherits methods from a base class that it does not need.\n\n```python\nimport numpy as np\nfrom abc import ABC, abstractmethod\n\nclass Mammals(ABC):\n    @abstractmethod\n    def swim() -> bool:\n        print(\"Can Swim\") \n\n    @abstractmethod\n    def walk() -> bool:\n        print(\"Can Walk\") \n\nclass Human(Mammals):\n    def swim():\n        return print(\"Humans can swim\") \n\n    def walk():\n        return print(\"Humans can walk\") \n\nclass Whale(Mammals):\n    def swim():\n        return print(\"Whales can swim\") \n\t\n# ========================================= #\nHuman.swim()\nHuman.walk()\n\nWhale.swim()\nWhale.walk()\n\n# Humans can swim\n# Humans can walk\n# Whales can swim\n# Can Walk\n```\n\nThe sub-class whale can still invoke the method ‚Äúwalk‚Äù but it shouldn‚Äôt, and we must avoid it.\n\nThe way suggested by `ISP` is to create more client-specific interfaces rather than one general-purpose interface. So, our code example becomes:\n\n```python\nfrom abc import ABC, abstractmethod\n\nclass Walker(ABC):\n  @abstractmethod\n  def walk() -> bool:\n    return print(\"Can Walk\") \n\nclass Swimmer(ABC):\n  @abstractmethod\n  def swim() -> bool:\n    return print(\"Can Swim\") \n\nclass Human(Walker, Swimmer):\n  def walk():\n    return print(\"Humans can walk\") \n  def swim():\n    return print(\"Humans can swim\") \n\nclass Whale(Swimmer):\n  def swim():\n    return print(\"Whales can swim\") \n\nif __name__ == \"__main__\":\n  Human.walk()\n  Human.swim()\n\n  Whale.swim()\n  Whale.walk()\n\n# Humans can walk\n# Humans can swim\n# Whales can swim\n```\n\n---\n\n- ## Tags:\n- Reference:\n  - [[SOLID Coding in Python|r.(.2021.11.10.solid-coding-in-python]]\n- Related:\n  - [[Python Abstract Base Classes|s.l.python.oop.abstract-base-classes]]\n\n","n":0.061}}},{"i":1144,"$":{"0":{"v":"The Dependency Inversion Principle","n":0.5},"1":{"v":"\n\n> > ‚ÄúAbstractions should not depend on details. Details should depend on abstraction. High-level modules should not depend on low-level modules. Both should depend on abstractions‚Äù\n>\n>  So, that abstractions (e.g., the interface, as seen above) should not be dependent on low-level methods but both should depend on a third interface.\n> <br>\n> To better explain this concept, I prefer to think of a sort of information flow.\n> <br>\n> Imagine that you have a program that takes in input a specific set of info (a file, a format, etc) and you wrote a script to process it.\n> <br>\n> What would happen if that info were subject to changes?\n> <br>\n> You would have to rewrite your script and adjust the new format. Losing the retro compatibility with the older files.\n> <br>\n> However, you could solve this by creating a third abstraction that takes the info as input and passes it to the others.\n> This is basically what an API is also, used for.\n\n![alt](assets/images/Pasted_image_20211110092721.png)\n\n---\n\n- ## Tags:\n- Reference:\n  - [[SOLID Coding in Python|r.(.2021.11.10.solid-coding-in-python]]\n- Related:\n  - [[Python Abstract Base Classes|s.l.python.oop.abstract-base-classes]]\n\n","n":0.076}}},{"i":1145,"$":{"0":{"v":"2022","n":1}}},{"i":1146,"$":{"0":{"v":"01","n":1}}},{"i":1147,"$":{"0":{"v":"26","n":1}}},{"i":1148,"$":{"0":{"v":"Sql_for_data_analytics_perform_fast_and_efficient","n":1},"1":{"v":"\n\n[sql_for_data_analytics_perform_fast_and_efficient](/assets/pdfs/SQL_for_Data_Analytics_Perform_Fast_and_Efficient_....pdf)\n\n- [[s.q.postgres.data-t.casting]]\n- [[s.q.postgres.funcs.coalesce]]\n- [[s.q.postgres.funcs.least-greatest]]\n- [[s.q.postgres.funcs.window-functions]]\n- [[s.q.postgres.funcs.copy]]\n- [[s.q.postgres.tips-tricks.extract-date-parts]]\n- [[s.q.postgres.tips-tricks.date-intervals]]\n- [[s.q.postgres.data-t.array]]\n","n":0.333}}},{"i":1149,"$":{"0":{"v":"Window Functions","n":0.707},"1":{"v":"\n\nExamples of window functions\n\n```sql\nSELECT {columns}\n     , {window_func} OVER (PARTITION BY {partition_key} ORDER BY {order_key})\nFROM table1;\n```\n\nmore realistic example:\n\n```sql\nSELECT customer_id\n     , title\n     , first_name\n     , last_name\n     , gender\n     , COUNT(*) OVER (PARTITION BY gender ORDER BY customer_id) AS total_customers\n     , SUM(CASE WHEN title IS NOT NULL THEN 1 ELSE 0 END) OVER (PARTITION BY gender ORDER BY customer_id) AS total_customers_title\nFROM customers\nORDER BY customer_id;\n```\n\nThe window Keyword:\n\n```sql\nSELECT customer_id\n     , title\n     , first_name\n     , last_name\n     , gender\n     , COUNT(*) OVER w AS total_customers,\n     , SUM(CASE WHEN title IS NOT NULL THEN 1 ELSE 0 END) OVER w AS total_customers_title\nFROM customers\n     WINDOW w AS (PARTITION BY gender ORDER BY customer_id) -- Reduces typing and improves legibility\nORDER BY customer_id;\n```\n\n\n","n":0.094}}},{"i":1150,"$":{"0":{"v":"Least Greatest","n":0.707},"1":{"v":"\n\nUnlike aggregate functions such as `MIN` or `MAX` using `LEAST` or `GREATEST` seems to be scalar oriented\n\n> Two functions that come in handy for data preparation are the `LEAST` and `GREATEST` functions. Each function takes any number of values and returns the least or the greatest of the values, respectively.\n>\n> A simple use of this variable would be to replace the value if it's too high or low. For example, the sales team may want to create a sales list where every scooter is $600 or less than that. We can create this using the following query:\n\n```sql\nSELECT product_id\n     , model\n     , year\n     , product_type\n     , LEAST(600.00, base_msrp) AS base_msrp\n     , production_start_date\n     , production_end_date\nFROM products\nWHERE product_type='scooter'\nORDER BY 1;\n```\n\n","n":0.092}}},{"i":1151,"$":{"0":{"v":"Coalese","n":1},"1":{"v":"\n\n\n> To illustrate a simple usage of the COALESCE function, let's return to the customers table. Let's say the marketing team would like a list of the first names, last names, and phone numbers of all male customers. However, for those customers with no phone number, they would like the table to instead write the value 'NO PHONE'. We can accomplish this request with `COALESCE`:\n  \n```sql\nSELECT first_name\n     , last_name\n     , COALESCE(phone, 'NO PHONE') AS phone\nFROM customers\nORDER BY 1;\n```\n\n> When dealing with creating default values and avoiding `NULL`, `COALESCE` will always be helpful.\n","n":0.104}}},{"i":1152,"$":{"0":{"v":"Video","n":1}}},{"i":1153,"$":{"0":{"v":"Zip Function in Python Combine Iterables Together","n":0.378},"1":{"v":"\n\n- `URL:` <https://youtu.be/NgIWu-lDucM>\n- `Channel/Host:` Tech With Tim\n- `Publish Date:` 2021.09.28\n- `Reviewed Date:` \n\n---\n\n<center><iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/NgIWu-lDucM\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></center>\n\n---\n\n-\n\n","n":0.209}}},{"i":1154,"$":{"0":{"v":"Writing Your First Ansible Playbook Iac Deep Dive Pt 1","n":0.316},"1":{"v":"\n\n<https://youtu.be/Z7p9-m4cimg>\n","n":1}}},{"i":1155,"$":{"0":{"v":"Variations of the Strategy Pattern Using Python Features","n":0.354},"1":{"v":"\n\n- <https://youtu.be/n2b_Cxh20Fw>\n","n":0.707}}},{"i":1156,"$":{"0":{"v":"S Testing Theory and a Few Less Obvious Testing Techniques","n":0.316},"1":{"v":"\n\n- `URL:` <https://youtu.be/K47pr6lPxsA>\n- `Channel/Host:` ArjanCodes\n- `Publish Date:` 2021.09.24\n- `Reviewed Date:` \n\n---\n\n<center><iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/K47pr6lPxsA\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></center>\n\n---\n\n-\n\n","n":0.218}}},{"i":1157,"$":{"0":{"v":"Redgate Training","n":0.707}}},{"i":1158,"$":{"0":{"v":"Sql Source Control","n":0.577},"1":{"v":"\n### Getting Started with SQL Source Control\n\n#### Getting Started\n\n##### [Linking a development database to your source control system](https://www.red-gate.com/hub/university/courses/sql-source-control/sql-source-control/getting-started/linking-development-database-source-control-system)\n\n- Can link your database to a repository solution\n  - Right click on database\n  - link database with source control\n  - link to my source control system\n  - Select your source control **which for ADO? git?**\n    - Browse for target folder\n    - Click on it\n    - Add commit Message\n    - OK\n    - select either (See [[#shared-vs-dedicated-development-model]])\n      - dedicated database\n      - shared database\n  - When link is complete the DB icon will turn green\n  - You need to start by committing all your objects\n  - Click on \"Commit\" in Redgate source control\n  - add commit message\n  - Commit\n    - this will export all your objects as create scripts to your source control\n\n##### [Shared vs Dedicated development model][3]\n\n- Shared is redundant when it comes to \"pull changes\" because everyone shares the same DB and changes are pushed to the repository\n- Dedicated is like the standard git model where all devs have their own copy of changes but to actually implement those changes they have to commit the changes to source control\n  - and by effect move through the PR processgg\n\n##### [Alternative linking options][]\n\n- `Just let me try it out`: Great way to test the tool or show the team\n\n##### Linking static data tables\n\n1. Right click a database in [[s.q.tsql.tools.ssms]]\n2. `Other SQL Source Control tasks`\n3. `Link or unlink static data`\n4. `save and close`\n5. Right click a database in [[s.q.tsql.tools.ssms]]\n6. `Commit changes to source control`\n7. In source control pane you will now see a commit with the data link change type that shows the diff as a bunch of insert statements\n8. Commit message and commit\n   - Result is that in your source control repository there is now a `Data/` directory with a SQL file in it consisting of the insert statements.\n\n- **To source control the data on your tables they need a PK**\n\n#### Working with SQL Source Control\n\n##### Committing changes\n\n- any changes made to DB ojects just\n  - Right click a database in [[s.q.tsql.tools.ssms]]\n  - `Commit changes to source control`\n\n##### Sharing changes with a team using SQL Source Control\n\n- New database exists\n\n1. Right click a database in [[s.q.tsql.tools.ssms]]\n2. `Link this database to source control`\n3. Instead of committing, `get latest` to `git pull` your team's work into your now versioned DB\n\n##### Working with Distributed Version Control Systems\n\n- If using git then you need to commit changes to the local repository first (the folder on your local machine)\n- Then SQL Source Control will tell you that there is a commit in your local repository that can be pushed to the remote repository and give you an easy button to do that.\n\n##### Reviewing the history\n\n- Right click on the object in the [[s.db.ms-sql-server.tools.ssms]] object explorer\n- `View History`\n- see the commit history of an object\n\n##### Undoing a change\n\n1. Right click a database in [[s.q.tsql.tools.ssms]]\n2. `Other SQL Source Control Tasks`\n3. `Undo Changes`\n\nRolling back changes (undo) on the database to a prior state:\n\n1. Right click a database in [[s.q.tsql.tools.ssms]]\n2. `View History`\n3. left click on version line item you want to roll back to\n4. At bottom of menu `Update your database to the selected version using:`\n   - Select your compare product to do the comparison\n\n#### Advanced SQL Source Control operations\n\n##### Conflict resolution\n\n##### Using object locking with SQL Source Control\n\n- For shared database model (think sharepoint item checkout)\n\n##### Setting up filters\n\n- Filter rules are basically a GUI version of a gitignore for ignoring certain types of objects\n\n##### Updating to a previous revision\n\n#### Manual Deployments with SQL Source Control\n\n##### Deploying schema changes with SQL Compare\n\n##### Deploying data changes with SQL Data Compare\n\n##### Deploying without access to your target\n","n":0.041}}},{"i":1159,"$":{"0":{"v":"Sql Change Automation","n":0.577},"1":{"v":"\n## Getting started with SQL Change Automation with SQL Source Control Projects\n\n### CI Builds using the SCA Azure DevOps Extensions\n\n<https://www.red-gate.com/hub/university/courses/sql-change-automation/sql-change-automation/ci-builds-using-the-sca-azure-devops-extensions/installing-azure-devops-extensions>\n\n#### Installing the Azure DevOps extensions\n\n- Extensions: <https://marketplace.visualstudio.com/search?term=REDGATE&target=AzureDevOps&category=All%20categories&sortBy=Relevance>\n\n","n":0.192}}},{"i":1160,"$":{"0":{"v":"Deploy","n":1},"1":{"v":"\n## SQL Server Tools in Redgate Deploy\n\n### [SQL Server Tools in Redgate Deploy](https://www.red-gate.com/hub/university/courses/redgate-deploy/introduction-to-redgate-deploy/redgate-deploy/sql-server)\n\n- Redgate deploy can integrate with [[s.apps.azure.pipelines]] and [[cli.cmd.git.tools.github.github-actions]] to name a few services, to enable release automation\n","n":0.183}}},{"i":1161,"$":{"0":{"v":"Pythons Staticmethod and Classmethod What Are They For","n":0.354},"1":{"v":"\n\n- `URL:` <https://youtu.be/SXApHXsDe8I>\n- `Channel/Host:` mCoding\n- `Publish Date:` 2021.11.27\n- `Reviewed Date:` \n\n---\n\n<center><iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/SXApHXsDe8I\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></center>\n\n---\n\n-\n\n","n":0.218}}},{"i":1162,"$":{"0":{"v":"Python Programming 86 Sql and Sqlite with Python 12 Minute Review","n":0.302},"1":{"v":"\n\n- `URL:` <https://youtu.be/DQ91bQzdRrk>\n- `Channel/Host:` Caleb Curry\n- `Publish Date:` 2020.09.26\n- `Reviewed Date:` \n\n---\n\n<center><iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/DQ91bQzdRrk\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></center>\n\n---\n\n-\n\n","n":0.213}}},{"i":1163,"$":{"0":{"v":"Programming Terms Memoization","n":0.577},"1":{"v":"\n\n- `URL:` <https://youtu.be/a7EjmdQzPqY>\n- `Channel/Host:` Corey Schafer\n- `Publish Date:` 2015.10.28\n- `Reviewed Date:` \n\n---\n\n<center><iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/a7EjmdQzPqY\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></center>\n\n---\n\n-\n\n","n":0.213}}},{"i":1164,"$":{"0":{"v":"Playlists to Pick through for Videos","n":0.408},"1":{"v":"\n\n- Pick through this playlist to find inputs <https://www.youtube.com/playlist?list=PLWKjhJtqVAbnqBxcdjVGgT3uVR10bzTEB>\n- Pick through this playlist to find inputs <https://www.youtube.com/playlist?list=PLWKjhJtqVAbkmRvnFmOd4KhDdlK1oIq23>\n- Pick through this playlist to find inputs <https://www.youtube.com/playlist?list=PLWKjhJtqVAblFnET3DbnAik--u4CBz62G>\n","n":0.2}}},{"i":1165,"$":{"0":{"v":"Natural Language Processing with Spacy and Python Course for Beginners","n":0.316},"1":{"v":"\n\n- `URL:` <https://youtu.be/dIUTsFT2MeQ>\n- `Channel/Host:` FreeCodeCamp\n- `Publish Date:` 2021.09.27\n- `Reviewed Date:` \n\n---\n\n<center><iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/dIUTsFT2MeQ\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></center>\n\n---\n\n-\n\n","n":0.218}}},{"i":1166,"$":{"0":{"v":"Mongodb Crash Course","n":0.577},"1":{"v":"\n\n- `URL:` <https://youtu.be/ofme2o29ngU>\n- `Channel/Host:` Web Dev Simplified\n- `Publish Date:` 2021.09.28\n- `Reviewed Date:` \n\n---\n\n<center><iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/ofme2o29ngU\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></center>\n\n---\n\n-\n\n","n":0.209}}},{"i":1167,"$":{"0":{"v":"Mind Bending Metaclasses Adding Function Overloads to Python","n":0.354},"1":{"v":"\n\n- `URL:` <https://youtu.be/yWzMiaqnpkI>\n- `Channel/Host:` mCoding\n- `Publish Date:` 2021.10.02\n- `Reviewed Date:` \n\n---\n\n<center><iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/yWzMiaqnpkI\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></center>\n\n---\n\n-\n\n","n":0.218}}},{"i":1168,"$":{"0":{"v":"Kubernetes Course Full Beginners Tutorial Containerize Your Apps","n":0.354},"1":{"v":"\n\n<https://youtu.be/d6WC5n9G_sM>\n","n":1}}},{"i":1169,"$":{"0":{"v":"Iterators, Iterables, and Itertools in Python Python Tutorial Learn Python Programming","n":0.302},"1":{"v":"\n\n- `URL:` <https://youtu.be/WR7mO_jYN9g>\n- `Channel/Host:` Socratica\n- `Publish Date:` 2021.09.27\n- `Reviewed Date:` \n\n---\n\n<center><iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/WR7mO_jYN9g\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></center>\n\n---\n\n-\n\n","n":0.218}}},{"i":1170,"$":{"0":{"v":"If You Are Not Using Python Data Classes yet You Should ","n":0.302},"1":{"v":"\n\n- [[s.l.python]] [If you're not using Python DATA CLASSES yet, you should üöÄ](https://youtu.be/vRVVyl9uaZc)\n","n":0.277}}},{"i":1171,"$":{"0":{"v":"Eleven Tips and Tricks to Write Better Python Code","n":0.333},"1":{"v":"\n\n- `URL:` <https://youtu.be/8OKTAedgFYg>\n- `Channel/Host:` python-engineer\n- `Publish Date:` 2020.07.05\n- `Reviewed Date:` \n\n---\n\n<center><iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/8OKTAedgFYg\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></center>\n\n---\n\n-\n\n","n":0.218}}},{"i":1172,"$":{"0":{"v":"Do We Still Need Dataclasses Pydantic Tutorial","n":0.378},"1":{"v":"\n\n- [Do we still need dataclasses? // PYDANTIC tutorial](https://youtu.be/Vj-iU-8_xLs)\n  - <https://github.com/ArjanCodes/2021-dataclasses>\n  - <https://github.com/ArjanCodes/2021-pydantic>\n  - <https://pydantic-docs.helpmanual.io/>\n","n":0.258}}},{"i":1173,"$":{"0":{"v":"Diagnose Slow Python Code Featuring Async Await","n":0.378},"1":{"v":"\n\n- `URL:` <https://youtu.be/m_a0fN48Alw>\n- `Channel/Host:` mCoding\n- `Publish Date:` 2021.06.26\n- `Reviewed Date:` \n\n---\n\n<center><iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/m_a0fN48Alw\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></center>\n\n---\n\n-\n\n","n":0.218}}},{"i":1174,"$":{"0":{"v":"Data Classes in Python Are the New Standard","n":0.354},"1":{"v":"\n\n- `URL:` <https://youtu.be/ojrbuVKblew>\n- `Channel/Host:` NeuralNine\n- `Publish Date:` 2021.08.24\n- `Reviewed Date:` \n\n---\n\n<center><iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/ojrbuVKblew\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></center>\n\n---\n\n-\n\n","n":0.218}}},{"i":1175,"$":{"0":{"v":"Building a Custom Context Manager in Python a Closer Look","n":0.316},"1":{"v":"\n\n<https://youtu.be/14z_Tf3p2Mw>\n","n":1}}},{"i":1176,"$":{"0":{"v":"Args and Kwargs in Python Accept Unlimited Arguments","n":0.354},"1":{"v":"\n\n- <https://youtu.be/L9pw3kbc4KI>\n","n":0.707}}},{"i":1177,"$":{"0":{"v":"Any Function in Python Check If an Iterable Contains True","n":0.316},"1":{"v":"\n\n- `URL:` <https://youtu.be/h5YiHNh8S5Y>\n- `Channel/Host:` Tech With Tim\n- `Publish Date:` 2021.09.28\n- `Reviewed Date:` \n\n---\n\n<center><iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/h5YiHNh8S5Y\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></center>\n\n---\n\n-\n\n","n":0.209}}},{"i":1178,"$":{"0":{"v":"2022","n":1}}},{"i":1179,"$":{"0":{"v":"07","n":1}}},{"i":1180,"$":{"0":{"v":"06","n":1}}},{"i":1181,"$":{"0":{"v":"Mastering Chaos a Netflix Guide to Microservices","n":0.378},"1":{"v":"\n## Challenges and Solutions\n\n### Dependency\n\n#### Intra-service Requests\n\n- Microservice A talking to Microservice B\n- Problems\n  - Network Latency, Congestion, failure\n  - Logical or Scaling failure\n- Solutions\n  - Have a fallback service to call or at the very least a static response that allows the customer to carry on with their business\n  - fail fast, and return to the fallback or wait to recover\n  - (FIT) Fault Injection Testing\n    - Synthetic Transactions\n    - Override by device or account\n    - % of live traffic up to 100% (test a launched service under load from live customers)\n    - Enforced thoughout the call\n  - How do we contrain testing scope?\n    - the most critical services are identified as a group for barest functionality and a FIT reciepe is made and blacklists all non-essential services\n\n#### Client Libraries\n\n#### Data Persistence\n\n- CAP Theorem: \"In the presence of a network partition, you much choose between consistency and availability.\"\n  - If you have 1 service needing to write to 3 databases, what if one write fails?\n    - Do you cancel the write? or do you write to what you can?\n    - you can aim for eventual consistency by writing to what databases you can and settle up later\n    - The client writes to one node which then orchestrates the writing to all the other nodes\n      - \"Local Quorum\"\n\n#### Infrastructure\n\n- Have redundant hosting across nodes to prevent catastrophic down time\n\n### Scale\n\n#### Stateless Services\n\n- Its not a cache or database\n- frequently accessed metadata\n- no instance affinity\n- loss of a node is a non-event\n- Autoscaling groups\n  - Compute efficiency\n  - Node failure\n  - Traffic Spikes\n  - Performance Bugs\n- Chaos monkey tool test that when a node dies, the service continues to work\n\n#### Stateful Services\n\n- databases and caches\n- sometimes a custom app that holds large amounts of data (avoid storing business logic, and state within 1 application if you can avoid it)\n- loss of a node is a notable event\n- redundancy is fundemental\n- EVCache -> difference nodes -> each node has multiple shard caches\n- separate out systems used for batch versus real time transactions\n- do request level caching\n- have an encrypted token with the data to fall back on should the service be unavailable to updated the requested data\n\n### Variance\n\n#### Operation Drift\n\n- drift over time\n  - alert thresholds\n  - timeouts, retries, fallbacks\n  - throughput (RPS)\n- Across microservices\n  - Reliability best practices\n- Continious learning and automation\n  - Incident --> Resolution --> Review --> Remediation --> Analysis --> Best Practices? --> Automation --> Adoption\n- Production Ready best practices\n  - Alerts\n  - Apache & tomcat\n  - Automated canary Analysis\n  - Autoscaling\n  - Chaos\n  - Consistent naming\n  - ELB Config\n  - Healthcheck\n  - Immutable machine images\n  - Squeeze testing\n  - Staged, red/black deployments\n  - Timeouts, retries, fallbacks\n\n#### Polyglot & Containers\n\n- The Paved Road (do this for a smooth experience)\n  - Stash\n  - Nebula/Gradle\n  - BaseAMI/Ubuntu\n  - Jenkins\n  - Spinnaker\n  - Runtime Platform\n- Cost of Variance\n  - Productivity Tooling\n  - Insight & Triage Capabilities\n  - Base Image Fragmentation\n  - Node management\n  - Library/Platform duplication\n  - Learning curve - production expertise\n- Strategic Stance\n  - Raise awareness of costs\n  - Constrain centralized support\n  - Prioritize by impact\n  - Seek reusable solutions\n\n### Change\n\n- Integrated, Automated practices\n  - Conformity checks\n  - Red/black pipelines\n  - Automated canaries\n  - Staged deployments\n  - Squeeze tests\n","n":0.043}}},{"i":1182,"$":{"0":{"v":"05","n":1}}},{"i":1183,"$":{"0":{"v":"10 Design Patterns Explained in 10 Minutes","n":0.378},"1":{"v":"\n- <https://youtu.be/tv-_1er1mWI>\n\n![[theory.design-patterns]] ","n":0.707}}},{"i":1184,"$":{"0":{"v":"04","n":1}}},{"i":1185,"$":{"0":{"v":"26","n":1}}},{"i":1186,"$":{"0":{"v":"Scary Sql Surprises and Mistakes with Brent Ozar Redgate","n":0.333},"1":{"v":"\nBrentOzarl.com/sp_blitz for any disabled indexes in any databases\nDDL triggers for when people create a table without a clustered index\n\n<https://www.youtube.com/embed/UesS08AUcDQ?start=639&end=1057>\n\nSQL Server, dont install SSIS, SSRS, SSAS onto the sql server box, the RAM is the most valuable thing you have there\nDont run SSMS on the SQL server dont even remote in\ndump as much memory as you can into it\n","n":0.131}}},{"i":1187,"$":{"0":{"v":"03","n":1}}},{"i":1188,"$":{"0":{"v":"16","n":1}}},{"i":1189,"$":{"0":{"v":"Super Pythons Most Misunderstood Feature","n":0.447},"1":{"v":"\n- [docs][1]\n- [code used][2]\n\n[1]: https://docs.python.org/3.8/library/functions.html#super\n[2]: https://github.com/mCodingLLC/VideosSampleCode/tree/master/videos/093_super_in_python\n","n":0.408}}},{"i":1190,"$":{"0":{"v":"12","n":1}}},{"i":1191,"$":{"0":{"v":"__new__ Vs __init__ in Python","n":0.447},"1":{"v":"\n<center><iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/-zsV0_QrfTw\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></center>\n\n---\n\n![[s.l.python.quirks.dunder-methods.in-oop.__new__]]\n","n":0.302}}},{"i":1192,"$":{"0":{"v":"02","n":1}}},{"i":1193,"$":{"0":{"v":"24","n":1}}},{"i":1194,"$":{"0":{"v":"What_is_api_idempotency_and_why_is_it_important","n":1},"1":{"v":"\n## Metadata\n\n<https://youtu.be/I08syTslan8>\n\n---\n\n<center><iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/I08syTslan8\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></center>\n\n---\n\n## Notes\n\n- [[terms.idempotent]] [[terms.api]]'s should not duplicate an outcome despite duplicating requests\n  - should a server not respond to a request then if we send more requests the outcome should not result in multiple events or side effects\n- Resilient [[terms.api]]'s use built-in client retries, client generated tokens to guarantee [[terms.idempotent]]cy, and return identical responses to support predictable client behavior\n- Approaches\n  - ![attempt1](/assets/images/2022-02-24-13-36-48.png)\n    - Client makes request\n    - [[terms.api]] Arguments are sent to the Resource server\n    - A hash function on the arguments is generated and creates a request token\n    - The request token is then stored in a stateStore database in the resource server\n    - The resources server then fulfills the request\n    - If a duplicate request is sent, the first thing that happens is the stateStore is checked for this request and if it has already been fulfilled then it can kick back an error response and not crash.\n      - The token's uniqueness could be the hash, on several items, the timestamp, the user, the actual request content, and several other things to make it easily unique\n        - downside is, what if we actually WANTED to have multiple requests granted?\n  - ![A better way](/assets/images/2022-02-24-13-50-53.png)\n    - Instead of resource server inspecting the resource arguments to determine if this is a repeat request or a duplicate, or retry we put the onus on the Client\n    - as part of the [[terms.api]] contract, you (the user) need to provide a [[terms.uuid]] as part of sending a request\n    - this way the token from the client sent to the resource server is either duplicated for a retry or a duplicate action and can get processed or kicked back if appropriate\n    - but if the client sends a duplicate request but with a different [[terms.uuid]] then the resources server can check the state store and determine that multiple requests need to be fulfilled.\n    - Important point is that for any requests that use the same token, the resource server but return syntactically identical responses\n      - Why is this important?\n        - ![Always Success](/assets/images/2022-02-24-13-58-19.png)\n        - What if our first request made it through and our request was fulfilled, and we never got a response of success back\n        - We then send a retry which is now a duplicate request in the stateStore.\n        - Do we send an error message back that a duplicate operation is occurring?\n        - No, we should just send a `Success` response back for the duplicate request because the request has already been fulfilled so ultimately the duplicate is trying to do something that was already done so in this case the user receives success\n","n":0.048}}},{"i":1195,"$":{"0":{"v":"22","n":1}}},{"i":1196,"$":{"0":{"v":"The Ideal CI CD Pipeline Concepts Overview","n":0.378},"1":{"v":"\n\n<center><iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/OPwU3UWCxhw\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></center>\n\n![Ideal Pipeline](/assets/images/2022-02-22-17-35-55.png)\n\n- **Source** \n  - [[cli.cmd.git]] version control\n  - Require `X` reviewers\n  - Independent Dev DB and any dependencies are replicated for Dev copies\n- **Build**\n  - Should be Toggle-able for when you dont want something to run through the gamut\n  - Compile Source and Dependencies\n  - Unit tests\n  - Coverage > 90%\n- **Test**\n  - Independent Test DB\n  - Should be Toggle-able for when you dont want something to run through the gamut\n  - Integration tests\n    - If you have an [[terms.api]] then test a POST request followed by a GET request\n    - If you have external service dependencies, test them too\n    - In essence, test the core functionality of your app so that changed behavior will easily show up\n- **Prod** (1box)\n  - Independent Prod DB\n  - 1 Box (have incremental roll out to a single machine or a small fraction of them so impacts are smaller and more readily identified and rolled back)\n  - Alarms on Errors, Latency, and Key business Metrics can indicate a needed rollback\n    - Robust system can monitor these and run an automated rollback\n  - Bake Period (24hrs)\n    - Testing that the change is still good live in prod\n    - Anomaly Detection or Error counts + Latency Breaches over the time period\n  - Canary (in a coal mine)\n    - Have a cron job test the [[terms.api]] at a regular interval (POST/GET/UPDATE/DELETE etc.)\n    - Should the cron job fail then it can be an alarm.\n- **Prod**\n  - The other 90% of the traffic\n  - Also has all the Alarms, canary, etc. from the 1box too\n  - Traffic split through [[n.protocol.dns]]?\n","n":0.061}}},{"i":1197,"$":{"0":{"v":"17","n":1}}},{"i":1198,"$":{"0":{"v":"Bryson Tyrrell Your Code Should Document Itself Embedding Documentation into Your Python Projects","n":0.277},"1":{"v":"\n\n<center><iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/JQ8RQru-Y9Y\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></center>\n\n![[s.m.restructured-text.syntax]]\n![[s.m.restructured-text.tools.sphinx]]\n![[s.m.restructured-text.read-the-docs]]\n","n":0.302}}},{"i":1199,"$":{"0":{"v":"01","n":1}}},{"i":1200,"$":{"0":{"v":"27","n":1}}},{"i":1201,"$":{"0":{"v":"Best Practices around Production Ready Web Apps with Docker Compose","n":0.316},"1":{"v":"\n- REVISIT\n  - `docker-compose.overrive.yml` for further splitting prod and dev container builds\n  - Variable interpolation with similar [[s.l.bash]] syntax `${variable:calue}`?\n","n":0.224}}},{"i":1202,"$":{"0":{"v":"11","n":1}}},{"i":1203,"$":{"0":{"v":"Python API Development Comprehensive Course for Beginners","n":0.378},"1":{"v":"\n\n- `URL:` <https://youtu.be/0sOvCWFmrtA>\n- `Channel/Host:` FreeCodeCamp\n- `Publish Date:` 2021.11.01\n\n---\n\n<center><iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/0sOvCWFmrtA\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></center>\n\n---\n\n## Authentication\n\n## CRUD Operation\n\n![alt](assets/images/Pasted_image_20211221144047.png)\n\n- Convention is that the end point uses plurals:\n  - user --> users\n  - post --> posts\n\n## Validation\n\n## Documentation\n\n<https://github.com/Sanjeev-Thiyagarajan/fastapi-course>\n","n":0.16}}},{"i":1204,"$":{"0":{"v":"07","n":1}}},{"i":1205,"$":{"0":{"v":"Pyinstrument Introduction","n":0.707},"1":{"v":"\n<https://calmcode.io/pyinstrument/introduction.html>\n","n":1}}},{"i":1206,"$":{"0":{"v":"2021","n":1}}},{"i":1207,"$":{"0":{"v":"12","n":1}}},{"i":1208,"$":{"0":{"v":"21","n":1}}},{"i":1209,"$":{"0":{"v":"How to Easily Do Asynchronous Programming with Asyncio in Python","n":0.316},"1":{"v":"\n\n- `URL:` <https://youtu.be/2IW-ZEui4h4>\n- `Channel/Host:` ArjanCodes\n- `Publish Date:` 2021.12.17\n- `Reviewed Date:` [[log.daily.2021.12.21]]\n\n---\n\n<center><iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/2IW-ZEui4h4\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></center>\n\n---\n\n## Example:\n\n```python\nimport asyncio\n\nasync def main():\n\tawait asyncio.sleep(0.5)\n\tprint('Bryan')\n\tawait asyncio.sleep(0.5)\n\nasyncio.run(main())\n\n#>>> Bryan\n```\n\n### async\n\n```python\nimport asyncio\n\nasync def main():\n\tprint('Bryan')\n\nasyncio.run(main())\n```\n\n### await\n\n```python\nimport asyncio\n\nasync def main():\n\tawait asyncio.sleep(0.5)\n\tprint('Bryan')\n\tawait asyncio.sleep(0.5)\n\nasyncio.run(main())\n\n#>>> Bryan\n```\n\n### gather\n\nRun several functions in parallel\n\n```python\nimport asyncio\n\nasync def main0():\n\tprint('Bryan')\n\nasync def main1():\n\tprint('John')\n\nasync def main2():\n\tprint('Jane')\n\nasync def testing():\n    asyncio.gather(\n            main0(),\n            main1(),\n            main2()\n    )\n\nasyncio.run(testing())\n\n```\n\n### Structure parallelism and sequential execution elegantly\n\n```python\nimport asyncio\n\nasync def run_sequence(*functions: Awaitable[Any]) -> None:\n\tfor function in functions:\n\t\tawait function\n\nasync def run_parallel(*functions: Awaitable[Any]) -> None:\n\tawait asyncio.gather(*functions)\n\n```\n\n","n":0.112}}},{"i":1210,"$":{"0":{"v":"15","n":1}}},{"i":1211,"$":{"0":{"v":"Python Typing Type Hints and Annotations","n":0.408},"1":{"v":"\n\n- `URL:` <https://youtu.be/QORvB-_mbZ0>\n- `Channel/Host:` Tech With Tim\n- `Reference:` [[Typing|s.l.python.libs.typing]]\n- `Publish Date:` 2021.09.29\n- `Reviewed Date:` [[log.daily.2021.12.15]]\n\n---\n\n<center><iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/QORvB-_mbZ0\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></center>\n\n---\n\n- [09:20](https://youtu.be/QORvB-_mbZ0#t=560.036194) \n  - To do a type annotation for items in a list (a vector basically) you can pass the type like `list[int]` but this can also be used to pass things like a list of int lists: `list[list[int]]`\n  - To use `List` as a type you need to `from typing import List` : `List[List[int]]`\n- [10:31](https://youtu.be/QORvB-_mbZ0#t=631.544946)\n  - `from typing import Dict`\n  - Dictionary typing: `x: Dict[str, str] = {\"a\": \"b\"}`\n- [10:56](https://youtu.be/QORvB-_mbZ0#t=656.309631835968)\n  - `from typing import Set`\n  - Set typing: `x: Set[str] = {\"a\", \"b\"}`\n- [11:42](https://youtu.be/QORvB-_mbZ0#t=702.2289898435974)\\`\n  - Custom Typing:\n  - ```python\n    from typing import List\n\n    Vector = List[float]\t\n\n    def foo(v: Vector) -> Vector:\n    \tprint(v)\n    ```\n  - ![alt](assets/images/Pasted_image_20211215085306.png)\n  - Can also use our own custom types like this: \n  - ```python\n    from typing import List\n\n    Vector = List[float]\n    Vectors = List[Vector]\n\n    def foo(v: Vectors) -> Vectors:\n    \tprint(v)\n    ```\n- [14:22](https://youtu.be/QORvB-_mbZ0#t=862.292403)\n  - Optional typing\n  - ```python\n    from typing import Optional\n\n    def foo(output: Optional[bool]=False):\n    \tpass\n    foo()\n    ```\n- [14:33](https://youtu.be/QORvB-_mbZ0#t=873.880233)\n  - Any Type is the same as not adding an annotation but more explicit\n  - ```python\n    from typing import Any\n\n    def foo(output: Any):\n    \tpass\n    ```\n- [15:25](https://youtu.be/QORvB-_mbZ0#t=925.293389)\n  - Sequence Type\n  - ```python\n    from typing import Sequence\n\n    def foo(seq: Sequence[str]):\n    \tpass\n    foo(\"Hello\") # This is fine because a string is a sequence of characters\n    foo((\"a\", \"b\", \"c\")) # a Tuple is an ordered and immutable indexed Object\n    foo([\"a\", \"b\", \"c\"]) # A list is an ordered and indexed object \n    foo({1, 2, 3}) # A set is hashed and not indexed or ordered so it cannot be a sequence\n    foo(1)\n    #>>> Last one throws an error because static analysis determines that it is an incompabile type\n    ```\n- [17:11](https://youtu.be/QORvB-_mbZ0#t=1031.02662)\n  - Tuple Type:\n  - ```python\n    from typing import Tuple\n\n    # This is an error because the tuple can contain items of differing types \n    # so you need to specify the type of each item within it\n    x: Tuple[int] = (1, 2, 3) \n\n    x: Tuple[int, int, int] = (1, 2, 3)\n    ```\n- [18:16](https://youtu.be/QORvB-_mbZ0#t=1096.941175)\n  - Callable Type:\n  - ```python\n    from typing import callable, Optional\n\n    def foo(func: Callable[[int, int, Optional[int]], int]) -> None:\n    \tfunc(1, 2)\n\n    def add(x: int, y: int) -> int:\n    \treturn x + y\n\n    foo(add)\n\n    #=================================================================#\n\n    def foo() -> Callable[[int, int, Optional[int]], int]):\n    \tdef add(x: int, y: int) -> int:\n    \t\treturn x + y\n    \treturn add\n\n    foo()\n\n    #=================================================================#\n\n    def foo() -> Callable[[int, int], int]):\n    \tfunc: Callable[[int, int], int]) = Lambda x, y: x + y\n    \treturn func\n\n    foo()\n    ```\n- [21:40](https://youtu.be/QORvB-_mbZ0#t=1300.829273)\n  - Generics:\n  - ```python\n    from typing import TypeVar, List\n\n    T = TypeVar('T')\n\n    def get_item(lst: List[T], index: int) -> T:\n    \treturn lst[index]\n    ```\n\n","n":0.047}}},{"i":1212,"$":{"0":{"v":"07","n":1}}},{"i":1213,"$":{"0":{"v":"Get the Last Argument of the Last Run Command in Your Shell","n":0.289},"1":{"v":"\n\n- `URL:` <https://youtu.be/vt-IvdFP5ZA>\n- `Channel/Host:` nick-janetakis\n- `Publish Date:` 2021.12.07\n- `Reviewed Date:` 2021.12.07\n\n---\n\n<center><iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/vt-IvdFP5ZA\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></center>\n\n---\n\n- `$_` will give you the last argument of the last run command:\n\n```bash\nmkdir testDir\necho \"$_\"\n#> testDir\n```\n\n- `${_}` runs the last run command\n\n","n":0.154}}},{"i":1214,"$":{"0":{"v":"11","n":1}}},{"i":1215,"$":{"0":{"v":"18","n":1}}},{"i":1216,"$":{"0":{"v":"Python F Strings Can Do More than You Thought","n":0.333},"1":{"v":"\n\n- `URL:` <https://youtu.be/BxUxX1Ku1EQ>\n- `Channel/Host:` mCoding\n- `Publish Date:` 2021.06.19\n- `Reviewed Date:` [[import.research.video.2021.11.18]]\n\n---\n\n<center><iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/BxUxX1Ku1EQ\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></center>\n\n---\n\n- f strings that have a trailing `=` will print a statement like this:\n\n```python\nx=7\nprint(f'{x=}')\n# >>> x=7\nprint(f'{x =}')\n# >>> x =7\nprint(f'{x = }')\n# >>> x = 7\n```\n\n- to print the repr of the value end the fstring with a `!r`:\n\n```python\nx = \"hello ‚úÖ\"\nprint(f'{x!r}')\n# >>> \"hello ‚úÖ\"\n```\n\n- to print only ascii values end the fstring with a `!a`:\n\n```python\nx = \"hello ‚úÖ\"\nprint(f'{x!a}')\n# >>> \"hello \\u2705\"\n```\n\n- to print string values without quotes end the fstring with a `!s`:\n\n```python\nx = \"hello ‚úÖ\"\nprint(f'{x!a}')\n# >>> hello ‚úÖ\n```\n\n**Formatting**\n\n- format fstrings with a colon in the brace and the format on the right hand side\n\n`import datetime; print(f'{datetime.datetime.utcnow():%Y-%m-%d}')`\n\n**Nested Formatting**\n\n```python\nnum_value = 123.456\nnested_format = \".2f\"\nprint(f'{num_value:{nested_format}}')\n# >>> 123.46\n```\n\n","n":0.089}}},{"i":1217,"$":{"0":{"v":"15","n":1}}},{"i":1218,"$":{"0":{"v":"What Is a Patch Panel Do You Need One","n":0.333},"1":{"v":"\n\n- `URL:` <https://youtu.be/lg2oGE02DJE>\n- `Channel/Host:` Budget Nerd\n- `Publish Date:` 2017.04.28\n- `Reviewed Date:` [[log.daily.2021.11.15]]\n\n---\n\n<center><iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/lg2oGE02DJE\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></center>\n\n---\n\n- Patch panel is solely used for organization\n- Patch panels typically are used for\n  - Network jack cabling that will never be changed\n  - Running Hard lines to various locations\n  - organizing cable output locations into the patch panel which goes into the router\n    - This way when the patch cable between the patch panel and switch wears out its not the house wiring that is getting worn its the disposable gear.\n- Patch panel cables that get ran through your house are not stranded cables rather they are solid core cables and are not meant to be handled often\n- Patch panel cabling is useful for terminating wire ends of house cabling into the panel which turns into jacks to connect to the switch/router\n\n","n":0.083}}},{"i":1219,"$":{"0":{"v":"10","n":1}}},{"i":1220,"$":{"0":{"v":"25","n":1}}},{"i":1221,"$":{"0":{"v":"Generators in Python Python Tutorial Learn Python Programming","n":0.354},"1":{"v":"\n\n- `URL:` <https://youtu.be/gMompY5MyPg>\n- `Channel/Host:` [[@Socratica|@socratica]]\n- `Publish Date:` 2021.10.25\n- `Reviewed Date:` 2021.10.25\n\n---\n\n<center><iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/gMompY5MyPg\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></center>\n\n---\n\n-\n\n","n":0.218}}},{"i":1222,"$":{"0":{"v":"20","n":1}}},{"i":1223,"$":{"0":{"v":"Beautiful Python Refactoring","n":0.577},"1":{"v":"\n\n- `URL:` <https://youtu.be/KTIl1MugsSY>\n- `Channel/Host:` coding-tech\n- `Publish Date:` 2020.04.19\n- `Reviewed Date:` 2021.10.20\n\n---\n\n<center><iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/KTIl1MugsSY\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></center>\n\n---\n\n- Change 1\n  - Enumerate\n    - Before\n      - ![alt](assets/images/Pasted_image_20211020110345.png)\n    - After\n      - ![alt](assets/images/Pasted_image_20211020110412.png)\n    - Remove print, its superflous\n      - ![alt](assets/images/Pasted_image_20211020110450.png)\n    - Change to list comprehension\n      - Before\n        - ![alt](assets/images/Pasted_image_20211020110517.png)\n      - After\n        - ![alt](assets/images/Pasted_image_20211020110528.png)\n- Avoid the [[Itm|theory.anti-patterns.itm]]\n- Change 5\n  - Use Slicing for lists\n    - Before\n      - ![alt](assets/images/Pasted_image_20211020110917.png)\n    - After\n      - ![alt](assets/images/Pasted_image_20211020110929.png)\n- ![alt](assets/images/Pasted_image_20211020111618.png)\n\n","n":0.118}}},{"i":1224,"$":{"0":{"v":"11","n":1}}},{"i":1225,"$":{"0":{"v":"Chr and Ord in Python Using Ascii Values","n":0.354},"1":{"v":"\n\n- `URL:` <https://youtu.be/_tBHdKsRLVM>\n- `Channel/Host:` Tech With Tim\n- `Publish Date:` 2021.10.09\n- `Reviewed Date:` [[import.log.daily.2021.10.11]]\n\n---\n\n<center><iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/_tBHdKsRLVM\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></center>\n\n---\n\n- [00:21](https://youtu.be/_tBHdKsRLVM#t=21.631139091552733)\n  - `ord(\"A\")` == `65`\n- [00:39](https://youtu.be/_tBHdKsRLVM#t=39.979604)\n  - `chr(65)` == `\"A\"`\n\n","n":0.174}}},{"i":1226,"$":{"0":{"v":"Article","n":1}}},{"i":1227,"$":{"0":{"v":"Write Beautiful Python Documentation with Sphinx","n":0.408},"1":{"v":"\n\n- [[s.l.python]] [[s.l.python.libs.sphinx]] [Write Beautiful Python Documentation with Sphinx][6]\n\n[6]: https://python.plainenglish.io/documentation-with-sphinx-dd86bedb7512\n","n":0.316}}},{"i":1228,"$":{"0":{"v":"What‚Äôs New in Python 3 10 4 Amazing Features You Should Try","n":0.289},"1":{"v":"\n\n- `Author:` dario-radeƒçiƒá\n- `Link:` <https://towardsdatascience.com/whats-new-in-python-3-10-4-amazing-features-you-should-try-4f3044871476>\n- `Publish Date:` 2021.06.05\n- `Reviewed Date:` \n\n---\n\n-\n\n","n":0.302}}},{"i":1229,"$":{"0":{"v":"What Is Service Oriented Architecture","n":0.447},"1":{"v":"\n\n- <https://medium.com/@SoftwareDevelopmentCommunity/what-is-service-oriented-architecture-fa894d11a7ec>\n","n":0.707}}},{"i":1230,"$":{"0":{"v":"Vim to Emacs and Back","n":0.447},"1":{"v":"\n\n- `Author:` \n- `Link:` <https://sean-warman.medium.com/vim-to-emacs-and-back-a0025855037e>\n- `Publish Date:` 2021.04.16\n- `Reviewed Date:` \n\n---\n\n-\n\n","n":0.302}}},{"i":1231,"$":{"0":{"v":"The Power of the Plugin Architecture in Python","n":0.354},"1":{"v":"\n\n- [[s.l.python]] [The Power Of The Plugin Architecture In Python][1]\n\n[1]: https://youtu.be/iCE1bDoit9Q\n","n":0.302}}},{"i":1232,"$":{"0":{"v":"The Last 20 Python Packages You Will Ever Need","n":0.333},"1":{"v":"\n\n- `Author:` sandro-luck\n- `Link:` <https://pub.towardsai.net/the-last-20-python-packages-you-will-ever-need-a4bc0a0d1214>\n- `Publish Date:` 2021.09.18\n- `Reviewed Date:` \n\n---\n\n-\n\n","n":0.302}}},{"i":1233,"$":{"0":{"v":"The Future of Python Packages Is Here","n":0.378},"1":{"v":"\n\n- `Author:` \n- `Link:` <https://medium.com/trymito/the-future-of-python-packages-is-here-ea3769cff692>\n- `Publish Date:` 2021.09.11\n- `Reviewed Date:` \n\n---\n\n-\n\n","n":0.302}}},{"i":1234,"$":{"0":{"v":"Store Passwords Safely in Python","n":0.447},"1":{"v":"\n<https://python.plainenglish.io/store-passwords-safely-in-python-e38a8c0c8618>\n","n":1}}},{"i":1235,"$":{"0":{"v":"Sqlfluff the Linter for Modern Sql","n":0.408},"1":{"v":"\n\n- `Author:` daniel-mateus-pires\n- `Link:` <https://towardsdatascience.com/sqlfluff-the-linter-for-modern-sql-8f89bd2e9117>\n- `Publish Date:` 2021.05.13\n- `Reviewed Date:` \n\n---\n\n-\n\n","n":0.302}}},{"i":1236,"$":{"0":{"v":"Refactoring Code to Load a Document","n":0.408}}},{"i":1237,"$":{"0":{"v":"Python Functools Lru_cache","n":0.577},"1":{"v":"\n\n- `Author:` GeeksForGeeks\n- `Link:` <https://www.geeksforgeeks.org/python-functools-lru_cache/>\n- `Publish Date:` 2020.06.26\n- `Reviewed Date:` \n\n---\n\n-\n\n","n":0.302}}},{"i":1238,"$":{"0":{"v":"Python F Strings, Far beyond the Expectation","n":0.378},"1":{"v":"\n<https://python.plainenglish.io/python-f-strings-far-beyond-the-expectation-e2245cfef629>\n","n":1}}},{"i":1239,"$":{"0":{"v":"Python Design Patterns","n":0.577},"1":{"v":"\n<https://python-patterns.guide/>\n","n":1}}},{"i":1240,"$":{"0":{"v":"Python Dependency Inversion","n":0.577},"1":{"v":"\n\n- `Author:` zack-bunch \n- `Link:` <https://medium.com/@zackbunch/python-dependency-inversion-8096c2d5e46c>\n- `Publish Date:` 2021.07.24\n- `Reviewed Date:` \n\n---\n\n- related: [[The Dependency inversion Principle|r.{.clean-code.the-dependency-inversion-principle]]\n\n","n":0.243}}},{"i":1241,"$":{"0":{"v":"Python Custom Exceptions","n":0.577},"1":{"v":"\n\n- `Author:` \n- `Link:` <https://www.programiz.com/python-programming/user-defined-exception>\n- `Publish Date:` \n- `Reviewed Date:` \n\n---\n\n-\n\n","n":0.302}}},{"i":1242,"$":{"0":{"v":"Python behind the Scenes 13 the Gil and Its Effects on Python Multithreading","n":0.277},"1":{"v":"\n\n- `Author:` victor-skvortsov\n- `Link:` <https://tenthousandmeters.com/blog/python-behind-the-scenes-13-the-gil-and-its-effects-on-python-multithreading/>\n- `Publish Date:` 2021.09.22\n- `Reviewed Date:` \n\n---\n\n-\n\n","n":0.302}}},{"i":1243,"$":{"0":{"v":"Profiling","n":1},"1":{"v":"\n\n- Try out [[s.l.python]] [profiling][8]\n\n```python\nimport cProfile\nimport pstats\nwith cProfile.Profile() as pr:\n    yourfunctionhere()\nstats = pstats.Stats(pr)\nstats.sort_stats(pstats.SortKey.TIME)\nstats.print_stats()\n```\n\n[8]: https://docs.python.org/3/library/profile.html\n","n":0.267}}},{"i":1244,"$":{"0":{"v":"Pareto Chart with Python","n":0.5},"1":{"v":"\n\n- `Author:` roberto-salazar\n- `Link:` <https://medium.com/swlh/pareto-chart-with-python-5200459ee65c>\n- `Publish Date:` 2021.03.02\n- `Reviewed Date:` \n\n---\n\n-\n\n","n":0.302}}},{"i":1245,"$":{"0":{"v":"Pandas Tricks I Wish I Knew Earlier","n":0.378},"1":{"v":"\n\n- [[s.l.python]] [[s.l.python.libs.pandas]] [Pandas tricks I wish I knew earlier][1]\n\n[1]: https://preettheman.medium.com/pandas-tricks-i-wish-i-knew-earlier-b222f8d37f65\n","n":0.302}}},{"i":1246,"$":{"0":{"v":"Packaging in Python Tools and Formats","n":0.408},"1":{"v":"\n\n- `Author:` martin-thoma\n- `Link:` <https://towardsdatascience.com/packaging-in-python-tools-and-formats-743ead5f39ee>\n- `Publish Date:` 2020.11.06\n- `Reviewed Date:` \n\n---\n\n-\n\n","n":0.302}}},{"i":1247,"$":{"0":{"v":"Nbterm Jupyter Notebooks in the Terminal","n":0.408},"1":{"v":"\n\n- `Author:` david-brochart\n- `Link:` <https://blog.jupyter.org/nbterm-jupyter-notebooks-in-the-terminal-6a2b55d08b70>\n- `Publish Date:` 2021.04.26\n- `Reviewed Date:` \n\n---\n\n-\n\n","n":0.302}}},{"i":1248,"$":{"0":{"v":"Learning Python through Illustrated Stories Real Python Podcast 78","n":0.333},"1":{"v":"\n\n- [[s.l.python]] [Learning Python Through Illustrated Stories Real Python Podcast 78][1]\n\n[1]: https://youtu.be/oMSk9t_eI9I\n","n":0.289}}},{"i":1249,"$":{"0":{"v":"Kickstart Collaborative Devsecops Practices with GitHub and Azure","n":0.354},"1":{"v":"\n\n- [[s.apps.azure.devops]] [[cli.cmd.git.tools.github]] [[s.apps.azure.devops]] [kickstart collaborative DevSecOps practices with GitHub and Azure][1]\n\n[1]: https://techcommunity.microsoft.com/t5/azure-developer-community-blog/kickstart-collaborative-devsecops-practices-with-github-and/ba-p/2357730\n","n":0.277}}},{"i":1250,"$":{"0":{"v":"Jupyter Notebook and Vim Neovim","n":0.447},"1":{"v":"\n\n- `Author:` alpha2phi \n- `Link:` <https://alpha2phi.medium.com/jupyter-notebook-vim-neovim-c2d67d56d563>\n- `Publish Date:` 2021.09.26\n- `Reviewed Date:` \n\n---\n\n-\n\n","n":0.289}}},{"i":1251,"$":{"0":{"v":"Intoduction to Mongodb","n":0.577},"1":{"v":"\n\n<https://donaldfeury.xyz/introduction-to-mongodb/>\n","n":1}}},{"i":1252,"$":{"0":{"v":"I Modified an Sql Query from 24 Mins down to 2 Seconds a Tale of Query Optimization","n":0.243},"1":{"v":"\n\n- [[s.q.tsql]] [I modified an SQL query from 24 mins down to 2 seconds - A tale of query optimization](https://medium.com/swlh/i-modified-an-sql-query-from-24-mins-down-to-2-seconds-a-tale-of-query-optimization-bcf49d50174b)\n","n":0.224}}},{"i":1253,"$":{"0":{"v":"How to Scan a Container for Vulnerabilities and Publish Results as a Part of Azure Devops CI","n":0.243}}},{"i":1254,"$":{"0":{"v":"How to Scan a Container for Vulnerabilities and Publish Results as a Part of Azure Devops CI CD Pipeline","n":0.229},"1":{"v":"\n\n- [[s.apps.azure.devops]] [[terms.ci-cd]] [[s.apps.azure.pipelines]] [How to scan a container for vulnerabilities and publish results as a part of Azure DevOps CI/CD pipeline][1]\n\n[1]: https://www.winopsdba.com/blog/azure-cloud-container-build-scan-publish.html\n","n":0.209}}},{"i":1255,"$":{"0":{"v":"How to Encrypt and Decrypt Application Password Using Python","n":0.333},"1":{"v":"\n\n- `Author:` nabarun-chakraborti\n- `Link:` <https://ch-nabarun.medium.com/how-to-encrypt-and-decrypt-application-password-using-python-15893cd28bef>\n- `Publish Date:` 2021.06.01\n- `Reviewed Date:` \n\n---\n\n-\n\n","n":0.302}}},{"i":1256,"$":{"0":{"v":"How to Build Advanced Sql","n":0.447},"1":{"v":"\n\n- [[s.q.tsql]] [How to Build Advanced SQL][1]\n\n[1]: https://betterprogramming.pub/how-to-build-advanced-sql-798d615ba323\n","n":0.354}}},{"i":1257,"$":{"0":{"v":"Get Better at Python F Strings","n":0.408},"1":{"v":"\n\n- <https://python.plainenglish.io/get-better-at-python-f-strings-83b123bb4ce0>\n","n":0.707}}},{"i":1258,"$":{"0":{"v":"From Bullet Points to Data Storytelling","n":0.408},"1":{"v":"\n\n- `Author:` andr√©-sionek\n- `Link:` <https://medium.com/gousto-engineering-techbrunch/from-bullet-points-to-data-storytelling-6b0db47ce1e6>\n- `Publish Date:` 2021.05.11\n- `Reviewed Date:` \n\n---\n\n-\n\n","n":0.302}}},{"i":1259,"$":{"0":{"v":"Exercism","n":1},"1":{"v":"\n\n- [ ] <https://exercism.org/> ‚ùó‚ùó‚ùó‚ùó‚ùó\n","n":0.447}}},{"i":1260,"$":{"0":{"v":"Dotfiles for Developers Part 2","n":0.447},"1":{"v":"\n\n- `Author:` [[@Chris Jones|@chris-jones]]\n- `Link:` <https://leeked.medium.com/dotfiles-for-developers-part-2-2c02029f771e>\n- `Publish Date:` 2021.04.23\n- `Reviewed Date:` \n\n---\n\n-\n\n","n":0.289}}},{"i":1261,"$":{"0":{"v":"Design Pattern","n":0.707},"1":{"v":"\n![](assets/pdfs/Arjan%20Codes%20Software%20Design%20Guide.pdf)\n","n":1}}},{"i":1262,"$":{"0":{"v":"Data Warehouse Pipeline Basic Concepts and Roadmap","n":0.378},"1":{"v":"\n\n- [[terms.etl]] [[theory.data-warehousing]] [Data Warehouse Pipeline: Basic Concepts and Roadmap][1]\n\n[1]: https://towardsdatascience.com/building-a-data-warehouse-pipeline-basic-concepts-roadmap-d14032890ab6\n","n":0.302}}},{"i":1263,"$":{"0":{"v":"Data Engineering Battle Python Vs Sql Vs Visualcode","n":0.354},"1":{"v":"\n\n- `Author:` [[@Raj Bains|@raj-bains]]\n- `Link:` <https://medium.com/prophecy-io/data-engineering-battle-python-vs-sql-vs-visual-code-d440d899cce3>\n- `Publish Date:` 2021.07.26\n- `Reviewed Date:` \n\n---\n\n-\n\n","n":0.289}}},{"i":1264,"$":{"0":{"v":"Comparing Python and Sql for Building Data Pipelines","n":0.354},"1":{"v":"\n\n- `Author:` marc-laforet\n- `Link:` <https://towardsdatascience.com/python-vs-sql-comparison-for-data-pipelines-8ca727b34032>\n- `Publish Date:` 2019.02.16\n- `Reviewed Date:` \n\n---\n\n-\n\n","n":0.302}}},{"i":1265,"$":{"0":{"v":"Code as Documentation","n":0.577},"1":{"v":"\n\n- `Author:` monica-powell\n- `Link:` <https://github.com/readme/guides/code-as-documentation>\n- `Publish Date:` 2021.10.13\n- `Reviewed Date:` \n\n---\n\n-\n\n","n":0.302}}},{"i":1266,"$":{"0":{"v":"Avoiding Premature S Abstractions","n":0.5},"1":{"v":"\n\n- `Author:` jonas-tulstrup\n- `Link:` <https://betterprogramming.pub/avoiding-premature-software-abstractions-8ba2e990930a>\n- `Publish Date:` 2021.11.15\n- `Reviewed Date:` \n\n---\n\n-\n\n","n":0.302}}},{"i":1267,"$":{"0":{"v":"Automating Windows Applications Using Com","n":0.447},"1":{"v":"\n\n- `Author:` chris-moffitt\n- `Link:` <https://pbpython.com/windows-com.html>\n- `Publish Date:` 2018.07.02\n- `Reviewed Date:` \n\n---\n\n-\n\n","n":0.302}}},{"i":1268,"$":{"0":{"v":"Automated and Manual Testing with Azure Test Plan","n":0.354},"1":{"v":"\n\n- [[s.apps.azure.devops]] [[s.apps.azure.test-plans]] [Automated and Manual Testing with Azure Test Plan][7]\n\n[7]: https://youtu.be/LF0hmSysWCg\n","n":0.289}}},{"i":1269,"$":{"0":{"v":"Auto Documenting a Python Project Using Sphinx","n":0.378},"1":{"v":"\n\n- [[s.l.python]] [[s.l.python.libs.sphinx]] [Auto Documenting a Python Project Using Sphinx][5]\n\n[5]: https://betterprogramming.pub/auto-documenting-a-python-project-using-sphinx-8878f9ddc6e9\n","n":0.302}}},{"i":1270,"$":{"0":{"v":"5 Ways to Schedule Jobs in Python","n":0.378},"1":{"v":"\n\n- `Author:` pratik-choudhari\n- `Link:` <https://python.plainenglish.io/5-ways-to-schedule-jobs-in-python-99de8a80f28e>\n- `Publish Date:` 2021.09.06\n- `Reviewed Date:` \n\n---\n\n-\n\n","n":0.302}}},{"i":1271,"$":{"0":{"v":"5 Python Use Cases That Only a Few Programmers Know","n":0.316},"1":{"v":"\n\n- <https://levelup.gitconnected.com/5-python-use-cases-that-only-a-few-programmers-know-35e25ddf13d4>\n","n":0.707}}},{"i":1272,"$":{"0":{"v":"5 Best Windows 11 Apps for Productivity","n":0.378},"1":{"v":"\n\n- `Author:` Abhinav Chandoli\n- `Link:` <https://medium.com/geekculture/5-best-windows-10-apps-for-productivity-12d713b56d8e>\n- `Publish Date:` 2021.06.16\n- `Reviewed Date:` \n\n---\n\n-\n\n","n":0.289}}},{"i":1273,"$":{"0":{"v":"4 anti Patterns in Python and How to Avoid Them","n":0.316},"1":{"v":"\n\n- `Author:` Raimi Karim\n- `Link:` <https://betterprogramming.pub/4-anti-patterns-in-python-a6d5023c8473>\n- `Publish Date:` 2021.09.13\n- `Reviewed Date:` \n\n---\n","n":0.289}}},{"i":1274,"$":{"0":{"v":"2022","n":1}}},{"i":1275,"$":{"0":{"v":"05","n":1}}},{"i":1276,"$":{"0":{"v":"12","n":1}}},{"i":1277,"$":{"0":{"v":"What Is a Microservice Catalog and Why Do You Need One","n":0.302},"1":{"v":"\n> \"One thing that‚Äôs probably a clear signal is if developers are asking around for information frequently. Instead of having somewhere to look for data or processes, they ask other developers where something is. This is a signal that there needs to be something that all the developers can use to search for their answers first instead of bothering other people about something that a catalog could answer.\"\n\n## What Do I Put in a Microservice Catalog?\n\nLet‚Äôs summarize some of the use cases for a microservice catalog:\n\n- A single website that can display information for the kind of service or application you deploy.\n- Links to the source code and developer documentation.\n- Links and endpoint links for API use cases.\n- Links to example usages.\n- Information and links on the production system.\n- Statistics on the performance of the production system.\n- Links to the build system that pushes those services or applications to production.\n- Anything else that anyone on that team may find helpful for using your services.\n","n":0.078}}},{"i":1278,"$":{"0":{"v":"03","n":1}}},{"i":1279,"$":{"0":{"v":"16","n":1}}},{"i":1280,"$":{"0":{"v":"Three Useful yet Neglected Sql Statements","n":0.408},"1":{"v":"\n## FILTER\n\n### Syntax\n\n```sql\nSELECT SUM(<expression>) FILTER (WHERE <condition>)\n```\n\n### Example\n\n```sql\nSELECT\n    physician_last_name,\n    COUNT(*) FILTER (WHERE age >= 60) AS ‚Äú60+‚Äù,\n    COUNT(*) FILTER (WHERE age >=50 AND age < 60) AS \"50s\",\n    COUNT(*) FILTER (WHERE age >= 40 AND age < 50) AS \"40s\",\n    COUNT(*) FILTER (WHERE age >= 30 AND age < 40) AS \"30s\",\n    COUNT(*) FILTER (WHERE age >= 20 AND age < 30) AS \"20s\",\n    COUNT(*) FILTER (WHERE age >= 13 AND age <20) AS \"Teens\",\n    COUNT(*) FILTER (WHERE age <= 12) AS \"12 or younger\"\n    FROM tutorial.patient_list\nGROUP BY 1\nORDER BY 1;\n```\n\n![tabular output](/assets/images/2022-03-16-12-43-06.png)\n","n":0.104}}},{"i":1281,"$":{"0":{"v":"How to Use These Six Unusual Sql Functions","n":0.354},"1":{"v":"\n## Sign\n\nThe `SIGN()` function returns a value depending on whether the column it's given is positive or negative.\n\n- If a number is > 0, it returns 1.\n- If a number is < 0, it returns -1.\n- If the number is = 0, it returns 0.\n\nThis function will only work on columns that are of a number data type.\n\n```sql\nSELECT\n      customer_name\n    , amount\nFROM bank_statements\nWHERE SIGN(amount) IN (-1, 0)\n```\n\n## Lead\n\nThe `LEAD()` function saves you from needing to do a confusing, messy join to another table.\nIt allows you to access the values in the rows after the row you are currently looking at.\nIt makes comparison super easy.\n\nIn a grocery store, there are multiple different checkout lanes 1‚Äì10.\nThen, within each checkout lane are different customers.\nWhoever arrived first is first in line and whoever arrived last is last in line.\n\n![customers](/assets/images/2022-03-16-13-38-16.png)\n\n```sql\nSELECT\n   customer_name,\n   LEAD(customer_name) OVER(PARTITION BY line_number ORDER BY arrived_at ASC) AS next_in_line\nFROM grocery_customers\n```\n\n![output](/assets/images/2022-03-16-13-38-41.png)\n\n## Lag\n\nOpposite from the `LEAD()` function, `LAG()` allows you to compare your current row to the rows before it, rather than those after it.\nIt is still used for comparison, it just serves a bit of a different purpose.\nSimilarly, with `LEAD()`, you choose the column you wish to output from the rows before your current row and partition based on how you wish to separate out your columns.\nThen, the most important part is `ORDER BY`.\nThis will determine whether you‚Äôre getting the value you want or not.\nIf you choose `ASC` or `DESC` values, that can change your whole query.\nJust be sure it fits the context of your problem and what you‚Äôre trying to solve.\n\n```sql\nSELECT\n   customer_name,\n   LAG(Name) OVER(PARTITION BY line_number ORDER BY arrived_at ASC) AS ahead_in_line\nFROM grocery_customers\n```\n\n![lag results](/assets/images/2022-03-16-13-40-28.png)\n\n## IIF\n\nIt‚Äôs essentially a simpler `CASE` statement. The `IIF()` function tests a condition and returns a specified value if the condition is TRUE and another specified value if the condition is FALSE.\n\nin essence it acts like the excel IF function\n\n```sql\nSELECT\n  iif(1=1,'TRUE','FALSE') AS 'T'\n, iif(1=0,'TRUE','FALSE') AS 'F'\n```\n\n![RESULTS](/assets/images/2022-03-16-13-46-43.png)\n","n":0.056}}},{"i":1282,"$":{"0":{"v":"Five Powerful Tips for Bash Scripting","n":0.408},"1":{"v":"\n## Error-Proof Your Variables\n\n```bash\nexport somedir=\"/home/user/somedir\"\nrm -rf /$somedir\n# IF $somedir is unset or null then it will wipe out root \"/\"\n#\n# The failsafe\nrm -rf /${somedir:?}\n```\n\n## Skip the Long if-else Statements\n\n```bash\n# INSTEAD of\n\n#!/bin/bash\nrsync -azP somefile server1:/tmp\nif [ ! $? -eq 0 ]\nthen\n  echo \"error with rsync\"\n  exit 1\nfi\necho \"continuing next step\"\n\n# USE THIS\n\n[ ! $? -eq 0 ] && { echo \"error with rsync\"; exit 1; } \n```\n\nThe `{}` braces are basically your `then` statements separated by `;`.\n\n## Don‚Äôt Rely on Passing Arguments\n\n```bash\n# Instead of assuming the order of the values was provided as desired like `args` in python\n# Rely on `\"${@}\"1 like kwargs in python\n\n#!/bin/bash\n## reads in name and age, has boolean flag \"--reset\" which changes age to be 1\nsource functions.sh\nget_params \"${@}\"\n\n# Each of thuese results in the below\n\n./main.sh --name joe --reset --age 25\n./main.sh --age 25 --name joe --reset\n\n#> NAME=\"joe\"\n#> AGE=\"25\"\n#> RESET=\"true\"\n```\n\n## Easily Check Your Positional Arguments\n\n```bash\nname=${1:?\"Error: parameter missing Name\"}\nage=${2:?\"Error: parameter missing Age\"}\n\n./main joe\n#> Error: parameter missing Age\n```\n\n## Create a Default Value for a Variable\n\n```bash\necho \"enter your name\"\nread name\nname=${name:-Unknown}\n```\n\nIf a user enters blank, your $name will be set to Unknown. The dash after the colon provides a default fallback value.\n","n":0.073}}},{"i":1283,"$":{"0":{"v":"A Cheat Sheet for Working with Json in Sql Server","n":0.316},"1":{"v":"\n## Resources\n\n- <https://docs.microsoft.com/en-us/sql/relational-databases/json/json-data-sql-server?view=sql-server-ver15>\n- <https://docs.microsoft.com/en-us/sql/relational-databases/json/solve-common-issues-with-json-in-sql-server?view=sql-server-ver15>\n\nThere are a few key functions for working with JSON in SQL Server.\n\n- `OPENJSON` ‚Äî open a JSON string into a query-able object\n- `FOR` JSON ‚Äî format data back into a JSON String\n- `ISJSON` ‚Äî check if a string is a valid JSON format\n- `JSON_VALUE` ‚Äî extract a specific value from a JSON object\n- `JSON_QUERY` ‚Äî extract embedded objects and lists from a JSON object\n- `JSON_MODIFY` ‚Äî update values in a JSON object\n\n![function graphic](/assets/images/2022-03-16-13-14-59.png)\n\n## JSON to VARCHAR\n\n```sql\nDECLARE @json NVARCHAR(MAX);\nSET @json = N'{JSON:HERE}'\n```\n\n## Path Expressions\n\nWe write JSON ‚ÄúPath Expressions‚Äù to get data out of objects with either the `JSON_VALUE` or `JSON_QUERY` Functions.\nThe Path Expressions allow for the following patterns.\n\n![json path](/assets/images/2022-03-16-13-16-34.png)\n\n## Querying JSON Objects\n\n![querying](/assets/images/2022-03-16-13-17-49.png)\n\n![querying with some json retained](/assets/images/2022-03-16-13-18-42.png)\n\n## Rename Values on Selection\n\n```sql\nJSON_MODIFY(<json object>, <path to select>, <new value>)\n```\n\n![json modify](/assets/images/2022-03-16-13-19-45.png)\n\n## Lax vs Strict mode\n\n> JSON queries can also use a lax or strict mode to help control the behavior when data does not exist or when fields are not found.\n> Specifying the mode at the beginning of a query string will enforce the mode.\n\n```sql\nSELECT * FROM OPENJSON(@json, N'lax $.info');\n```\n\n![info](/assets/images/2022-03-16-13-20-44.png)\n","n":0.075}}},{"i":1284,"$":{"0":{"v":"14","n":1}}},{"i":1285,"$":{"0":{"v":"Understanding Time Zones in Sql Server","n":0.408},"1":{"v":"\n![[s.q.tsql.data-t.dates]]\n","n":1}}},{"i":1286,"$":{"0":{"v":"5 Modern Bash Scripting Techniques That Only a Few Programmers Know","n":0.302},"1":{"v":"\n![[s.l.bash.tips-tricks.create-loading-animations]]\n![[s.l.bash.tips-tricks.displaying-native-gui-notifications-from-bash]]\n![[s.l.bash.tips-tricks.multiprocessing-in-bash-scripts]]\n","n":1}}},{"i":1287,"$":{"0":{"v":"07","n":1}}},{"i":1288,"$":{"0":{"v":"Data Warehouse Etl Framework","n":0.5},"1":{"v":"\n<!-- ACTIVE -->\n\n> My primary use case for indexed views is using them to mirror data warehouse tables. I do not allow anybody that is not a data engineer access to the original tables. Not even on a read only basis. I create the index views for reports analyst. These are people that know SQL, but have no need to see the audit columns used to run the database.\n>\n> -- <https://tutorials.massstreet.net/v/transact-sql/advanced-topics/lesson-36.-indexed-views>\n\n## ETL Developers Field Guide\n\n### Python Software Engineering Considerations\n\nUse [[s.df.yaml]] configuration files for python [[terms.etl]]\n\n**Directory Permissions**\n\nYou should use a Proxy to run Python just like you would SSIS. The Windows account that is being used for the credential has to be explicitly named in the folder permissions. For me, I was in dev and was confused because I was an administrator and administrator was named. It had to be my specific login.\n\n**Absolute File Paths**\n\nWhen executing from SQL Server Agent, your script actually executes at `C:\\WINDOWS\\system32`. That means you can't use `os.getcwd()` as the base of file paths. Instead, if you use absolute paths, everything works fine.\n\n### EDW ETL Overview\n\n![EDW ETL Overview](/assets/images/2022-07-06-16-39-18.png)\n\n#### Acquire\n\nEach ETL process that pulls data into the system is entirely independent of any other process. Each dataset is pulled from its source system and placed in a staging table.\n\n#### Consolidate\n\nAll data that is collected in staging tables is moved to common model tables together. The common model is a unified representation of all data across systems.\n\n#### Integrate\n\nMoving data from consolidate to integrate is accomplished in the same step as moving from acquire to consolidate. Integrate is where we move the data from the common model into the warehouse tables.\n \n#### Deliver\n\nAt this time, there are no OLAP cubes in the data architecture. Data is delivered through various vectors. Most of those vectors pass through the warehouse. A few bypass the warehouse and go straight to de-normalized reporting tables.\n\n### ETL Environment Databases\n\n- `EDW`: The Data Warehouse\n- `ODS`: Operational Data Store\n  - This is where all ETL functions take place.\n  - It is where staging tables and the tables that support the common model live.\n  - The stored procedures that perform ETL live here as well as any views that support monitoring of the ETL processes.\n  - This database is not accessible to business users.\n- `REPORTING`:\n  - The database consists of de-normalized reporting tables and views that are built from tables in the data warehouse.\n  - This database allows rapid access to data without having to build complex reports.\n  - Every model in production, is represented here as a de-normalized view.\n- `SSISManagement`:\n  - SSISManagment is the database that holds the logging information from the execution of SSIS packages.\n  - This database is FAR more useful and user friendly than the execution information provided by SQL Server.\n\n### Data Acquisition Paradigms\n\n#### Demand Pull\n\n- trigged by the data warehouse environment.\n- The grand majority of your processes should be demand pull.\n- Demand pull is when the system reaches out to other systems on a schedule defined by whatever is stet in your specific orchestration tool.\n- The key element being that the data warehouse box has access to the remote system.\n- For example, a database to database pull that is executed via a linked server.\n\n#### Supply Push\n\n- Supply push processes are initiated by processes external to the data warehouse.\n- The general scenario here is data is usually dropped by a 3rd party into a folder that sits on an edge server.\n- That folder is then scanned by data warehouse processes and moved into the `InterfacesAndExtracts` folder.\n- Supply push processes should be rare and only done when there are no other options.\n- A good example are bank feeds like bank reconciliation files.\n- Those are published are published by the bank and the data warehouse does not have the ability to pull the data from the source system.\n\n### The Common Model\n\n> The common model represents the unified data model for the enterprise. The common model is necessary to process master data.\n\n### The Semantic Layer\n\n","n":0.039}}},{"i":1289,"$":{"0":{"v":"03","n":1}}},{"i":1290,"$":{"0":{"v":"Understanding the Sql Server Nolock Hint","n":0.408},"1":{"v":"\n## Link\n\n<https://www.mssqltips.com/sqlservertip/2470/understanding-the-sql-server-nolock-hint/>\n\n## Notes\n\n> What does the SQL Server `NOLOCK` hint do?\n\n1. The `NOLOCK` hint allows SQL to read data from tables by ignoring any locks and therefore not get blocked by other processes.\n2. This can improve query performance by removing the blocks, but introduces the possibility of dirty reads.\n3. Read further to better understand the use of `NOLOC`K`.\n\n## Dirty Reads\n\nThe `NOLOCK` hint is the same as the `READUNCOMMITED` hint and can be used as follows with the same results.\n\n```sql\nSELECT * FROM Person.Contact WITH (READUNCOMMITTED)\n```\n\nThis allows the reading of data that hasnt even been comitted to the database yet.\n","n":0.101}}},{"i":1291,"$":{"0":{"v":"Sql Server Script to Rebuild All Indexes for All Tables and All Databases","n":0.277},"1":{"v":"\n## Rebuild All Indexes Script for SQL Server 2005 and Later\n\n```sql\nDECLARE @Database NVARCHAR(255)\nDECLARE @Table NVARCHAR(255)\nDECLARE @cmd NVARCHAR(1000)\n\nDECLARE DatabaseCursor CURSOR READ_ONLY FOR\nSELECT name FROM master.sys.databases\nWHERE name NOT IN ('master','msdb','tempdb','model','distribution')  -- databases to exclude\n--WHERE name IN ('DB1', 'DB2') -- use this to select specific databases and comment out line above\nAND state = 0 -- database is online\nAND is_in_standby = 0 -- database is not read only for log shipping\nORDER BY 1\n\nOPEN DatabaseCursor\n\nFETCH NEXT FROM DatabaseCursor INTO @Database\nWHILE @@FETCH_STATUS = 0\nBEGIN\n\n   SET @cmd = 'DECLARE TableCursor CURSOR READ_ONLY FOR SELECT ''['' + table_catalog + ''].['' + table_schema + ''].['' +\n   table_name + '']'' as tableName FROM [' + @Database + '].INFORMATION_SCHEMA.TABLES WHERE table_type = ''BASE TABLE'''\n\n   -- create table cursor\n   EXEC (@cmd)\n   OPEN TableCursor\n\n   FETCH NEXT FROM TableCursor INTO @Table\n   WHILE @@FETCH_STATUS = 0\n   BEGIN\n      BEGIN TRY\n         SET @cmd = 'ALTER INDEX ALL ON ' + @Table + ' REBUILD'\n         --PRINT @cmd -- uncomment if you want to see commands\n         EXEC (@cmd)\n      END TRY\n      BEGIN CATCH\n         PRINT '---'\n         PRINT @cmd\n         PRINT ERROR_MESSAGE()\n         PRINT '---'\n      END CATCH\n\n      FETCH NEXT FROM TableCursor INTO @Table\n   END\n\n   CLOSE TableCursor\n   DEALLOCATE TableCursor\n\n   FETCH NEXT FROM DatabaseCursor INTO @Database\nEND\nCLOSE DatabaseCursor\nDEALLOCATE DatabaseCursor\n```\n","n":0.072}}},{"i":1292,"$":{"0":{"v":"Sql Server Cte Vs Temp Table Vs Table Variable Performance Test","n":0.302},"1":{"v":"\n\n## Link\n\n<https://www.mssqltips.com/sqlservertip/5118/sql-server-cte-vs-temp-table-vs-table-variable-performance-test/>\n\n## Related\n\nIt appears that [[CTE's|s.q.tsql.dbos.common-table-expressions]] are the most efficient and fastest of the temporary result set options and even [[s.q.tsql.dbos.temp-tables]] are better than [[s.q.tsql.syntax.table-variables]]\n\n## Notes\n\n```sql\n-- CTE\nWITH t (customerid, lastorderdate) AS \n (SELECT customerid, max(orderdate) \n  FROM sales.SalesOrderHeader\n  GROUP BY customerid)\nSELECT * \nFROM sales.salesorderheader soh\nINNER JOIN t ON soh.customerid=t.customerid AND soh.orderdate=t.lastorderdate\nGO\n\n-- Temporary table\nCREATE TABLE #temptable (customerid [int] NOT NULL PRIMARY KEY, lastorderdate [datetime] NULL);\n\nINSERT INTO #temptable\nSELECT customerid, max(orderdate) as lastorderdate \nFROM sales.SalesOrderHeader\nGROUP BY customerid;\n\nSELECT * \nFROM sales.salesorderheader soh\nINNER JOIN #temptable t ON soh.customerid=t.customerid AND soh.orderdate=t.lastorderdate\n\nDROP TABLE #temptable\nGO\n\n-- Table variable\nDECLARE @tablevariable TABLE (customerid [int] NOT NULL PRIMARY KEY, lastorderdate [datetime] NULL);\n\nINSERT INTO @tablevariable\nSELECT customerid, max(orderdate) as lastorderdate \nFROM sales.SalesOrderHeader\nGROUP BY customerid;\n\nSELECT * \nFROM sales.salesorderheader soh\nINNER JOIN @tablevariable t ON soh.customerid=t.customerid AND soh.orderdate=t.lastorderdate\nGO\n```\n\n---\n\n![sql profiler](/assets/images/2022-03-03-12-49-56.png)\n\n---\n\nHere are the updated queries which add a WHERE clause to each statement we tested above.\n\n```sql\n-- CTE\nWITH t (customerid, lastorderdate) AS \n (SELECT customerid, max(orderdate) \n  FROM sales.SalesOrderHeader\n  WHERE customerid=27604 \n  GROUP BY customerid)\nSELECT * \nFROM sales.salesorderheader soh\nINNER JOIN t ON soh.customerid=t.customerid AND soh.orderdate=t.lastorderdate\nGO\n\n--Temp table\nCREATE TABLE #temptable (customerid [int] NOT NULL PRIMARY KEY, lastorderdate [datetime] NULL);\n\nINSERT INTO #temptable\nSELECT customerid, max(orderdate) as lastorderdate \nFROM sales.SalesOrderHeader\nWHERE customerid=27604\nGROUP BY customerid;\n\nSELECT * \nFROM sales.salesorderheader soh\nINNER JOIN #temptable t ON soh.customerid=t.customerid AND soh.orderdate=t.lastorderdate\n\nDROP TABLE #temptable\nGO\n\n--Table variable\nDECLARE @tablevariable TABLE (customerid [int] NOT NULL PRIMARY KEY, lastorderdate [datetime] NULL);\n\nINSERT INTO @tablevariable\nSELECT customerid, max(orderdate) as lastorderdate \nFROM sales.SalesOrderHeader\nWHERE customerid=27604\nGROUP BY customerid;\n\nSELECT * \nFROM sales.salesorderheader soh\nINNER JOIN @tablevariable t ON soh.customerid=t.customerid AND soh.orderdate=t.lastorderdate\nGO\n```\n\n---\n\n![sql profiler 2](/assets/images/2022-03-03-12-50-45.png)\n","n":0.065}}},{"i":1293,"$":{"0":{"v":"Shift K in Vim","n":0.5},"1":{"v":"\n## Link\n\n<https://wenijinew.medium.com/vim-powerful-shift-k-748fec296319>\n\n## Notes\n\n<kbd>shift</kbd>+<kbd>K</kbd> makes it so documentation can be shown for the keyword your cursor is on.\n\nyou can press <kbd>qq</kbd> to return back to your document\n\nand the `keywordprg` variable in vim is the thing that determines what is used for the documentation that is brought up. This is useful for configuring the editor based on filetypes to bring up docs specific to that given language.\n","n":0.124}}},{"i":1294,"$":{"0":{"v":"Setting up Alerts for All Sql Server Agent Jobs","n":0.333},"1":{"v":"\n<https://www.mssqltips.com/sqlservertip/1091/setting-up-alerts-for-all-sql-server-agent-jobs/>\n\n![[s.q.tsql.sql-agent-jobs.setting-up-alerts-for-all-sql-server-agent-jobs]]\n","n":1}}},{"i":1295,"$":{"0":{"v":"Secret Features in Your Unix Shell Cdpath","n":0.378},"1":{"v":"\n## Link\n\n<https://medium.com/@symflower/secret-features-in-your-unix-shell-cdpath-cd0fe29f52cf>\n\n## Notes\n\n> When you pass a relative path to `cd`, then the directories in `$CDPATH` will be used as base directories.\n\n## Example\n\n```bash\nmkdir places-to-be\nmkdir places-to-be/hogwarts\nmkdir places-to-be/narnia\nmkdir places-to-be/the-shire\ntree places-to-be\n# places-to-be/\n# ‚îú‚îÄ‚îÄ hogwarts\n# ‚îú‚îÄ‚îÄ narnia\n# ‚îî‚îÄ‚îÄ the-shire\n\nexport CDPATH=$CDPATH:$PWD/places-to-be\n\ncd ..\ncd ..\npwd\n/Users/\ncd narnia\n~/places-to-be/narnia\npwd\n~/places-to-be/narnia\n\n```\n","n":0.16}}},{"i":1296,"$":{"0":{"v":"Introduction to the Sp_executesql Stored Procedure with Examples","n":0.354},"1":{"v":"\n## Link\n\n<https://www.sqlshack.com/introduction-to-sp_executesql-stored-procedure-with-examples/>\n\n## Syntax\n\n```sql\nsp_executesql @stmt ,N'@parametername1_datatype,@parametername2_datatype,@parameternameN_datatype'\n,@parametername1='Value1' ,@parametername2='Value2',@parameternameN='ValueN'\n```\n\n- `@stmt` parameter is used to specify dynamically generated SQL statement or batch. The data type of this parameter must be Unicode strings, for this reason, we have to add N prefix for the direct text usage or have to use nvarchar or nchar data typed variables.\n- `@parameternameN_datatype` defines the parameter‚Äôs name and data type that has been used in the dynamically constructed SQL statements.\n- With the help of the `@parameternameN=‚ÄôValueN‚Äô` expression, we can assign a value to the defined parameters which are placed in the SQL statement. In the following sections of the article, we will explore the usage details with examples from easy to difficult.\n\n## Example\n\n```sql\nDECLARE  @SqlStatment AS NVARCHAR(1000)\nDECLARE  @ColNames AS NVARCHAR(100)\n\nSET @ColNames = N'FirstName , MiddleName , LastName';\nSET @SqlStatment = 'SELECT ' + @ColNames + ' FROM Person.Person WHERE Persontype=@PerType'\n\nEXECUTE sp_executesql @SqlStatment , N'@PerType nchar(2)',@PerType='EM'\n```\n\n### Getting sp_executesql result with output parameter\n\n> `sp_executesql` provides to return execution result of the dynamically constructed SQL statement or batch. The `OUTPUT` parameter plays a key role to resolve this case. In this example, we will count the row number of the PersonPhone table and then we will set the return value to a variable with the `OUTPUT` parameter. The trick of this usage is to indicate the `@RowNumber` parameter as an `OUTPUT` parameter and then we assigned this internal parameter value to the `@Result` parameter:\n\n```sql\nDECLARE  @SqlStatment AS NVARCHAR(1000)\nDECLARE  @PhoneIdType AS INT\nDECLARE  @Result AS INT\n\nSET @SqlStatment='SELECT @RowNumber= COUNT(PhoneNumber) from Person.PersonPhone WHERE PhoneNumberTypeID=@PhoneType'\nSET @PhoneIdType=1\nEXEC sp_executesql @SqlStatment , N'@PhoneType INT,@RowNumber INT OUTPUT' , @PhoneType=@PhoneIdType ,@RowNumber=@Result OUTPUT\n\nSELECT @Result AS [TableRowNumber]\n```\n\n## sp_executesql vs EXEC statement\n\nUseful but `sp_executesql` has the ability to reuse the cached query plans\n\n```sql\nDECLARE  @SqlStatment AS NVARCHAR(1000)\n    DECLARE  @ColNames AS NVARCHAR(100)\n    DECLARE @Persontype AS NVARCHAR(2)= 'EM'\n    SET @ColNames = N'FirstName , MiddleName , LastName';\n    SET @SqlStatment = 'SELECT ' + @ColNames + ' FROM Person.Person WHERE Persontype=  ''' + @Persontype + ''''\n    EXEC(@SqlStatment)\n```\n","n":0.056}}},{"i":1297,"$":{"0":{"v":"How to Use Rowcount in Sql Server","n":0.378},"1":{"v":"\n## Link\n\nHow to use `@@ROWCOUNT` in SQL Server\n\n<https://www.mssqltips.com/sqlservertip/6091/how-to-use-rowcount-in-sql-server/>\n\n## Usage\n\n`SELECT @@ROWCOUNT` in the same execution block to get the result back\n\n```sql\nSELECT TOP 1000 * FROM dbo.Customer;\nSELECT @@ROWCOUNT;\n```\n\nThis returns the query results and the count of how many rows from that result set\n\n```sql\nSELECT @@ROWCOUNT;\n```\n\nexecuted by itself only returns a count of 1 record (itself).\n\n## Error Handling and Business Rules\n\n> Using SQL Server `@@ROWCOUNT` for Error Handling and Checking a Business Rule\n\n```sql\nBEGIN TRAN\n\nUPDATE [Sales].[SalesOrderHeader]\nSET [SubTotal] = [SubTotal] * 1.1; -- 10% increase\n\nIF @@ROWCOUNT = 0\n    PRINT 'Something went wrong!'\nELSE PRINT 'Rows were updated...'\n\n--COMMIT\nROLLBACK\n```\n\n## Instances of Large ROWCOUNT\n\nSQL Server `ROWCOUNT_BIG` function\n\nThe data type of `@@ROWCOUNT` is integer. In the cases where a higher number of rows are affected than an integer can handle (meaning more than 2,147,483,647 rows!), you need to use the ROWCOUNT_BIG function. This function returns the data type `bigint`.\n\n```sql\nSELECT TOP 1000 * FROM dbo.Customer;\nSELECT ROWCOUNT_BIG();\n```\n\n## Utilizing ROWCOUNT with Try Catch Statements\n\n```sql\nBEGIN TRY\n    SELECT TOP 100 * FROM [AdventureWorks2017].[Person].[Person];\nEND TRY\nBEGIN CATCH\n    SELECT TOP 50 * FROM [AdventureWorks2017].[Person].[Person];\nEND CATCH\nSELECT @@ROWCOUNT;\n\n/*\n\n@@ROWCOUNT returns zero! This is because the last statement is not the SELECT statement from the TRY block (which has been executed), it‚Äôs also not the one from the TRY block as it‚Äôs the last SELECT in the script. It‚Äôs the TRY/CATCH block itself! @@ROWCOUNT returns the affected rows from any statement, even if it‚Äôs not DML or a SELECT query.\n\nTo avoid this kind of scenario, you can store the row count in a local variable. The script would then look like this:\n\n*/\n\nDECLARE @rowcount INT;\nBEGIN TRY\n    SELECT TOP 100 * FROM [AdventureWorks2017].[Person].[Person];\n    SET @rowcount = @@ROWCOUNT;\nEND TRY\nBEGIN CATCH\n    SELECT TOP 50 * FROM [AdventureWorks2017].[Person].[Person];\n    SET @rowcount = @@ROWCOUNT;\nEND CATCH\nSELECT @rowcount;\n\n```\n\n## SQL Server SET NOCOUNT AND SET ROWCOUNT\n\n### SET ROWCOUNT\n\nAlthough the name, `SET ROWCOUNT` is very similar, it doesn‚Äôt impact `@@ROWCOUNT` directly. `SET ROWCOUNT` simply tells SQL Server to stop processing a query after the specified number of rows have been returned, which makes it kind of a ‚Äúglobal TOP clause‚Äù.\n\nIn the following example, we‚Äôre limiting the rows to 500. The SELECT query itself should return 1,000 rows, but as you can see `@@ROWCOUNT` tells us only 500 were returned.\n\n![SET ROWCOUNT](/assets/images/2022-03-03-14-02-14.png)\n\n### SET NOCOUNT\n\n`SET NOCOUNT ON` also doesn‚Äôt affect `@@ROWCOUNT`. `SET NOCOUNT` tells SQL Server to stop displaying the message with the number of rows affected by a query. However, `@@ROWCOUNT` is still updated.\n\nLet‚Äôs illustrate with an example. First the default configuration where `NOCOUNT` is off.\n\n![NOCOUNT](/assets/images/2022-03-03-14-03-56.png)\n","n":0.05}}},{"i":1298,"$":{"0":{"v":"How to Read Log File in Sql Server Using Tsql","n":0.316},"1":{"v":"\n\n<https://www.mssqltips.com/sqlservertip/1476/how-to-read-log-file-in-sql-server-using-tsql/>\n\n## How to Read Log File in SQL Server using TSQL\n\n### Problem\n\n> One of the issues I have is that the SQL Server Error Log is quite large and it is not always easy to view the contents with the Log File Viewer. In a previous tip \"Simple way to find errors in SQL Server error log\" you discussed a method of searching the error log. Are there any other ways to search and find errors in the error log files?\n\n### Solution\n\n> SQL Server offers an undocumented system stored procedure `sp_readerrorlog`. This SP allows you to read the contents of the SQL Server error log files directly from a query window and also allows you to search for certain keywords when reading the error file.\n>\n> This is a sample of the stored procedure that already exists in the master database. You will see that when this gets called it calls an extended stored procedure `xp_readerrorlog`.\n\n```sql\n/*\nThis procedure takes four parameters:\n\n1. Value of error log file you want to read: 0 = current, 1 = Archive #1, 2 = Archive #2, etc...\n2. Log file type: 1 or NULL = error log, 2 = SQL Agent log\n3. Search string 1: String one you want to search for\n4. Search string 2: String two you want to search for to further refine the results\n\nIf you do not pass any parameters this will return the contents of the current error log.\n*/\n\nCREATE PROC [sys].[sp_readerrorlog](\n   @p1 INT = 0,\n   @p2 INT = NULL,\n   @p3 VARCHAR(255) = NULL,\n   @p4 VARCHAR(255) = NULL)\nAS\nBEGIN\n\n   IF (NOT IS_SRVROLEMEMBER(N'securityadmin') = 1)\n   BEGIN\n      RAISERROR(15003,-1,-1, N'securityadmin')\n      RETURN (1)\n   END\n\n   IF (@p2 IS NULL)\n       EXEC sys.xp_readerrorlog @p1\n   ELSE\n       EXEC sys.xp_readerrorlog @p1,@p2,@p3,@p4\nEND\n```\n\nThe above is basically a copy of `xp_readerrorlog` but only using 4 of the parameters\n\nThe actual extended procedure `xp_readerrorlog` can take up to 7 parameters\n\n1. Value of error log file you want to read: 0 = current, 1 = Archive #1, 2 = Archive #2, etc...\n2. Log file type: 1 or NULL = error log, 2 = SQL Agent log\n3. Search string 1: String one you want to search for\n4. Search string 2: String two you want to search for to further refine the results\n5. Search from start time\n6. Search to end time\n7. Sort order for results: N'asc' = ascending, N'desc' = descending\n\nHere is are some examples:\n\n```sql\nEXEC master.dbo.xp_readerrorlog 0, 1, '2005', 'exec', NULL, NULL, N'desc'\nEXEC master.dbo.xp_readerrorlog 0, 1, '2005', 'exec', NULL, NULL, N'asc'\n```\n\n## Potential pitfalls\n\n> for later versions of SQL Server you may need to use double quotes or you might get this error.\n\n`Msg 22004, Level 12, State 1, Line 0\nError executing extended stored procedure: Invalid Parameter Type`\n\nTry this instead.\n\n```sql\nEXEC master.dbo.xp_readerrorlog 0, 1, \"backup\", \"failed\", \"2017-01-02\", \"2017-02-02\", \"desc\"\nEXEC master.dbo.xp_readerrorlog 0, 1, \"2005\", \"exec\", NULL, NULL, \"asc\"\n```\n\nOr try this, putting N before each parameter.\n\n```sql\nEXEC master.dbo.xp_readerrorlog 0, 1, N'backup', NULL, N'2017-01-02', N'2017-02-02', N'desc'\nEXEC master.dbo.xp_readerrorlog 0, 1, N'backup', N'failed', NULL, NULL, N'asc'\n```\n","n":0.046}}},{"i":1299,"$":{"0":{"v":"How to Create Scheduled Tasks with Command Prompt on Windows 10","n":0.302},"1":{"v":"\n## Link\n\n<https://www.windowscentral.com/how-create-task-using-task-scheduler-command-prompt>\n\n## Notes\n\nCLI way to schedule tasks akin to Task Scheduler functionality\n\n### Syntax\n\nFor more info\n\n```powershell\nSCHTASKS /CREATE /?\nSCHTASKS /CHANGE /?\nSCHTASKS /DELETE /?\n```\n\n---\n\n```powershell\nSCHTASKS /CREATE /SC DAILY /TN \"FOLDERPATH\\TASKNAME\" /TR \"C:\\SOURCE\\FOLDER\\APP-OR-SCRIPT\" /ST HH:MM\n```\n\n- `/CREATE` ‚Äî specifies that you want to create a new an automated routine.\n- `/SC` ‚Äî defines the schedule for the task. Options available, include MINUTE, HOURLY, DAILY, WEEKLY, MONTHLY, ONCE, ONSTART, ONLOGON, ONIDLE, and ONEVENT.\n- `/D` ‚Äî specifies the day of the week to execute the task. Options available, include MON, TUE, WED, THU, FRI, SAT, and SUN. If you're using the MONTHLY option, then you can use 1 - 31 for the days of the month. Also, there's the wildcard \"*\" that specifies all days.\n- `/TN` ‚Äî specifies the task name and location. The \"MyTasks\\Notepad task\" uses the \"Notepad task\" as the name and stores the task in the \"MyTasks\" folder. If the folder isn't available, it'll be created automatically.\n- `/TR` ‚Äî specifies the location and the name of the task that you want to run. You can select an app or custom script.\n- `/ST` ‚Äî defines the time to run the task (in 24 hours format).\n- `/QUERY` ‚Äî displays all the system tasks.\n- `/RU` ‚Äî specifies the task to run under a specific user account.\n\n### Example\n\n#### Create Task\n\n```powershell\nSCHTASKS /CREATE /SC DAILY /TN \"MyTasks\\Notepad task\" /TR \"C:\\Windows\\System32\\notepad.exe\" /ST 17:45\n```\n\n![created task](/assets/images/2022-03-03-17-45-22.png)\n\n#### Change Task\n\n- `/CHANGE` ‚Äî specifies that you want to edit an existing task.\n- `/TN` ‚Äî specifies the name and location of the task that you want to modify.\n- `/ST` ‚Äî defines the new time to run the automated routine.\n- `/DISABLE` ‚Äî disables the task.\n\n```powershell\nSCHTASKS /CHANGE /TN \"MyTasks\\Notepad task\" /ST 09:00\n```\n\n#### Disable a Task\n\nAnd the inverse of this is just replace `/DISABLE` with `/ENABLE`\n\n```powershell\nSCHTASKS /CHANGE /TN \"FOLDERPATH\\TASKNAME\" /DISABLE\n```\n\n#### Delete Task\n\n- `/DELETE` ‚Äî specifies that you want to delete an existing task.\n- `/TN` ‚Äî specifies the name and location of the task that you want to delete.\n\n```powershell\nSCHTASKS /DELETE /TN \"MyTasks\\Notepad task\"\n```\n","n":0.056}}},{"i":1300,"$":{"0":{"v":"Generate a Parameter List for All Sql Server Stored Procedures and Functions","n":0.289},"1":{"v":"\n## Link\n\n<https://www.mssqltips.com/sqlservertip/1669/generate-a-parameter-list-for-all-sql-server-stored-procedures-and-functions/>\n\n## Notes\n\n```sql\nSELECT \n   SCHEMA_NAME(SO.SCHEMA_ID) AS [Schema],\n   SO.Name AS [ObjectName],\n   SO.Type_Desc AS [ObjectType (UDF/SP)],\n   PM.Parameter_ID AS [ParameterID],\n   CASE\n      WHEN PM.Parameter_ID = 0 THEN 'Returns'\n      ELSE PM.Name\n      END AS [ParameterName],\n   TYPE_NAME(PM.User_Type_ID) AS [ParameterDataType],\n   CASE\n      WHEN TYPE_NAME(PM.User_Type_ID) IN ('float', 'uniqueidentifier', 'datetime', 'bit', 'bigint', 'int', 'image', 'money', 'xml', 'varbinary', 'tinyint', 'text', 'ntext', 'smallint', 'smallmoney') THEN ''\n      WHEN TYPE_NAME(PM.User_Type_ID) IN ('decimal', 'numeric') THEN '(' + CAST( PM.Precision AS VARCHAR(4) ) + ', ' + CAST( PM.Scale AS VARCHAR(4)) + ')'\n      WHEN PM.Max_Length = -1 THEN '(Max)'\n      WHEN TYPE_NAME(PM.User_Type_ID) IN ('nvarchar', 'nchar' ) THEN CAST( PM.Max_Length/2 AS VARCHAR(5))\n      ELSE CAST( PM.Max_Length AS VARCHAR(5))\n      END AS [Size],\n   CASE\n      WHEN PM.Is_Output = 1 THEN 'Output'\n      ELSE 'Input'\n      END AS [Direction]\nFROM sys.objects AS SO\n    INNER JOIN sys.parameters AS PM \n        ON SO.OBJECT_ID = PM.OBJECT_ID\nWHERE SO.TYPE IN ('P','FN')\nORDER BY SO.Type_Desc, [Schema], SO.Name, PM.parameter_id;\n```\n","n":0.086}}},{"i":1301,"$":{"0":{"v":"02","n":1}}},{"i":1302,"$":{"0":{"v":"17","n":1}}},{"i":1303,"$":{"0":{"v":"Cool Yaml Features You Probably Didn‚Äôt Know About","n":0.354},"1":{"v":"\n\n<https://faun.pub/cool-yaml-features-you-probably-didnt-know-cb15e8112576>\n\n![[s.df.yaml.tips-tricks.md]]\n![[s.df.yaml.tips-tricks.anchors.md]]\n![[s.df.yaml.tips-tricks.explicit-tags.md]]\n![[s.df.yaml.tips-tricks.multi-line-strings.md]]\n![[s.df.yaml.tips-tricks.multiple-docs-in-single-file.md]]\n","n":1}}},{"i":1304,"$":{"0":{"v":"01","n":1}}},{"i":1305,"$":{"0":{"v":"26","n":1}}},{"i":1306,"$":{"0":{"v":"Postgres Can Do That","n":0.5},"1":{"v":"\n\n<https://medium.com/cognite/postgres-can-do-that-f221a8046e>\n\n- `Author:` alex brasetvik\n- `Link:` <https://medium.com/cognite/postgres-can-do-that-f221a8046e>\n- `Publish Date:` 2021.12.06\n- `Reviewed Date:` [[log.daily.2022.01.26]]\n\n---\n\n- [[s.q.postgres.tips-tricks.query-tuning-with-explain]]\n- [[s.q.postgres.tips-tricks.writeable-cte]]\n\nGenerate a mandelbrot set\n\n```sql\n--Mandelbrot set\nWITH RECURSIVE x(i) AS (\n\tVALUES(0)\n\tUNION ALL\n\tSELECT i + 1 FROM x WHERE i < 101\n),\nZ(Ix, Iy, Cx, Cy, X, Y, I) AS (\n\tSELECT Ix, Iy, X::float, Y::float, X::float, Y::float, 0\n\tFROM (SELECT -2.2 + 0.031 * i, i FROM x) AS xgen(x, ix)\n\t\tCROSS JOIN (SELECT -1.5 + 0.031 * i, i FROM x) AS ygen(y, iy)\n\tUNION ALL\n\t\tSELECT Ix, Iy, Cx, Cy, X * X - Y * Y + CX AS X, Y * X * 2 + Cy, I + 1\n\t\tFROM Z\n\t\tWHERE X * X + Y * Y < 16.0 AND I < 27\n),\nZt (Ix, Iy, I) AS (\n\tSELECT Ix, Iy, MAX (I) AS I\n\tFROM Z\n\tGROUP BY Iy, Ix\n\tORDER BY Iy, Ix\n)\nSELECT array_to_string(\n\tarray_agg(\n\t\tSUBSTRING(\n\t\t\t' .,,,-----++++%%%%@@@@#### ',\n\t\t\tGREATEST (I,1),\n\t\t\t1\n\t\t)\n\t),''\n)\nFROM Zt\nGROUP BY Iy\nORDER BY Iy;\n```\n\n\n","n":0.085}}},{"i":1307,"$":{"0":{"v":"Dockerfile Tutorial by Example Basics and Best Practices 2018","n":0.333},"1":{"v":"\n- `URL:` <https://takacsmark.com/dockerfile-tutorial-by-example-dockerfile-best-practices-2018/>\n    - <https://youtu.be/6Er8MAvTWlI>\n    - <https://youtu.be/ZcMr4G5DH7c>\n- `Author:` M√°rk Tak√°cs\n\n- Docker files MUST start with `FROM` but after that you can also add data like:\n\n```docker\nFROM python:3.9.7\nMAINTAINER Bryan Jenks bryan@bryanjenks.dev\n```\n\n- When you build your docker image from a docker file with [[s.containers.docker.cmd.build]] each command in the file create a new image and the layers are plastered on top, but each layer is cached so when you change things iteratively, only the changed items onward get re-ran. Essentially lazy loading.\n","n":0.113}}},{"i":1308,"$":{"0":{"v":"14","n":1}}},{"i":1309,"$":{"0":{"v":"An Overview of Job Scheduling Tools for Postgresql","n":0.354},"1":{"v":"\n\nReference: <https://severalnines.com/database-blog/overview-job-scheduling-tools-postgresql>\n\nLike [[s.q.tsql.tools.sql-agent]] it is a job scheduling agent available for PostgreSQL that allows the execution of stored procedures, SQL statements, and shell scripts.\n\nThe purpose is to have this agent running as a daemon on Linux systems and periodically does a connection to the database to check if there are any jobs to execute.\n\nThis scheduling is easily managed by PgAdmin 4, but it‚Äôs not installed by default once the pgAdmin installed, it‚Äôs necessary to download and install it on your own.\n\n\n## Step 1\n\nInstallation of pgAdmin 4\n\n```bash\nsudo apt install pgadmin4 pgadmin4-apache\n```\n\n## Step 2\n\nCreation of plpgsql procedural language if not defined\n\n```sql\nCREATE TRUSTED PROCEDURAL LANGUAGE 'plpgsql'\nHANDLER plpgsql_call_ handler\nHANDLER plpgsql validator;\n```\n\n## Step 3\n\nInstallation of pgAgent\n\n```bash\nsudo apt-get install pgagent\n```\n\n## Step 4\n\nCreation of the pgagent extension\n\n```sql\nCREATE EXTENSION pageant\n```\n\nIn order to define a new job, it's only necessary select \"Create\" using the right\nbutton on \"pgAgent Jobs\", and it'll insert a designation for this job and define the\nsteps to execute it:\n\n![pgagent](/assets/images/2022-01-14-23-43-37.png)\n\n![job](/assets/images/2022-01-14-23-44-04.png)\n\n![schedules](/assets/images/2022-01-14-23-44-19.png)\n\n## Step 5\n\nFinally, to have the agent running in the background it's necessary to launch the\nfollowing process manually:\n\n```bash\n/usr/bin/pgagent host=localhost dbname=postgres user=postgres port=5432 -l 1\n```\n","n":0.075}}},{"i":1310,"$":{"0":{"v":"0","n":1}}},{"i":1311,"$":{"0":{"v":"Where Are Docker Images and Containers Stored on the Host","n":0.316},"1":{"v":"\n## The Difference Between Images and Containers\n\n> Images are what you create when you run docker build; they‚Äôre stored in a container registry like the Docker Hub, and contain all the files and code to run an app. You can think of them like ISO files for a virtual machine operating system.\n>\n> Containers are created from images, and they‚Äôre like the actual virtual machine that runs the application. You might have multiple containers running in parallel off the same image. **Each container will have its own file system, optionally created with ‚Äúvolume mounts‚Äù that bind data from the host to the container.**\n\n## Images stored locally\n\n- **Linux:** `/var/lib/docker/`\n- **Windows:** `C:\\ProgramData\\DockerDesktop`\n- **macOS:** `~/Library/Containers/com.docker.docker/Data/vms/0/`\n\n## Notes\n\n- [[s.containers.docker.cmd.image.ls]]\n- [[s.containers.docker.cmd.image.prune]]\n- [[s.containers.docker.cmd.inspect]]\n- [[s.containers.docker.tips-and-tricks.modify-container-filesystem]]\n","n":0.093}}},{"i":1312,"$":{"0":{"v":"The Best Way to Request User Input in Python","n":0.333},"1":{"v":"\n\n## Installation\n\n```bash\npip install pyinputplus\n```\n\n## Usage\n\n```python\nimport pyinputplus as pyinput\n\nprompt = 'How old are you:'\nage = pyinput.inputInt(prompt=prompt, greaterThan=0)\n```\n\n## Example Output\n\n```markdown\nHow old are you:-1\nNumber must be greater than 0.\nHow old are you: 11.5\n'11.5' is not an integer.\nHow old are you: 14\n```\n","n":0.162}}},{"i":1313,"$":{"0":{"v":"2021","n":1}}},{"i":1314,"$":{"0":{"v":"12","n":1}}},{"i":1315,"$":{"0":{"v":"20","n":1}}},{"i":1316,"$":{"0":{"v":"Linux Shell Tricks","n":0.577},"1":{"v":"\n\n- `Author:` Sergio Daniel Cortez Chavez\n- `Link:` <https://sergiocortez-37830.medium.com/linux-shell-tricks-2f34c5935b89>\n- `Publish Date:` 2021.11.29\n- `Reviewed Date:` [[log.daily.2021.12.20]]\n\n---\n\n## Stdin as a file argument\n\n```bash\n# Command expects a file:\nwc file1 file2\n# Instead of making a temp file to read in a little text use this to pass in\n# text as a temp file to STDIN\nwc file1 - file2 # waits for you to type input and you complete this process by using `CTRL+D` which inserts the EOF character\n```\n\n## Use the output of another command as a file argument\n\n```bash\nwc file1 <(echo ‚Äúhello world‚Äù) file2\n```\n\n> When you wrap a command with `<(...)` bash generate a temporal file in a path like `/dev/fd/64`, then execute your wrapped command, put the output in this temporal file, and finally replace `<(...)` with the filename of the temporal file, in this case, `/dev/fd/64`\n\n## Avoid conflicts with filenames that start with a dash\n\n```bash\n# -- indicates the end of the options section\n# -myFile.txt uses a dash after the options section to avoid conflicts\ncat -- -myFile.txt\n```\n\n## Re-run commands\n\n```bash\n# of course there's\nsudo !!\n# but you can also do\n!-N # where N is the Nth command (Relative)\n# or\n!N # for the N command in your history (Absolute)\n```\n\n## Re-use command arguments\n\n```bash\nmkdir very-large-directory-name\ncd very-large-directory-name\n# Instead of duplicating the argument of the mkdir command, you can use !$ for retrieve the last argument of the last command, the result is:\nmkdir very-large-directory-name\ncd !$ # == cd very-large-directory-name\n```\n\n## Ignore the first N lines\n\n> By default, the tail command will show the last n rows, but if you specified the option -n with a number that starts with the + symbol, like +5 , the first 5 lines are going to be skipped.\n\n```bash\n# In this example, the tail command is going to skip the first 10 lines and print the rest of the file content.\ntail -n +10 dataset.csv\n```\n\n## Track the content of a log file\n\n> See the contents of a file in real time\n\n```bash\nwatch cat log.txt\n```\n\n> Although this command does the job, it is not the best option. You can use the tail command with the -f option to track only the new lines that are appended to the file,\n\n","n":0.054}}},{"i":1317,"$":{"0":{"v":"How to Think like the Sql Server Engine","n":0.354},"1":{"v":"\n\n- `Author:` Brent Ozar\n- `Link:` <https://youtu.be/fERXOywBhlA>\n- `Publish Date:` 2020.08.18\n- `Reviewed Date:` [[log.daily.2021.12.20]]\n\n---\n\n```sql\n-- Show the statistics for an Index \nDBCC SHOW_STATISTICS('ticketer.app.metric', 'CIX_Created_Date');\nGO\n```\n\n","n":0.218}}},{"i":1318,"$":{"0":{"v":"An Extremely Simple Way to Schedule Programs with Python on Windows","n":0.302},"1":{"v":"\n\n- `Author:` Robby Boney\n- `Link:` <https://medium.com/short-bits/an-extremely-simple-way-to-schedule-programs-with-python-on-windows-46fc34074874>\n- `Publish Date:` 2021.12.14\n- `Reviewed Date:` [[log.daily.2021.12.20]]\n\n---\n\n- [[s.l.python.libs.schedule]] library:\n\n\n```python\nimport schedule\nimport time\n\ndef job():\n  print(\"I'm working...\")\nschedule.every(10).seconds.do(job)\nschedule.every(10).minutes.do(job)\nschedule.every().hour.do(job)\nschedule.every().day.at(\"10:30\").do(job)\nschedule.every(5).to(10).minutes.do(job)\nschedule.every().monday.do(job)\nschedule.every().wednesday.at(\"13:15\").do(job)\nschedule.every().minute.at(\":17\").do(job)\nwhile True:\n  schedule.run_pending()\n  time.sleep(1)\n```\n\n- The package includes many other actions available from the main API including:\n  - Use a decorator to schedule a job\n  - Pass arguments to a job schedule.every(2).seconds.do(greet, name=\"Alice\")\n  - Cancel a job\n  - Run a job once\n  - Get all jobs\n  - Cancel all jobs\n  - Get several jobs, filtered by tags\n  - Cancel several jobs, filtered by tags\n  - Run a job at random intervals\n  - Run a job until a certain time\n  - Time until the next execution\n  - Run all jobs now, regardless of their scheduling\n- Schedule a python script on windows with a 3 file setup\n  - A bat file which can be executed (directly or via shortcut) automatically by windows in the startup folder\n    - ![alt](assets/images/Pasted_image_20211220105600.png)\n    - Ensure this runs even after an automatic or scheduled restart by placing the script or a shortcut to it in the startup directory which can be found by running:\n      - `shell:startup` in the menu that pops up when you press <kbd>ctrl</kbd>+ <kbd>R</kbd>\n  - a manager powershell script to perform any setup steps like activating a conda environment and then running the scheduler\n    - ![alt](assets/images/Pasted_image_20211220105611.png)\n  - a scheduler python script that runs a python function or command line script via a package like `subprocess`\n    - ![alt](assets/images/Pasted_image_20211220105625.png)\n\n## When Does this NOT Work\n\n- schedule is designed as a simple scheduling package. As mentioned on the the projects documentation, it is not ideal when the following are required:\n  - **Job persistence** (remember schedule between restarts) (although we have ‚Äúsomewhat‚Äù solved this one in this article)\n  - **Exact timing** (sub-second precision execution)\n  - **Concurrent execution** (multiple threads)\n  - **Localization** (time zones, workdays or holidays)\n\n","n":0.058}}},{"i":1319,"$":{"0":{"v":"16","n":1}}},{"i":1320,"$":{"0":{"v":"Why You Should Start Using Pathlib as an Alternative to the Os Module","n":0.277},"1":{"v":"\n\n- `Author:` Ahmed Besbes\n- `Link:` <https://towardsdatascience.com/why-you-should-start-using-pathlib-as-an-alternative-to-the-os-module-d9eccd994745>\n- `Publish Date:` 2021.12.16\n- `Reviewed Date:` [[import.research.article.2021.12.16]] \n\n---\n\n```python\nfrom pathlib import Path\n\npath = Path('/home/johndoe/Documents/pathlib.md')\npath.touch()\npath.name\n#>>> 'pathlib.md'\npath.stem\n#>>> pathlib\npath.suffix\n#>>> '.md'\npath.parent\n#>>> PosixPath('/home/johndoe/Documents')\npath.parent.parent\n#>>> PosixPath('/home/johndoe')\npath.anchor\n#>>> '/'\n```\n\n- Negates the need to combine [[s.l.python.libs.os]] with [[s.l.python.libs.glob]] to find paths that match a given pattern.\n- [[s.l.python.libs.os]] represents paths at their most simple level: strings whereas pathlib represents them as a class \n\n## Get common paths in a command\n\n```python\nfrom pathlib import Path\n\ncwd = Path.cwd()\nhome = Path.home()\n```\n\n## Easy file manipulation\n\n```python\nfrom pathlib import Path\n\nrandom_file = Path(\"random_file.txt\")\n\nrandom_file.exists()\n# False\n\nrandom_file.touch()\n\nrandom_file.exists()\n# True\n```\n\n## Recursive globbing\n\n```python\n\nfrom pathlib import Path\n\n# A quite large folder indeed!\npath = Path(\"/Users/ahmed.besbes/anaconda3/\")\n\npython_files = path.rglob(\"**/*.py\")\n\nnext(python_files)\n# PosixPath('/Users/ahmed.besbes/anaconda3/bin/rst2xetex.py')\n\nnext(python_files)\n# PosixPath('/Users/ahmed.besbes/anaconda3/bin/rst2latex.py')\n\nnext(python_files)\n# PosixPath('/Users/ahmed.besbes/anaconda3/bin/rst2odt_prepstyles.py')\n\n...\n\nlen(list(python_files))\n# 67481\n```\n\n- `.exists()` : To check if the path really exists on the filesystem\n- `.is_dir()` : To check if the path corresponds to a directory\n- `.is_file()` : To check if the path corresponds to a file\n- `.is_absolute()` : To check if the path is absolute\n- `.chmod()` : To change the file mode and permissions\n- `.is_mount()` : To check if the path is a mount point\n- `.suffix` : Get the extension of a file\n\n","n":0.077}}},{"i":1321,"$":{"0":{"v":"13","n":1}}},{"i":1322,"$":{"0":{"v":"Why You Need to Use Staticmethod in Your Python Code and the Benefits of It","n":0.258},"1":{"v":"\n\n- `Author:` Felipe Florencio Garcia\n- `Link:` <https://medium.com/dev-today/why-you-need-to-use-staticmethod-in-your-python-code-and-the-benefits-of-it-f777a5f21de6>\n- `Publish Date:` 2021.11.28\n- `Reviewed Date:` [[log.daily.2021.12.13]]\n\n---\n\n## Before\n\n```python\nclass Calendar:\n    \n    def __init__(self, date):\n        self.year = date.year\n        self.month = date.month\n        self.day = date.day\n        self.weekday = date.weekday()\n    \n    \n    def is_leap_year(self):\n        return self.year % 400 == 0 or \n               (self.year % 4 == 0 and self.year % 100 != 0)\n    \n    \n    def is_weekend(self):\n        return self.weekday > 4\n```\n\n![alt](assets/images/Pasted_image_20211213151355.png)\n\nWe want to decouple the `is_weekend` and `is_leap_year` from the calendar class instance because they relate to any date not just that class instance.\n\n## After\n\n```python\nclass Calendar:\n    \n    def __init__(self, date):\n        self.year = date.year\n        self.month = date.month\n        self.day = date.day\n        self.weekday = date.weekday()\n    \n    \n    @staticmethod\n    def is_leap_year(date):\n        return date.year % 400 == 0 or \n        (date.year % 4 == 0 and date.year % 100 != 0)\n    \n    \n    @staticmethod\n    def is_weekend(date):\n        return date.weekday() > 4\n```\n\nOk, the changes are:\n\n1. Add the decorator `@staticmethod`;\n2. Rename the expected parameter to be a date object;\n3. Adjust the is_weekend function to get weekday as function and not variable.\n\nUsage:\n\n![alt](assets/images/Pasted_image_20211213151513.png)\n\n## Benefits\n\n> **The benefits of using it and when to use it.**\n> The most important to take from this decorator is the purpose of using it.\n> You should consider this decorator when writing any function that you believe is connected to the ‚Äúsubject‚Äù or the class that you are using but do not necessarily need that ‚Äúsubject‚Äù or class where you created the function.\n> By doing this you can decouple the function itself, but still, keep it organized and with a clear meaning for which purpose can be used.\n> From now on, any piece of code that you want to be reusable, but, at the same time you want to make it clear the ‚Äúmeaning‚Äù of when or how it could be used you should consider using this decorator.\n\n","n":0.059}}},{"i":1323,"$":{"0":{"v":"The Secret World of Newline Characters","n":0.408},"1":{"v":"\n\n- `Author:` yang-yang\n- `Link:` <https://enigma.com/blog/post/the-secret-world-of-newline-characters>\n- `Publish Date:` 2018.06.19\n- `Reviewed Date:` [[log.daily.2021.12.13]]\n\n---\n\n| Terminator | System                                 |\n| ---------- | -------------------------------------- |\n| `\\n`       | Unix and Linux style                   |\n| `\\r\\n`     | Microsoft Windows style                |\n| `\\r`       | The somewhat rarer MacOS classic style |\n","n":0.156}}},{"i":1324,"$":{"0":{"v":"Record Separator","n":0.707},"1":{"v":"\n\n## Record Separator\n\n> \"Within a group (or table) the records are separated with RS or record separator.\"\n> <br>\n> We occasionally see CSV-ish files that use RS to separate records, which at first sounds defensible but honestly doesn't really help, because CSV authors just want to hit the enter key. And now your CSV parser has to support yet another newline.\n\n---\n\n> In the late 1970s, ASCII was extended by the ANSI standard to include additional control characters‚Äîto differentiate, the former are called C0 controls, the latter C1 controls. Using these new-fangled computer terminals of the day (such as 1978's VT100) could draw primitive graphics at arbitrary cursor locations. Aivosto Oy takes us on a helpful tour of these:\n> <br>\n> \"According to ANSI, the C1 controls were intended for input/output control of two-dimensional character-imaging devices, including interactive terminals of both the cathode ray tube and printer types, as well as output to microfilm printers.\"\n> <br>\n> Evidently, the authors could not resist adding in a new-fangled newline amongst this fresh batch of characters.\n","n":0.077}}},{"i":1325,"$":{"0":{"v":"Next Line","n":0.707},"1":{"v":"\n\n## C1 Next Line\n\n> \"LF, having two alternative functions, has been a major source of confusion. While LF was initially defined as a \"move down\" operator, standards began to allow LF as a newline too. As a result, operating systems differ in their definition of a newline. A newline is LF on Unix. Operating systems using CR LF include CP/M, DOS, OS/2 and Windows. Naturally, this caused an incompatibility. To solve the problem, control characters IND and NEL were added to the C1 area. This did not solve the issue, resulting in IND being removed later.\n> <br>\n> Note: NEL maps to the control character NL (New Line) in the EBCDIC character set used on IBM mainframes.\"\n> <br>\n> EBCDIC is an encoding descended from punched cards and the six bit decimal code used with most IBMs of the late 1950s and early 1960s. Wikipedia has a great picture of such a punch card.\n> <br>\n> Finally, in the early 1990s when it was becoming increasingly obvious that the Internet, and soon the burgeoning World Wide Web in particular, would require a character set that supported all multilingual text, Unicode was born. By the time Unicode hit version 1.1 in 1993, it included the majority of common European- and Asian-based characters as well as‚Äîsurprise, surprise‚Äîa few new control characters of course:\n> <br>\n> \"A paragraph separator--independent of how it is encoded--is used to indicate a separation between paragraphs. A line separator indicates where a line break alone should occur, typically within a paragraph. For comparison, line separators basically correspond to HTML `<BR>`, and paragraph separators to older usage of HTML `<P>` (modern HTML delimits paragraphs by enclosing them in `<P>`...`</P>`).\n> <br>\n> The Unicode Standard defines two unambiguous separator characters: U+2029 (PS) and U+2028 (LS). In Unicode text, the PS and LS characters should be used wherever the desired function is unambiguous.\"\n> <br>\n> Yes, this surely made everything better.\n> <br>\n> Given the reality of reading CSVs, at best a loose convention with more interpretations and incarnations than even the newline, the most sanity-preserving path is usually to stick to the basic newlines (LF, CR+LF, CR) and call it a day, if you can get away with it.\n> <br>\n> But if one day you encounter a VT masquerading as a space in the text editor, or rescue some long-siloed database that was instructed by its departed master to delimit records with RS, perhaps you'll recall the enigmatic history of these dust-gathering control characters.\n","n":0.05}}},{"i":1326,"$":{"0":{"v":"Newline Characters","n":0.707},"1":{"v":"\n\n### Newline Characters\n\n| Terminator | Definition                          |\n| ---------- | ----------------------------------- |\n| `\\n`       | Line Feed (LF)                      |\n| `\\r`       | Carriage Return (CR)                |\n| `\\r\\n`     | Carriage Return + Line Feed (CR+LF) |\n| `\\x0b`     | Line Tabulation (VT)                |\n| `\\x0c`     | Form Feed (FF)                      |\n| `\\x1c`     | File Separator (FS)                 |\n| `\\x1d`     | Group Separator (GS)                |\n| `\\x1e`     | Record Separator (RS)               |\n| `\\x85`     | Next Line (NEL)                     |\n| `\\u2028`   | Line Separator (LS)                 |\n| `\\u2029`   | Paragraph Separator (PS)            |\n","n":0.112}}},{"i":1327,"$":{"0":{"v":"Line Tabulation","n":0.707},"1":{"v":"\n\n## Line Tabulation\n\n> \"The vertical tab is like the horizontal tab defined to reduce the amount of work for creating layouts, and also reduce the amount of storage space for formatted text pages. The VT control code is used to jump to the next marked line.\"\n> <br>\n> In the world of typewriters, a vertical tab typically moved a distance of 6 lines, the same way a horizontal tab would typically move a distance of 8 spaces. In old printers, the vertical tab would also speed up vertical movement by indicating a jump to the next spot on a special tab belt, which was helpful for aligning content on forms.\n","n":0.096}}},{"i":1328,"$":{"0":{"v":"Group Separator","n":0.707},"1":{"v":"\n\n## Group Separator\n\n> \"Data storage was one of the main reasons for some control codes to get in the ASCII definition. Databases are most of the time setup with tables, containing records. All records in one table have the same type, but records of different tables can be different. The group separator GS is defined to separate tables in a serial data storage system. Note that the word table wasn't used at that moment and the ASCII people called it a group.\"\n","n":0.11}}},{"i":1329,"$":{"0":{"v":"Form Feed","n":0.707},"1":{"v":"\n\n## Form Feed\n\n> \"The form feed code FF was designed to control the behaviour of printers. When receiving this code the printer moves to the next sheet of paper.\"\n","n":0.186}}},{"i":1330,"$":{"0":{"v":"File Separator","n":0.707},"1":{"v":"\n\n## File Separator\n\n> \"The file separator FS is an interesting control code, as it gives us insight in the way that computer technology was organized in the sixties. We are now used to random access media like RAM and magnetic disks, but when the ASCII standard was defined, most data was serial. I am not only talking about serial communications, but also about serial storage like punch cards, paper tape and magnetic tapes. In such a situation it is clearly efficient to have a single control code to signal the separation of two files. The FS was defined for this purpose.\"\n> <br>\n> Nowadays we still need a way to delimit files within a serialized stream, for example when uploading photos on a website. But how do we get around the fact that each file, especially a non-text image file, could itself contain the FS character? The MIME spec calls for a custom-defined boundary, and suggests using an improbable string of gibberish:\n\n```\nContent-Type: multipart/mixed;\n     boundary=gc0p4Jq0M2Yt08jU534c0p\n```\n","n":0.078}}},{"i":1331,"$":{"0":{"v":"11","n":1}}},{"i":1332,"$":{"0":{"v":"30","n":1}}},{"i":1333,"$":{"0":{"v":"Reduce Your Python Code Complexity with This Simple Trick","n":0.333},"1":{"v":"\n\n- `Author:` ran-isenberg\n- `Link:` <https://isenberg-ran.medium.com/reduce-your-python-code-complexity-with-this-simple-trick-7046b7c54e7a>\n- `Publish Date:` 2021.07.01\n- `Reviewed Date:` [[log.daily.2021.11.30]]\n\n---\n\n- A customer management system receives requests.\n- ![alt](assets/images/Pasted_image_20211130095653.png)\n- Each request type is a Python dictionary and all 4 are handled uniquely\n  - ![alt](assets/images/Pasted_image_20211130095905.png)\n\n```python\nrequest1 = {\n    \"action\": \"create\",\n    \"customer\": \"customer1\",\n}\n\nrequest2 = {\n    \"action\": \"activate\",\n    \"customer\": \"customer2\",\n}\n\nrequest3 = {\n    \"action\": \"suspend\",\n    \"customer\": \"customer2\",\n}\n\nrequest4 = {\n    \"action\": \"delete\",\n    \"customer\": \"customer2\",\n}\n\ndef function_handler(request: Dict[str, Any]) -> None:\n    # handle request\n```\n\n90e9dc\n\n```python\nfrom typing import Any, Dict\n\n\ndef function_handler(request: Dict[str, Any]) -> None:\n    action = request.get(\"action\")\n    customer_name = request.get(\"customer\")\n    # validate input\n    \n    if action == \"create\":\n        _handle_create_request(customer_name)\n    elif action == \"activate\":\n        _handle_activate_request(customer_name)\n    elif action == \"suspend\":\n        _handle_suspend_suspend(customer_name)\n    elif action == \"delete\":\n        _handle_delete_request(customer_name)\n\n\ndef _handle_create_request(customer_name: str) -> None:\n    # do something related to create\n    return\n\n\ndef _handle_activate_request(customer_name: str) -> None:\n    # do something related to activate\n    return\n\n\ndef _handle_suspend_suspend(customer_name: str) -> None:\n    # do something related to suspend\n    return\n\n\ndef _handle_delete_request(customer_name: str) -> None:\n    # do something related to delete\n    return\n```\n\ndf2a07\n\n```python\nfrom typing import Any, Dict\n\nACTION_MAPPING = {\n    \"create\": _handle_create_request,\n    \"activate\": _handle_activate_request,\n    \"suspend\": _handle_suspend_suspend,\n    \"delete\": _handle_delete_request,\n}\n\ndef function_handler(request: Dict[str, Any]) -> None:\n    action = request.get(\"action\")\n    customer_name = request.get(\"customer\")\n    # validate input\n    _handle_request(action, customer_name)\n\n\ndef _handle_request(action: str, customer_name: str) -> None:\n    action_handler = ACTION_MAPPING.get(action)\n    # handle action\n    action_handler(customer_name)\n\n\ndef _handle_create_request(customer_name: str) -> None:\n    # do something related to create\n    return\n\n\ndef _handle_activate_request(customer_name: str) -> None:\n    # do something related to activate\n    return\n\n\ndef _handle_suspend_suspend(customer_name: str) -> None:\n    # do something related to suspend\n    return\n\n\ndef _handle_delete_request(customer_name: str) -> None:\n    # do something related to delete\n    return\n```\n\nc90001\n\n","n":0.065}}},{"i":1334,"$":{"0":{"v":"12","n":1}}},{"i":1335,"$":{"0":{"v":"Pragmatic Ai Labs and Solutions Testing in Python","n":0.354},"1":{"v":"\n\n- `Author:` alfredo-deza\n- `Link:` <https://paiml.com/docs/home/books/testing-in-python/chapter02-testing-conventions/>\n- `Reviewed Date:` [[import.research.article.2021.11.12]]\n\n---\n\n- author links to have his tests in the source code directory alongside existing codebase and mirror the directory structure of the code.\n- a separate sub-directory under the `tests/` directory for tests like sending an API call are a functional test and not something as granular to test in a unit like a sum function\n- have tests even if living at the top level of the project (this is so the test code doesnt ship with the source code and is just less code to move around) and have them mirror the directory structure of the code base so if the `src/` directory has `src/utilities/utils.py` then there should be `tests/utilities/test_utils.py`\n\n## Special test class methods\n\nAside from test naming conventions, there are other special names that you should be aware of when using classes. These names should be considered reserved, and should only be used for their intended purpose. These are all the special methods:\n\n`setup`: This method allows to provide attributes or anything else that is used by tests. By convention, it is called once before every test method in the class is executed. If lots of tests are using some sample data, it can be defined once here instead of having it referenced over and over in every single test method.\n\n`teardown`: This method allows to perform any cleanup actions needed by tests. Just like the setup method, it gets called once, but after every test method in the class is executed. For example, if a test is always leaving behind artifacts like files that shouldn‚Äôt be present, this special method could remove them, so that the next test doesn‚Äôt have a polluted environment.\n\n`setupclass`: Similar to setup, but instead of running before every test is executed it runs once before starting a test in a class.\n\n`teardownclass`: This method runs once after all tests in the class have been executed.\n\nIf you are wondering why `__init__` is not mentioned in this list, it is because you should not have one for test classes. Historically, `unittest.TestCase` (Python‚Äôs standard library for testing) didn‚Äôt have them, and it relied on setup and teardown class methods, and tools like pytest skips collection of test classes if it detects an `__init__` method in them.\n\n","n":0.052}}},{"i":1336,"$":{"0":{"v":"10","n":1}}},{"i":1337,"$":{"0":{"v":"Solid Coding in Python","n":0.5},"1":{"v":"\n\n- `Author:` mattia-cinelli\n- `Link:` <https://towardsdatascience.com/solid-coding-in-python-1281392a6a94>\n- `Reference:` [[r.{.clean-code]]\n- `Publish Date:` 2021.06.29\n- `Reviewed Date:` [[log.daily.2021.11.10]]\n\n---\n\n- [[The Single-Responsibility Principle|r.{.clean-code.the-single-responsibility-principle]] (`SRP`)\n- [[The Open-Closed Principle|r.{.clean-code.the-open-closed-principle]] (`OCP`)\n- [[The Liskov Substitution Principle|r.{.clean-code.the-liskov-substitution-principle]] (`LSP`)\n- [[The Interface Segregation Principle|r.{.clean-code.the-interface-segregation-principle]] (`ISP`)\n- [[The Dependency inversion Principle|r.{.clean-code.the-dependency-inversion-principle]] (`DIP`)\n\n","n":0.167}}},{"i":1338,"$":{"0":{"v":"Level up Your Python Code with Abstract Classes","n":0.354},"1":{"v":"\n\n- `Link:` <https://python.plainenglish.io/level-up-your-python-code-with-abstract-classes-7f7f6bdcbb5c>\n- `Publish Date:` 2021-10-17\n- `Reviewed Date:` [[log.daily.2021.11.10]]\n\n---\n\n> you should use abstract classes to specify which methods must be implemented by the child classes. The abc module \"make sure\" that you implement all those methods before being able to instantiate the objects.\n\n```python\ndef animate(animal):\n\tprint(animal.get_sound())\n\tfor leg in animal.legs_number:\n\t\tprint(\"Moving leg\", leg)\n\tprint(\"Moved!\")\n```\n\n```python\nfrom abc import ABC, abstractmethod\n\nclass Animal(ABC):\n\t\n\t@abstractmethod\n\tdef get_sound(self) -> str:\n\t\tpass\n\t\n\t@property #  you need to add the @propertydecorator both in the abstract class and in every sub-class.\n\t@abstractmethod\n\tdef legs_number(self) -> int:\n\t\tpass\n\n# >>>a = Animal()\n# Traceback (most recent call last):\n#   File \"c:\\abstract_class.py\", line 9, in <module>\n#     a = Animal()\n# TypeError: Can't instantiate abstract class Animal with abstract method get_sound\n\nclass Cat(Animal):\n\t\n\tdef get_sound(self) -> str:\n\t\treturn \"Meow\"\n\t\n\t@property #  you need to add the @propertydecorator both in the abstract class and in every sub-class.\n\tdef legs_number(self) -> int:\n  \t\treturn 4\n\n# >>> a = Cat()\n# >>> a.get_sound()\n# Meow\n\n```\n\n![alt](assets/images/Pasted_image_20211105215356.png)\n\n","n":0.086}}},{"i":1339,"$":{"0":{"v":"05","n":1}}},{"i":1340,"$":{"0":{"v":"Write Clean Python Code Using Pipes","n":0.408},"1":{"v":"\n- `Author:` khuyen-tran\n- `Link:` <https://towardsdatascience.com/write-clean-python-code-using-pipes-1239a0f3abf5>\n- `Reference:` [[s.l.python.libs.pipe]]\n- `Publish Date:` 2021-10-27\n- `Reviewed Date:` [[log.daily.2021.11.05]]\n\n---\n\n```python\narr = [1, 2, 3, 4, 5]\nlist(map(lambda x: x * 2, filter(lambda x: x % 2 == 0, arr)))\n# >>> [4, 8]\n```\n\n```python\nfrom pipe import where, select\narr = [1, 2, 3, 4, 5]\nlist(arr,\n\t | where(lambda x: x % 2 == 0, arr)\n\t | select(lambda x: x * 2))\n# >>> [4, 8]\n```\n\n```python\nfrom pipe import where\narr = [1, 2, 3, 4, 5]\nlist(arr | where(lambda x: x % 2 == 0))\n# >>> [2, 4]\n```\n\n```python\nfrom pipe import where, select\narr = [1, 2, 3, 4, 5]\nlist(arr | select(lambda x: x * 2))\n# >>> [2, 4, 6. 8, 10]\n```\n\n```python\nfrom pipe import chain\nnested = [[1, 2, [3]], [4, 5]]\nlist(nested | chain)\n# >>> [1, 2, [3], 4, 5]\n# OR FOR DEEPLY NESTED:\nfrom pipe import traverse\nnested = [[1, 2, [3]], [4, 5]]\nlist(nested | traverse)\n# >>> [1, 2, 3, 4, 5]\n```\n\n```python\nfrom pipe import traverse, select\nfruits = [\n\t{\"name\": \"apple\", \"price\": [2, 5]},\n\t{\"name\": \"orange\", \"price\": 4},\n\t{\"name\": \"grape\", \"price\": 5},\n]\nlist(fruits\n\t | select(lambda fruit: fruit[\"price\"])\n\t | traverse)\n```\n\n```python\nfrom pipe import groupby, select \nlist( \n\t(1, 2, 3, 4, 5, 6, 7, 8, 9)\n\t| groupby( lambda x: \"Even\" if x % 2 == 0 else \"Odd\") \n\t| select( lambda x: {x[0]: list(x[1])})\n)\n# >>> [{'Even': [2, 4, 6 ,8]}, {\"Odd\": [1, 3, 5, 7, 9]}]\n```\n\n```python\nfrom pipe import groupby, select \nlist( \n\t(1, 2, 3, 4, 5, 6, 7, 8, 9)\n\t| groupby( lambda x: \"Even\" if x % 2 == 0 else \"Odd\") \n\t| select( lambda x: {x[0]: list(x[1] | where(lambda x: x > 2))})\n)\n# >>> [{'Even': [4, 6 ,8]}, {\"Odd\": [3, 5, 7, 9]}]\n```\n\n","n":0.063}}},{"i":1341,"$":{"0":{"v":"01","n":1}}},{"i":1342,"$":{"0":{"v":"Write Data This Alternative Is 7 Times Faster","n":0.354},"1":{"v":"\n\n- `Author:` dario-radeƒçiƒá\n- `Link:` <https://towardsdatascience.com/stop-using-pandas-to-read-write-data-this-alternative-is-7-times-faster-893301633475>\n- `Publish Date:` 2021-10-22\n- `Reviewed Date:` [[log.daily.2021.11.01]]\n\n---\n\n- Pyarrow for faster data reads\n  - `pip install pyarrow`\n- video format of this article <https://youtu.be/gFd4I1oXG8E>\n\n![alt](assets/images/Pasted_image_20211101091818.png)\n![alt](assets/images/Pasted_image_20211101091826.png)\n![alt](assets/images/Pasted_image_20211101091836.png)\n\n```python\n# Create a dummy dataset:\nimport random\nimport string\nimport numpy as np\nimport pandas as pd\nimport pyarrow as pa\nimport pyarrow.csv as csv\nfrom datetime import datetime\n\ndef gen_random_string(length: int = 32) -> str:\n    return ''.join(random.choices(\n        string.ascii_uppercase + string.digits, k=length)\n    )\n\ndt = pd.date_range(\n    start=datetime(2000, 1, 1),\n    end=datetime(2021, 1, 1),\n    freq='min'\n)\n\nnp.random.seed = 42\ndf_size = len(dt)\nprint(f'Dataset length: {df_size}')\n\n\ndf = pd.DataFrame({\n    'date': dt,\n    'a': np.random.rand(df_size),\n    'b': np.random.rand(df_size),\n    'c': np.random.rand(df_size),\n    'd': np.random.rand(df_size),\n    'e': np.random.rand(df_size),\n    'str1': [gen_random_string() for x in range(df_size)],\n    'str2': [gen_random_string() for x in range(df_size)]\n})\n# 1 test baseline speed of pandas\n## even being kind by using the compression parameter\n\ndf.to_csv('csv_pandas.csv.gz', index=False, compression='gzip')\n\n# Check read times\n\ndf1 = pd.read_csv('csv_pandas.csv')\n\n# **NOTE:** Here‚Äôs a thing you should know about PyArrow ‚Äî it can‚Äôt handle datetime columns. You‚Äôll have to convert the date attribute to a timestamp. Here‚Äôs how:\n\ndf_pa = df.copy()\ndf_pa['date'] = df_pa['date'].values.astype(np.int64) // 10 ** 9\ndf_pa_table = pa.Table.from_pandas(df_pa)\ncsv.write_csv(df_pa_table, 'csv_pyarrow.csv')\n\n# Adding compression\n\nwith pa.CompressedOutputStream('csv_pyarrow.csv.gz', 'gzip') as out:\n    csv.write_csv(df_pa_table, out)\n\n# You can read both compressed and uncompressed dataset with the csv.read_csv() function:\n\ndf_pa_1 = csv.read_csv('csv_pyarrow.csv')\ndf_pa_2 = csv.read_csv('csv_pyarrow.csv.gz')\n\n# Both will be read in the pyarrow.Table format, so use the following command to convert them to a Pandas DataFrame:\n\ndf_pa_1 = df_pa_1.to_pandas()\n```\n\n","n":0.07}}},{"i":1343,"$":{"0":{"v":"10","n":1}}},{"i":1344,"$":{"0":{"v":"07","n":1}}},{"i":1345,"$":{"0":{"v":"How I Redesigned over 100 Etl into Elt Data Pipelines","n":0.316},"1":{"v":"\n\n- `Author:` nicholas-leong\n  - `Notable Authors:` \n- `Link:` <https://towardsdatascience.com/how-i-redesigned-over-100-etl-into-elt-data-pipelines-c58d3a3cb3c>\n- `Reference:` \n- `Publish Date:` 2021-10-04\n- `Reviewed Date:` [[log.daily.2021.10.07]]\n\n---\n","n":0.243}}},{"i":1346,"$":{"0":{"v":"Paper","n":1}}},{"i":1347,"$":{"0":{"v":"Data Engineering Essentials Patterns and Best Practices","n":0.378},"1":{"v":"\n\n![data-engineering-essentials,-patterns-and-best-practices.pdf](/assets/pdfs/data-engineering-essentials,-patterns-and-best-practices-CHrpjIk5jMad.pdf)\n","n":1}}},{"i":1348,"$":{"0":{"v":"Podcast","n":1}}},{"i":1349,"$":{"0":{"v":"Tweet","n":1}}},{"i":1350,"$":{"0":{"v":"Projects","n":1}}},{"i":1351,"$":{"0":{"v":"Todo","n":1}}},{"i":1352,"$":{"0":{"v":"Arch Linux","n":0.707}}},{"i":1353,"$":{"0":{"v":"Installation","n":1}}},{"i":1354,"$":{"0":{"v":"2021","n":1},"1":{"v":"\n\n## 2021\n\n- Download Arch ISO from [Archlinux.org](https://archlinux.org/download/)\n- On a Windows machine download [Rufus](https://rufus.ie/en/)\n  - Use Rufus to burn the ISO to a USB\n  - This makes a bootable disk for bootstrapping the system\n  - Settings as of 2021-10-25\n    - ![Alt](assets/images/Pasted_image_20211025015639.png)\n    - ![Alt](assets/images/Pasted_image_20211025015715.png)\n- insert USB into machine\n- [Helpful installation guide](https://wiki.archlinux.org/title/Installation_guide)\n- in the computer setup menu change the boot order to boot from the USB as first priority\n- Ensure UEFI mode is active and prefered, verify once on the CLI with: `ls /sys/firmware/efi/efivars`\n- Connect over wifi using `iwctl` \n  - Interactive Mode (These menus have Tab completion)\n    - First, if you do not know your wireless device name, list all Wi-Fi devices: `[iwd]# device list`\n    - Then, to scan for networks: `[iwd]# station <device> scan`\n    - You can then list all available networks: `[iwd]# station <device> get-networks`\n    - Finally, to connect to a network: `[iwd]# station <device> connect <SSID>`\n  - Single Command with passed values: `iwctl --passphrase <passphrase> station <device> connect <SSID>`\n- **AT THIS STAGE YOU CAN JUST RUN THE ARCHINSTALL SCRIPT AND CALL IT DONE AFTERWARDS**\n  - no need to stay in chroot afterwards\n  - restart computer and log back in using user account\n- installed `netctl` and `dialog` to use `wifi-menu`\n  - also got connected to internet via `nmcli device wifi connect SSID_or_BSSID password password` nmcli comes from the NetworkManager program\n- **AT THIS POINT IT WOULD BE IDEAL TO LAUNCH A BOOT STRAPPING SCRIPT FOR ALL THE USER SETTINGS AND PACKAGES FOR THE DESKTOP ENVIRONMENT**\n  - such as [LARBS](https://github.com/tallguyjenks/LARBS/blob/master/larbs.sh) but repurposed for my own usage\n","n":0.063}}},{"i":1355,"$":{"0":{"v":"2020 2","n":0.707},"1":{"v":"\n\n## 2021-2\n\n- Download Arch ISO from [Archlinux.org](https://archlinux.org/download/)\n- On a Windows machine download [Rufus](https://rufus.ie/en/)\n  - Use Rufus to burn the ISO to a USB\n  - This makes a bootable disk for bootstrapping the system\n  - Settings as of 2021-10-25\n    - ![Alt](assets/images/Pasted_image_20211025015639.png)\n    - ![Alt](assets/images/Pasted_image_20211025015715.png)\n- insert USB into machine\n- [Helpful installation guide](https://wiki.archlinux.org/title/Installation_guide)\n- in the computer setup menu change the boot order to boot from the USB as first priority\n- Ensure UEFI mode is active and prefered, verify once on the CLI with: `ls /sys/firmware/efi/efivars`\n- Connect over wifi using `iwctl` \n  - Interactive Mode (These menus have Tab completion)\n    - First, if you do not know your wireless device name, list all Wi-Fi devices: `[iwd]# device list`\n    - Then, to scan for networks: `[iwd]# station <device> scan`\n    - You can then list all available networks: `[iwd]# station <device> get-networks`\n    - Finally, to connect to a network: `[iwd]# station <device> connect <SSID>`\n  - Single Command with passed values: `iwctl --passphrase <passphrase> station <device> connect <SSID>`\n- **AT THIS STAGE YOU CAN JUST RUN THE ARCHINSTALL SCRIPT AND CALL IT DONE AFTERWARDS**\n- check accuracy of system clock: `timedatectl set-ntp true`\n- See drives `lsblk`\n- Partition drives with `cfdisk`\n  - `[new] -> 600M [enter] -> [type] -> EFI -> [enter]`\n  - `[new] -> 2xRAM in GB [enter] -> [type] -> Linux Swap -> [enter]`\n  - `[new] -> 25G [enter] -> [type] -> Linux File System -> [enter]`\n  - `[new] -> THE REST in GB [enter] -> [type] -> Linux File System -> [enter]`\n  - `[write]`\n  - `yes -> [enter]`\n  - `[quit]`\n- Write the EXT4 file system to the partitions and FAT32 for EFI \n  - `mkfs.fat -F32 /dev/sda1`\n  - `mkfs.ext4 /dev/sda3`\n  - `mkfs.ext4 /dev/sda4`\n- Activate your swap partition\n  - `mkswap /dev/sda2`\n  - `swapon /dev/sda2`\n- Mount your partitions to `/mnt`\n  - `mount /dev/sda3 /mnt` &lt;&lt;- mounting the root\n    - `mkdir /mnt/home`\n      - `mount /dev/sda4 /mnt/home`\n    - `mkdir /mnt/boot`\n      - `mount /dev/sda1 /mnt/boot`\n- bootstrap the system with some initial packages and software\n  - `pacstrap /mnt base base-devel vim networkmanager grub linux linux-firmware man-db man-pages texinfo`\n- generate an fstab file\n  - `genfstab /mnt`\n  - `genfstab -U /mnt >> /mnt/etc/fstab`\n  - `vim /mnt/etc/fstab`\n- root access into the new system `arch-chroot /mnt`\n- activate network manager `systemctl enable NetworkManager`\n- set the timezone `In -sf /usr/share/zoneinfo/America/Los_Angeles /etc/localtime`\n- Run hwclock to generate /etc/adjtime: `hwclock --systohc`\n- localization: `vim /etc/locale.gen` un-comment the `en_US` items\n- run `locale-gen`\n- `vim /etc/locale.conf` add: \"LANG=en_US.UTF-8\"\n- `vim /etc/hostname` put name of machine here (i.e. what do you want your computers name to be)\n- set password for ROOT account `passwd`\n- enable microcode updates?? `initrd=\\cpu_manufacturer-ucode.img initrd=\\initramfs-linux.img`\n- setup boot loader\n  - `grub-install --target=i386-pc /dev/sda`\n  - `grub-mkconfig -o /boot/grub/grub.cfg`\n- exit the chroot environment `exit`\n- unmount all partitions `umount -R /mnt`\n- reboot the system `reboot`\n  - while reboot is occurring remove the bootable USB\n  - Login to the system as the root user\n","n":0.046}}},{"i":1356,"$":{"0":{"v":"2020 1","n":0.707},"1":{"v":"\n\n## 2020-1\n\n```bash\ntimedatectl set-ntp true\nping lukesmith.xyz\nwifi-menu\ncfdisk\n[new] -> 600M [enter] -> [type] -> EFI -> [enter]\n[new] -> 2xRAM in GB [enter] -> [type] -> Linux Swap -> [enter]\n[new] -> 25G [enter] -> [type] -> Linux File System -> [enter]\n[new] -> THE REST in GB [enter] -> [type] -> Linux File System -> [enter]\n[write]\nyes -> [enter]\nquit\nmkfs.ext4 /dev/sda1\nmkfs.ext4 /dev/sda3\nmkfs.ext4 /dev/sda4\nmkswap /dev/sda2\nswapon /dev/sda2\nmount /dev/sda3 /mnt                        # mounting the root\nmkdir /mnt/home\nmkdir /mnt/boot\nmount /dev/sda1 /mnt/boot\nmount /dev/sda4 /mnt/home\npacstrap /mnt base base-devel vim\ngenfstab /mnt\ngenfstab -U /mnt >> /mnt/etc/fstab\nvim /mnt/etc/fstab\narch-chroot /mnt\npacman -S networkmanager\nsystemctl enable NetworkManager\npacman -S grub\ngrub-install --target=i386-pc /dev/sda\ngrub-mkconfig -o /boot/grub/grub.cfg\npasswd\nvim /etc/locale.gen #uncomment the en_US items\nlocale-gen\nvim /etc/locale.conf # add: \"LANG=en_US.UTF-8\"\nln -sf /usr/share/zoneinfo/America/los-angelas /etc/localtime\nvim /etc/hostname # put name of machine here\nexit\numount -R /mnt\nreboot\n\n#~=============================~\n#AFTER LARBS NETWORK MANAGEMENT\n#~=============================~\n\nsysctl net.ipv4.tcp_ecn=0\n```\n","n":0.093}}},{"i":1357,"$":{"0":{"v":"2019","n":1},"1":{"v":"\n\n## 2019\n\n```bash\ntimedatectl set-ntp true\nping lukesmith.xyz\nwifi-menu\nfdisk /dev/sda\nmkfs.ext4 /dev/sda1\nmkfs.ext4 /dev/sda3\nmkfs.ext4 /dev/sda4\nmkswap /dev/sda2\nswapon /dev/sda2\nmount /dev/sda3 /mnt\nmkdir /mnt/home\nmkdir /mnt/boot\nmount /dev/sda1 /mnt/boot\nmount /dev/sda4 /mnt/home\npacstrap /mnt base base-devel vim\ngenfstab /mnt\ngenfstab -U /mnt >> /mnt/etc/fstab\nvim /mnt/etc/fstab\narch-chroot /mnt\npacman -S networkmanager\nsystemctl enable NetworkManager\npacman -S grub\ngrub-install --target=i386-pc /dev/sda\ngrub-mkconfig -o /boot/grub/grub.cfg\npasswd\nvim /etc/locale.gen #uncomment the en_US items\nlocale-gen\nvim /etc/locale.conf # add: \"LANG=en_US.UTF-8\"\nln -sf /usr/share/zoneinfo/America/los-angelas /etc/localtime\nvim /etc/hostname # put name of machine here\nexit\numount -R /mnt\nreboot\n\n#~=============================~\n#AFTER LARBS NETWORK MANAGEMENT\n#~=============================~\n\nsysctl net.ipv4.tcp_ecn=0\n```\n","n":0.124}}},{"i":1358,"$":{"0":{"v":"Priority","n":1}}},{"i":1359,"$":{"0":{"v":"Done","n":1}}},{"i":1360,"$":{"0":{"v":"Dendron","n":1}}},{"i":1361,"$":{"0":{"v":"Templates","n":1}}},{"i":1362,"$":{"0":{"v":"Variables","n":1},"1":{"v":"\n\n## VS Code Stanard Variables\n\n- <https://code.visualstudio.com/docs/editor/userdefinedsnippets>\n\n## Template Variables\n\nDendron supports various template variables.\n\n- For inserting the current date and time:\n  - CURRENT_YEAR: The current year\n  - CURRENT_MONTH: The month as two digits (example '02')\n  - CURRENT_DAY: The day of the month as two digits (example '08')\n  - CURRENT_HOUR: The current hour in 24-hour clock format\n  - CURRENT_MINUTE: The current minute as two digits\n  - CURRENT_SECOND: The current second as two digits\n\n### VS Code default variables\n\nThe following variables can be used:\n\n- `TM_SELECTED_TEXT` The currently selected text or the empty string\n- `TM_CURRENT_LINE` The contents of the current line\n- `TM_CURRENT_WORD` The contents of the word under cursor or the empty string\n- `TM_LINE_INDEX` The zero-index based line number\n- `TM_LINE_NUMBER` The one-index based line number\n- `TM_FILENAME` The filename of the current document\n- `TM_FILENAME_BASE` The filename of the current document without its extensions\n- `TM_DIRECTORY` The directory of the current document\n- `TM_FILEPATH` The full file path of the current document\n- `RELATIVE_FILEPATH` The relative (to the opened workspace or folder) file path of the current document\n- `CLIPBOARD` The contents of your clipboard\n- `WORKSPACE_NAME` The name of the opened workspace or folder\n- `WORKSPACE_FOLDER` The path of the opened workspace or folder\n\nFor inserting the current date and time:\n\n- `CURRENT_YEAR` The current year\n- `CURRENT_YEAR_SHORT` The current year's last two digits\n- `CURRENT_MONTH` The month as two digits (example '02')\n- `CURRENT_MONTH_NAME` The full name of the month (example 'July')\n- `CURRENT_MONTH_NAME_SHORT` The short name of the month (example 'Jul')\n- `CURRENT_DATE` The day of the month as two digits (example '08')\n- `CURRENT_DAY_NAME` The name of day (example 'Monday')\n- `CURRENT_DAY_NAME_SHORT` The short name of the day (example 'Mon')\n- `CURRENT_HOUR` The current hour in 24-hour clock format\n- `CURRENT_MINUTE` The current minute as two digits\n- `CURRENT_SECOND` The current second as two digits\n- `CURRENT_SECONDS_UNIX` The number of seconds since the Unix epoch\n\n### Example\n\n```md\nToday is {{ CURRENT_YEAR }}.{{ CURRENT_MONTH }}.{{ CURRENT_DAY }},\n```\n\noutput:\n\n> Today is 2022.01.04\n\n## Template Variable replacement\n\nFor replacing the standard variables inside the dendron template files\n\n<https://wiki.dendron.so/notes/GelEQPZrSgr3CK9y10Nrg/#template-variables>\n\n\n## VSCode Snippet Tricks\n\n1. You can set a default value for a variable by using a colon (:).\n\nExample:\n\n- The DUE: property in the below snippet defaults to the current current month, date, hour but can be edited fairly quick\n\n```json\n\"TODO\": {\n   \"prefix\": \"stodo\",\n   \"body\": [\n    \"- [ ] ${1:Enter Task}\",\n    \"- **CAPTURED:**        ${CURRENT_YEAR}-${CURRENT_MONTH}-${CURRENT_DATE}T${CURRENT_HOUR}:${CURRENT_MINUTE}:${CURRENT_SECOND}-08:00\",\n    \"- **DUE:**             ${CURRENT_YEAR}-${2:${CURRENT_MONTH}}-${3:${CURRENT_DATE}}T${4:${CURRENT_HOUR}}:${5:${CURRENT_MINUTE}}:00-08:00\",\n    \"- **PRIORITY:**        ${6|HIGH,MEDIUM,LOW|}\",\n    \"- **STATUS:**          ${7|TODO,WAITING,IN PROGRESS,DONE|}\",\n    \"- **NOTES:**           \",\n    \"    - $0\",\n    ],\n    \"description\": \"Capture new TODO\"\n}\n```\n\n1. You can set dropdown values for a variable using a pipe (|).\n\nExample:\n\n```json\n\"Context Switch\": {\n   \"prefix\": \"scontext\",\n   \"body\": [\n    \"- **TYPE:**          ${1|COMMS,SUPPORT,RESEARCH,MEETING,DEVELOPMENT,TESTING,VALIDATION,CI/CD,PROJECT MGMT,CONSULTING,DOCUMENTATION,ADMINISTRATION,TRAINING,BREAK|}\",\n    \"- **PROJECT:**       ${2|PROJ1,PROJ2|}\",\n    \"- **TOOLS:**         ${3|N/A,PYTHON,AZURE,POWER APPS,POWER AUTOMATE,POWER BI,SHAREPOINT,DENDRON|}\",\n    \"- **START:**         ${CURRENT_YEAR}-${CURRENT_MONTH}-${CURRENT_DATE}T${CURRENT_HOUR}:{$CURRENT_MINUTE}:${CURRENT_SECOND}-08:00\",\n    \"- **END:**           \",\n    \"- **DURATION:**      \",\n    \"- **NOTES:**         \",\n    \"    - $0\",\n    \"---\"\n    ],\n    \"description\": \"Capture new context switch\"\n}\n```\n","n":0.048}}},{"i":1363,"$":{"0":{"v":"Doing","n":1}}},{"i":1364,"$":{"0":{"v":"Homelab","n":1}}},{"i":1365,"$":{"0":{"v":"Todo","n":1},"1":{"v":"\n\n![[n]]\n","n":1}}},{"i":1366,"$":{"0":{"v":"Services","n":1}}},{"i":1367,"$":{"0":{"v":"TrueNAS","n":1},"1":{"v":"\n## Installation\n\nHelpful Resource: <https://youtu.be/psVNn-JVT9Q>\n\n1. View [[p.doing.homelab.servers.fafnir.hardware.idrac]] interface in firefox\n   1. Set console to be HTML5\n2. Load .iso virtual media to the CD/ROM\n3. `F11` to open UEFI manager\n4. change boot order and select boot device\n   1. select `Virtual Media Optical Disk`\n5. Install with the minimal prompts to the 2 mirrored SSD's\n6. Reboot\n7. Change the boot order to now boot from the SSD's first\n8. Boot into TrueNAS\n9. Begin [[p.doing.homelab.services.truenas.configuration]]\n","n":0.122}}},{"i":1368,"$":{"0":{"v":"Troubleshooting","n":1},"1":{"v":"\n## Issue with unable to add drives to a ZFS Pool \n\n> [EFAULT] Failed to wipe disk da14: [Errno 22] Invalid argument\n\n> I just want to add my thanks to the OP for creating and particularly to swissroot for the link that made it all come together.\n>\n> I bought 6 4Tb Seagate drives from a recycler thinking that I could just plug them into my Dell T620 bays and load them up as mirrored vdevs. Its a new build that I'm playing with and while I waited for my H220 flashed to LSI HBA from The Art of Server, I noticed that the H710P raid card could see all the devices but only one was open and usable and five were marked as 'blocked'. That is a well-documented issue that should be fixed by updating the firmware of the card but mine wasn't playing ball. I figured that the H220/LSI would see the drives and make them available when I installed it.\n>\n> No bueno! The H220 could see the drives but at 0.00Gb; at least I could format them through the BIOS interface for the H220 if only one at a time and 15 hours each. I thought that was the end of the issue but I suspected it might not be.\n>\n> Fast forward, all got formatted through the H220, I fired up TrueNAS core and it could see all the drives but threw an error when I tried to create the vdevs. Searching that error brought me to this thread and the link provided by swissroot provided the info I needed to sg_format the drives in parallel to a 512 byte sector rather than 520 byte.\n>\n> For those reading this with the same issue, what I've learned so far is that used HDD are often good value but if they have been used in Netapp/EMC hardware, they need to be mounted on an HBA (not a raid card) and re-formatted to 512 byte sectors in order for them to work and be mounted as useable drives in Freenas/Truenas.\n>\n> The reason this is pretty unique and hard to track down is that it seems to be an issue that is limited or confined to situations where drives that have been used in other storage arrays that utilise 520 bytes sectors are used in equipment that is looking for 512 byte sectors.\n\n### Resolution\n\n<https://bitfix.be/freenas-error-unable-to-gpt-format-the-disk-ada0/>\n\n1. Login via SSH, execute commands below.\n   - if you need to configure\n     - `System > SSH Keypairs > add` Generate SSH keypair for root user\n     - `Accounts > Users > root` for root and put public key in appropriate area\n     - `Services > SSH > Actions (configure)` allow `Log in as Root with Password`\n     - On remote machine `ssh root@#.#.#.#`\n2. `sysctl kern.geom.debugflags=0x10`\n3. `dd if=/dev/zero of=/dev/da0 bs=512 count=1`\n   - My cheat way:\n     - `for disk in $(ls /dev | grep -E \"(^da[0-9]$) | (^da1[1-5]$)\"); do dd if=/dev/zero of=/dev/$disk bs=512 count=1;done`\n     - The `dd` command way might not work so if not resort to the next option\n   - Failsafe\n     - `sg_format --format --size=512 --six -v /dev/da9`\n       - `for disk in $(ls /dev | grep -E \"(^da[0-9]$) | (^da1[1-5]$)\"); do sg_format --format --size=512 --six -v /dev/$disk && echo \"$disk reformatteded\";done`\n4. Log into web interface and use ‚ÄúView Disks‚Äù to wipe the drives in that interface\n5. Create new ZFS volume including these disks.\n","n":0.043}}},{"i":1369,"$":{"0":{"v":"Services","n":1}}},{"i":1370,"$":{"0":{"v":"Plex","n":1},"1":{"v":"\n## Resources\n\n- [Documentation](https://support.plex.tv/articles/)\n- [Full setup guide](https://troypoint.com/plex-media-server-setup-guide/#Media)\n\n## Troubleshooting\n\nIf accessing plex from outside your network or if its virtualized on a [[terms.vlan]] and youre accessing it from another [[terms.vlan]] then you need to add a specific piece of text into the configuration file for plex through the TrueNAS CLI\n\n<https://www.truenas.com/community/threads/plex-not-authorized-you-do-not-have-access-to-this-server.96858/post-669513>\n\nResolved by adding an entry to Plex's `Preferences.xml`:\n\n```xml\nallowedNetworks=\"#.#.#.#/255.255.255.0\"\n```\n\nFile located at: `/mnt/mimisbrunnr/iocage/jails/plex/root/Plex Media Server/Preferences.xml`\n\n## configuration\n\n- File Naming Conventions\n  - [Naming Movies](https://support.plex.tv/articles/naming-and-organizing-your-movie-media-files/)\n  - [Naming TV Shows](https://support.plex.tv/articles/naming-and-organizing-your-tv-show-files/)\n  - [Naming Music Files](https://support.plex.tv/articles/categories/your-media/naming-and-organizing-music-media/)\n  - [Naming Media Files](https://support.plex.tv/articles/categories/your-media/naming-and-organizing-personal-media/)\n","n":0.113}}},{"i":1371,"$":{"0":{"v":"Configuration","n":1},"1":{"v":"\n## Link Aggregation\n\n[[n.link-aggregation]] / [[n.protocol.lacp]]\n\nin the console follow the prompts to add all current interfaces to a `lagg` using [[n.protocol.lacp]], Then configure the aggregation for [[n.protocol.dhcp]]\n\nNow the web console should be available at a listed IP Address\n\n## Configure SMART Tests\n\n- `Tasks > S.M.A.R.T Test > Add`\n\n```txt\nAll Disks\nType: LONG\nDescription: Long SMART test\nSchedule: Monthly (0 0 1 * *) on the first day of the month at 00:00 (12:00 AM)\nSAVE\n```\n\n## Hardening\n\n- <https://www.truenas.com/docs/scale/communityrecommends/hardened-backup-repository-for-veeam/#configure-smart-tests>\n\n1. Use Fixed IP Address not DHCP\n2. Disable Service Announcement\n   - NetBIOS-NS\n   - mDNS\n   - WS-Discovery\n3. use well known DNS servers\n   - `1.1.1.1`\n   - `8.8.8.8`\n4. Keep 1 interface for management layer and 3 interfaces in [[n.protocol.lacp]] for data\n5. `System > General > web interface address`\n   - use [[n.protocol.https]] redirect\n6. make [[n.protocol.ssh]] NOT start automatically.\n   - And in the advanced settings `ssh > pencil icon > advanced > auxillary parameters`\n     - add `AllowUsers root@#.#.#.#` where `#.#.#.#` is the IP Address of the computer you want to be able to [[n.protocol.ssh]] from\n7. Give root an email for those important notifications (destination)\n   - configure the notifications: `system > email`\n   - use the gmail OAuth and my service account email\n8. Periodic snapshots: `tasks > periodic snapshots`\n   - <https://www.truenas.com/docs/scale/communityrecommends/hardened-backup-repository-for-veeam/#configure-zfs-periodic-snapshots>\n     - hourly, daily, and weekly\n9. Configure [[n.protocol.ssh]] rules\n\n## Configure Users and groups for shared volumes\n\n- <https://www.truenas.com/community/threads/how-to-set-up-truenas-from-beginning-to-end-including-secure-remote-access-to-files-and-web-gui.89229/>\n\n- To create shared volumes you can access through connection to your local network, see the following instructions.\n  - Go to accounts on the left panel.\n    - Click on groups.\n    - Click add.\n    - Enter a group name (you can leave the GID as it is).\n    - Enable permit sudo and samba authentication.\n    - Submit.\n    - Go to accounts on the left panel.\n    - Click on users.\n    - Click add.\n    - Fill in all the empty field under Identification\n    - Uncheck new primary group.\n    - Choose the group you made previously from the drop down menu in primary groups.\n    - Go ahead and check all of the boxes under Home Directory Permissions.\n    - Under Authentication check permit sudo and Samba authentication.\n    - Submit.\n    - Go to Storage -> Pools\n    - Click add.\n      - Select create new pool then click create pool.\n    - Go back to Storage -> Pools\n    - You should see the name of your new pool pop up.\n    - Click on the three dots on the right side of that name.\n      - Click add Zvol (this must be done!)\n      - Put in a name and select a size for the Zvol (for a 1TB drive I used 1 GB, this is block device mainly used for VMs, so you can use less if you don't plan on using VMs on your NAS, more if you do).\n      - Click submit.\n    - Click on the three dots on the right side of the pool once again.\n      - Click add dataset.\n      - Type in a name and click submit.\n    - Now you should be able to see the name of that dataset underneath your pool in Storage -> Pools\n    - Click on the three dots on the right side of the name of the dataset.\n      - Click on permissions.\n      - Set the user under owner to www and group to www.\n      - Click apply user and apply group.\n      - Under access mode, check all of the boxes.\n      - Click apply permissions recursively under advanced.\n      - Click save.\n    - Click on the three dots on the right side of the name of the dataset.\n      - Click on permissions.\n      - Click on ACL manager.\n      - Click on the preset open under the dropdown menu.\n      - Set the user under owner to www and group to www.\n      - Click apply user and apply group.\n      - Click apply permissions recursively under advanced.\n      - Click save\n    - Go to Services\n      - Enable SMB and click on start automatically.\n    - Go to Sharing -> Windows Shares (SMB)\n      - Click add.\n        - Select the path to your dataset.\n        - Click submit.\n    - Now to access this folder from your Windows machine on your local network.\n      - Go to file explorer -> network\n      - Click on the top field and enter the IP address of your TrueNAS machine in this fashion (should be the same as the IP address you used to connect to your WebGUI)\n        - `\\\\youripaddress`\n      - When it asks for username and password, use the username of the new account you created in the WebGUI and its password.\n      - If you see your folder, great! If not, refer back to the previous steps to see if you did anything wrong.\n\n## snapshots\n\nSnapshots only store the differential of the change so if data is 100GB and i add 1GB the snapshot is only 1GB\n\n## Setup iperf3 on the server\n\n```bash\napt-get install iperf3\n```\n\nIn the `~/.profile` file, add this line:\n\n```bash\niperf3 -s &\n```\n\nthis will make it so upon server startup iperf3 will be run as an independant process that can can gather data from.\n\nBy default it listens on port [[n.port.5021]]\n","n":0.035}}},{"i":1372,"$":{"0":{"v":"Proxmox","n":1},"1":{"v":"\n\n![[n.hypervisor]]\n","n":1}}},{"i":1373,"$":{"0":{"v":"VM","n":1}}},{"i":1374,"$":{"0":{"v":"Win10 Visualstudio","n":0.707}}},{"i":1375,"$":{"0":{"v":"Win10 SSMS","n":0.707},"1":{"v":"\n## Resources\n\nGuide Used: <https://youtu.be/6c-6xBkD2J4>\n\n## Instructions\n\n1. Download [Windows 10 iso][0] (64bit)\n2. Download the Latest [virtio-win iso][1]\n3. upload the iso's to [[p.doing.homelab.services.proxmox]]\n4. Create new VM in Proxmox\n   1. General\n      1. Give it a name\n      2. ![General](/assets/images/2022-03-12-16-52-44.png)\n   2. OS\n      1. Select windows iso\n      2. guest type to windows\n      3. version 10\n      4. ![OS](/assets/images/2022-03-12-16-53-32.png)\n   3. System\n      1. Turn on QEMU Agent\n      2. ![System](/assets/images/2022-03-12-16-54-16.png)\n   4. Hard Disk\n      1. Bus/Device --> SCSI\n      2. Storage --> your choice\n      3. Disk Size --> 60GB?\n      4. !!**Cache --> Write back**!!\n      5. ![hard disk](/assets/images/2022-03-12-16-56-29.png)\n   5. CPU\n      1. Cores --> 24?\n      2. ![CPU](/assets/images/2022-03-12-16-57-19.png)\n   6. Memory\n      1. Ballooning (use minimum 1GB max 8GB)\n      2. Memory (MiB) --> 8192\n      3. Minimum memory (MiB) --> 1024\n      4. ![Memory](/assets/images/2022-03-12-16-58-55.png)\n   7. Network\n      1. Model --> VirtIO (paravirtualized)\n      2. ![Network](/assets/images/2022-03-12-16-59-42.png)\n   8. Confirm\n      1. Click Finish but do not start VM yet you need to configure 1 more thing\n   9. VirtIO Virtual Disk\n      1. We need to install the virtIO drivers to this VM\n      2. therefore need to give the VM a disk drive to load the virtual disk into\n      3. Select the VM in the proxmox panel\n      4. Select the `Hardware` sub menu\n      5. Click `Add > CD/DVD Drive`\n      6. ![add drive](/assets/images/2022-03-12-17-02-41.png)\n      7. Bus/Device --> IDE and 1\n      8. Storage --> your choice\n      9. Select the VirtIO iso file\n      10. ![virtual disk](/assets/images/2022-03-12-17-03-46.png)\n5. Click on the `VM > Console`\n6. Right click `VM > Start`\n7. follow allow with the normal installation of windows\n8. can continue on without product key for reduced functionality mode\n   - If you want to RDP onto the machine it needs to be a windows 10 Pro version\n9. Select Custom install\n    1. No hard drives found to install windows onto, need to load drivers from virtio\n    2. Click `Load Driver`\n    3. ![load driver](/assets/images/2022-03-12-17-06-28.png)\n    4. click `Browse`\n    5. ![browse](/assets/images/2022-03-12-17-07-09.png)\n    6. Go to virtio disk and expand\n    7. ![expand](/assets/images/2022-03-12-17-07-35.png)\n    8. First install vioscsi\n    9. ![vioscsi](/assets/images/2022-03-12-17-08-39.png)\n    10. `vioscsi > w10 > amd64 > OK`\n    11. ![amd64](/assets/images/2022-03-12-17-09-22.png)\n    12. Click `Next`\n    13. Now we can see the hard drive\n    14. ![hard drive](/assets/images/2022-03-12-17-10-06.png)\n    15. Click `Load Driver`\n    16. ![load driver](/assets/images/2022-03-12-17-06-28.png)\n    17. click `Browse`\n    18. Go to virtio disk and expand\n    19. ![expand](/assets/images/2022-03-12-17-07-35.png)\n    20. `NetKVM > w10 > amd64`\n        1. downloads network adapter drivers so we can get upgrades while installing\n    21. ![netkvm](/assets/images/2022-03-12-17-15-03.png)\n    22. Click `Next`\n    23. Click `Load Driver`\n    24. ![load driver](/assets/images/2022-03-12-17-06-28.png)\n    25. click `Browse`\n    26. Go to virtio disk and expand\n    27. ![expand](/assets/images/2022-03-12-17-07-35.png)\n    28. `Balloon > w10 > amd64`\n    29. ![balloon](/assets/images/2022-03-12-17-17-15.png)\n    30. Click `Next`\n10. Now ready to continue with windows installation\n11. Click `Next`\n12. choose location\n13. keyboard layout\n14. personal use\n15. offline account\n16. name the pc\n17. password\n18. security questions\n19. choose privacy settings (uncheck everything)\n20. windows is running\n21. go to `Device Manager`\n22. Double click missing driver under `Other Devices`\n    1. ![Other Devices](/assets/images/2022-03-12-17-20-23.png)\n    2. Click `Update Driver...`\n    3. Browse my computer for driver software\n    4. Browse to the virtio disk and select it\n    5. Click `OK`\n    6. When prompted click `Install` to install the driver\n23. Need to install the Guest Agent\n    1. Go to `This PC`\n    2. Enter the `virtio disk > guest-agent`\n    3. Execute `qemu-ga-x86_64`\n    4. Click `Yes` to install\n    5. reboot\n24. Click on `VM > Summary` See that guest agent isn't running because windows hasn't booted yet\n25. Enter the Console\n26. Boot the VM\n27. once booted check on the guest-agent has an IP\n28. Install [[s.q.tsql.tools.ssms]]\n29. Done!\n30. BONUS\n    1. For faster performance can activate Remote Desktop and just RDP onto the VM for near native performance\n    2. On mac use [this app](https://apps.apple.com/us/app/microsoft-remote-desktop-10/id1295203466?mt=12)\n       - Username from the VM (Microsoft account email)\n       - Pass for that Microsoft account\n       - Destination is IP of the VM\n       - Gateway ignoring internal traffic is the gateway IP for the VLAN the VM's are on\n\n[0]: https://www.microsoft.com/en-us/software-download/windows10ISO\n[1]: https://docs.fedoraproject.org/en-US/quick-docs/creating-windows-virtual-machines-using-virtio-drivers/index.html\n","n":0.041}}},{"i":1376,"$":{"0":{"v":"Tips Tricks Hacks","n":0.577},"1":{"v":"\n\n## Tips\n\nIn the Server view, the `Datacenter` option is for settings that affect all your nodes. In essence the \"tree\" view allows setting editing for all children under the parent item.\n\n## VM Templates\n\n<!-- markdownlint-disable MD031 -->\n<!-- markdownlint-disable MD003 -->\n<!-- markdownlint-disable MD022 -->\n<!-- markdownlint-disable MD023 -->\n\nWhen you have a default VM config you like, power down the VM, right click, Convert to template.\n\nIt can no longer be used as a VM but you can clone from that template\n\n- Mode:\n  - Linked clone: dependent child on the template with cascading downstream changes\n  - Full Clone: independent entity\n    - After cloning these steps will reset important information\n      - Change Hostname\n        - `sudo vim /etc/hostname`\n      - Change hosts file\n        - `sudo vim /etc/hosts`\n      - Reset Machine ID\n        -  \n        ```bash\n        rm -f /etc/machine-id /var/lib/dbus/machine-id\n        dbus-uuidgen --ensure=/etc/machine-id\n        dbus-uuidgen --ensure\n        ```\n      - Regenerate [[n.protocol.ssh]] keys\n        -  \n        ```bash\n        regen ssh keys\n        sudo rm /etc/ssh/ssh_host_*\n        sudo dpkg-reconfigure openssh-server\n        ```\n\n<!-- markdownlint-enable MD031 -->\n<!-- markdownlint-enable MD003 -->\n<!-- markdownlint-enable MD022 -->\n<!-- markdownlint-enable MD023 -->\n","n":0.078}}},{"i":1377,"$":{"0":{"v":"Setup","n":1},"1":{"v":"\n\n## Proxmox setup steps\n\n0. [Great installation video](https://youtu.be/azORbxrItOo)\n1. [download iso](https://proxmox.com/en/downloads)\n2. Use management interface on the server, [[p.doing.homelab.servers.fafnir.hardware.idrac]]\n   1. Turn server on\n   2. Attach virtual media (the .iso)\n3. Follow the prompts and fill in the information\n   1. chose [[n.raid#raid-z]]1 for a mirrored boot drive on SSD pair\n      1. if SSD's are not visible on boot, check that the SATA settings in device settings is set to ACHI and auto\n4. fill in network information\n   1. Much of it can be gleaned from your router console\n   2. `ifconfig get default | grep gateway` for the default gateway\n   3. for MacOS to find [[n.protocol.dns]] server just search for `DNS` in *system preferences*\n5. Once proxmox is finished bootstrapping and restarts the server, remove the virtual media\n6. if screen loads to a console then you can just transition back to your main machine and use the web interface to finish.\n7. management console is at: `https://#.#.#.#:8006` (replace `#` with valid IPV4 address)\n8. connection will be insecure and that's okay, proceed anyhow\n9. login as `root` with the password you previously set.\n10. Ignore subscription popup, its FOSS unless you want enterprise subscription\n\n## Post Install Configuration\n\nTODO reformat this section by separating out the steps to their own notes and making this list more legible\n\n1. `apt-get install neovim ranger tldr`\n2. [[p.doing.homelab.services.proxmox.configuration]]\n","n":0.069}}},{"i":1378,"$":{"0":{"v":"Resources","n":1},"1":{"v":"\n\n## Documentation\n\n- [official docs](assets/pdfs/pve-admin-guide.pdf)\n","n":0.5}}},{"i":1379,"$":{"0":{"v":"LXE","n":1}}},{"i":1380,"$":{"0":{"v":"MSSQL","n":1},"1":{"v":"\n## Initial Setup Script\n\n```bash\napt update\napt upgrade\n# Makes it so i can add a repository for SQL Server to get installed later\napt install software-properties-common\n```\n\n## Install SQL Server\n\n```bash\n# Register the package\nwget -qO- https://packages.microsoft.com/keys/microsoft.asc | sudo apt-key add -\n# Install SQL Server\nsudo add-apt-repository \"$(wget -qO- https://packages.microsoft.com/config/ubuntu/20.04/mssql-server-2019.list)\"\nsudo apt-get update\nsudo apt-get install -y mssql-server\n# Setup SA user with Password\nsudo /opt/mssql/bin/mssql-conf setup\n# 2 Developer Copy\n# Yes to license agreement\n# Password\n# Verify Service is running\nsystemctl status mssql-server --no-pager\n```\n\n## Install SQL command line tools\n\n```bash\nsudo apt-get update \nsudo apt install curl\n#Import the public repository GPG keys.\ncurl https://packages.microsoft.com/keys/microsoft.asc | sudo apt-key add -\n# Register the Microsoft Ubuntu repository.\ncurl https://packages.microsoft.com/config/ubuntu/20.04/prod.list | sudo tee /etc/apt/sources.list.d/msprod.list\n# Update the sources list and run the installation command with the unixODBC developer package.\nsudo apt-get update \nsudo apt-get install mssql-tools unixodbc-dev\n# Add¬†/opt/mssql-tools/bin/¬†to your¬†PATH¬†environment variable in a bash shell.\necho 'export PATH=\"$PATH:/opt/mssql-tools/bin\"' >> ~/.bash_profile\n# To make¬†sqlcmd/bcp¬†accessible from the bash shell for interactive/non-login sessions, modify the¬†PATH¬†in the¬†~/.bashrc¬†file with the following command:\necho 'export PATH=\"$PATH:/opt/mssql-tools/bin\"' >> ~/.bashrc\nsource ~/.bashrc\n```\n\n## Enable SSH from external machines\n\n- <https://pmsl.com.ng/ssh-into-a-proxmox-lxc-container/>\n\n```bash\n# in proxmox shell\nlxc-attach --name 109\n# change the line `PermitRootLogin` without-password to `PermitRootLogin` yes\nvi /etc/ssh/sshd_config\n# Restart the service\nservice ssh restart\n```\n\n## Enable the SQL Agent\n\n```bash\nsudo /opt/mssql/bin/mssql-conf set sqlagent.enabled true \nsudo systemctl restart mssql-server\n```\n\n## Set timezone\n\n```bash\nsudo timedatectl set-timezone America/Los_Angeles\n```\n\n## Setup ODBC Driver for connectivity to this server\n\n- <https://manjaro.site/how-to-connect-to-microsoft-sql-server-using-python-on-macos-catalina/>\n\n```bash\nbrew update\nbrew install unixodbc freetds # Install dependencies\nsudo -H pip install pyodbc\ntsql -C # Find freetds conf file\n```\n\n```bash\nsudo nvim /usr/local/etc/freetds.conf # Add configuration information\n```\n\n```ini\n[Ubuntu-Docker] # <-- Change this\nhost = 192.168.100.52 # <-- Change this\nport = 1433\ntds version = 7.3\n```\n\n```bash\ntsql -S Ubuntu-Docker -U myUser -P myPassword # Test connection\n```\n\n```bash\nodbcinst -j # Edit DSN files\n```\n\n```bash\nsudo nvim /usr/etc/local/odbcinst.ini # Add configuration information\n```\n\n```ini\n[FreeTDS]\nDescriptionFreeTDS Driver for Linux MSSOL\nDriver-/usr/local/lib/libtdsodbc.so\nSetup-/usr/local/lib/libtdsodbc.so\nUsageCount=1\n```\n\n```bash\nsudo nvim /usr/etc/local/odbc.ini # Add configuration information\n```\n\n```ini\n[Ubuntu-Docker]\nDescription = SOL Server on Ubuntu Docker\nDriver = FreeTDS\nServername = Ubuntu-Docker\n```\n\n```bash\nisql Ubuntu-Docker myUser myPassword # verify connectivity\n```\n\n### pyodbc connection to database\n\n> Temporary issue with pyodbc <https://stackoverflow.com/questions/71067094/pyodbc-deprecation-warning-when-printing>\n> work around: \"set an environment variable named `PYTHONWARNINGS` to the value `ignore::DeprecationWarning` and then just run the script normally.\"\n\n```python\nimport pyodbc\nmyconn = pyodbc.connect('DSN-Ubuntu-Docker;UID-sa;PWD=mYPasswd.23')\nmycursor = myconn.cursor ()\nmyrows = mycursor.execute(\"SELECT @@VERSION\").fetchall()\nprint(myrows)\nmycursor.close()\nmyconn.close()\n```\n","n":0.055}}},{"i":1381,"$":{"0":{"v":"Configuration","n":1},"1":{"v":"\n## Updates Repository\n\nFor regular updates and to avoid errors set the updates repository from the enterprise proxmox repo (subscription required) to the `pve-no-subscription` repo.\n\n![repos](/assets/images/2022-01-25-23-37-43.png)\n\n0. `pve node > updates > repositories`\n1. disable the enterprise repo\n2. `[Add]`\n3. `pve-no-subscription`\n4. run `apt-get update; apt dist-upgrade; reboot`\n\n## Enable IOMMU\n\n<!-- markdownlint-disable MD031-->\n\nEnable [[terms.iommu]] so VM's can access hardware not made for virtualization (GPU's etc.)\n\n1. you can do this but updating the `/etc/default/grub` file\n   - change `GRUB_CMDLINE_LINUX_ DEFAULT=\"quiet\"`\n   - to: `GRUB_CMDLINE LINUX DEFAULT=\"quiet intel iommu=on\"`\n2. Then run `update-grub`\n3. Then edit `/etc/modules` Add these 4 lines to it:\n4.  \n   ```txt\n   `vfio`\n   `vfio_iommu_typel`\n   `vfio_pci`\n   `vfio_virqfd`\n   ```\n5. Then run `update-initramfs -u -k all`\n6. reboot\n\n<!-- markdownlint-enable MD031-->\n## Make Proxmox VLAN aware\n\n1. go to `pve node > System > Network`\n2. \"Edit\" your Linux bridge\n3. check the box for `VLAN aware:`\n4. Click `Apply Configuration`\n\nThis will update `/etc/network/interfaces` with new settings and where it says `bridge-vids` you can change the default `2-4094` to be a single number for the [[terms.vlan]] of the server, or do that for individual virtual machines\n\n## Setup Linux Bridge for Virtual Machines Separate from management Layer\n\n1. `pve node > System > Network > Create > Linux Bond`\n2. `bond0`\n3. List all the bridge ports in a space separated list except the 1 used for the management layer\n4. choose [[n.ieee-802.3ad]] mode for [[n.protocol.lacp]]\n5. Add Comment\n6. after finished creating modify switch side settings for [[n.protocol.lacp]] for those ports\n\n### Make Network Bridge for Virtual Machines\n\n- <https://youtu.be/qTbeHpdHcqs>\n\n1. `pve node > System > Network > Create > Linux Bridge`\n2. `vmbr1` is fine\n3. Give it a IPV4 address like `10.10.10.0/24`\n4. make it `VLAN aware:`\n5. List all the bridge ports in a space separated list (the [[n.protocol.lacp]] `bond0` you made)\n6. Add Comment\n\n## Setup NFS for backups\n\n0. You need to have the [[terms.nfs]] share already setup so [[p.doing.homelab.servers.fafnir]] needs to already be setup and mounted to the proxmox instance?\n1. `Datacenter node > storage > add > nfs`\n2. `ID` ==> \"Backups\"\n3. Server IPV4 address (address to [[p.doing.homelab.servers.fafnir]]?)\n4. Export `/mnt/storage <++>`\n\n### Schedule Backups\n\n1. `Datacenter node > backup > add`\n2. Select Node to backup\n3. Select storage share to send backups to\n4. Schedule Backups\n5. Email notification Settings\n6. Compression level (ZSTD)\n7. mode == snapshot\n8. test it\n   1. make a backup immediately\n\n## Download Windows VirtIO drivers\n\n1. Go To [This page](https://pve.proxmox.com/wiki/Windows_VirtIO_Drivers)\n2. Click the link under `Installation` for downloading latest stable release\n3. upload iso to proxmox iso's in `local > ISO images > Upload`\n\n## Configure Email notifications\n\nChange `/etc/postfix/main.cf` to include/change these lines:\n\n```txt\nrelayhost = [smtp.gmail.com]:587\nsmtp_use_tls = yes\nsmtp_sasl_auth_enable = yes\nsmtp_sasl_security_options = noanonymous\nsmtp_sasl_password_maps = hash:/etc/postfix/sasl_passwd\nsmtp_tls_CAfile = /etc/ssl/certs/ca-certificates.crt\n\n#mydestination = $myhostname, localhost.$mydomain, localhost\n```\n\nBe sure there are no dupes as the `main.cf` may have `smtp_sasl_security_options = {}` , and `relayhost = {}`. Just delete or comment those lines.\n\nCreate an `/etc/postfix/sasl_passwd` file with:\n\n```txt\n[smtp.gmail.com]:587    testmehere@gmail.com:PASSWD\n```\n\nrun\n\n```bash\nchmod 600 /etc/postfix/sasl_passwd\npostmap /etc/postfix/sasl_passwd\n```\n\ninstall for passwd support:\n\n```bash\napt-get install libsasl2-modules\n```\n\nRestart service:\n\n```bash\nsystemctl restart postfix.service\n```\n\nTest:\n\n```bash\necho \"Test mail from postfix\" | mail -s \"Test Postfix\" test@test.com\n```\n\nTest from PVE:\n\n```bash\necho \"test\" | /usr/bin/pvemailforward\n```\n\n## Setup port forwarding for RDP to windows VM's and make VM's visible on the internal network:\n\n1. Start a shell from the web console\n2. edit `/etc/network/interfaces`\n3. make it look like:\n\n```bash\nauto vmbr1\niface vmbr1 inet static\n        address 10.1.10.0/24\n        bridge-ports bond0\n        bridge-stp off\n        bridge-fd 0\n        bridge-vlan-aware yes\n        bridge-vids 20\n        post-up echo 1 > /proc/sys/net/ipv4/ip_forward\n        post-up iptables -t nat -A POSTROUTING -s '192.168.0.0/24' -o vmbr0 -j MASQUERADE\n        post-down iptables -t nat -D POSTROUTING -s '192.168.0.0/24' -o vmbr0 -j MASQUERADE    \n        iptables -t nat -A PREROUTING -i bond0 -p tcp --dport 13389 -j DNAT --to 192.168.3.15:3389\n#VM Net\n```\n\n## Setup iperf3 on the server\n\n```bash\napt-get install iperf3\n```\n\nIn the `~/.profile` file, add this line:\n\n```bash\niperf3 -s &\n```\n\nthis will make it so upon server startup iperf3 will be run as an independant process that can can gather data from.\n\nBy default it listens on port [[n.port.5021]]\n","n":0.041}}},{"i":1382,"$":{"0":{"v":"Pfsense","n":1},"1":{"v":"\n\npfsense firewall\n\n<https://youtu.be/lUzSsX4T4WQ>\n","n":0.707}}},{"i":1383,"$":{"0":{"v":"Servers","n":1},"1":{"v":"\n\n- [[p.doing.homelab.servers.ymir]]\n- [[p.doing.homelab.servers.fafnir]]\n","n":0.577}}},{"i":1384,"$":{"0":{"v":"Ymir","n":1},"1":{"v":"\n## Resources\n\n- [Manual](assets/pdfs/hp-dl360p-g8-manual.pdf)\n\n## Hardware\n\n- [Information on iLO][1]\n- [TO BUY for more memory some day][3]\n\n## Services\n\n- Running [[p.doing.homelab.services.proxmox]]\n\n## Projects\n\n- [reorganizing hardware with m.2 for OS][2]\n  - [This advice for mirroring the boot drives][4]\n\n## Post menus\n\n### First Menu\n\n- <kbd>F8</kbd> iLO 4 advanced\n- <kbd>F9</kbd> setup\n- <kbd>CTRL</kbd> + <kbd>S</kbd> enter Ethernet Boot Agent Configuration Menu\n\n### Second Menu\n\n- <kbd>F5</kbd> Smart Storage Administrator\n- <kbd>F8</kbd> Run the Option ROM Configuration For Arrays Utility\n- <kbd>ESC</kbd> Skip Configuration and Continue\n- <kbd>CTRL</kbd> + <kbd>C</kbd> to start the Avago utility\n\n### Third Menu\n\n- <kbd>F9</kbd> ROM-Based Setup Utility (same as <kbd>F9</kbd> in Menu One)\n- <kbd>F10</kbd> Intelligent Provisioning (can access menus to get to Storage Admin, diagnostics, RBSU utility, etc)\n- <kbd>F11</kbd> Default Boot Override Options\n- <kbd>F12</kbd> Network Boot\n\n---\n\n[1]: https://en.wikipedia.org/wiki/HP_Integrated_Lights-Out\n[2]: https://www.reddit.com/r/homelab/comments/t5na4v/comment/hz66dwy/?utm_source=share&utm_medium=web2x&context=3\n[3]: https://www.ebay.com/itm/222462491975?hash=item33cbcc3d47:g:Ks4AAOSwNZRfLGSf\n[4]: https://forum.proxmox.com/threads/installation-with-m-2-ok.58009/\n","n":0.092}}},{"i":1385,"$":{"0":{"v":"iLO","n":1},"1":{"v":"\n\n## Resources\n\n- <https://youtu.be/LxdCzfF77t4>\n\n## Using iLO\n\n### From scratch\n\n- enter iLO menu with `F8` after POST\n- in the `[file]` option there is a reset to default settings\n- as long as the above points are handled then you can get a new [[n.protocol.dhcp]] DORA process going so that you can use intelligent provisioning via `F10` to boot from an `.iso` on the remote machine.\n- **NOTE:** to use the virtual media install you need an iLO license, a trial license should work just fine\n\n### Caveats and Gotchyas\n\n- Make sure the iLO port is connected to a port on the switch that is on the same VLAN as the remote device attempting to connect to it.\n- you can let [[n.protocol.dhcp]] handle DORA and configuration and then boot from virtual media via iLO\n- Booting from virtual media is an option in the `F9` menu that needs to be enabled before attempting iLO boot\n","n":0.082}}},{"i":1386,"$":{"0":{"v":"Fafnir","n":1},"1":{"v":"\n## Resources\n\n- [Manual](assets/pdfs/dell-poweredge-r720_owners-manual_en-us.pdf)\n## Hardware\n\n<++>\n\n## Services\n\n- Running [[p.doing.homelab.services.truenas]]\n\n## Projects\n\n- [This upgrade][1]\n  - SSD mirror pair for OS\n  - HBA card to use ZFS over [[n.raid]] card\n  - [further notes][2]\n\n[1]: https://dan.langille.org/2019/10/05/preparing-the-dell-r720-for-zfs/\n[2]: https://gist.github.com/dlangille/cd784830cd7fb00c63744dfac1dd2e16\n","n":0.183}}},{"i":1387,"$":{"0":{"v":"Hardware","n":1}}},{"i":1388,"$":{"0":{"v":"iDRAC","n":1},"1":{"v":"\n1. In boot menu settings configure iDRAC to get IP address from DHCP and then use that IP to connect in the browser\n\n<https://www.dell.com/support/kbdoc/en-il/000124001/using-the-virtual-media-function-on-idrac-6-7-8-and-9#idrac6>\n","n":0.209}}},{"i":1389,"$":{"0":{"v":"Backlog","n":1}}},{"i":1390,"$":{"0":{"v":"Textsniper Windows Clone","n":0.577},"1":{"v":"\n\nuse [[s.l.python]] to make a textsniper clone but for windows\n","n":0.316}}},{"i":1391,"$":{"0":{"v":"Speach Recognition","n":0.707},"1":{"v":"\n<https://www.assemblyai.com/blog/kaldi-speech-recognition-for-beginners-a-simple-tutorial>\n","n":1}}},{"i":1392,"$":{"0":{"v":"Multi Clipboard","n":0.707},"1":{"v":"\non linux this would be useful\n\nits part of this video <https://youtu.be/Oz3W-LKfafE>\n","n":0.302}}},{"i":1393,"$":{"0":{"v":"Make a Discord Bot","n":0.5},"1":{"v":"\n\n- <https://www.youtube.com/watch?v=SPTfmiYiuok>\n  - <https://gist.github.com/beaucarnes/51ec37412ab181a2e3fd320ee474b671>\n  - <https://replit.com/@BeauCarnes/Encourage-Bot>\n- <https://medium.com/@moomooptas/how-to-make-a-simple-discord-bot-in-python-40ed991468b4>\n","n":0.378}}},{"i":1394,"$":{"0":{"v":"Ftp File Transfer Application","n":0.5},"1":{"v":"\n\n- [Article On This Project](https://medium.com/geekculture/build-your-own-file-transfer-app-using-python-within-5-minutes-56adffc7906b)\n- Uses: [[os|import.os]], [[socket|import.socket]], [[tqdm|import.tqdm]]\n\n## Server:\n\n```python\nimport socket\nimport tqdm\nimport os\n\nSERVER_HOST = \"0.0.0.0\"\nSERVER_PORT = 5001\nBUFFER_SIZE = 4096\nSEPARATOR = \"<SEPARATOR>\"\n\ns = socket.socket()\ns.bind((SERVER_HOST, SERVER_PORT))\ns.listen(10)\nprint(f\"[*] Listening as {SERVER_HOST}:{SERVER_PORT}\")\nprint(\"Waiting for the client to connect... \")\nclient_socket, address = s.accept()\nprint(f\"[+] {address} is connected.\")\nreceived = client_socket.recv(BUFFER_SIZE).decode()\nfilename, filesize = received.split(SEPARATOR)\nfilename = os.path.basename(filename)\nfilesize = int(filesize)\nprogress = tqdm.tqdm(range(filesize), f\"Receiving {filename}\", unit=\"B\", unit_scale=True, unit_divisor=1024)\nwith open(filename, \"wb\") as f:\n  while True:\n\t  bytes_read = client_socket.recv(BUFFER_SIZE)\n\t  if not bytes_read:\n\t\t  break\n\t  f.write(bytes_read)\n\t  progress.update(len(bytes_read))\nclient_socket.close()\ns.close()\n```\n\n## Client:\n\n```python\nimport socket\nimport tqdm\nimport os\n\nSEPARATOR = \"<SEPARATOR>\"\nBUFFER_SIZE = 4096\n\ns = socket.socket()\nhost = \"192.168.1.109\"\nport = 5001\nprint(f\"[+] Connecting to {host}:{port}\")\ns.connect((host, port))\nprint(\"[+] Connected to \", host)\nfilename = input(\"File to Transfer : \")\nfilesize = os.path.getsize(filename)\ns.send(f\"{filename}{SEPARATOR}{filesize}\".encode())\n#file = open(filename, 'wb') \n\nprogress = tqdm.tqdm(range(filesize), f\"Sending {filename}\", unit=\"B\", unit_scale=True, unit_divisor=1024)\nwith open(filename, \"rb\") as f:\n  while True:\n\t  bytes_read = f.read(BUFFER_SIZE)\n\t  if not bytes_read:\n\t\t  break\n\t  s.sendall(bytes_read)\n\t  progress.update(len(bytes_read))\ns.close()\n```\n\n## Tips:\n\n> You can extend this code by adding more features to meet your own needs. These are only a few of them:\n\n- Enable the server to receive multiple files from multiple clients at the same time using threads.\n- Compress the file before sending it.\n- Encrypt the file before sending it to ensure no one intercepting it will read it.\n- To make sure we sent the files properly, use secure hashing algorithms. It will check the checksums of both files ‚Äî the original sender file and the received file.\n","n":0.068}}},{"i":1395,"$":{"0":{"v":"Audio Transcription","n":0.707},"1":{"v":"\n\n- [[s.l.python]] [Transcribe Audio and Use Speech Recognition in Python](https://youtu.be/L0N2Ve9vhPk)\n","n":0.316}}},{"i":1396,"$":{"0":{"v":"24 7 Livestream","n":0.577},"1":{"v":"\n<https://youtu.be/0scjy6Zxzwc>\n","n":1}}},{"i":1397,"$":{"0":{"v":"Networking","n":1},"1":{"v":"\n## Pending Research\n\n---\n\n- Patch Panel\n  - [[r.+.2021.11.15.what-is-a-patch-panel-do-you-need-one]]\n","n":0.378}}},{"i":1398,"$":{"0":{"v":"Zfs","n":1},"1":{"v":"\nTODO flesh out notes on this topic\n\n<https://itsfoss.com/what-is-zfs/>\n","n":0.378}}},{"i":1399,"$":{"0":{"v":"Tools","n":1}}},{"i":1400,"$":{"0":{"v":"Wireshark","n":1},"1":{"v":"\n\n<https://www.wireshark.org/>\n\n![wireshark](/assets/images/2022-01-10-22-23-18.png)\n","n":1}}},{"i":1401,"$":{"0":{"v":"Subnetting","n":1},"1":{"v":"\n\n[[assets/pdfs/subnetting-cheat-sheet.pdf]]\n","n":1}}},{"i":1402,"$":{"0":{"v":"Raid","n":1},"1":{"v":"\n## RAID\n\n> Redundant Array of Independent Disks\n\n- Is not a backup\n  - If your operating system or software, rather than the hard disk, corrupts your data, this corrupted data is sent to both disks and simultaneously corrupts both drives.\n\n### RAID 0\n\n- ![RAID 0](/assets/images/2022-03-12-15-04-25.png)\n- Striping (Disk A and B contain data split between them that together forms the whole)\n\n### RAID 1\n\n- ![RAID 1](/assets/images/2022-03-12-15-02-23.png)\n- Mirroring (Disk A and B are exact copies of each other)\n\n### RAID 10\n\n- ![RAID 0, 1, and 10 Example](/assets/images/2022-03-12-14-20-16.png)\n- Combination of [[RAID 0|n.raid#raid-0]] and [[RAID 1|n.raid#raid-1]]\n- Requires at least 4 drives\n  - Drives should be identical (The disk geometry (number of heads, cylinders, etc.) is critical and it is strongly recommended NOT to use dissimilar disks.)\n- Protects you from a single drive failure\n  - reads the surviving mirror and stores the copy to the new drive you replaced. (Not nearly as taxing of an operation as [[RAID 5|n.raid#raid-5]])\n- cuts your usable disk space in half 4x2TB Disks == 4TB total storage\n\n### RAID 4\n\n- ![RAID 4](/assets/images/2022-03-12-16-31-20.png)\n- consists of block-level striping with a dedicated parity disk.\n- As a result of its layout, RAID 4 provides good performance of random reads\n- while the performance of random writes is low due to the need to write all parity data to a single disk\n\n### RAID 5\n\n- ![RAID 5](/assets/images/2022-03-12-15-10-33.png)\n- When a drive fails\n  - it needs to read everything on all the remaining drives to rebuild the new, replaced disk (A heavy load for the surviving disk and potential failure point of the 2nd disk)\n- Storage Volume ((Number of hard drives - 1) x storage capacity of the smallest hard drive)\n  - 3x1TB drives == 2TB storage, 3rd disk is for parity data\n- Only at risk for failure if at least 2 drives fail simultaneously\n  - That‚Äôs why, typically, an odd number of data carriers, i.e., three, five, seven, etc., is combined.\n\n### RAID 6\n\n- ![RAID 6](/assets/images/2022-03-12-14-49-20.png)\n- Combines four or more hard drives into a single logical drive.\n- Often referred to as ‚ÄúRAID 5 expansion‚Äù\n- Striping (All data is divided into blocks and distributed evenly to the participating hard disks.)\n- Parity (always saves two sets of parity information. In that way, associated data can be restored if one or two disks fail.)\n- Storage Volume ((Number of hard drives - 2) x space of the smallest hard drive)\n  - For example, with four 1GB hard disks, only 50% of their potential memory would be available to store user data. However, as the number of disks increases, this relationship between capacity and parity improves.\n- Advantage over [[RAID 5|n.raid#raid-5]]\n  - parity information to recover lost data is saved in duplicate. Duplicated parity data is a more efficient way of creating redundancy, and also ensures higher reliability.\n  - This is less taxing on the remaining drives compared to ordinary\n\n### RAID 50\n\n- ![RAID 50](/assets/images/2022-03-12-16-28-30.png)\n- Minimum of 6 drives\n\n### RAID 60\n\n- ![RAID 60](/assets/images/2022-03-12-16-30-23.png)\n\n## Storage via ZFS\n\nSee [[n.zfs]]\n\n## RAID-Z\n\nTODO <https://www.diskinternals.com/raid-recovery/what-is-raidz/>\n","n":0.046}}},{"i":1403,"$":{"0":{"v":"Protocol","n":1}}},{"i":1404,"$":{"0":{"v":"UDP","n":1},"1":{"v":"\n\n`U`ser `D`atagram `P`rotocol\n","n":0.577}}},{"i":1405,"$":{"0":{"v":"Tftp","n":1},"1":{"v":"\n\n`T`rivial `F`ile `T`ransfer `P`rotocol\n\nPort: [[n.port.69]]\n","n":0.447}}},{"i":1406,"$":{"0":{"v":"Telnet","n":1},"1":{"v":"\n\nPort [[n.port.23]]\n\nUnsecured connection with credentials passed in plain text\n","n":0.333}}},{"i":1407,"$":{"0":{"v":"TCP","n":1},"1":{"v":"\n\n`T`ransmission `C`ontrol `P`rotocol\n\n## Initiation\n\nOperates through a 3 way opening handshake\n\n- Client [[terms.syn]] --> Server\n- Server [[terms.syn]]-[[terms.ack]] --> Client\n- Client [[terms.ack]] --> Server\n\n---\n\n1. The client sends a [[terms.syn]] segment to the server with a randomly generated sequence number. The client enters\nthe [[terms.syn]] state.\n2. The server, currently in the LISTEN state (assuming it is online), responds with a [[terms.syn]]/[[terms.ack]] segment, containing its own randomly generated sequence number. The server enters the [[terms.syn]] state.\n3. The client responds with an [[terms.ack]] segment. The client assumes the connection is ESTABLISHED.\n4. The server opens a connection with the client and enters the ESTABLISHED state.\n\n## Termination - Abrupt\n\nTerminates communication abruptly with an [[terms.rst]] segment\n\n## Termination - Graceful\n\nGraceful exit to the connection is done through a 4-way handshake consisting of:\n\n- Client [[terms.fin]] (enters [[terms.fin]]-WAIT1 state) --> Server\n- Server [[terms.ack]] (enters CLOSE-WAIT state) --> Client\n- Client (Receives [[terms.ack]] and enters [[terms.fin]]-WAIT2 state) --> Server\n- Server [[terms.fin]] (enters LAST-[[terms.ack]] state) --> Client\n- Client [[terms.ack]] (enters TIME-WAIT state) --> Server\n\n---\n\n1. The client sends a [[terms.fin]] segment to the server and enters the [[terms.fin]]-WAIT1 state.\n2. The server responds with an [[terms.ack]] segment and enters the CLOSE-WAIT state.\n3. The client receives the [[terms.ack]] segment and enters the [[terms.fin]]-WAIT2 state. The server sends its own [[terms.fin]] segment\nto the client and goes to the LAST-[[terms.ack]] state.\n4. The client responds with an [[terms.ack]] and enters the TIME-WAIT state. After a defined period, the client closes its connection.\n5. The server closes the connection when it receives the [[terms.ack]] from the client.\n","n":0.064}}},{"i":1408,"$":{"0":{"v":"Secure Socket Layer","n":0.577}}},{"i":1409,"$":{"0":{"v":"SSH","n":1},"1":{"v":"\n\n`S`ecure `Sh`ell\n\nPort [[n.port.22]]\n","n":0.577}}},{"i":1410,"$":{"0":{"v":"SNMP","n":1},"1":{"v":"\n\n`S`imple `N`etwork `M`anagement `P`rotocol\n","n":0.5}}},{"i":1411,"$":{"0":{"v":"Monitor","n":1},"1":{"v":"\n\nManagement software that provides a location from which you can oversee network activity. \n\nThe monitor polls agents at regular intervals for information from their [[terms.mib]]'s and displays the information for review. \n\nIt also displays any trap operations as alerts for the network administrator to assess and act upon as necessary. \n\nThe monitor can retrieve information from a device in two main ways:\n\n- [[n.protocol.snmp.monitor.get]]\n- [[n.protocol.snmp.monitor.trap]]\n\nThe monitor can be used to change certain variables using the `Set` command. \n\nIt can also walk an [[terms.mib]] subtree by using multiple `Get` and `Get Next` commands. \n\nThis is used to discover the complete layout of an [[terms.mib]]. \n\nDevice queries take place over [[n.protocol.udp]] port [[n.port.161]]; traps are communicated over UDP port [[n.port.162]].\n","n":0.092}}},{"i":1412,"$":{"0":{"v":"Trap","n":1},"1":{"v":"\n\nThe agent informs the monitor of a notable event (port failure, for instance). \n\nThe threshold for triggering traps can be set for each value.\n","n":0.204}}},{"i":1413,"$":{"0":{"v":"Get","n":1},"1":{"v":"\n\nGet The software queries the agent for a single OID.\n\nThis command is used by the monitor to perform regular polling (obtaining information from devices at defined intervals).\n","n":0.192}}},{"i":1414,"$":{"0":{"v":"Agent","n":1},"1":{"v":"\n\na process (software or firmware) running on a switch, router, server, or other SNMP-compatible network device. \n\nThis agent maintains a database called a [[Management Information Base|terms.mib]].\n","n":0.196}}},{"i":1415,"$":{"0":{"v":"Smtp","n":1},"1":{"v":"\n\n`S`imple `M`ail `T`ransfer `P`rotocol\n\nPort: [[n.port.25]]\nPort: [[n.port.587]] Secure\n","n":0.378}}},{"i":1416,"$":{"0":{"v":"Smb","n":1},"1":{"v":"\n\n`S`erver `M`essage `B`lock\n\nPort: [[n.port.445]]\n","n":0.5}}},{"i":1417,"$":{"0":{"v":"SLAAC","n":1},"1":{"v":"\n\n`S`tate`l`ess `a`ddress `a`uto`c`onfiguration\n\nallows a host to autoconfigure an interface by listening for Router Advertisements to obtain a network prefix.\n","n":0.229}}},{"i":1418,"$":{"0":{"v":"Sip","n":1},"1":{"v":"\n\n`S`ession `I`nitiation `P`rotocol\n\n- Port: [[n.port.5060]] Session Initiation Protocol\n- Port: [[n.port.5061]] Session Initiation Protocol Secure\n","n":0.267}}},{"i":1419,"$":{"0":{"v":"Rtp","n":1},"1":{"v":"\n\n`R`eal `T`ime `P`rotocol\n\n- Port: [[n.port.5004]] Real-Time Protocol\n- Port: [[n.port.5005]] Real-Time Control Protocol\n","n":0.289}}},{"i":1420,"$":{"0":{"v":"Rip","n":1},"1":{"v":"\n\n`R`outing `I`nformation `P`rotocol\n\nDistance vector \n\nInterior Gateway Protocol [[n.protocol.igp]] \n\n[[n.protocol.udp]] Port [[n.port.520]] or [[n.port.521]]\n\nMaximum hop count is 15 \n","n":0.236}}},{"i":1421,"$":{"0":{"v":"Rdp","n":1},"1":{"v":"\n\n`R`emote `D`esktop `P`rotocol\n\nPort: [[n.port.3389]]\n","n":0.5}}},{"i":1422,"$":{"0":{"v":"Pop3","n":1},"1":{"v":"\n\n[[n.protocol.pop]] but secure\n","n":0.577}}},{"i":1423,"$":{"0":{"v":"Pop","n":1},"1":{"v":"\n\n`P`ost `O`ffice `P`rotocol\n\nPort: [[n.port.110]]\n","n":0.5}}},{"i":1424,"$":{"0":{"v":"OSPF","n":1},"1":{"v":"\n\n`O`pen `S`hortest `P`ath `F`irst\n\nLink-state \n\nInterior Gateway Protocol [[n.protocol.igp]]\n\nPort [[n.port.89]]\n","n":0.333}}},{"i":1425,"$":{"0":{"v":"NTP","n":1},"1":{"v":"\n\n`N`etwork `T`ime `P`rotocol\n\nPort [[n.port.123]]\n","n":0.5}}},{"i":1426,"$":{"0":{"v":"Ldap","n":1},"1":{"v":"\n\n`L`ightweight `D`irectory `A`ccess `P`rotocol\n\nPort: [[n.port.389]]\nPort: [[n.port.636]] Secure\n\n","n":0.378}}},{"i":1427,"$":{"0":{"v":"LACP","n":1},"1":{"v":"\n\n## Resources\n\n- <https://docs.rackspace.com/blog/lacp-bonding-and-linux-configuration/>\n\nLink Aggregation Control Protocol (LACP) [[n.ieee-802.3ad]]\n\nUsed to detect configuration errors and recover from the failure of one of the physical links.\n\n## Modes\n\n- `Mode 0 (balance-rr):`\nThis mode is also known as round-robin mode.\nPackets are sequentially transmitted and received through each interface one by one.\nThis mode provides load balancing functionality.\n- `Mode 1 (active-backup):`\nThis mode has only one interface set to active, while all other interfaces are in the backup state.\nIf the active interface fails, a backup interface replaces it as the only active interface in the bond.\nThe media access control (MAC) address of the bond interface in `mode 1` is visible on only one port (the network adapter), which prevents confusion for the switch.\n`Mode 1` provides fault tolerance.\n- `Mode 2 (balance-xor):`\nThe source MAC address uses exclusive or (XOR) logic with the destination MAC address.\nThis calculation ensures that the same slave interface is selected for each destination MAC address.\n`Mode 2` provides fault tolerance and load balancing.\n- `Mode 3 (broadcast):`\nAll transmissions are sent to all the slaves.\nThis mode provides fault tolerance.\n- `Mode 4 (802.3ad):`\nThis mode creates aggregation groups that share the same speed and duplex settings, and it requires a switch that supports an IEEE [[802.3ad|n.ieee-802.3ad]] dynamic link.\n`Mode 4` uses all interfaces in the active aggregation group.\nFor example, you can aggregate three 1 GB per second (GBPS) ports into a 3 GBPS trunk port.\nThis is equivalent to having one interface with 3 GBPS speed.\nIt provides fault tolerance and load balancing.\n- `Mode 5 (balance-tlb):`\nThis mode ensures that the outgoing traffic distribution is set according to the load on each interface and that the current interface receives all the incoming traffic.\nIf the assigned interface fails to receive traffic, another interface is assigned to the receiving role.\nIt provides fault tolerance and load balancing.\n- `Mode 6 (balance-alb):`\nThis mode is supported only in x86 environments.\nThe receiving packets are load balanced through Address Resolution Protocol (ARP) negotiation.\nThis mode provides fault tolerance and load balancing.\n\n![link aggregation](/assets/images/2022-02-20-11-46-53.png)\n","n":0.056}}},{"i":1428,"$":{"0":{"v":"Imap","n":1},"1":{"v":"\n\n`I`nternet `M`essage `A`ccess `P`rotocol\n\n- Port: [[n.port.143]]\n- Port: [[n.port.993]] Secure\n","n":0.333}}},{"i":1429,"$":{"0":{"v":"Igrp","n":1},"1":{"v":"\n\n`I`nterior `G`ateway `R`outing `P`rotocol\n","n":0.5}}},{"i":1430,"$":{"0":{"v":"IGP","n":1},"1":{"v":"\n\n`I`nterior `G`ateway `P`rotocol\n\nis one that performs routing within a network under the administrative control of a single owner, also referred to as an [[n.protocol.as]]. An [[n.protocol.egp]]\n","n":0.196}}},{"i":1431,"$":{"0":{"v":"ICMP","n":1},"1":{"v":"\n\nin essence it is the [[cli.cmd.ping]] command\n","n":0.378}}},{"i":1432,"$":{"0":{"v":"HTTPS","n":1},"1":{"v":"\n\n`H`yper `T`ext `T`ransfer `P`rotocol `S`ecure\n","n":0.447}}},{"i":1433,"$":{"0":{"v":"HTTP","n":1},"1":{"v":"\n\n`H`yper `T`ext `T`ransfer `P`rotocol\n","n":0.5}}},{"i":1434,"$":{"0":{"v":"H323","n":1},"1":{"v":"\n\nH.323 Call Signaling\n\nPort: [[n.port.1720]]\n","n":0.5}}},{"i":1435,"$":{"0":{"v":"Ftp","n":1},"1":{"v":"\n\nPort [[n.port.20]] File Transfer Protocol-Data\nPort [[n.port.21]] File Transfer Protocol-Control\n","n":0.333}}},{"i":1436,"$":{"0":{"v":"EIGRP","n":1},"1":{"v":"\n\n`E`nhanced `I`nterior `G`ateway `R`outing `P`rotocol\n\nDistance vector (Hybrid)\n\nInterior Gateway Protocol [[n.protocol.igp]]\n\nPort [[n.port.88]]\n","n":0.302}}},{"i":1437,"$":{"0":{"v":"EGP","n":1},"1":{"v":"\n\n`E`xterior `G`ateway `P`rotocol\n","n":0.577}}},{"i":1438,"$":{"0":{"v":"DNS","n":1},"1":{"v":"\n\n`D`omain `N`ame `S`ystem\n\n![dns](/assets/images/2022-01-10-23-27-55.png)\n\nCommon public DNS servers\n\n![alt](/assets/images/Pasted_image_20211222203708.png)\n\nRuns on port [[n.port.53]]\n\n> DNS is a hierarchical system of distributed name server databases that contain information on domains and hosts within those domains.\n>\n> DNS is operated by ICANN (<https://www.icann.org>), which also manages the generic [[terms.tld]]'s.\n\n\n","n":0.156}}},{"i":1439,"$":{"0":{"v":"Resource Records","n":0.707}}},{"i":1440,"$":{"0":{"v":"Txt","n":1},"1":{"v":"\n\n`T`e`xt` records\n\nused to store any free-form text that may be needed to support other network services. \nA single domain name may have many `TXT` records, but most commonly they are used as part of [[n.protocol.dns.resource-records.spf]] and [[n.protocol.dns.resource-records.dkim]]\n","n":0.164}}},{"i":1441,"$":{"0":{"v":"Srv","n":1},"1":{"v":"\n\n`S`e`rv`ice Record\n\n![srv](/assets/images/2022-01-10-23-48-27.png)\n\nused to identify a record that is providing a network service or protocol. \n`SRV` records are often used to locate VoIP or media servers. \n`SRV` records are also an essential part of the infrastructure supporting Microsoft‚Äôs Active Directory; they are used by clients to locate domain controllers, for instance. \nAs with [[n.protocol.dns.resource-records.mx]], `SRV` records can be configured with a priority value.\n","n":0.127}}},{"i":1442,"$":{"0":{"v":"Spf","n":1},"1":{"v":"\n\n`S`ender `P`olicy `F`ramework\n\nAn `SPF` record is used to list the `IP` addresses or names of servers that are permitted to send email from a particular domain and is used to combat the sending of spam.\n","n":0.169}}},{"i":1443,"$":{"0":{"v":"Soa","n":1},"1":{"v":"\n\n`S`tart `O`f `A`uthority\n\n> identifies the primary DNS name server that is authoritative for the zone and is therefore responsible for resolving names in the domain (plus any subdomains).\n","n":0.189}}},{"i":1444,"$":{"0":{"v":"Ptr","n":1},"1":{"v":"\n\n`P`oin`t`e`r`\n\nused to resolve IP addresses to Host names i.e. 8.8.8.8 --> <https://www.google.com>\n","n":0.289}}},{"i":1445,"$":{"0":{"v":"Ns","n":1},"1":{"v":"\n\n`N`ame `S`erver\n\n> identify authoritative DNS name servers for the zone. \n> In most enterprise networks, each zone will have several (at least two) DNS servers holding a replicated copy of the zone. \n> Therefore, two or more NS records are configured for redundancy.\n","n":0.152}}},{"i":1446,"$":{"0":{"v":"Mx","n":1},"1":{"v":"\n\n`M`ail `E`xchanger\n\nused to identify an email server for the domain. \nIn a typical network, multiple servers are installed to provide redundancy, and each one will be represented with an `MX` record. \nEach server record is given a preference value with the lowest numbered entry preferred.\n","n":0.149}}},{"i":1447,"$":{"0":{"v":"Dkim","n":1},"1":{"v":"\n\n`D`omain`K`eys `I`dentified `M`ail\n\nused to decide whether you should allow received email from a given source, preventing spam and mail spoofing.\n`DKIM` can use encrypted signatures to prove that a message really originated from the domain it claims.\n","n":0.167}}},{"i":1448,"$":{"0":{"v":"Cn","n":1},"1":{"v":"\n\n`C`anonical `N`ame\n\n(or **alias**) record is used to represent an alias for a host ([[n.protocol.dns.resource-records.a]] or [[n.protocol.dns.resource-records.aaaa]]).\nFor example, the true name of a web server could be masked as the alias `www.` **CNAME** records are also often used to make [[n.protocol.dns]] administration easier. \nFor example, an alias can be redirected to a completely different host temporarily during system maintenance.\n","n":0.131}}},{"i":1449,"$":{"0":{"v":"Aaaa","n":1},"1":{"v":"\n\n`A`ddress\n\nperforms the same function as an [[n.protocol.dns.resource-records.a]] record, but for resolving a host name to an IPv6 address.\n","n":0.236}}},{"i":1450,"$":{"0":{"v":"A","n":1},"1":{"v":"\n\n`A`ddress\n\nused to resolve a host name to an IPv4 address. \nThis is the most common type of record in a DNS zone. \nIn a lot of infrastructures, there will be an A record for every client on the network, plus servers, printers, and other connected devices. \nHowever, in some environments, client workstations will not be listed as A records‚Äîonly servers, printers, and other shared resources.\n\n","n":0.124}}},{"i":1451,"$":{"0":{"v":"Dhcp6","n":1},"1":{"v":"\n\n`D`ynamic `H`ost `C`onfiguration `P`rotocol (IPv`6`)\n\n- Port: [[n.port.546]] DHCPv6 Client\n- Port: [[n.port.547]] DHCPv6 Server\n","n":0.277}}},{"i":1452,"$":{"0":{"v":"Dhcp","n":1},"1":{"v":"\n\n`D`ynamic `H`ost `C`onfiguration `P`rotocol\n","n":0.5}}},{"i":1453,"$":{"0":{"v":"Ddns","n":1},"1":{"v":"\n\n`D`ynamic [[n.protocol.dns]]\n","n":0.707}}},{"i":1454,"$":{"0":{"v":"Bootp","n":1},"1":{"v":"\n\nPort: [[n.port.67]] BOOTP/DHCP Server\nPort: [[n.port.68]] BOOTP/DHCP Client\n","n":0.378}}},{"i":1455,"$":{"0":{"v":"BGP","n":1},"1":{"v":"\n\n`B`order `G`ateway `P`rotocol\n\nDistance vector (Hybrid)\n\nExterior Gateway Protocol [[n.protocol.egp]]\n\n[[n.port.179]]\n","n":0.354}}},{"i":1456,"$":{"0":{"v":"AS","n":1},"1":{"v":"\n\n`A`utonomous `S`ystem\n","n":0.707}}},{"i":1457,"$":{"0":{"v":"ARP","n":1},"1":{"v":"\n\n`A`ddress `R`esolution `P`rotocol\n\n\n","n":0.577}}},{"i":1458,"$":{"0":{"v":"Port","n":1}}},{"i":1459,"$":{"0":{"v":"995","n":1},"1":{"v":"\n\n[[n.protocol.pop3]]\n","n":1}}},{"i":1460,"$":{"0":{"v":"993","n":1},"1":{"v":"\n\n[[n.protocol.imap]]\n","n":1}}},{"i":1461,"$":{"0":{"v":"89","n":1},"1":{"v":"\n\n[[n.protocol.ospf]]\n","n":1}}},{"i":1462,"$":{"0":{"v":"88","n":1},"1":{"v":"\n\n[[n.protocol.eigrp]]\n","n":1}}},{"i":1463,"$":{"0":{"v":"80","n":1},"1":{"v":"\n\n[[n.protocol.http]]\n","n":1}}},{"i":1464,"$":{"0":{"v":"69","n":1},"1":{"v":"\n\n[[n.protocol.tftp]]\n","n":1}}},{"i":1465,"$":{"0":{"v":"68","n":1},"1":{"v":"\n\n[[n.protocol.bootp]]\n","n":1}}},{"i":1466,"$":{"0":{"v":"67","n":1},"1":{"v":"\n\n[[n.protocol.bootp]]\n","n":1}}},{"i":1467,"$":{"0":{"v":"636","n":1},"1":{"v":"\n\n[[n.protocol.ldap]]\n","n":1}}},{"i":1468,"$":{"0":{"v":"587","n":1},"1":{"v":"\n\n[[n.protocol.smtp]]\n","n":1}}},{"i":1469,"$":{"0":{"v":"547","n":1},"1":{"v":"\n\n[[n.protocol.dhcp6]]\n","n":1}}},{"i":1470,"$":{"0":{"v":"546","n":1},"1":{"v":"\n\n[[n.protocol.dhcp6]]\n","n":1}}},{"i":1471,"$":{"0":{"v":"53","n":1},"1":{"v":"\n\n[[n.protocol.dns]]\n","n":1}}},{"i":1472,"$":{"0":{"v":"521","n":1},"1":{"v":"\n\n[[n.protocol.rip]]\n","n":1}}},{"i":1473,"$":{"0":{"v":"520","n":1},"1":{"v":"\n\n[[n.protocol.rip]]\n","n":1}}},{"i":1474,"$":{"0":{"v":"5061","n":1},"1":{"v":"\n\n![[n.protocol.sip]]\n","n":1}}},{"i":1475,"$":{"0":{"v":"5060","n":1},"1":{"v":"\n\n![[n.protocol.sip]]\n","n":1}}},{"i":1476,"$":{"0":{"v":"5021","n":1},"1":{"v":"\nThe port that the service iperf3 listens on\n","n":0.354}}},{"i":1477,"$":{"0":{"v":"5005","n":1},"1":{"v":"\n\n![[n.protocol.rtp]]\n","n":1}}},{"i":1478,"$":{"0":{"v":"5004","n":1},"1":{"v":"\n\n![[n.protocol.rtp]]\n","n":1}}},{"i":1479,"$":{"0":{"v":"445","n":1},"1":{"v":"\n\n[[n.protocol.smb]]\n","n":1}}},{"i":1480,"$":{"0":{"v":"443","n":1},"1":{"v":"\n\n[[n.protocol.https]]\n","n":1}}},{"i":1481,"$":{"0":{"v":"389","n":1},"1":{"v":"\n\n[[n.protocol.ldap]]\n","n":1}}},{"i":1482,"$":{"0":{"v":"3389","n":1},"1":{"v":"\n\n[[n.protocol.rdp]]\n","n":1}}},{"i":1483,"$":{"0":{"v":"25","n":1},"1":{"v":"\n\n[[n.protocol.smtp]]\n","n":1}}},{"i":1484,"$":{"0":{"v":"23","n":1},"1":{"v":"\n\n[[n.protocol.telnet]]\n","n":1}}},{"i":1485,"$":{"0":{"v":"22","n":1},"1":{"v":"\n\n[[n.protocol.ssh]]\n","n":1}}},{"i":1486,"$":{"0":{"v":"21","n":1},"1":{"v":"\n\n[[n.protocol.ftp]]\n","n":1}}},{"i":1487,"$":{"0":{"v":"20","n":1},"1":{"v":"\n\n[[n.protocol.ftp]]\n","n":1}}},{"i":1488,"$":{"0":{"v":"179","n":1},"1":{"v":"\n\n[[n.protocol.bgp]]\n","n":1}}},{"i":1489,"$":{"0":{"v":"1720","n":1},"1":{"v":"\n\n[[n.protocol.h323]]\n","n":1}}},{"i":1490,"$":{"0":{"v":"162","n":1},"1":{"v":"\n\n![[n.protocol.snmp.monitor.trap]]\n","n":1}}},{"i":1491,"$":{"0":{"v":"161","n":1},"1":{"v":"\n\n![[n.protocol.snmp.monitor.get]]\n","n":1}}},{"i":1492,"$":{"0":{"v":"Default port for SQL Server","n":0.447}}},{"i":1493,"$":{"0":{"v":"143","n":1},"1":{"v":"\n\n[[n.protocol.imap]]\n","n":1}}},{"i":1494,"$":{"0":{"v":"123","n":1},"1":{"v":"\n\n[[n.protocol.ntp]]\n","n":1}}},{"i":1495,"$":{"0":{"v":"110","n":1},"1":{"v":"\n\n[[n.protocol.pop]]\n","n":1}}},{"i":1496,"$":{"0":{"v":"Link Aggregation","n":0.707},"1":{"v":"\n\n[[n.link-aggregation]] or [[n.protocol.lacp]] is the combining two or more separate cabled links into a single logical channel, referred to as an `EtherChannel`\nFrom the host end, this can also be called `NIC teaming`; at the switch end, it can be called `port aggregation`\n\nThe term bonding is also widely substituted for aggregation. \nFor example, a single network adapter and cable segment might support 1 Gbps; \nbonding this with another adapter and cable segment gives a link of 2 Gbps.\n","n":0.114}}},{"i":1497,"$":{"0":{"v":"Ip Addressing","n":0.707},"1":{"v":"\n\n- IP addressing conventions\n  - 1st Network IP Address --> Default Gateway i.e. Router\n  - Try to use IP Addresses in sequential order\n  - Try to separate servers from clients\n    - Like `197.156.4.10` to `197.154.4.19` for servers\n    - and `197.156.4.200` to `197.156.4.254` for clients\n  - Document these things for future tech's\n","n":0.14}}},{"i":1498,"$":{"0":{"v":"Ieee 802","n":0.707}}},{"i":1499,"$":{"0":{"v":"3ad","n":1},"1":{"v":"\n\nDefines the Link Aggregation Control Protocol (LACP)\n\n![[n.protocol.lacp]]\n","n":0.378}}},{"i":1500,"$":{"0":{"v":"1ax","n":1}}},{"i":1501,"$":{"0":{"v":"Hypervisor","n":1},"1":{"v":"\n\n- <https://youtu.be/LMAEbB2a50M>\n  - ![IBM hypervisor](assets/images/2022-01-07-23-45-39.png)\n","n":0.447}}},{"i":1502,"$":{"0":{"v":"Device Hardening","n":0.707},"1":{"v":"\n\n![device hardening](/assets/images/2022-01-08-12-52-30.png)\n","n":0.707}}},{"i":1503,"$":{"0":{"v":"CLI","n":1}}},{"i":1504,"$":{"0":{"v":"Ip","n":1},"1":{"v":"\n\nSee IP addresses for given interfaces on a linux machine\n\n```bash\nip addr\n```\n","n":0.302}}},{"i":1505,"$":{"0":{"v":"Dhclient","n":1},"1":{"v":"\n\nRelease all IP Addresses on a given interface on linux\n\n```bash\ndhclient -r eth0\n```\n\nGet a new IP Address lease on a given interface\n\n```bash\ndhclient eth0\n```\n","n":0.213}}},{"i":1506,"$":{"0":{"v":"Cat6 Cabling","n":0.707},"1":{"v":"\n\n- [Cat6 Cabling](https://youtu.be/NWhoJp8UQpo)\n  - UTP - Unshielded Twisted Pair\n  - RJ45 - The jack Tip of the cable\n  - 8 wires, 4 pairs of 2 twisted wires\n  - 2 standards for cable T-568A & T-568B\n    - B is more widely used, and both ends must be the same standard\n","n":0.143}}},{"i":1507,"$":{"0":{"v":"Log","n":1}}},{"i":1508,"$":{"0":{"v":"Daily","n":1}}},{"i":1509,"$":{"0":{"v":"2022","n":1}}},{"i":1510,"$":{"0":{"v":"07","n":1}}},{"i":1511,"$":{"0":{"v":"05","n":1},"1":{"v":"\n- [[r.+.2022.07.05.10-design-patterns-explained-in-10-minutes]]\n- [[theory.design-patterns]]\n","n":0.577}}},{"i":1512,"$":{"0":{"v":"05","n":1}}},{"i":1513,"$":{"0":{"v":"2022-05-14","n":1},"1":{"v":"\n- [[p.doing.homelab.services.proxmox.lxe.mssql]]\n  - mailer service\n    - Setup DB mail profile for the mailer service\n    - made the table and objects\n    - Created the SQL agent job\n  - Create METRICS database and a heartbeat dashboard\n  - Add SSIS metrics tables to METRICS database under schema `ssis`\n- [[p.doing.homelab.services.proxmox.vm.win10-visualstudio]]\n  - spin up new VM to run Visual Studio\n    - Install SQL Server Data Tools\n","n":0.128}}},{"i":1514,"$":{"0":{"v":"04","n":1}}},{"i":1515,"$":{"0":{"v":"25","n":1},"1":{"v":"\n- [[p.doing.homelab.services.proxmox.vm.win10-ssms]]\n  - Install SSMS (T-SQL)\n- [[p.doing.homelab.services.proxmox.lxe.mssql]]\n  - Management > Database Mail > Configure and setup `(See [[s.q.tsql.system-resources.stored-procedure.msdb.sp_send_dbmail]])`\n  - Setup alternate login\n\n```sql\nCREATE LOGIN [Bryan] WITH PASSWORD = <++>, \nDEFAULT_DATABASE=[master], \nDEFAULT_LANGUAGE=[us_english], \nCHECK_EXPIRATION=OFF, \nCHECK_POLICY=ON;\nGO\nALTER SERVER ROLE [sysadmin] ADD MEMBER [Bryan];\nGO\n```\n","n":0.162}}},{"i":1516,"$":{"0":{"v":"03","n":1}}},{"i":1517,"$":{"0":{"v":"2022-03-03","n":1},"1":{"v":"\nRead lots of articles on SQL and its getting me excited to be an admin over my own personal SQL Server. Basically cleared out all the notes from my work email inbox so i can start to tidy up the lists of all these inputs i wanted to review!\n\n- [[r.(.2022.03.03.generate-a-parameter-list-for-all-sql-server-stored-procedures-and-functions.md]]\n- [[r.(.2022.03.03.how-to-create-scheduled-tasks-with-command-prompt-on-windows-10.md]]\n- [[r.(.2022.03.03.how-to-read-log-file-in-sql-server-using-tsql.md]]\n- [[r.(.2022.03.03.how-to-use-rowcount-in-sql-server.md]]\n- [[r.(.2022.03.03.introduction-to-the-sp_executesql-stored-procedure-with-examples.md]]\n- [[r.(.2022.03.03.secret-features-in-your-unix-shell-cdpath.md]]\n- [[r.(.2022.03.03.setting-up-alerts-for-all-sql-server-agent-jobs.md]]\n- [[r.(.2022.03.03.shift-k-in-vim.md]]\n- [[r.(.2022.03.03.sql-server-cte-vs-temp-table-vs-table-variable-performance-test.md]]\n- [[r.(.2022.03.03.sql-server-script-to-rebuild-all-indexes-for-all-tables-and-all-databases.md]]\n- [[r.(.2022.03.03.understanding-the-sql-server-nolock-hint.md]]\n","n":0.129}}},{"i":1518,"$":{"0":{"v":"02","n":1}}},{"i":1519,"$":{"0":{"v":"2022-02-17","n":1},"1":{"v":"\n\n## Inputs\n\n- [[r.(.2022.02.17.cool-yaml-features-you-probably-didn‚Äôt-know-about.md]]\n- [[r.+.2022.02.17.bryson-tyrrell-your-code-should-document-itself-embedding-documentation-into-your-python-projects.md]]\n\n## Notes\n\n- [[cli.cmd.diff.show-color-side-by-side-diff.md]]\n- [[s.df.yaml.tips-tricks.anchors.md]]\n- [[s.df.yaml.tips-tricks.explicit-tags.md]]\n- [[s.df.yaml.tips-tricks.md]]\n- [[s.df.yaml.tips-tricks.multi-line-strings.md]]\n- [[s.df.yaml.tips-tricks.multiple-docs-in-single-file.md]]\n- [[s.m.restructured-text.read-the-docs.md]]\n- [[s.m.restructured-text.syntax.block-content.code.md]]\n- [[s.m.restructured-text.syntax.block-content.doctest-block.md]]\n- [[s.m.restructured-text.syntax.block-content.line-block.md]]\n- [[s.m.restructured-text.syntax.block-content.lists.md]]\n- [[s.m.restructured-text.syntax.block-content.md]]\n- [[s.m.restructured-text.syntax.block-content.quote.md]]\n- [[s.m.restructured-text.syntax.block-content.tables.md]]\n- [[s.m.restructured-text.syntax.comments.md]]\n- [[s.m.restructured-text.syntax.directives.admonitions.md]]\n- [[s.m.restructured-text.syntax.directives.container.md]]\n- [[s.m.restructured-text.syntax.directives.md]]\n- [[s.m.restructured-text.syntax.directives.raw.md]]\n- [[s.m.restructured-text.syntax.field-lists.md]]\n- [[s.m.restructured-text.syntax.figures.md]]\n- [[s.m.restructured-text.syntax.headers-and-sections.md]]\n- [[s.m.restructured-text.syntax.info-fields.md]]\n- [[s.m.restructured-text.syntax.inline-markup.bold.md]]\n- [[s.m.restructured-text.syntax.inline-markup.citations.md]]\n- [[s.m.restructured-text.syntax.inline-markup.code.md]]\n- [[s.m.restructured-text.syntax.inline-markup.definition-lists.md]]\n- [[s.m.restructured-text.syntax.inline-markup.footnotes.md]]\n- [[s.m.restructured-text.syntax.inline-markup.hyperlinks.md]]\n- [[s.m.restructured-text.syntax.inline-markup.italic.md]]\n- [[s.m.restructured-text.syntax.inline-markup.md]]\n- [[s.m.restructured-text.syntax.md]]\n- [[s.m.restructured-text.tools.sphinx.extensions.develop-your-own.md]]\n- [[s.m.restructured-text.tools.sphinx.extensions.git-changelog.md]]\n- [[s.m.restructured-text.tools.sphinx.extensions.md]]\n- [[s.m.restructured-text.tools.sphinx.md]]\n","n":0.156}}},{"i":1520,"$":{"0":{"v":"06","n":1}}},{"i":1521,"$":{"0":{"v":"2022-06-19","n":1},"1":{"v":"\nSpent most of the morning finishing up all my report views for the financial transactions, then moved on to how to get flat file data into the server. turns out SQL Server hosted on linux cannot use the `bulkadmin` role and bulk insert is basically out the window or if its not the configuration for it was a mire of unhelpful articles so i went for the custom python/pandas insert route\n\nenter database driver issues. since im not on windows at all i cant use the `ODBC Driver 17 for SQL Server` driver that we use adnauseum at work i had to figure out a bunch of round about crap to get a driver so i could connect to my server container running on the hypervisor. finally got that figured out now im just designing process around how to deal with the files so my partner and i can manage our transactions easier.\n\nthinking something like:\n\n- she gets a custom drop off point in her file share on the NAS\n- python file watch sees new file\n- python copies file to sql server private share\n- python processes the file and upserts data and metrics\n- python adds file name to list of file names to ignore because it was been processed already\n- python uses sql server to send my partner a text that her file was processed successfully\n\n‚ú® D A T A ‚ú®\n","n":0.066}}},{"i":1522,"$":{"0":{"v":"2022-06-18","n":1},"1":{"v":"\nNearly done with the bulk of my SQL Server financial system! i spent the entire day literally almost the entire day non stop coding out all the automations, tables, joins, constrains, jobs, everything to make this system a well oiled machine for personal finance! a few more odds and ends to do but im excited for it to all be automated and trace-able wil double entry accounting!\n\neven going to have it generate a an email with an HTML table in the body with all transaction line items for my partner's monthly invoice for our joint finances. \n\n‚ú® A U T O M A T I O N ‚ú®","n":0.096}}},{"i":1523,"$":{"0":{"v":"01","n":1}}},{"i":1524,"$":{"0":{"v":"2022-01-27","n":1},"1":{"v":"\nSpent a lot of time learning about [[s.containers.docker]] today. There's a lot to learn about containers but their utility is something else. I managed to already get a containerized [[s.l.python.libs.fastapi]] going on my machine and it worked!\n","n":0.164}}},{"i":1525,"$":{"0":{"v":"2022-01-26","n":1},"1":{"v":"\nDid a lot of research and testing of virtual machines in [[p.doing.homelab.services.proxmox]] trying to see what i can get set up. Looking at trying to get [[p.doing.homelab.services.truenas]] setup on [[p.doing.homelab.servers.fafnir]] so i can use that as the storage volume for things because at this point stuff is acting weird and im just trying to get something working and operational lol. \n\nAlso got the rest of the unifi gear headed here so i can work on the actual network deployment and use my switch and the dream machine pro to manage the network at a higher level.\n\nDecided i felt like learning more about [[s.q.postgres]] today via [[r.(.2022.01.26.postgres-can-do-that]]\n\nFinishing Work KT story on [[s.q.postgres]] by reviewing [[r.{.2022.01.26.sql_for_data_analytics_perform_fast_and_efficient]]\n","n":0.094}}},{"i":1526,"$":{"0":{"v":"2022-01-10","n":1},"1":{"v":"\n\n\n## Inputs\n\n---\n\n---\n\n## Notes\n\n---\n\n[[cli.cmd.netstat.md]]\n[[n.ieee-802.1ax]]\n[[n.ieee-802.3ad]]\n[[n.ieee-802]]\n[[n.link-aggregation]]\n[[n.protocol.icmp]]\n[[n.protocol.lacp]]\n[[n.protocol]]\n[[n.protocol.tcp]]\n[[n.protocol.udp]]\n[[p.done.dendron.templates.variables]]\n[[s.q.postgres.data-t]]\n[[s.q.postgres.data-t.numeric.serial]]\n[[s.q.postgres.funcs]]\n[[s.q.postgres.funcs.now]]\n[[s.q.postgres]]\n[[s.q.postgres.setup]]\n[[s.q.postgres.tips-tricks]]\n[[s.q.postgres.tips-tricks.returning-newly-inserted-record]]\n[[s.q.postgres.tools]]\n[[s.q.postgres.tools.pgadmin]]\n[[s.q.postgres.workflow.adding-data-to-a-table]]\n[[s.q.postgres.workflow]]\n[[s.q.tsql.dbos.common-table-expressions.chaining]]\n[[s.q.tsql.syntax.dml.insert-into]]\n[[s.q.tsql.flow.loops.for.md]]\n[[s.q.tsql.flow.loops.md]]\n[[s.q.tsql.flow.loops.while.md]]\n[[s.q.tsql.flow.md]]\n[[s.q.tsql.tips-tricks.date-stamping-inserts]]\n[[s.q.tsql.tips-tricks]]\n[[templates.s.funcs.md]]\n[[terms.ack.md]]\n[[terms.api.md]]\n[[terms.cab.md]]\n[[terms.ci-cd.md]]\n[[terms.drp.md]]\n[[terms.dry.md]]\n[[terms.etl.md]]\n[[terms.fin.md]]\n[[terms.mitm.md]]\n[[terms.nack.md]]\n[[terms.rfc.md]]\n[[terms.rst.md]]\n[[terms.sla.md]]\n[[terms.slc.md]]\n[[terms.syn.md]]\n[[terms.vpn.md]]\n\n---\n\n","n":0.577}}},{"i":1527,"$":{"0":{"v":"On This Day...","n":0.577},"1":{"v":"\n\n#### Inputs\n\n- [[r.+.2021.11.18.python-f-strings-can-do-more-than-you-thought]]\n- [[r.(.the-power-of-the-plugin-architecture-in-python]]\n- [[r.(.5-python-use-cases-that-only-a-few-programmers-know]]\n- for fixed width files:\n  - ![alt](assets/images/Pasted_image_20211229095411.png)\n\n#### Notes\n\n","n":0.289}}},{"i":1528,"$":{"0":{"v":"2022-01-02","n":1},"1":{"v":"\n\n## Inputs\n\n---\n\n---\n\n## Notes\n\n---\n\nToday i used the import pod functionality from dendron to formally import all my prior notes in obsidian to dendron. It's still buggy with changing my horizontal rules to all asterisks and not dealing with the yaml front matter better but oh well. At least i can start to work with everything better now.\n\n---\n","n":0.134}}},{"i":1529,"$":{"0":{"v":"2022-01-01","n":1},"1":{"v":"\n\n## Inputs\n\n## Notes\n\nToday i read from a comment on a youtube video of mine from another user that a modern IT practice these days is to forgo installing a dedicated OS like a linux disto and instead to just put a [[hypervisor]] like [[proxmox]] on the bare metal and use that to run [[VM's|virtual machine]] and [[docker]] containers.\n\nSo now i'm going to need to look more into how to set up [[proxmox]] and more about [[docker]] containers and [[VM's|virtual machine]]\n\nTo help with monthly reviews in dendron i just made a [[s.apps.vscode]] task to get me the files edited that month from the dendron vault!\n\n```json\n{\n    \"version\": \"2.0.0\",\n    \"tasks\": [\n        {\n            \"label\": \"Notes Made This Month\",\n            \"type\": \"shell\",\n            \"command\": \"cd \\\"${workspaceFolder}\\\" && lsd -lA *.md | awk '{print $7,$10,$NF}' | grep \\\"$(date +\\\"%b %Y\\\")\\\" | awk '{print \\\"[[\\\"$NF\\\"]]\\\"}'\"\n        }\n    ]\n}\n```\n","n":0.085}}},{"i":1530,"$":{"0":{"v":"2021","n":1}}},{"i":1531,"$":{"0":{"v":"12","n":1}}},{"i":1532,"$":{"0":{"v":"2021-12-31","n":1},"1":{"v":"\n\nRestarted Dendron again! A whole new barrel of things to re-figure out but ready for the dot hierarchies to organize all this crap for me now\n","n":0.196}}},{"i":1533,"$":{"0":{"v":"On This Day...","n":0.577},"1":{"v":"\n\n#### Inputs\n\n- [[r.+.2021.12.21.how-to-easily-do-asynchronous-programming-with-asyncio-in-python]]\n\n#### Notes\n\n","n":0.5}}},{"i":1534,"$":{"0":{"v":"On This Day...","n":0.577},"1":{"v":"\n\n#### Inputs\n\n- [[r.(.2021.12.20.linux-shell-tricks]]\n- [[r.(.2021.12.20.an-extremely-simple-way-to-schedule-programs-with-python-on-windows]]\n\n#### Notes\n\n","n":0.447}}},{"i":1535,"$":{"0":{"v":"On This Day...","n":0.577},"1":{"v":"\n\n#### Inputs\n\n#### Notes\n\nBuilt the server rack today! holy hell is it a glorious beastie!\n\n","n":0.267}}},{"i":1536,"$":{"0":{"v":"15","n":1},"1":{"v":"\n#### Inputs\n\n- [[r.(.python-dependency-inversion]]\n- [[r.(.how-to-encrypt-and-decrypt-application-password-using-python]]\n- [[r.+.2022.01.11.python-api-development-comprehensive-course-for-beginners]]\n\n#### Notes\n\n","n":0.408}}},{"i":1537,"$":{"0":{"v":"13","n":1},"1":{"v":"\n\n#### Inputs\n\n- [[r.(.2021.12.13.why-you-need-to-use-staticmethod-in-your-python-code-and-the-benefits-of-it]]\n- [[r.(.2021.12.13.the-secret-world-of-newline-characters]]\n\n#### Notes\n\n","n":0.447}}},{"i":1538,"$":{"0":{"v":"07","n":1},"1":{"v":"\n\n#### Inputs\n\n- [[r.+.2021.12.07.get-the-last-argument-of-the-last-run-command-in-your-shell]]\n\n#### Notes\n\n","n":0.5}}},{"i":1539,"$":{"0":{"v":"11","n":1}}},{"i":1540,"$":{"0":{"v":"30","n":1},"1":{"v":"\n\n#### Inputs\n\n- [[r.+.mind-bending-metaclasses-adding-function-overloads-to-python]]\n- [[r.+.2022.03.12.__new__-vs-__init__-in-python]]\n- [[r.+.diagnose-slow-python-code-featuring-async-await]]\n- [[r.+.pythons-staticmethod-and-classmethod-what-are-they-for]]\n- [[r.(.2021.11.30.reduce-your-python-code-complexity-with-this-simple-trick]]\n\n#### Notes\n\n","n":0.354}}},{"i":1541,"$":{"0":{"v":"29","n":1},"1":{"v":"\n#### Inputs\n\n#### Notes\n\n- Learned how to setup a [[s.containers.docker]]ized [[s.q.tsql]] Server on MacOS\n  - <https://database.guide/how-to-install-sql-server-on-a-mac/>\n  - <https://www.freecodecamp.org/news/cjn-how-to-connect-your-microsoft-sql-server-docker-container-with-azure-data-studio/>\n\n","n":0.243}}},{"i":1542,"$":{"0":{"v":"17","n":1},"1":{"v":"\n\n#### Inputs\n\n- [[r.+.2021.11.18.python-f-strings-can-do-more-than-you-thought]]\n\n#### Notes\n\n","n":0.5}}},{"i":1543,"$":{"0":{"v":"15","n":1},"1":{"v":"\n\n#### Inputs\n\n- [[r.+.2021.11.15.what-is-a-patch-panel-do-you-need-one]]\n\n#### Notes\n\n","n":0.5}}},{"i":1544,"$":{"0":{"v":"10","n":1},"1":{"v":"\n\n#### Inputs\n\n- [[r.(.2021.11.12.pragmatic-ai-labs-and-solutions-testing-in-python]]\n\n#### Notes\n\n","n":0.5}}},{"i":1545,"$":{"0":{"v":"0","n":1},"1":{"v":"\n\n#### Inputs\n\n- [[r.(.2021.11.10.level-up-your-python-code-with-abstract-classes]] <https://python.plainenglish.io/level-up-your-python-code-with-abstract-classes-7f7f6bdcbb5c>\n- [[r.(.2021.11.10.solid-coding-in-python]] SOLID <https://towardsdatascience.com/solid-coding-in-python-1281392a6a94>\n\n#### Notes\n\n","n":0.354}}},{"i":1546,"$":{"0":{"v":"05","n":1},"1":{"v":"\n\n#### Inputs\n\n- [[r.(.2021.11.05.write-clean-python-code-using-pipes]]\n\n#### Notes\n\n","n":0.5}}},{"i":1547,"$":{"0":{"v":"03","n":1},"1":{"v":"\n\n#### Inputs\n\n#### Notes\n\n- [[s.l.python.libs.qrcode]]\n\n","n":0.5}}},{"i":1548,"$":{"0":{"v":"01","n":1},"1":{"v":"\n\n#### Inputs\n\n- [[r.(.2021.11.01.write-data-this-alternative-is-7-times-faster]]\n- [[r.{.refactoring-improving-the-design-of-existing-code]]\n\n#### Notes\n\n","n":0.447}}},{"i":1549,"$":{"0":{"v":"10","n":1}}},{"i":1550,"$":{"0":{"v":"28","n":1},"1":{"v":"\n\n#### Inputs\n\n#### Notes\n\n- [[s.l.python.libs.sqlite3]] <https://stackoverflow.com/a/40091114/12339658> how to script with SQLite3 \n  - `sqlite3 database.db < file.sql`\n\n","n":0.25}}},{"i":1551,"$":{"0":{"v":"25","n":1},"1":{"v":"\n\n#### Inputs\n\n- [[r.+.2021.10.25.generators-in-python-python-tutorial-learn-python-programming]]\n\n#### Notes\n\n- [[s.l.python.libs.enum]]\n\n","n":0.447}}},{"i":1552,"$":{"0":{"v":"22","n":1},"1":{"v":"\n\n#### Inputs\n\n- [x] 2021-10-25 [[s.l.python]] [[s.l.python.libs.enum]]\n- [x] 2021-10-27 [[s.l.python]] Abstract Classes\n- [x] 2021-10-27 [[s.l.python]] Abstract Methods\n\n- [[r.+.data-classes-in-python-are-the-new-standard]]\n- [[r.(.4-anti-patterns-in-python-and-how-to-avoid-them]]\n- [[r.(.5-ways-to-schedule-jobs-in-python]]\n\n#### Notes\n\n","n":0.224}}},{"i":1553,"$":{"0":{"v":"20","n":1},"1":{"v":"\n\n#### Inputs\n\n- [[r.+.2021.10.20.beautiful-python-refactoring]]\n\n#### Notes\n\n","n":0.5}}},{"i":1554,"$":{"0":{"v":"18","n":1},"1":{"v":"\n\n#### Inputs\n\n#### Notes\n\n- [[s.l.python.libs.workalendar]]\n\n","n":0.5}}},{"i":1555,"$":{"0":{"v":"15","n":1},"1":{"v":"\n\n#### Inputs\n\n#### Notes\n\n- [[s.q.tsql]] Jobs in [[s.db.ms-sql-server]] [[s.q.tsql.sql-agent-jobs]]\n\n","n":0.354}}},{"i":1556,"$":{"0":{"v":"14","n":1},"1":{"v":"\n\n#### Inputs\n\n#### Notes\n\n- [[s.l.python]] [[s.l.python.libs.rich.inspect]]\n  - This damn thing makes it so easy and convenient to get a quick view at stuff with aesthetic output\n\n","n":0.2}}},{"i":1557,"$":{"0":{"v":"13","n":1},"1":{"v":"\n\n#### Inputs\n\n- [[r.(.code-as-documentation]]\n\n#### Notes\n\n","n":0.5}}},{"i":1558,"$":{"0":{"v":"0","n":1},"1":{"v":"\n\n#### Inputs\n\n- [[r.+.2021.10.11.chr-and-ord-in-python-using-ascii-values]]\n\n#### Notes\n\n","n":0.5}}},{"i":1559,"$":{"0":{"v":"07","n":1},"1":{"v":"\n\n#### Inputs\n\n- [[r.(.2021.10.07.how-i-redesigned-over-100-etl-into-elt-data-pipelines]]\n\n#### Notes\n\n","n":0.5}}},{"i":1560,"$":{"0":{"v":"05","n":1},"1":{"v":"\n\n#### Inputs\n\n#### Notes\n\nIf a file in Python is opened without a context manager or is just taken up by a python process then to get it to let go of the file to delete it, open it in python, assign it to a variable then run the close method:\n\n```python\nf = open('file.txt')\nf.close()\n```\n\n","n":0.14}}},{"i":1561,"$":{"0":{"v":"04","n":1},"1":{"v":"\n\n#### Inputs\n\n-  [[r.+.args-and-kwargs-in-python-accept-unlimited-arguments]]\n  - <https://youtu.be/L9pw3kbc4KI>\n- [[r.+.variations-of-the-strategy-pattern-using-python-features]]\n  - <https://youtu.be/n2b_Cxh20Fw>\n\n#### Notes\n\n","n":0.333}}},{"i":1562,"$":{"0":{"v":"0","n":1}}},{"i":1563,"$":{"0":{"v":"29","n":1},"1":{"v":"\n\n#### Inputs\n\n- [x] [[r.+.2021.12.15.python-typing-type-hints-and-annotations]]\n- [[r.(.python-custom-exceptions]]\n\n#### Notes\n\nToday i worked a decent amount with [[s.l.python.libs.pyyaml]] and moving all authentication variables and values to a single [[s.df.yaml]] data file stored in the users local appdata folder\n\nLearned that matches from the [[s.l.python.libs.re]] module can be converted to booleans for if statements by wrapping the whole function in a `bool()`\n\nalso started playing a little more with custom exceptions messages\n\n","n":0.125}}},{"i":1564,"$":{"0":{"v":"28","n":1},"1":{"v":"\n\n#### Inputs\n\n- [[r.(.5-best-windows-11-apps-for-productivity]]\n- [[r.(.packaging-in-python-tools-and-formats]]\n- [[r.(.the-last-20-python-packages-you-will-ever-need]]\n- [[r.(.sqlfluff-the-linter-for-modern-sql]]\n- [[r.(.dotfiles-for-developers-part-2]]\n- [[r.(.vim-to-emacs-and-back]]\n- [[r.(.the-future-of-python-packages-is-here]]\n- [[r.(.comparing-python-and-sql-for-building-data-pipelines]]\n- [[r.(.data-engineering-battle-python-vs-sql-vs-visualcode]]\n- [[r.(.from-bullet-points-to-data-storytelling]]\n- [[r.(.pareto-chart-with-python]]\n- [[r.(.nbterm-jupyter-notebooks-in-the-terminal]]\n- [[r.(.python-functools-lru_cache]]\n- [[r.+.programming-terms-memoization]]\n- [[r.(.automating-windows-applications-using-com]]\n- [[r.+.python-programming-86-sql-and-sqlite-with-python-12-minute-review]]\n- [[r.+.mongodb-crash-course]]\n- [[r.+.zip-function-in-python-combine-iterables-together]]\n- [[r.+.any-function-in-python-check-if-an-iterable-contains-true]]\n- [[r.+.iterators,-iterables,-and-itertools-in-python-python-tutorial-learn-python-programming]]\n- [[r.+.natural-language-processing-with-spacy-and-python-course-for-beginners]]\n- Pick through this playlist to find inputs <https://www.youtube.com/playlist?list=PLWKjhJtqVAbnqBxcdjVGgT3uVR10bzTEB>\n- Pick through this playlist to find inputs <https://www.youtube.com/playlist?list=PLWKjhJtqVAbkmRvnFmOd4KhDdlK1oIq23>\n- Pick through this playlist to find inputs <https://www.youtube.com/playlist?list=PLWKjhJtqVAblFnET3DbnAik--u4CBz62G>\n- Look into using this tool as part of the python dev workflow <https://github.com/kylepollina/objexplore>\n- [[r.(.jupyter-notebook-and-vim-neovim]]\n- [[r.(.python-behind-the-scenes-13-the-gil-and-its-effects-on-python-multithreading]]\n\n#### Notes\n\n","n":0.126}}},{"i":1565,"$":{"0":{"v":"22","n":1},"1":{"v":"\n- [[cli.cmd.git.tools.github]] new tool [[cli.cmd.git.tools.github.tools.deep-source]] discovered and implemented for code analysis\n- [[s.q.tsql.tools.sql-smash]] add in for [[s.q.tsql.tools.ssms]] to make several things easier:\n  - Summarize code actions\n  - format according to desired spec\n\n","n":0.18}}},{"i":1566,"$":{"0":{"v":"21","n":1},"1":{"v":"\n\n- [[s.l.python]] [[s.l.python.libs.numpy]] [NumPy Tutorial](https://youtube.com/playlist?list=PLhTjy8cBISEpTyVbZGYUesjpeUXth8rqs)\n- [x] [This One Technique Is How I Build Projects Without Getting Stuck][1]\n  - Write comments (pseudo-code) for everything that should happen then write the code for it\n  - Writing out comments for the logic of the code/functions to flesh out\n- [[s.l.python]] [6 Must-try Python Programs][2]\n\n[1]: https://youtu.be/Qvmp4F-hOKA\n[2]: https://levelup.gitconnected.com/6-must-try-python-programs-5d92ff36e620\n","n":0.139}}},{"i":1567,"$":{"0":{"v":"20","n":1},"1":{"v":"\n\n- [[s.l.python]] [Python is a Bad Programming Language][1]\n- [[s.l.python]] [[terms.etl]] [Python ETL vs. ETL Tools][2]\n- [[s.l.python]] [Python‚Äôs Data Classes a Data Engineer‚Äôs best friend][3]\n- [[s.l.rust]] [Why you shouldn‚Äôt use Rust][4]\n- [[s.l.python]] [[s.l.python.libs.sphinx]] [Auto Documenting a Python Project Using Sphinx][5]\n- [[s.l.python]] [[s.l.python.libs.sphinx]] [Write Beautiful Python Documentation with Sphinx][6]\n- [[s.apps.azure.devops]] [[s.apps.azure.test-plans]] [Automated and Manual Testing with Azure Test Plan][7]\n- Try out [[s.l.python]] [profiling][8]\n\n```python\nimport cProfile\nimport pstats\nwith cProfile.Profile() as pr:\n    yourfunctionhere()\nstats = pstats.Stats(pr)\nstats.sort_stats(pstats.SortKey.TIME)\nstats.print_stats()\n```\n\n[1]: https://medium.com/nerd-for-tech/python-is-a-bad-programming-language-2ab73b0bda5\n[2]: https://towardsdatascience.com/python-etl-vs-etl-tools-9709171c9e58\n[3]: https://medium.com/analytics-and-data/pythons-data-classes-a-data-engineer-s-best-friend-173617ee0941\n[4]: https://preettheman.medium.com/why-you-shouldnt-use-rust-e55b6607e711\n[5]: https://betterprogramming.pub/auto-documenting-a-python-project-using-sphinx-8878f9ddc6e9\n[6]: https://python.plainenglish.io/documentation-with-sphinx-dd86bedb7512\n[7]: https://youtu.be/LF0hmSysWCg\n[8]: https://docs.python.org/3/library/profile.html\n","n":0.114}}},{"i":1568,"$":{"0":{"v":"18","n":1},"1":{"v":"\n\n- [[s.l.python]] [Learn the Magic of the Star Operator in Python 3](https://python.plainenglish.io/learn-the-magic-of-the-star-operator-in-python-3-b13804abe966)\n- [[terms.etl]] [[theory.data-warehousing]] [Data Warehouse Pipeline: Basic Concepts and Roadmap](https://towardsdatascience.com/building-a-data-warehouse-pipeline-basic-concepts-roadmap-d14032890ab6)\n- [[s.q.tsql]] [How to Build Advanced SQL](https://betterprogramming.pub/how-to-build-advanced-sql-798d615ba323)\n\n","n":0.192}}},{"i":1569,"$":{"0":{"v":"17","n":1},"1":{"v":"\n\n- [[s.apps.azure.devops]] [[cli.cmd.git.tools.github]] [[s.apps.azure.devops]] [kickstart collaborative DevSecOps practices with GitHub and Azure](https://techcommunity.microsoft.com/t5/azure-developer-community-blog/kickstart-collaborative-devsecops-practices-with-github-and/ba-p/2357730)\n- [[s.l.python]] [The Power Of The Plugin Architecture In Python](https://youtu.be/iCE1bDoit9Q)\n- [[s.l.python]] [Learning Python Through Illustrated Stories Real Python Podcast 78](https://youtu.be/oMSk9t_eI9I)\n- [[s.apps.azure.devops]] [[terms.ci-cd]] [[s.apps.azure.pipelines]] [How to scan a container for vulnerabilities and publish results as a part of Azure DevOps CI/CD pipeline](https://www.winopsdba.com/blog/azure-cloud-container-build-scan-publish.html)\n- [[s.l.python]] [[s.l.python.libs.pandas]] [Pandas tricks I wish I knew earlier](https://preettheman.medium.com/pandas-tricks-i-wish-i-knew-earlier-b222f8d37f65)\n- [[s.l.python]] [3 Insane Secret Weapons for Python](https://towardsdatascience.com/the-3-secret-weapons-that-changed-my-python-editor-forever-c99f7b2e0084)\n- [[s.q.tsql]] [I modified an SQL query from 24 mins down to 2 seconds - A tale of query optimization](https://medium.com/swlh/i-modified-an-sql-query-from-24-mins-down-to-2-seconds-a-tale-of-query-optimization-bcf49d50174b)\n- [[cli]] [Navi](https://github.com/denisidoro/navi)\n- [[cli.cmd.git]] [[cli.cmd.git.git-lfs]] [git-lfs wiki tutorial](https://github.com/git-lfs/git-lfs/wiki/Tutorial)\n- [[cli.cmd.git]] [[cli.cmd.git.git-lfs]] [Git Large File Storage - How to Work with Big Files](https://youtu.be/uLR1RNqJ1Mw)\n","n":0.097}}},{"i":1570,"$":{"0":{"v":"14","n":1},"1":{"v":"\n\n- [[s.l.python.libs.pandas]] [[s.l.python]] [[s.df.csv]] [Why ‚Äúdf.to_csv‚Äù could be a Mistake ?][1]\n- [[s.q.tsql.tools.ssis]] [[s.q.tsql]] [[s.q.tsql.tools.ssms]] [[s.l.python]] [3 Reasons Why I‚Äôm Ditching SSIS for Python][2]\n- [[s.l.bash]] [looping through `ls` results in bash shell script][3]\n\n[1]: https://medium.com/analytics-vidhya/why-df-to-csv-could-be-a-mistake-f361cf6d40bd\n[2]: https://towardsdatascience.com/3-reasons-why-im-ditching-ssis-for-python-ee129fa127b5\n[3]: https://superuser.com/questions/31464/looping-through-ls-results-in-bash-shell-script#31466\n","n":0.169}}},{"i":1571,"$":{"0":{"v":"13","n":1},"1":{"v":"\n\n- [Do we still need dataclasses? // PYDANTIC tutorial][1]\n  - <https://github.com/ArjanCodes/2021-dataclasses>\n  - <https://github.com/ArjanCodes/2021-pydantic>\n  - <https://pydantic-docs.helpmanual.io/>\n- building flow call stack charts of [[s.l.python]] programs\n  - use this python module: [code2flow][2]\n    - need graphviz installed OR use set `--output` to `file_name.dot` \n    - Then use this vscode extension: `tintinweb.graphviz-interactive-preview` to preview it\n- [[s.l.python.libs.pytesseract]] [Calm Code Pytesseract][3]\n- <https://exercism.org/> ‚ùó‚ùó‚ùó‚ùó‚ùó\n- <https://github.com/Instagram/MonkeyType> Monkeytype for static type generation on the code\n\n[1]: https://youtu.be/Vj-iU-8_xLs\n[2]: https://github.com/scottrogowski/code2flow\n[3]: https://calmcode.io/shorts/pytesseract.py.html\n","n":0.121}}},{"i":1572,"$":{"0":{"v":"10","n":1},"1":{"v":"\n\n- [[s.l.python]] [If you're not using Python DATA CLASSES yet, you should üöÄ](https://youtu.be/vRVVyl9uaZc)\n\n","n":0.277}}},{"i":1573,"$":{"0":{"v":"0","n":1},"1":{"v":"\n\n- [[cli.cmd.git]] a convention but not officially supported is to use `.gitkeep` or `.keep` files in the directory structure you'd like maintained in a repo only just for placeholders.\n  - have dont README placeholder files but i kind of like this convention and the fact that its a dot file means many instances it wont even be visible\n","n":0.131}}},{"i":1574,"$":{"0":{"v":"0","n":1},"1":{"v":"\n\n- [[s.l.python]] [5 Advanced Python Function Concepts Explained With Examples][1]\n- [[s.l.python]] [7 Levels of Using F-Strings in Python][2]\n- [[s.l.python]] [Logging in Python like a PRO üêçüå¥][3]\n- [[terms.etl]] information technology data management [Why You Should Learn To Manually Code Data Warehouse Processes][4]\n- [[s.l.python]] [Do You Read Excel Files with Python? There is a 1000x Faster Way][5]\n- [[s.q.tsql]] [[s.l.python]] [[terms.etl]] [The Benefits Of Using Python And T-SQL Over SSIS For ETL][6]\n- [[terms.etl]] [[s.q.tsql]] [MASS STREET DATA WAREHOUSE ETL FRAMEWORK][7]\n\n[1]: https://betterprogramming.pub/5-advanced-python-function-concepts-explained-with-examples-dcf10389ac9a\n[2]: https://python.plainenglish.io/7-levels-of-using-f-strings-in-python-99b11707d14b\n[3]: https://blog.guilatrova.dev/how-to-log-in-python-like-a-pro/\n[4]: https://datadrivenperspectives.com/why-you-should-learn-to-manually-code-data-warehouse-processes-b2ebf2eb6b4e\n[5]: https://www.kdnuggets.com/2021/09/excel-files-python-1000x-faster-way.html\n[6]: https://datadrivenperspectives.com/the-benefits-of-using-python-and-t-sql-over-ssis-for-etl-ca50c6e11819\n[7]: https://etl-framework.massstreetuniversity.com/data-warehouse-etl-framework/\n","n":0.109}}},{"i":1575,"$":{"0":{"v":"0","n":1}}},{"i":1576,"$":{"0":{"v":"30","n":1},"1":{"v":"\n\n-  [[s.l.python]] [5 Python BAD Practices To Avoid][1]\n  -  [[s.l.python]] [Brew a Coffee With Python - Tuya Smart IOT Platform Walkthrough][2]\n  -  [[s.l.python]] [[s.l.python.libs.rich]] [calmcode rich: trees][3]\n  -  [[s.l.python]] [[s.l.python.libs.rich]] [calmcode rich: constructions][4]\n  -  [[s.l.python]] [[s.l.python.libs.multiprocessing]] [Python Tutorial - how to use multiprocessing to run multiple functions at the same time][5]\n\n[1]: https://youtu.be/5Ui37whUDrM\n[2]: https://youtu.be/Jj2T4TuHRRo\n[3]: https://calmcode.io/rich/trees.html\n[4]: https://calmcode.io/rich/constructions.html\n[5]: https://youtu.be/35yYObtZ95o\n","n":0.134}}},{"i":1577,"$":{"0":{"v":"24","n":1},"1":{"v":"\n  \n-  [[s.l.python]] [[s.l.python.libs.pandas]] [25 Pandas Functions You Didn‚Äôt Know Existed P Guarantee = 0.8][1]\n-  [[s.l.python]] [[s.l.python.libs.borb]] [Creating PDF Invoices in Python with borb][2]\n\n[1]: https://towardsdatascience.com/25-pandas-functions-you-didnt-know-existed-p-guarantee-0-8-1a05dcaad5d0\n[2]: https://stackabuse.com/creating-pdf-invoices-in-python-with-borb/\n","n":0.196}}},{"i":1578,"$":{"0":{"v":"19","n":1},"1":{"v":"\n\n- [[s.apps.microsoft-orchestrator]] Get Affected User Email through relationships [How to get the Affected User from an Incident RRS feed][1]\n  - [Get Affected User from an Incident in Service Manager with Orchestrator][2]\n-  [[s.l.python]] [[s.l.python.libs.prefect]] [The Prefect Way to Automate & Orchestrate Data Pipelines][3]\n  \n  -  [[s.l.python]] [[s.l.python.libs.holoviz]] [[s.l.python.libs.panel]] [[s.l.python.libs.hvplot]] [Visualization and Interactive Dashboard in Python][4]\n\n[1]: https://social.technet.microsoft.com/Forums/en-US/614749e4-704d-4098-86a6-8d47b0de4730/how-to-get-the-affected-user-from-an-incident?forum=scogeneral\n[2]: http://systemcenterme.com/get-affected-user-from-an-incident-in-service-manager-with-orchestrator/\n[3]: https://towardsdatascience.com/the-prefect-way-to-automate-orchestrate-data-pipelines-d4465638bac2\n[4]: https://towardsdatascience.com/visualization-and-interactive-dashboard-in-python-c2f2a88b2ba3\n","n":0.131}}},{"i":1579,"$":{"0":{"v":"18","n":1},"1":{"v":"\n\n- [[s.apps.microsoft-orchestrator]] Get Affected User Email through relationships [How to get the Affected User from an Incident RRS feed][1]\n  - [Get Affected User from an Incident in Service Manager with Orchestrator][1]\n-\n\n\n[1]: https://social.technet.microsoft.com/Forums/en-US/614749e4-704d-4098-86a6-8d47b0de4730/how-to-get-the-affected-user-from-an-incident?forum=scogeneral\n[2]: http://systemcenterme.com/get-affected-user-from-an-incident-in-service-manager-with-orchestrator/\n","n":0.174}}},{"i":1580,"$":{"0":{"v":"17","n":1},"1":{"v":"\n\n- [[s.apps.microsoft-orchestrator]]  \n- [[s.q.tsql]] make a database single user and also cut off other sessions so you can drop it\n  \n```sql\nALTER DATABASE <DB NANME HERE> SET SINGLE_USER WITH ROLLBACK IMMEDIATE;\n```\n  \n- [SQL SERVER ‚Äì FIX : Error : 3702 Cannot drop database because it is currently in use.][1]\n- [Set a Database to Single-user Mode][2]\n- [SQL Server's Auto Update Statistics Async option][3]\n\n\n[1]: https://blog.sqlauthority.com/2007/12/07/sql-server-fix-error-3702-cannot-drop-database-because-it-is-currently-in-use/\n[2]: https://docs.microsoft.com/en-us/sql/relational-databases/databases/set-a-database-to-single-user-mode?view=sql-server-ver15\n[3]: https://www.mssqltips.com/sqlservertip/2904/sql-servers-auto-update-statistics-async-option/\n","n":0.125}}},{"i":1581,"$":{"0":{"v":"16","n":1},"1":{"v":"\n-  [[s.l.python]] [[s.containers.docker]] [scaffoldy][1] service to make the generation of docker template files easier\n   -  [[s.l.python]] 3.10 case statements [Structural Pattern Matching - Exciting New Python Feature 3.10][2]\n   \n## New case statements\n\n```python\nx = \"hello\"\n\nmatch x:\n  case \"hello\":\n      print(\"hello\")\n    case \"hi\":\n      print(\"hi\")\n    case _:\n      print(\"default case\")\n```\n\n[1]: https://scaffoldy.io/\n[2]: https://youtu.be/PeJNU339WHc\n","n":0.146}}},{"i":1582,"$":{"0":{"v":"12","n":1},"1":{"v":"\n\n- [Free IT Books][1]\n\n[1]: https://it-ebooks.info/\n","n":0.447}}},{"i":1583,"$":{"0":{"v":"11","n":1},"1":{"v":"\n\n-  [[s.l.python]] [Python Is Weird...][1]\n\n[1]: https://youtu.be/hz7ipeH5Dug\n","n":0.408}}},{"i":1584,"$":{"0":{"v":"10","n":1},"1":{"v":"\n\n-  [[s.l.python]] [10 Python Shortcuts You Need To Know][1]\n  -  [[s.l.python]] [[s.apps.azure.devops]] [[s.l.python.sec]] [[s.apps.snyk]] [Find Vulnerabilities In Your Code With Snyk][2]\n     -  [[s.l.bash]] [CDPATH - A Bash variable I didn't know existed][3]\n  -  [[s.l.python]] [Python Generators Explained][4]\n  -  [[cli]] [Command Line Interface Guidelines][5]\n\n[1]: https://youtu.be/CssrFJGH_dU\n[2]: https://youtu.be/1N6VBHMoPsw\n[3]: https://youtu.be/4-Nun5c3qeA\n[4]: https://youtu.be/u3T7hmLthUU\n[5]: https://clig.dev/\n","n":0.144}}},{"i":1585,"$":{"0":{"v":"0","n":1},"1":{"v":"\n\n- [[s.q.tsql]] [Renaming SQL Server database objects and changing object owners][1]\n  - Rename a database with `sp_renamedb` or `sp_rename`\n\n## Example: rename database from Test1 to Test2\n\n```sql\nALTER DATABASE [Test1] MODIFY NAME = [Test2]\n--or\nsp_renamedb 'Test1' , 'Test2\n--or\nsp_rename 'Test1', 'Test2', 'DATABASE';\n```\n\n- This could be any object that exists with SQL Server table, stored procedure, trigger, etc.\n\n## Example: rename object Test1 to Test2.\n\n```sql\nsp_rename 'dbo.Test1', 'Test2', 'OBJECT';\n```\n\n-  [[s.l.python]] [[s.l.python.libs.mito]] [[s.l.python.libs.lux]] [3 Python Packages that make Data Science Simple][2]\n\n[1]: https://www.mssqltips.com/sqlservertip/1396/renaming-sql-server-database-objects-and-changing-object-owners/?utm_source=feedburner&utm_medium=feed&utm_campaign=Feed%3A+MSSQLTips-LatestSqlServerTips+%28MSSQLTips+-+Latest+SQL+Server+Tips%29\n[2]: https://medium.com/analytics-vidhya/3-python-packages-that-make-data-science-simple-40744de22592\n","n":0.115}}},{"i":1586,"$":{"0":{"v":"0","n":1},"1":{"v":"\n\n- [[s.l.python]] [[s.l.r]] [Choosing Python or R for Data Analysis? An Infographic][1]\n- [[s.db.mongodb]] [Donald Feury MongoDB notes][2]\n\n[1]: https://www.datacamp.com/community/tutorials/r-or-python-for-data-analysis\n[2]: https://donaldfeury.xyz/introduction-to-mongodb/\n","n":0.229}}},{"i":1587,"$":{"0":{"v":"07","n":1}}},{"i":1588,"$":{"0":{"v":"29","n":1},"1":{"v":"\n\n- [Mastering Chaos - A Netflix Guide to Microservices][1]\n- [[cli.cmd.git.tools.github]] task lists [Github Task Lists][2]\n  - New Github task lists combined with issues, projects, and milestones make it easier to replicate an Epic->Feature->Story->Task setup like Azure DevOps!\n- [Boston Dynamics][3]\n  - Just waiting for the day when Covered CA gets its first robot .\\_\\_\\_. \n    Major Terminator / Matrix vibes\n\n\n[1]: https://youtu.be/CZ3wIuvmHeM\n[2]: https://youtu.be/BplF7vHXewA\n[3]: https://www.facebook.com/watch/?v=939320813295083\n","n":0.127}}},{"i":1589,"$":{"0":{"v":"28","n":1},"1":{"v":"\n\n-  [[s.l.python]] [Jupyter Notebooks in Visual Studio Code][1]\n  -  [[s.l.python]] [Jupyter Tips and Tricks][2]\n- [[s.l.python.tools.jupyter]] `shift + tab` shows function doc strings\n-  [[s.l.python]] [Quick introduction to Jupyter Notebook][3]\n\n\n[1]: https://youtu.be/FSdIoJdSnig\n[2]: https://youtu.be/2eCHD6f_phE\n[3]: https://youtu.be/jZ952vChhuI\n","n":0.18}}},{"i":1590,"$":{"0":{"v":"27","n":1},"1":{"v":"\n\n-  [[s.l.python]] [[s.l.python.tools.jupyter]] [jupyter notebook introduction][1]\n   -  [[s.l.python]] [[s.l.python.tools.jupyter]] [Jupyter Notebook Tutorial: Introduction, Setup, and Walkthrough][2]\n\n[1]: https://realpython.com/jupyter-notebook-introduction/\n[2]: https://youtu.be/HW29067qVWk\n","n":0.236}}},{"i":1591,"$":{"0":{"v":"23","n":1},"1":{"v":"\n\n-  [azure-sql-database-vs-sql-server](https://azurelessons.com/azure-sql-database-vs-sql-server/) \n","n":0.577}}},{"i":1592,"$":{"0":{"v":"22","n":1},"1":{"v":"\n\n- [[s.l.python]] [Transcribe Audio and Use Speech Recognition in Python][1]\n\n[1]: https://youtu.be/L0N2Ve9vhPk\n","n":0.302}}},{"i":1593,"$":{"0":{"v":"21","n":1},"1":{"v":"\n  \n-  [2023 California Technology Strategic Vision ][1] \n-  [Market Research Guidelines][2] \n- [[s.apps.azure.pipelines]] [[s.apps.azure.devops]] dependabot [[cli.cmd.git.tools.github]] [[cli.cmd.git.tools.github.github-actions]] [Dependabot for Azure DevOps: Automated Vulnerability Scanning Build LIVE with Me][3]\n  - getting this set up on ADO is a pain\n  - ![image.png](assets/images/image_1626903965728_0.png)\n  - ![image.png](assets/images/image_1626904851289_0.png)\n\n[1]: https://vision2023.cdt.ca.gov/pdf/Vision-2023-California-Technology-Strategic-Plan.pdf\n[2]: https://cdt.ca.gov/wp-content/uploads/2019/08/Market-Research-Guidelines.pdf\n[3]: https://youtu.be/4ELai1FivK4\n","n":0.147}}},{"i":1594,"$":{"0":{"v":"19","n":1},"1":{"v":"\n\n-[[s.apps.azure.devops]] [[s.l.python]] [[s.l.python.libs.requests]] rest [[terms.api]] [Azure DevOps Services REST API Reference][1]\n  - [Work item tracking][2]\n\n\n[1]: https://docs.microsoft.com/en-us/rest/api/azure/devops/?view=azure-devops-rest-6.1\n[2]: https://docs.microsoft.com/en-us/rest/api/azure/devops/wit/?view=azure-devops-rest-6.1\n","n":0.243}}},{"i":1595,"$":{"0":{"v":"18","n":1},"1":{"v":"\n\n-  [[s.l.javascript]] [[s.l.javascript.libs.node]] [Discussing node.js - Computerphile][1]\n\n[1]: https://youtu.be/whwa7ua_RbA\n","n":0.354}}},{"i":1596,"$":{"0":{"v":"17","n":1},"1":{"v":"\n\n- [[cli.cmd.git.tools.github]] [Free Programming Books Repo][1]\n- [[s.m.html]] [[s.m.css]] [[s.m.css.pre-processors.sass]] [[s.l.javascript]] [Web Developer Road Map][2]\n\n[1]: https://github.com/EbookFoundation/free-programming-books\n[2]: https://github.com/kamranahmedse/developer-roadmap\n","n":0.25}}},{"i":1597,"$":{"0":{"v":"16","n":1},"1":{"v":"\n\n-  [[s.q.tsql]] [[s.l.python.libs.sql-alchemy]] [SqlAlchemy ProgrammingError 42000 and MS SQL][1] useful to figuring out basic mechanics of SQL Alchemy\n\n\n\n[1]: https://www.blog.pythonlibrary.org/2011/01/15/sqlalchemy-programmingerror-42000-and-ms-sql/\n","n":0.229}}},{"i":1598,"$":{"0":{"v":"13","n":1},"1":{"v":"\n\n-  [[s.o.make]] [How To Write a Makefile][1]\n  -  [Github Copilot AI facing Criticism][2]\n  -  [[s.l.python]] [Send email with python][3]\n\n[1]: https://youtu.be/TQ7SyYyKXhk\n[2]: https://www.theinsaneapp.com/2021/07/github-copilot-ai-facing-criticism.html\n[3]: https://realpython.com/python-send-email/\n","n":0.213}}},{"i":1599,"$":{"0":{"v":"12","n":1},"1":{"v":"\n\n-  [[s.o.make]] [What is a Makefile and how does it work?][1]\n  -  [[s.o.make]] [C++ Programming Tutorial 75 - Creating a Simple Makefile][2]\n  -  [[s.o.make]] [makefiles: the problem][3]\n  -  [[s.o.make]] [How to Create a Simple Makefile - Introduction to Makefiles][4]\n  -  [[s.o.make]] [How To Manage Your Dotfiles With Make][5]\n\n[1]: https://opensource.com/article/18/8/what-how-makefile\n[2]: https://youtu.be/6Gw1rNyTJWA\n[3]: https://calmcode.io/makefiles/the-problem.html\n[4]: https://youtu.be/_r7i5X0rXJk\n[5]: https://youtu.be/aP8eggU2CaU\n","n":0.137}}},{"i":1600,"$":{"0":{"v":"11","n":1},"1":{"v":"\n\n-  [[s.l.python]] [The Magic Of Python by Tech With Tim][1]\n\n[1]: https://youtu.be/ScUKeVuL7Y8\n","n":0.302}}},{"i":1601,"$":{"0":{"v":"0","n":1},"1":{"v":"\n     \n-  [[s.l.python]] [python tips][1]\n  -  [[s.l.python]] [[s.l.r]] [The Flawless Pipes of Python/ Pandas][2]\n-  [[s.l.python]] [Global Maintainer Summit 2021: Mariatta Wijaya-The Bots of CPython][3]\n- [[s.q.tsql]] to view all kinds of schema information on DBO's in a database use this quick query\n\n```sql\nUSE FMDShop\nSELECT * \nFROM INFORMATION_SCHEMA.TABLES\nWHERE table_name LIKE '%StartingList%'\nORDER BY table_name\n```\n\n[1]: https://betterprogramming.pub/4-ways-to-level-up-your-python-code-f148a50efeea\n[1]: https://towardsdatascience.com/the-flawless-pipes-of-python-pandas-30f3ee4dffc2\n[1]: https://youtu.be/6sDLtmXPErY\n","n":0.137}}},{"i":1602,"$":{"0":{"v":"07","n":1},"1":{"v":"\n\n- setting up devlog onto github pages with publish, using the desktop app, github cron job for auto push sync, and just figuring out the whole shenanigans.\n- I finished getting my [[cli.cmd.git]] sync [[s.l.powershell]] script setup on windows task scheduler so now i have a live sync of my DevLog using the desktop app and windows!\n  - Clunky but it will do\n-  [[s.l.python]] [[s.l.python.libs.parse]] [parse library for common string parsing](https://calmcode.io/parse/parse.html)\n- [[s.q.tsql]] to view [[s.q.tsql.tools.ssis]] packages in the visual programming interface within [[s.apps.visual-studio]]:\n  - Need to have the SQL data Tools installed from the `tools and features` menu in visual studio\n  - Install the extension for `SQL Server Integration Services Project` to view the [[s.df.xml]] as a GUI visual programming interface\n-  [[s.l.python]] [The Controversy Behind The Walrus Operator in Python](https://dev.to/renegadecoder94/the-controversy-behind-the-walrus-operator-in-python-4k4e)\n-  [[s.l.python]] [The Most Controversial Python Walrus Operator](https://pythonsimplified.com/the-most-controversial-python-walrus-operator/)\n-  [[s.l.python]] [Dustin Ingram - PEP 572: The Walrus Operator - PyCon 2019](https://youtu.be/6uAvHOKofws)\n-  [strangler fig application](https://martinfowler.com/bliki/StranglerFigApplication.html) \n-  [strangler applications](https://paulhammant.com/2013/07/14/legacy-application-strangulation-case-studies/)\n  - ![image.png](assets/images/image_1625766775514_0.png)\n-  [[s.l.python]] [python azure docs](https://docs.microsoft.com/en-us/azure/developer/python/) \n- CIA Triad:\n  - ![image.png](assets/images/image_1625726675422_0.png)\n- AAA categories:\n  - ![image.png](assets/images/image_1625726800914_0.png)\n- Network Topologies\n  - Star\n    - The most common topology such as around a router or WAP\n    - ![image.png](assets/images/image_1625727190861_0.png)\n  - Bus\n    - Terminators at either end of the connection which is a single cable and other devices tap into this cable for connectivity.\n    - should the cable get cut this can cause a loss of connectivity as well as a lot of excess noise\n    - ![image.png](assets/images/image_1625726865983_0.png)\n    - ![image.png](assets/images/image_1625726894847_0.png)\n  - Ring\n    - rare, if only 1 ring in 1 direction, a cut cable renders the topology useless, dual ring can help prevent this but this is not commonly used anymore\n    - ![image.png](assets/images/image_1625726930139_0.png)\n  - Mesh\n    - Not as common, used to connect every device directly to ever other device. LOTS of cables used\n    - ![image.png](assets/images/image_1625727233937_0.png)\n- Penetration Testing Team Color definitions\n  - ![image.png](assets/images/image_1625727501290_0.png)\n  - <https://danielmiessler.com/study/red-blue-purple-teams/>\n\n","n":0.058}}},{"i":1603,"$":{"0":{"v":"06","n":1}}},{"i":1604,"$":{"0":{"v":"30","n":1},"1":{"v":"\n\n- [[s.q.tsql]] [Configure SQL Jobs in SQL Server using T-SQL](https://codingsight.com/configure-sql-jobs-in-sql-server-using-t-sql/)\n","n":0.316}}},{"i":1605,"$":{"0":{"v":"26","n":1},"1":{"v":"\n\n- [[s.apps.vscode]] [25 VS Code Productivity Tips and Speed Hacks][1]\n  - hotkeys `CRTL + SHIFT + .` open symbols searcher.\n    - command palette plus a character changes behavior `>` opens the commands `@` opens symbol searcher, `#` global symbol search, `:` will let you traverse line numbers\n  - `ALT + SHIFT + ARROW` will not shift the line around but duplicate it in that direction\n  - BUILD TASKS are amazing! put all your commands into JSON to run all your work from the VSCode command palette\n- [[cli.cmd.git.tools.github]]'s new task forms made with [[s.df.yaml]]\n  - [Supported Configuration Options & Common Errors for Issue Forms][2]\n  - [Configuring issue templates for your repository][3]\n\n[1]: https://www.youtube.com/watch?v=ifTF3ags0XI\n[2]: https://gh-community.github.io/issue-template-feedback/structured/\n[3]: https://docs.github.com/en/communities/using-templates-to-encourage-useful-issues-and-pull-requests/configuring-issue-templates-for-your-repository#configuring-the-template-chooser\n","n":0.094}}},{"i":1606,"$":{"0":{"v":"24","n":1},"1":{"v":"\n\n-  [[s.l.python]] [5 Python Tips & Tricks That You Should Know][1]\n   -  [[s.l.python]] [[s.l.python.libs.pytest]] [[s.l.python.libs.pytest-duration-insights]] [pytest-duration-insights][2]\n   -  [[s.l.python]] [[s.l.python.libs.yarl]] [yarl.py][3]\n   -  [[s.l.python]] [[s.l.python.libs.interrogate]] [interrogate.py][4]\n   -  [[s.l.python]] [Python Modules and Packages ‚Äì An Introduction][5]\n\n[1]: https://youtu.be/XVB3dZ4H_AI\n[2]: https://calmcode.io/labs/pytest-duration-insights.html\n[3]: https://calmcode.io/shorts/yarl.py.html\n[4]: https://calmcode.io/shorts/interrogate.py.html\n[5]: https://realpython.com/python-modules-packages/\n","n":0.162}}},{"i":1607,"$":{"0":{"v":"22","n":1},"1":{"v":"\n\n-  [[s.l.python]] [[s.l.python.libs.pytest]] [[s.apps.azure.pipelines]] to [build test suite with an artifact report][1] with [some helpful docs][2]\n\n\n[1]: https://pypi.org/project/pytest-azurepipelines/\n[2]: https://medium.com/@anthonypjshaw/azure-pipelines-with-python-by-example-aa65f4070634\n","n":0.236}}},{"i":1608,"$":{"0":{"v":"21","n":1},"1":{"v":"\n\n-  [[s.l.python]] [Python Import](https://realpython.com/python-import/)\n","n":0.5}}},{"i":1609,"$":{"0":{"v":"20","n":1},"1":{"v":"\n\n-  [[s.l.python]] [[s.l.python.libs.textual]] [Python TUI library?](https://twitter.com/simonw/status/1406336417500860423) \n","n":0.378}}},{"i":1610,"$":{"0":{"v":"18","n":1},"1":{"v":"\n   \n-  [[s.l.python]] [[s.l.python.libs.watermark]] [[s.l.python.tools.jupyter]] [Calm Code Watermark][1]\n  -  move browser technical links to logseq\n-  [[s.apps.azure.devops]] [Implementing DevSecOps in Azure][2]\n-  [[s.apps.azure.pipelines]] [[s.apps.azure.devops]] [[R|r]] [Azure DevOps Pipelines for deploying content to RStudio Connect][3]\n  -  [[s.l.python]] [Absolute vs Relative Imports in Python][4]\n  - importing a package, essentially is importing the `__init__.py` module a module is any .py file\n    - so having the `__init__.py` importing the other modules is how you load the whole thing in one go\n  - Absolute imports are recommended in PEP8: \n  - but when you have a crazy directory structure\n    - `from package1.subpackage2.subpackage3.subpackage4.module5 import function6`\n    - sometimes relative may be preferred\n-  add pre-commit hooks for markdown somehow, settings auto fix via linter and pre-commit hooks?\n  -  [[s.l.python]] [10 common security gotchas in Python and how to avoid them][5]\n\n[1]: https://calmcode.io/shorts/watermark.py.html\n[2]: https://www.nearform.com/blog/getting-devsecops-right-in-azure/\n[3]: https://medium.com/rstudio-connect-digest/azure-devops-pipelines-for-deploying-content-to-rstudio-connect-e992f49103b6\n[4]: https://realpython.com/absolute-vs-relative-python-imports/\n[5]: https://hackernoon.com/10-common-security-gotchas-in-python-and-how-to-avoid-them-e19fbe265e03\n","n":0.086}}},{"i":1611,"$":{"0":{"v":"17","n":1},"1":{"v":"\n\n- [[cli.cmd.git.tools.github]] [CODEOWNERS file][1]\n    [Google Code Styleguide][2]\n- [Log aggregation and reporting][3]\n-  [[s.l.python]] [[s.l.python.build.poetry]] [Using Poetry to manage Python projects][4]\n  -  [Poetry: \"dependency management and packaging made easy\"][5]\n  -  [How to use Poetry to Manage Python Dependencies and Publish Packages][6]\n- [[s.apps.azure.devops]] [[s.apps.azure.pipelines]] \n  - [add pipeline status badge][7]\n  - [add board status badge][8]\n  - [more status badge article info][9]\n  - [MORE BADGES PLEASE, I NEED PROJECT INSIGHTS! ‚Äì CI / CD 9][10]\n-  [github actions][11]\n  - [[s.q.tsql]] [[s.q.tsql.tools.ssms]] Right click on any table or stored procedure and `View Dependencies` and it will show you every thing it depends on or that depends on it\n\n[1]: https://docs.github.com/en/github/creating-cloning-and-archiving-repositories/creating-a-repository-on-github/about-code-owners\n[2]: https://google.github.io/styleguide/\n[3]: https://youtu.be/j5Zsa_eOXeY?t=7574\n[4]: https://youtu.be/V7UhzA4g2yg\n[5]: https://youtu.be/QX_Nhu1zhlg\n[6]: https://youtu.be/Xf8K3v8_JwQ\n[7]: https://poanchen.github.io/blog/2019/07/12/How-to-add-Azure-Pipelines-badge-to-your-repository-s-README-in-GitHub\n[8]: https://docs.microsoft.com/en-us/azure/devops/boards/github/configure-status-badges?view=azure-devops\n[9]: https://blog.devops4me.com/status-badges-in-azure-devops-pipelines/\n[10]: https://never-stop-learning.de/more-badges-please-i-need-project-insights-ci-cd-9/\n[11]: https://docs.github.com/en/actions/learn-github-actions/introduction-to-github-actions\n","n":0.094}}},{"i":1612,"$":{"0":{"v":"16","n":1},"1":{"v":"\n\n- [[s.l.python]] [TALK / Meredydd Luff / Writing Good Documentation for Developers](https://youtu.be/eWaWvUhpseM?list=PL2Uw4_HvXqvYk1Y5P8kryoyd83L_0Uk5K) #üíªÔ∏è/üìñÔ∏è #üíªÔ∏è/‚≠ê\n- [[s.l.python]] [TALK / Mariatta Wijaya / Oops! I Became an Open Source Maintainer!](https://youtu.be/iPs64t1nsSM?list=PL2Uw4_HvXqvYk1Y5P8kryoyd83L_0Uk5K)\n- [[s.l.python]] [[s.l.python.libs.pytest]] [TUTORIAL / Moshe Z / Python Unit Testing with Pytest and Mock](https://youtu.be/DJoffYEPttY?list=PL2Uw4_HvXqvYk1Y5P8kryoyd83L_0Uk5K)\n- [[s.l.python]] [Python Features You Probably Don‚Äôt Know About, But Should](https://levelup.gitconnected.com/python-features-you-probably-dont-know-about-but-should-a66c6b30c528)\n\n## Named Tuples\n\n```python\nfrom collections import namedtuple\n\nCoordinate = namedtuple(\"Coordinate\", \"longitude latitude\")\nlocation = Coordinate(90, 37.5)\nprint(\"location:\", location) \n# accessing attributes with dot notation\nprint(location.longitude, location.latitude) \n# Output: \n# location: Coordinate(longitude=90, latitude=37.5) \n# (90, 37.5) \n```\n## For ... Else\n\n```python\n#case 1\nfor letter in 'foo':\n    print(letter)\nelse:\n    print(\"All letters have been printed\")\n\n#case 2\nfor letter in 'foo':\n    print(letter)\n    if letter == 'o':\n        break\nelse:\n    print(\"Letters have been printed\")\n    \n# Output:\n# case 1\n# f\n# o\n# o\n# All letters have been printed\n# case 2\n# f\n# o\n```\n## enums with the [[s.l.python.libs.enum]] module\n\n```python\nfrom enum import Enum\nSeason = Enum('Season', 'winter summer spring autumn')\nprint(Season.summer.name)\nprint(Season.summer.value)\n\n#using class\nclass Season(Enum):\n    winter = 1\n    summer = 2\n    spring = 3\n    autumn = 4\nprint(Season.winter.name)\nprint(Season.winter.value)\n\n# Output:\n# summer\n# 2\n# winter\n# 1\n```\n\n- [[s.l.python]] [[s.l.python.libs.black]] [[s.l.python.libs.flake8]] [[s.l.python.libs.isort]] <https://medium.com/staqu-dev-logs/keeping-python-code-clean-with-pre-commit-hooks-black-flake8-and-isort-cac8b01e0ea1>\n    [[s.l.python.workflow]]\n\n","n":0.078}}},{"i":1613,"$":{"0":{"v":"15","n":1},"1":{"v":"\n   \n-  [[s.l.python]] [KEYNOTE / Akshay Sharma](https://youtu.be/Jmly1Jfbhak?list=PL2Uw4_HvXqvYk1Y5P8kryoyd83L_0Uk5K)\n  -  [[s.l.python]] `py --list` lists your currently installed versions of python. `py 3.7 *.py` executes a python script using that version of python\n    -  [[s.l.python]] [TUTORIAL / Bern√°t Gabor / Python Packaging Demystified](https://youtu.be/ApDThpsr2Fw?list=PL2Uw4_HvXqvYk1Y5P8kryoyd83L_0Uk5K)\n","n":0.158}}},{"i":1614,"$":{"0":{"v":"14","n":1},"1":{"v":"\n\n-  [[s.l.python]] [[s.l.python.libs.asyncio]] [Python Asynchronous Programming - AsyncIO & Async/Await](https://youtu.be/t5Bo1Je9EmE)\n   -  [[s.l.python]] [Python 3's f-Strings: An Improved String Formatting Syntax (Guide)](https://realpython.com/python-f-strings/)\n   -  [[s.l.python]] [Assignment Expressions: The Walrus Operator](https://realpython.com/lessons/assignment-expressions/)\n   -  [[s.l.python]] [What's the meaning of underscores (\\_ & \\_\\_) in Python variable names?](https://youtu.be/ALZmCy2u0jQ)\n   -  [[s.l.python]] [[s.l.python.libs.openpyxl]] [Automate Excel With Python - Python Excel Tutorial (OpenPyXL)](https://youtu.be/7YS6YDQKFh0)\n","n":0.136}}},{"i":1615,"$":{"0":{"v":"13","n":1},"1":{"v":"\n\n-  [[s.l.python]] rich terminal output for CLI applications\n","n":0.354}}},{"i":1616,"$":{"0":{"v":"11","n":1},"1":{"v":"\n\n-  [[s.l.python]] Wheel in python \n-  [[s.l.python]] [Python Poetry](https://python-poetry.org/docs/cli/)\n    - [[s.l.python]] [What the heck is pyproject.toml?](https://snarky.ca/what-the-heck-is-pyproject-toml/)\n    - [[s.l.python]] <https://python.plainenglish.io/start-managing-your-dependencies-using-poetry-in-python-b2f1e227fcf7>\n    - [[s.l.python]] [New in Python 3.10: 4 Features You Should Try Out](https://betterprogramming.pub/new-in-python-3-10-4-features-you-should-try-out-d48db504500d)\n    - [[s.l.python]] [New Features in Python 3.10](https://youtu.be/5-A435hIYio)\n    - refactor [[s.l.python.workflow]] with [[s.l.python.build.poetry]] [[s.l.python.libs.black]] [[s.l.python.libs.sphinx]] [[s.m.restructured-text]] \n-  [[s.l.python]] [PandasGUI: Analyzing Pandas dataframes with a Graphical User Interface](https://towardsdatascience.com/pandasgui-analyzing-pandas-dataframes-with-a-graphical-user-interface-36f5c1357b1d)\n   -  [[s.l.python]] [The Hottest New Feature Coming In Python 3.10 - Structural Pattern Matching / Match Statement](https://youtu.be/-79HGfWmH_w)\n","n":0.116}}},{"i":1617,"$":{"0":{"v":"10","n":1},"1":{"v":"\n\n-  [[s.l.python]] [Calm Code Package Setup](https://calmcode.io/setup/introduction.html)\n-  [[s.l.python]] [[s.l.python.libs.mkdocs]] [Calm Code Documentation](https://calmcode.io/docs/introduction.html)\n      - [[s.l.python]] [[s.l.python.libs.pandas]] [Calm Code Pandas Pipe](https://calmcode.io/pandas-pipe/pipe.html)\n      - [[s.l.python]] [[s.l.python.libs.ray]] [Calm Code Ray](https://calmcode.io/ray/overhead.html)\n      - [[s.l.python]] [Object Oriented Programming (OOP) in Python](https://youtu.be/MikphENIrOo)\n      - [[s.l.python]] [Intro to Webhooks - Real Time App Automation (Discord Bot, Slack, GitHub)](https://youtu.be/c6d7lfvziRY)\n      - [[s.l.python]] [Python tips and tricks](https://github.com/CalebCurry/python-tips/blob/main/python_tips.ipynb)\n      - [[s.l.python]] [Python ‚Äútricks‚Äù I can not live without](https://levelup.gitconnected.com/python-tricks-i-can-not-live-without-87ae6aff3af8)\n      - [[s.l.python]] [Roadmap to Python Mastery](https://levelup.gitconnected.com/roadmap-to-python-mastery-93e1d24267f0) \n     [[cli.cmd.git.tools.github]] [Remove ability of users to use blank issue. Force Templates](https://docs.github.com/en/communities/using-templates-to-encourage-useful-issues-and-pull-requests/configuring-issue-templates-for-your-repository)\n-  [[s.l.python]] [Turn your Python Script into a 'Real' Program with Docker](https://python.plainenglish.io/turn-your-python-script-into-a-real-program-with-docker-c200e15d5265)\n","n":0.105}}},{"i":1618,"$":{"0":{"v":"0","n":1},"1":{"v":"\n\n-  [[s.l.python]] [[s.l.python.libs.black]] code formatter/linter\n   - [[s.l.python]] [Calm Code Decorators](https://calmcode.io/decorators/usage.html)\n   - [[s.l.python]] [Calm Code Logging](https://calmcode.io/logging/introduction.html)\n   - [[s.l.python]] [Calm Code Pre-Commit Hooks for Python Projects](https://calmcode.io/pre-commit/the-problem.html)\n   - [[s.l.python]] [[s.l.python.libs.pytest]] <https://testdriven.io/blog/testing-python/> \n- Best way to find an rss feed for any website is to just _\"View Source\"_ `CTRL + F` and search for **rss**\n-  [[s.l.python]] [Calm Code tqdm](https://calmcode.io/tqdm/making-a-progress-bar.html)\n    \n\n","n":0.134}}},{"i":1619,"$":{"0":{"v":"0","n":1},"1":{"v":"\n\n-  [[s.l.python]] [3 ways to send email with python](https://www.courier.com/blog/three-ways-to-send-emails-using-python-with-code-tutorials)\n   -  [[s.l.python]] [FTP file transfer](https://medium.com/geekculture/build-your-own-file-transfer-app-using-python-within-5-minutes-56adffc7906b)\n   \n\n","n":0.258}}},{"i":1620,"$":{"0":{"v":"07","n":1},"1":{"v":"\n\n-  [[s.l.python]] [[s.l.python.libs.argparse]] library for CLI applications <https://realpython.com/command-line-interfaces-python-argparse/>\n   - [[s.l.vba]] Found a way through VBA to [automatically mark all deleted emails as read so I don't have to](https://www.extendoffice.com/documents/outlook/1931-outlook-auto-mark-deleted-email-as-read.html)\n-  [[s.l.python]] unit testing using decorators [language summit article](https://pyfound.blogspot.com/2021/06/the-2021-python-language-summit-fuzzing.html?utm_source=feedburner&utm_medium=feed&utm_campaign=Feed:+PythonSoftwareFoundationNews+(Python+Software+Foundation+News))\n   \n","n":0.164}}},{"i":1621,"$":{"0":{"v":"06","n":1},"1":{"v":"\n\n- [[s.o.regular-expressions]] <http://regextutorials.com/index.html>\n","n":0.577}}},{"i":1622,"$":{"0":{"v":"04","n":1},"1":{"v":"\n- [[s.l.bash]] `case` statements can have actions split legibly across lines for legibility\n\n```bash\ncase \"$RESPONSE\" in\n\t[QqNn]) \n\tClean_Exit\n\t;;\n\t[Yy])\n\tgit config --global user.name \"$USER_NAME\"\n\tgit config --global user.email \"$USER_EMAIL@covered.ca.gov\"\n\techo -e \"\\n${GREEN}Great!${NC} That's all configured now...$successful_execution_msg\"\n\t;;\n\t*)\n\t>&2 echo -e \"Invalid choice, please select either ${LGREEN}y${NC} or ${LRED}n${NC}\\n\\n\"\n\tsleep 1\n\tDirty_Exit\n\t;;\nesac\n```\n\n- [[s.l.bash]] using git bash you can open a windows explorer window in the current directory by running the command `explorer`\n-  [[s.l.rust]] [[s.l.python]] [Google's Dependency Management service](https://deps.dev/)\n  \n\n","n":0.121}}},{"i":1623,"$":{"0":{"v":"03","n":1},"1":{"v":"\n\n-  [[s.l.python]]\n\t- the `__main__` function is used so that when you import the script as a module it will not execute the code within it, rather it will now let you import the code as a module so I can `from <module> import <something>` The only time the that `__name__ == __main__` is when we run the file as a script\n-  [[s.l.python]] [5 Things You're Doing Wrong When Programming in Python](https://www.youtube.com/watch?v=fMRzuwlqfzs&ab_channel=JackofSome)\n\t-  [[s.l.python]] [Python Decorators in 15 Minutes](https://www.youtube.com/watch?v=r7Dtus7N4pI&ab_channel=Kite)\n\t-  [[s.l.python]] [Make Python code 1000x Faster with Numba](https://www.youtube.com/watch?v=x58W9A2lnQc&ab_channel=JackofSome)\n\t-  [[s.l.python]] the `_` in python can hold the last value in an interactive shell session but can be used like the unnamed register in [[cli.cmd.vim]] and you can use it to avoid issues when unpacking tuples or just throwing something away:\n\n```python\nmy_tuple = (1,2,3)\nx, _, z = my_tuple # (1,2,3)\n#> x = 1\n#> _ = 2\n#> z = 3\n```\n\n-  [[s.l.python]] [thomas-cokelaer python notes](https://thomas-cokelaer.info/tutorials/python/index.html)\n      [[s.l.python]] [Operator Overloading](https://www.programiz.com/python-programming/operator-overloading)\n  b95d08-0498-4303-abb4-02cad357e380\n   -  [[s.l.python]] [[s.l.python.libs.rich.inspect]] module and [[s.df.xml]] module [Socratica -- XML & ElementTree || Python Tutorial || Learn Python Programming](https://youtu.be/j0xr0-IAqyk)\n\n```python\nimport xml.etree.ElementTree as ET\nfrom inspect import getmembers, isclass, isfunction \n\n# Display classes in ET module\nfor (name, member) in getmembers(ET, isclass):\nif not name.startswith(\"_\"):\n\tprint( name)\n```\n","n":0.072}}},{"i":1624,"$":{"0":{"v":"05","n":1}}},{"i":1625,"$":{"0":{"v":"27","n":1},"1":{"v":"\n\n- [[s.l.r]] [[s.l.r.tools.rmarkdown]]\n  - [[s.l.r.libs.slidev]] [Website](https://sli.dev/)\n    - Another presentation format for slideshows\n- [[s.apps.azure.pipelines]]\n  - [YAML Schema Reference for pipelines](https://docs.microsoft.com/en-us/azure/devops/pipelines/yaml-schema?tabs=schema%2Cparameter-schema&view=azure-devops)\n  - [Pipelines Documentation](https://docs.microsoft.com/en-us/azure/devops/pipelines/?view=azure-devops)\n  - Pushing successful Job outputs to [dev](https://docs.microsoft.com/en-us/learn/modules/create-multi-stage-pipeline/4-promote-dev) environment and then [test](https://docs.microsoft.com/en-us/learn/modules/create-multi-stage-pipeline/5-promote-test) environments\n    - Leading to [staging](https://docs.microsoft.com/en-us/learn/modules/create-multi-stage-pipeline/6-promote-staging)\n- [[s.l.r]] Install packages from [[s.apps.azure.devops]] Repos:\n\n```r\nremotes::install_git(\"<clone url>\", git = \"external\")\n```\n\n-  [[s.df.yaml]] [[s.l.python]] The [[s.l.python.libs.pyyaml]] module\n      [[s.apps.azure.devops]] naming branches in the repo's using forward slashes in the names groups them under folders:\n  - `project/user/branch`\n\n","n":0.119}}},{"i":1626,"$":{"0":{"v":"26","n":1},"1":{"v":"\n\n- [[s.q.tsql]] \n\n```sql\nSELECT @@VERSION\n-- Microsoft SQL Server 2017 (RTM-CU20) (KB4541283) - 14.0.3294.2 (X64)   Mar 13 2020 14:53:45   Copyright (C) 2017 Microsoft Corporation  Developer Edition (64-bit) on Windows Server 2016 Standard 10.0 <X64> (Build 14393: ) (Hypervisor) \n```\n\n- These are Global scoped variables\n- https://www.codeproject.com/Articles/39131/Global-Variables-in-SQL-Server\n- [[s.l.powershell]]\n  - Powershell is entirely case-insensitive so most of my case sensitive git aliases I make for \\*nix shells don't work\n- [[s.apps.azure.devops]]\n  - The Pull Request Process can let other suggest changes with the lightbulb _\"Suggestions\"_ option for easy application of changes nad resolution of open items for Merging.\n\n","n":0.104}}},{"i":1627,"$":{"0":{"v":"25","n":1},"1":{"v":"\n\n- [[s.apps.azure.devops]] Extension for [Automatic Release Notes](https://marketplace.visualstudio.com/items?itemName=richardfennellBM.BM-VSTS-XplatGenerateReleaseNotes&ssr=false#overview)\n- [[s.q.tsql]] [[s.q.tsql.tools.redgate]] [Version Control Demo With Git](https://youtu.be/mNXipSFbV0s)\n  - [[s.apps.vscode]] `https://github.com/microsoft/codetour` Code Tours to walk users through a code base\n  - [[s.l.bash]] `printenv` prints out all current environmental variables\n  - [[s.l.powershell]]\n  - Making a powershell module i had to save the script file as a `.psm1` to the `$PSModulePath` which didnt work initially so i instead passed an absolute path for module import:\n\n```powershell\nImport-Module -Name 'C:\\PathToModule' -Verbose\n```\n\n- To utilize non-ascii characters to get the script to print output like the `tree` command i had to open the file in Notepad++ and convert the encoding to `utf8-BOM` for `Byte Order Mark` weird shenanigans\n  - _Related Links:_\n    - https://stackoverflow.com/questions/14482253/utf8-script-in-powershell-outputs-incorrect-characters\n    - https://docs.microsoft.com/en-us/powershell/module/microsoft.powershell.core/about/about_character_encoding?view=powershell-7.1\n    - https://docs.microsoft.com/en-us/powershell/scripting/developer/module/modifying-the-psmodulepath-installation-path?view=powershell-7.1\n    - https://docs.microsoft.com/en-us/powershell/scripting/developer/module/importing-a-powershell-module?view=powershell-7.1\n    - https://ss64.com/ps/import-module.html#:~:text=To%20import%20the%20module%20into,PowerShell%20modules%20in%20the%20PSSession.\n      - Ultimately to get a version of [This Script replicating the tree command](https://www.powershellgallery.com/packages/Show-Tree/1.0.0/Content/Show-Tree.ps1) but with modifications so that it uses the non-ascii characters that the `tree` command used\n","n":0.082}}},{"i":1628,"$":{"0":{"v":"24","n":1},"1":{"v":"\n\n- [[s.apps.azure.devops]]\n  - figured out that the [[cli.cmd.git.tools.github.github-actions]] `Super linter` port to [[s.apps.azure.pipelines]] doesn't like [[s.df.yaml]] config files and had to port everything to [[s.df.json]] to get it to work\n\n","n":0.183}}},{"i":1629,"$":{"0":{"v":"23","n":1},"1":{"v":"\n\n- [[s.apps.vscode]]\n  - opening the file search with `CTRL+P` and then typing an `@` will search for _\"symbols\"_ like Classes, methods, and variables useful for navigating a Table of contents like organization of a code file\n  - Right clicking on Classes, Methods, and anything else and using `peek` will let you see the code's definition, declaration, and references for every instance of it's usage\n  - Right click and `rename symbol` refactors every instance of that variables name. It's much more efficient that a search and relpace since it's using a logical approach\n  - `CTRL+K Z` enters zen mode\n\n","n":0.101}}},{"i":1630,"$":{"0":{"v":"21","n":1},"1":{"v":"\n- [[cli.cmd.vim]]\n  - command `<number>i<text>`\n    - number of times to insert\n    - insert key\n    - text to insert\n- [[s.apps.vscode]] [Guided walkthroughs](https://github.com/microsoft/codetour) for a code base! ü§Ø #üíªÔ∏è/üìñÔ∏è\n  - [[s.l.bash]] [[s.apps.vscode]] Extension `rogalmic.bash-debug` to debug bash scripts\n  - [[s.l.bash]] [[s.apps.vscode]] Extension `mads-hartmann.bash-ide-vscode` to develop Bash scripts in an IDE link environment\n  - [[cli.cmd.git]] [[s.apps.vscode]] Extension `fabiospampinato.vscode-diff` makes doing `git diff` easy\n  - [[s.l.python]] [[s.apps.vscode]] Extension `ms-pyright.pyright` for static type checking\n  - [[s.apps.vscode]]\n    - Manually add code folding markers\n      - with comments:\n\n```\n//#region\n  fold me\n//#endregion\n```\n\n","n":0.11}}},{"i":1631,"$":{"0":{"v":"20","n":1},"1":{"v":"\n- [[s.q.tsql]] [[SSIS|ssis]]\n  - Can use variables within visual elements\n  - Can call scripts and other files like [[C|s.l.clang]]\n  - Can run processes in loops and have automation steps that send email reports\n- [[s.m.html]]\n  - Using [[@Andy Matuschak|@andy-matuschak]]'s Mnemonic Medium we can make web pages that add items to your \"[Orbit](https://withorbit.com/)\" | [Orbit Code](https://github.com/andymatuschak/orbit) \\| [Orbit Docs](https://docs.withorbit.com/)\n  - These components are driven by [[JavaScript]] embedded into [[HTML 1]] web pages with this code:\n  \t  ```html\n  \t  \t\t\t  <!DOCTYPE HTML>\n  \t  \t\t\t  <html>\n  \t  \t\t\t    <head>\n  \t  \t\t\t      <script type=\"module\" src=\"https://js.withorbit.com/orbit-web-component.js\"></script>\n  \t  \t\t\t    </head>\n  \t  \t\t\t    <body>\n  \t  \t\t\t      <orbit-reviewarea color=\"brown\">\n  \t  \t\t\t        <orbit-prompt\n  \t  \t\t\t          question=\"What's the working name for Andy's experimental mnemonic medium platform?\"\n  \t  \t\t\t          answer=\"Orbit\"\n  \t  \t\t\t        ></orbit-prompt>\n  \t  \t\t\t        <orbit-prompt\n  \t  \t\t\t          question=\"What's the new-ish web technology used to embed Orbit prompts into web pages?\"\n  \t  \t\t\t          answer=\"Web components\"\n  \t  \t\t\t        ></orbit-prompt>\n  \t  \t\t\t        <orbit-prompt\n  \t  \t\t\t          question=\"Given a right triangle with legs of length $a$ and $b$, what is the length of hypotenuse $c$?\"\n  \t  \t\t\t          answer=\"$$c = \\sqrt{a^2 + b^2}$$\"\n  \t  \t\t\t        ></orbit-prompt>\n  \t  \t\t\t      </orbit-reviewarea>\n  \t  \t\t\t    </body>\n  \t  \t\t\t  </html>\n  \t  \t\t\t  ```\n  \t-\n  ```\n\n","n":0.072}}},{"i":1632,"$":{"0":{"v":"19","n":1},"1":{"v":"\n- [[s.l.python]] [Socratica Video](https://www.youtube.com/watch?v=URBSvqib0xw&ab_channel=Socratica)\n  - using the [[s.l.python.libs.pydoc]] module you can review documentation\n  - This command (`python -m pydoc <++>`) searches for the following:\n    - modules (`math`)\n    - classes (`tuple`)\n    - functions (`pow`)\n  - [[s.l.python.libs.pydoc]] commands:\n  - `pydoc -k <keyword>`\n    - Search for a keyword in the synopsis lines of all available modules.\n  - `pydoc -n <hostname>`\n    - Start an HTTP server with the given hostname (default: localhost).\n  - `pydoc -p <port>`\n    - Start an HTTP server on the given port on the local machine. Port number 0 can be used to get an arbitrary unused port.\n  - `pydoc -b`\n    - Start an HTTP server on an arbitrary unused port and open a Web browser to interactively browse documentation. This option can be used in combination with -n and/or - p‚Ä¢\n  - `pydoc -W <name> ...`\n    - Write out the HTML documentation for a module to a file in the current directory. If <name> contains a '\\\\' it is treated as a filename; if it names a directory, documentation is written for all the contents.\n    - If <name> contains a '' it is treated as a filename; if it names a directory, documentation is written for all the contents.\n- [[s.m.css]]\n  - idea of replacing some tags with different appearances:\n\n```css\na.tag[data-ref=\"star\" i]::before {\n    content: \"‚≠ê\";\n    visibility: visible;\n    border-radius: 2px;\n    padding: 2px;\n    background: var(--blue);\n    box-shadow: 0 0 4px var(--blue);\n}\n\na.tag[data-ref=\"star\" i] {\n    visibility: hidden;\n    width: 24px;\n    white-space: nowrap;\n}\n```\n\n- from: https://discuss.logseq.com/t/custom-tags-rendering-with-emojis/709\n\n- [[s.q.tsql]]\n  - Exporting database objects to files for [[cli.cmd.git]]:\n  - _database-->Tasks-->Generate Scripts-->Choose file for each procedure option_\n  - Better option for [[cli.cmd.git]] version control is an actual [[cli.cmd.git]] repo via the [[s.q.tsql.tools.redgate]] tool\n    - **The Tool:** <https://www.red-gate.com/products/sql-development/sql-source-control/>\n    - **About it:** <https://www.youtube.com/watch?v=aR5IHfHvh98>\n\n","n":0.06}}},{"i":1633,"$":{"0":{"v":"18","n":1},"1":{"v":"\n\n- [[s.df.yaml]] There is more to YAML than simple key value pairs [wikipedia page for YAML](https://en.wikipedia.org/wiki/YAML)\n  - [[s.apps.vscode]] [snippet variables](https://code.visualstudio.com/docs/editor/userdefinedsnippets#_variables)\n","n":0.224}}},{"i":1634,"$":{"0":{"v":"15","n":1},"1":{"v":"\n-  [[s.l.python]]\n  - [[s.containers.docker]] [[s.o.make]] [[Linux|linux]] \n    - [Making your python script into a system service on linux](https://python.plainenglish.io/turning-your-python-script-into-a-real-program-cb702e16ed02) \n    - [Python Service Github Repo](https://github.com/adamcyber1/mypythonservice)\n  - [[s.l.python.libs.watchdog]] module for monitoring for file system changes\n- [[s.apps.obsidian]] [[s.l.python]] [[s.df.csv]] [[s.m.markdown]] community member made this [CSV to MD Python script](<https://github.com/kometenstaub/csv-to-md>)\n- [[cli.cmd.git]] fertching updates for the production branch without having to hop around with `git switch`\n  - [Source 1 - GitHub Notes](https://github.com/ebouchut/learn-git/wiki/Branch#merge-a-branch-without-doing-a-git-checkout-beforehand)\n  - [Source 2 - Discord](https://discord.com/channels/737199036817342466/737199948910690344/843161442299674634) \n  - [Source 3 - SO](https://stackoverflow.com/questions/3216360/merge-update-and-pull-git-branches-without-using-checkouts/17722977#17722977)\n\n","n":0.113}}},{"i":1635,"$":{"0":{"v":"14","n":1},"1":{"v":"\n\n- [[s.l.python]] Playing with new branches in my productivity app. Calendar date picker and instituting logging\n- [[s.apps.azure.devops]] no particular way to archive repos on devops, move them to a specific project designated as a repo \"graveyard\" [Potential Solution](https://techcommunity.microsoft.com/t5/azure/archive-a-project-in-azure-devops/m-p/408307)\n\n","n":0.162}}},{"i":1636,"$":{"0":{"v":"13","n":1},"1":{"v":"\n- [[s.q.tsql]] Comparing Sub queries and CTE's there's no real difference.\n  - CTE's care recursive whereas sub queries are not\n  - CTE's only live for the duration of the execution. If you need that data for multiple queries and it is used in multiple places then you're likely better off using temporary tables.\n\n```sql\nWITH myFirstCTE\nAS\n(\n\tSELECT * \n\tFROM BOA_BAICodes\n), mySecondCTE\nAS\n(\n\tSELECT TOP 100 *\n\tFROM myFirstCTE\n\tWHERE BAI_Code > 100\n)\n\tSELECT SUM(CAST(BAI_CODE AS INT)) AS mySum\n\tFROM mySecondCTE\n\tWHERE BAI_Code > 200\n```\n\n```bash\ngit notes add -m 'Tested-by: Johannes Sixt <j6t@kdbg.org>' 72a144e2\ngit show -s 72a144e\n#> [...]\n#>    Signed-off-by: Junio C Hamano <gitster@pobox.com>\n#>\n#> Notes:\n#>    Tested-by: Johannes Sixt <j6t@kdbg.org>\n```\n\n- Add notes to particular commits and then show them afterwards\n\n\t- Git hooks\n\t\t- Basically they're triggers that run on certain commands and execute scripts\n\t\t- [Getting started with git hooks](https://medium.com/@f3igao/get-started-with-git-hooks-5a489725c639)\n\t\t- [git hooks](https://pypi.org/project/git-pre-commit-hook/) \n\t\t- [More python git hooks](https://www.omerkatz.com/blog/2013/5/23/git-hooks-part-2-implementing-git-hooks-using-python) \n\t\t- [even more](https://pre-commit.com/)\n\t\t-  [awesome git hooks](https://github.com/aitemr/awesome-git-hooks)\n\t\t-  azure devops [Branch policies](https://docs.microsoft.com/en-us/azure/devops/repos/git/branch-policies?view=azure-devops) are kind of like hard stop checklist items like a merge conflict to be resolved before merge\n    - [[s.apps.azure.devops]] Pipelines like [[cli.cmd.git.tools.github.github-actions]] are automated [[terms.ci-cd]] tools driven by [[s.df.yaml]] files. This is the pipeline for a super linter:\n\n```yaml\n# Starter pipeline\n# Start with a minimal pipeline that you can customize to build and deploy your code.\n# Add steps that build, run tests, deploy, and more:\n# https://aka.ms/yaml\n\t\t\n# This code src: https://www.meziantou.net/running-github-super-linter-in-azure-pipelines.html\n# referenced docker container script: https://github.com/github/super-linter\ntrigger:\n- '*'\n\t\t\n# Use multiple jobs, so the linter can work in parallel to the build.\n# This also allows to run the Linter on Linux whereas you build can run on Windows or Mac.\njobs:\n- job: lint\npool:\nvmImage: 'ubuntu-20.04'\nsteps:\n- script: docker pull github/super-linter:latest\n\tdisplayName: Pull GitHub Super-Linter image\n- script: >-\n\tdocker run \\\n\t-e RUN_LOCAL=true \\\n\t-v $(System.DefaultWorkingDirectory):/tmp/lint \\\n\tgithub/super-linter\ndisplayName: 'Run GitHub Super-Linter'\n```\n\n- This pipeline will run the same Markdown Lint as the [[s.apps.vscode]] extension, sample [config file here](https://github.com/github/super-linter/blob/master/TEMPLATES/.markdown-lint.yml)\n- [Link to the super linter yaml file](https://www.meziantou.net/running-github-super-linter-in-azure-pipelines.htm)\n- [In two separate places for source material](https://blog.tyang.org/2020/06/27/use-github-super-linter-in-azure-pipelines/)\n","n":0.058}}},{"i":1637,"$":{"0":{"v":"12","n":1},"1":{"v":"\n\n- Just Found an amazing Documentation site! [devdocs.io](https://devdocs.io/) #üíªÔ∏è/üìñÔ∏è\n- [[s.q.tsql]] The `IN` operator can only replace the `=` logical operator. It cannot replace `<`, `>`, `<=`, `>=`, `BETWEEN`, or SQL `LIKE`. It will only find _exact matches_.\n\n","n":0.164}}},{"i":1638,"$":{"0":{"v":"11","n":1},"1":{"v":"\n\n- Found [this great table generator](https://www.tablesgenerator.com/markdown_tables) thanks to bri watson.\n  - It can export tables to [[s.m.html]], [[s.m.latex]], [[s.m.markdown]], and plain text\n- python found [this amazing Cheatsheet!](https://github.com/gto76/python-cheatsheet)\n  - python [article on logging for a python app](https://towardsdatascience.com/the-reusable-python-logging-template-for-all-your-data-science-apps-551697c8540)\n\n","n":0.167}}},{"i":1639,"$":{"0":{"v":"0","n":1},"1":{"v":"\n\n```bash\ngit config --global  alias.plog \"log --graph --format='%Cgreen%h %Cred%aN%Cblue%d%Creset %s %C(yellow)(%cr)%Creset'\"\n```\n- Set a git alias to make a _\"Pretty log\"_\n- Just discovered a treasure trove of information in [[docs.write-the-docs]]\n- Playing around more with [[s.l.lisp]]\n\n","n":0.174}}},{"i":1640,"$":{"0":{"v":"07","n":1},"1":{"v":"\n- windows Administrative Shares\n  - These are network shares (share drive / NAS (Network Attached Storage)) That users with _administrative privileges_ can access remotely.\n  - They have a naming convention that looks like the normal drive letter abbreviation but is subsequently followed by a dollar sign:\n    - `e$`\n  - There are also Windows OS Admin shares\n    - `admin$`\n  - and printer folder admin shares\n    - `print$`\n  - The dollar sign at the end of any share indicates it is a hidden share\n  - Environmental Variables\n    - <https://www.rapidee.com/en/environment-variables>\n    - Environmental variable `%TEMP%` opens a temporary folder directory on windows\n  -  [[s.l.powershell]] Block comment syntax for power shell starts with `<#`\n      -  [[s.q.tsql]] Great resource for SQL Server knowledge <https://www.mssqltips.com/sql-server-categories/>\n    \t- ssis Visual Programming of etl's into SQL Server\n- [[s.apps.azure.devops]] Bulk Insert of new work items like todoist [Bulk Insert](https://docs.microsoft.com/en-us/azure/devops/boards/queries/import-work-items-from-csv?view=azure-devops)\n\n","n":0.085}}},{"i":1641,"$":{"0":{"v":"06","n":1},"1":{"v":"\n\n- used the [[s.l.python.libs.pyinstaller]] package to make a python script into a `.exe` file\n- tried to use both [[s.m.markdown]] and [[s.m.html]] links to call the file and have it executed but none of these options worked.\n- In the end what satisfied me was having a link to a [[s.l.python.tools.jupyter]] notebook that then opens up and can contain both markdown documentation and the code to be executed in steps or batches.\n","n":0.12}}},{"i":1642,"$":{"0":{"v":"04","n":1},"1":{"v":"\n\n- In the `FROM` clause when referencing a table to read, after the optional alias portion you have the option to provide what's called _\"Table Hints\"_.\n- An example of which is one i've used that looks like this: `WITH (NOLOCK)`\n","n":0.158}}},{"i":1643,"$":{"0":{"v":"02","n":1},"1":{"v":"\n\n- Great bash config for using git from [this thoughtbot article](https://thoughtbot.com/upcase/videos/git-customizing)\n\n```bash\n# No arguments: `git status`\n# With arguments: acts like `git`\ng() {\nif [[ $# > 0 ]]; then\n\tgit $@\nelse\n\tgit status\nfi\n}\n\n# Complete g like git\ncompdef g=git\n```\n\n- A great tip to update your master branch return to the original branch you left and then merge changes. this is made as a git alias.\n- `!git checkout master && git pull && git fetch --prune && git checkout - && git merge master`\n- Aliased as `mup` for _\"Master Up\"_\n- The `!` is running it as a shell command as git aliases can only run 1 command. So this way we're still chaining commands\n- Removing a file from git history from [this SO article](https://stackoverflow.com/questions/307828/how-do-you-fix-a-bad-merge-and-replay-your-good-commits-onto-a-fixed-merge/15729420#15729420)\n\n","n":0.092}}},{"i":1644,"$":{"0":{"v":"04","n":1}}},{"i":1645,"$":{"0":{"v":"28","n":1},"1":{"v":"\n- [[s.m.markdown]] [[s.m.markdown.extended-functionality.mermaid-diagrams]]\n  - Since the vscode plugin for Mermaid syntax highlighting doesn't support the [[s.apps.azure.devops]] wiki syntax of triple colons for the code fence:\n\n```markdown\n:::mermaid\n  graph TD;\n    a-->b\n:::\n```\n\n  - I actually found an existing issue and added my comment support to it on [The Repo](https://github.com/bpruitt-goddard/vscode-mermaid-syntax-highlight)\n- [[s.apps.azure.devops]] The wiki does not like markdown links to section headings even within the document itself. Corrected, its actually just sensitive to some types of headings but section heading links do still actually work\n\n","n":0.113}}},{"i":1646,"$":{"0":{"v":"27","n":1},"1":{"v":"\n-  [[cli.cmd.git]] \n  - The `git checkout` command was replaced by `git switch` in git v2.23 as `git checkout` was apparently too overloaded.\n  - **Rebasing:** essentially takes a set of commits, \"copies\" them, and plops them down somewhere else.\n    - if you have 2 parallel branches and you rebase 1 onto the other it essentially looks for their common origin point (commit), takes the \"base\" of that branch and places the base at the end and right on top of branch you're Rebaasing.\n    - Then the branch that was the recipient of the rebasing needs to be updated so you rebase that onto the branch that was just rebased. This just moves the pointer to the tip of the merged branches\n    - Interactive Rebasing with `git rebase -i <commit hash>` make it a more interactive way to move around and reorder commits\n  - **HEAD** is simply the name of the currently checked out commit hash\n    - each commit is a pointer to the repo at a point in time\n      - each branch is a named pointer to a particular commit\n  - **Relative References** using `^` and `~` to traverse commits in the `git log` so that you don't need to type even the minimum 6 characters of the commit hash.\n    - `^` when given the name of a commit hash/branch name it will refer to the parent commit: `main^`\n      - These can be stacked too so you can refer to grandparent commit with `main^^`\n      - can also use with **HEAD** to traverse from current point: `git checkout HEAD^`\n    - `~` will let you specify a number of commits to travel back instead of `git checkout HEAD^^^^` you can use `git checkout HEAD~4` to traverse 4 commits backward\n  - **Forcing Branches** You can move what commit a branch is referencing with something like:\n    - `git branch -f myBranch locationToMoveItTo`\n  - **Reversing Commits** There are at least 2 ways to do this `git reset` and `git revert`\n    - `git reset` move the branch backwards in time\n    - `git revert` move the branch backwards in time and acts like the commit never even happened\n  - `git cherry-pick <commit hash> <commmit hash> ...`\n    - `git cherry-pick c2 c4`\n  - **Tagging** To tag commits as a project milestone or something the commands are very simple\n    - `git tag v1 <commit hash>` will tag what ever referenced commit hash with the tag _\"v1\"_\n    - `git tag v1` will tag what ever commit hash **HEAD** is on with the tag _\"v1\"_\n  - `git describe <ref>` If no ref is provided it will just look at wherever HEAD is. This can, however, be used on Tags.\n    - If you have a tag on the first commit of the repo such as `0.1` with a message of `initialized repository` and then ran the command `git describe` all it would tell you is something like:\n      - _\"0.1-62-g07f34f4\"_\n        - _0.1_ for the tag\n        - _62_ for the commits since that tag\n        - _g07f34f4_ is the hash being described (your current one that hasn't been committed yet)\n  -\n\n","n":0.044}}},{"i":1647,"$":{"0":{"v":"25","n":1},"1":{"v":"\n\n- [[s.q.tsql]] [[s.l.python.libs.sqlite3]]\n  - In vscode using the SQLite extention you can't use the command `PRAGMA foreign_keys = ON;` to enable foreign key constrains on your SQLite tables.\n  - You'd think that would be kind of a high priority change especially since the change appears to be an easy 1 liner change?\n    - Either way [I requested that the change be made asap](https://github.com/AlexCovizzi/vscode-sqlite/issues/60)\n\n","n":0.126}}},{"i":1648,"$":{"0":{"v":"23","n":1},"1":{"v":"\n- [[s.q.tsql]] \n  - Databases can live in a single `.db` file\n  - queries have to end with a `;`\n  - The syntax is similar to other SQL's but it of course has it differences and functionalities that it lacks\n  - Cant seem to find a way to do a string split cross apply with SQLite to take a single column with a string of values comma separated to split them then cross apply them to list and then filter/aggregate them.\n    - This is making me rely more of more tables in the relational model v.s. robust functions.\n ## Current ER diagram looking like this:\n\n```mermaid\nerDiagram\n        PERSON }|--|| LOCATION : \"Lives In\"\n        PERSON }|--o{ SUBJECT : Studies\n        PERSON ||--o{ TAGS : Has\n        PERSON }|--o| PROFESSION : \"Works As\"\n        PERSON }|--|| CONNECTION : Met\n\n```\n    \n\n- csv\n- clojure\n  - looked at clojure a little bit but immediately decided against looking into it further since apparently it's meant to run on a JVM or java Virtual Machine.\n  - I have no intention of looking into Java right now so that was a quick foray into the weird looking syntax of Clojure. maybe something like lisp/elisp for emacs will be more interesting and applicable for me.\n- markdown markdown hyperlinks when separated by declaration and definition, they can be re-used!\n  \n```markdown\n[link text][1]\n\n[1]: https://www.bryanjenks.dev\n\n[but I can also re-use the link here!][1]\n\nAnd this will work all throughout a markdown document\n```\n\n- CompTIA A+ Core2 1002 completed [this udemy course](https://www.udemy.com/course/comptia-220-1002-exam/) to prep for the exam.\n- [[cli.cmd.git]] Found [this GREAT graphical walkthrough tool](https://learngitbranching.js.org/) for learning git\n","n":0.063}}},{"i":1649,"$":{"0":{"v":"22","n":1},"1":{"v":"\n- Mermaid on [[s.apps.azure.devops]] uses a different syntax for the diagram code fences. Instead of 3 backticks \\`\\`\\`  they use colons `:::`\n  - The diagrams will only render and preview on the DevOps wiki pages not the markdown pages or their previews.\n  - The diagrams will also no render in the preview pane of the pull request review section\n  - The only way of reviewing diagram code visually is the code [[cli.cmd.diff]], or by using a sample test wiki page to show preview renders of the diagrams\n  - `mailto:` links have additional properties that can be set in [[s.m.html]] but also with Markdown\n    - [Resource Link](https://css-tricks.com/snippets/html/mailto-links/)\n    - in markdown, to generate an email addressed to someone, with defined subjects line, body, and other addressees you use these pieces of text as part of the links remembering to escape spaces with `$20`:\n      - `?subject=` the subject line of the email. `?subject=My%20Subject`\n      - `?cc=` add carbon copy addressees `?cc=jonny.test@gmail.com`\n      - `?bcc=` blind carbon copy someone `?bcc=jonny.test@gmail.com`\n      - `?body=` your body text remembering to escape spaces with `%20`\n        - `?body=My%20lovely%20email%20body%20message`\n      -  If you only use 1 parameter after the email addressee then that parameter will start with a `?` like `?subject=` every parameter used after that will use a `&` such as `&cc=`, or `&bcc=`, etc.\n\n## All together:\n\n```markdown\n[Send formatted email](mailto:bryan@bryanjenks.dev?cc=bryan@bryanjenks.dev&bcc=bryan@bryanjenks.dev&subject=My%20Subject%20Line&body=My%20lovely%20email%20body%20message)\n```\n\n[Send formatted email](mailto:bryan@bryanjenks.dev?cc=bryan@bryanjenks.dev&bcc=bryan@bryanjenks.dev&subject=My%20Subject%20Line&body=My%20lovely%20email%20body%20message)\n\n\n- The Git Stash command has some awesome options\n\n```bash\ngit stash push \n```\n- like an array method this will create a _Box_ and put all your changes inside of it and shove that _box_ in the corner of the room and give you a clean working tree.\n- The _box_ is now portable and you can switch to another branch and open the _box_ there and take out all of the changes.\n\n```bash\ngit stash pop\n```\n\n- This opens the _box_ and applies all those stashed changes to the current working tree.\n- This is very useful for the situations where maybe you made a bunch of changes and you forgot to make a new branch and you're still on `master`/`main` and you want to move all those changes to the actual feature branch.\n- markdown You can link to other markdown page headings from other documents\n\n```markdown\n[link](file-name.md#heading-with-dashes-for-spaces)\n```\n\n```bash\ngit worktree add master\n```\n\n- Create a bare repo and start making new worktrees\n  - This means that a copy of the repo files is made for each worktree at the source commit that the bare repo was made from\n  - Worktrees make it easier to open multiple repo branches at once under a unified workspace for easy switching of work between multiple features\n  - Doesn't lend itself to easy updating.\n    - The bare repo doesn't `git pull` itself but the worktrees after creation can use `git pull` but this is not ideal. The bare repo is basically frozen at a single commit for all new worktrees made.\n\n- HL7\n  - HL7 terms to better understand what is HL7. There are four primary HL7 standard message types:\n  - Patient Administration ([ADT](http://www.corepointhealth.com/resource-center/hl7-resources/hl7-adt))\n  - Orders ([ORM](http://www.corepointhealth.com/resource-center/hl7-resources/hl7-orm-message)'s)\n  - Results ([ORU](http://www.corepointhealth.com/resource-center/hl7-resources/hl7-oru-message)'s)\n  - Charges ([DFT](http://www.corepointhealth.com/resource-center/hl7-resources/hl7-dft-detail-financial-transaction)'s)\n  - Most commonly used HL7 message types include:\n    - [ACK](https://corepointhealth.com/resource-center/hl7-resources/hl7-acknowledgement-ack) ‚Äì General acknowledgement\n    - [ADT](https://corepointhealth.com/resource-center/hl7-resources/hl7-adt) ‚Äì Admit, Discharge, Tranfser\n    - BAR ‚Äì Add/change billing account\n    - [DFT](https://corepointhealth.com/resource-center/hl7-resources/hl7-dft-detail-financial-transaction)¬†‚Äì Detailed financial transaction\n    - [MDM](https://corepointhealth.com/resource-center/hl7-resources/hl7-mdm-message) ‚Äì Medical document management\n    - MFN ‚Äì Master files notification\n    - [ORM](https://corepointhealth.com/resource-center/hl7-resources/hl7-orm-message) ‚Äì Order (Pharmacy/treatment)\n    - [ORU](https://corepointhealth.com/resource-center/hl7-resources/hl7-oru-message) ‚Äì Observation result (unsolicited)\n    - QRY ‚Äì Query, original mode\n    - RAS ‚Äì Pharmacy/treatment administration\n    - [RDE](https://corepointhealth.com/resource-center/hl7-resources/hl7-rde-message-pharmacy) ‚Äì Pharmacy/treatment encoded order\n    - RGV ‚Äì Pharmacy/treatment give\n    - [SIU](https://corepointhealth.com/resource-center/hl7-resources/hl7-siu-message) ‚Äì Scheduling information unsolicited\n\n","n":0.042}}},{"i":1650,"$":{"0":{"v":"Linux","n":1}}},{"i":1651,"$":{"0":{"v":"Xdg","n":1},"1":{"v":"\n\n- <https://wiki.archlinux.org/title/XDG_Base_Directory>\n\n---\n\n| XDG Variable      | Reference Location   |\n| ----------------- | -------------------- |\n| `XDG_CONFIG_HOME` | `$HOME/.config`      |\n| `XDG_CACHE_HOME`  | `$HOME/.cache`       |\n| `XDG_DATA_HOME`   | `$HOME/.local/share` |\n| `XDG_STATE_HOME`  | `$HOME/.local/state` |\n|                   |                      |\n","n":0.183}}},{"i":1652,"$":{"0":{"v":"Systemd","n":1}}},{"i":1653,"$":{"0":{"v":"Profile","n":1},"1":{"v":"\n\nThis file is sourced upon system login so normally it should only be executed once upon a successful login into the system.\n\nThese profile files `.[zx]profile` can also just point to where you want the real file content to be such as \n\n`$HOME/.xprofile`:\n\n```\n.config/x11/xprofile\n```\n\nbecause this file is run once on system login it should also be the trigger to start the graphical environment in the tty.\n","n":0.125}}},{"i":1654,"$":{"0":{"v":"Hardware","n":1}}},{"i":1655,"$":{"0":{"v":"Raspberry Pi","n":0.707},"1":{"v":"\n\n- Raspberry Pi PLEX Home Media Server\n  - [Main Resource](https://youtu.be/gyMpI8csWis)\n  - KEY\n    - **Noobs Install**\n    - _ISO Install with Pi Installer_\n  - **Using Noobs install Raspberry Pi OS Lite**\n  - _Burn Raspberry Pi OS Lite to the SD card_\n    - _In menu press `Shift + X` to open advanced settings and activate SSH, use Ethernet so DHCP auto assigns an IP Address to the Pi_\n  - update password `passwd`\n  - Update and Upgrade everything: `sudo apt-get update && sudo apt-get upgrade`\n  - `sudo apt-get install vim`\n  - Try to install SSH: `sudo apt-get install openssh-server`\n  - Create SSH file: `touch /boot/ssh`\n  - Activate SSH: \n    - `sudo raspi-config`\n      - Interface Options\n      - Enable SSH\n    - OR\n      - `sudo systemctl enable ssh`\n      - `sudo systemctl start ssh`\n  - Figure out IP Address to SSH into: `hostname -i`\n  - [Install software for Cooling fan](https://wiki.geekworm.com/X735_V2.5_Software)\n    - `sudo apt-get install -y python-smbus python`\n    - `sudo apt-get install -y pigpio python-pigpio python3-pigpio git`\n    - `git clone https://github.com/geekworm-com/x735-v2.5`\n    - `cd x735-v2.5`\n    - `sudo chmod +x *.sh`\n    - `sudo bash install.sh`\n    - `sudo reboot`\n  - update `.bash_aliases`\n    - `alias v='vim'`\n    - `alias '..'='cd ..'`\n    - `alias 'll'='ls -lA'`\n  - Update `.bashrc`\n    - add this so that at startup fan always starts: `python /home/pi/x735-v2.5/pwm_fan_control.py &`\n  - Install OpenMediaVault: `wget -O - https://raw.githubusercontent.com/OpenMediaVault-Plugin-Developers/installScript/master/install | sudo bash`\n  - Go to the web location using the IP address of the pi in the URL location\n  - OpenMediaVault (OMV) default creds:\n    - username: admin\n    - password: openmediavault\n  - Update OMV credentials\n    - System > General Settings > Web Administrator Password\t\n  - Make sure disk/drive is listed\n    - Storage > Disks\n  - Then To mount the drive\n    - Storage > File Systems\n    - Create\n    - Select your device, Label for it, and `EXT4`\n    - Mount\n  - Provisioning\n    - Access Rights Management > Shared Folder\n    - Add\n    - Name it, select the drive, name the folder, default credentials\n    - Privileges\n      - Make sure Pi (or any other user) can read/write\n    - Apply\n  - Now to set up some services\n    - Services\n      - SMB == Windows\n        - Services > SMB > Settings > General Settings > Enable\n        - Services > SMB > Shares > Create\n          - Can leave them all default or modify later, just choose folder and that's MVP\n      - NFS == Linux/MacOS\n        - Services > NFS > Settings > Enable\n        - Services > NFS > Shares > Create\n  - User Access\n    - Access Rights Management > User\n    - Edit the Pi to use the same password as the system login\n    - Hit Save if/when you get an error, acknowledge and then hit Save again\n  - Map the network drives on the various computers using SMB\n  - Starting Plex Server Setup\n    - `sudo apt-get install apt-transport-https`\n    - `curl https://downloads.plex.tv/plex-keys/PlexSign.key | sudo apt-key add -`\n    - `echo deb https://downloads.plex.tv/repo/deb public main | sudo tee /etc/apt/sources.list.d/plexmediaserver.list`\n    - `sudo apt-get update`\n    - `sudo apt install plexmediaserver`\n      - When prompted for Which Repo version to use at around 40% completion, just say `N`\n  - Go to the web address of your IP address plus port 32400/web to open Plex\n  - Make a free account with plex and follow the prompts to set up your account\n\n---\n\n- Tags: \n  -\n- Reference:\n  -\n- Related:\n  -\n\n","n":0.043}}},{"i":1656,"$":{"0":{"v":"Docs","n":1}}},{"i":1657,"$":{"0":{"v":"Write the Docs","n":0.577},"1":{"v":"\n\n- <https://www.writethedocs.org/>\n  - [Style Guides](https://www.writethedocs.org/guide/writing/style-guides/)\n  - [CLI](https://www.writethedocs.org/guide/writing/style-guides/#command-line-resources)\n\n","n":0.378}}},{"i":1658,"$":{"0":{"v":"Devdocs","n":1},"1":{"v":"\n\n[devdocs.io](https://devdocs.io/)\n","n":1}}},{"i":1659,"$":{"0":{"v":"CLI","n":1},"1":{"v":"\n\n<https://clig.dev/>\n","n":1}}},{"i":1660,"$":{"0":{"v":"Shell","n":1}}},{"i":1661,"$":{"0":{"v":"Win Cmd","n":0.707}}},{"i":1662,"$":{"0":{"v":"Schedule Tasks","n":0.707},"1":{"v":"\n![[r.(.2022.03.03.how-to-create-scheduled-tasks-with-command-prompt-on-windows-10]]\n","n":1}}},{"i":1663,"$":{"0":{"v":"Bash","n":1}}},{"i":1664,"$":{"0":{"v":"Variables","n":1}}},{"i":1665,"$":{"0":{"v":"Cdp","n":1},"1":{"v":"\n![[r.(.2022.03.03.secret-features-in-your-unix-shell-cdpath]]\n","n":1}}},{"i":1666,"$":{"0":{"v":"Resources","n":1},"1":{"v":"\n\n- [Command Line Interface Guidelines](https://clig.dev/) #üíªÔ∏è/‚≠ê\n","n":0.408}}},{"i":1667,"$":{"0":{"v":"Philosophy","n":1},"1":{"v":"\n\n- **Human-first design**\n- **Simple parts that work together**\n- **Consistency across programs**\n- **Saying (just) enough**\n- **Ease of discovery**\n- **Conversation as the norm**\n- **Robustness**\n- **Empathy**\n- **Chaos**\n","n":0.204}}},{"i":1668,"$":{"0":{"v":"Guidelines","n":1},"1":{"v":"\n- **The Basics**\n  - _Use a command-line argument parsing library where you can._\n    - Go: Cobra, cli\n    - Java: picocli\n    - Node: oclif\n    - PHP: console\n    - Python: [[click|s.l.python.libs.click]], Typer, [[argparse|s.l.python.libs.argparse]]\n    - Ruby: TTY\n    - Rust: clap, structopt\n    - Swift: swift-argument-parser\n  - _Return zero exit code on success, non-zero on failure_\n  - _Send output to stdout._\n  - _Send messaging to stderr._\n- **Help**\n  - _Display help text when passed no options, the -h flag, or the --help flag._\n  - _Display a concise help text by default._\n  - _Show full help when -h and --help is passed._\n  - _Provide a support path for feedback and issues._\n  - _In help text, link to the web version of the documentation._\n  - _Lead with examples._\n  - _If you‚Äôve got loads of examples, put them somewhere else_\n  - _Display the most common flags and commands at the start of the help text._\n  - _Use formatting in your help text._\n  - _If the user did something wrong and you can guess what they meant, suggest it._\n  - _If your command is expecting to have something piped to it and stdin is an interactive terminal, display help immediately and quit._\n- **Documentation**\n  - _Provide web-based documentation._\n  - _Provide terminal-based documentation._\n  - _Consider providing man pages._\n- **Output**\n  - _Human-readable output is paramount._\n  - _Have machine-readable output where it does not impact usability_\n  - _If human-readable output breaks machine-readable output, use --plain to display output in plain, tabular text format for integration with tools like [[grep|cli.cmd.grep]] or [[awk|s.l.awk]]._\n  - _Display output as formatted [[JSON|s.l.python.libs.json]] if --json is passed._\n  - _Display output on success, but keep it brief._\n  - _If you change state, tell the user._\n  - _Make it easy to see the current state of the system._\n  - _Suggest commands the user should run._\n  - _Actions crossing the boundary of the program‚Äôs internal world should usually be explicit._\n  - _Increase information density‚Äîwith ASCII art!_\n  - _Use color with intention._\n  - _Disable color if your program is not in a terminal or the user requested it._\n    - `stdout` or `stderr` is not an interactive terminal (a TTY). It‚Äôs best to individually check‚Äîif you‚Äôre piping `stdout` to another program, it‚Äôs still useful to get colors on stderr. The `NO_COLOR` environment variable is set. The `TERM` environment variable has the value `dumb`. The user passes the option `--no-color`. You may also want to add a `MYAPP_NO_COLOR` environment variable in case users want to disable color specifically for your program.\n  - _If stdout is not an interactive terminal, don‚Äôt display any animations._\n  - _Use symbols and emoji where it makes things clearer._\n  - _By default, don‚Äôt output information that‚Äôs only understandable by the creators of the software._\n  - _Don‚Äôt treat `stderr` like a log file, at least not by default._\n  - _Use a pager (e.g. `less`) if you are outputting a lot of text._\n    - [[pypager|s.l.python.libs.pypager]] in [[python|software.language.python.]]\n- **Errors**\n  - _Catch errors and rewrite them for humans._\n  - _Signal-to-noise ratio is crucial._\n  - _Consider where the user will look first._\n  - _If there is an unexpected or inexplicable error, provide debug and traceback information, and instructions on how to submit a bug._\n  - _Make it effortless to submit bug reports._\n- **Arguments and flags**\n  - _Prefer flags to args._\n  - _Have full-length versions of all flags._\n  - _Only use one-letter flags for commonly used flags_\n  - _Multiple arguments are fine for simple actions against multiple files._\n  - _If you‚Äôve got two or more arguments for different things, you‚Äôre probably doing something wrong._\n  - _Use standard names for flags, if there is a standard._\n    - `-a`, `--all`: All. For example, `ps`, `fetchmail`.\n      - `-d`, `--debug`: Show debugging output.\n      - `-f`, `--force`: Force. For example, `rm -f` will force the removal of files, even if it thinks it does not have permission to do it. This is also useful for commands which are doing something destructive that usually require user confirmation, but you want to force it to do that destructive action in a script.\n      - `--json`: Display JSON output. See the output section.\n      - `-h`, `--help`: Help. This should only mean help. See the help section.\n      - `--no-input`: See the interactivity section.\n      - `-o`, `--output`: Output file. For example, `sort`, `gcc`.\n      - `-p`, `--port`: Port. For example, `psql`, `ssh`.\n      - `-q`, `--quiet`: Quiet. Display less output. This is particularly useful when displaying output for humans that you might want to hide when running in a script.\n      - `-u`, `--user`: User. For example, `ps`, `ssh`.\n      - `--version`: Version.\n      - `-v`: This can often mean either verbose or version. You might want to use -d for verbose and this for version, or for nothing to avoid confusion.\n  - _Make the default the right thing for most users._\n  - _Prompt for user input._\n  - _Never require a prompt._\n  - _Confirm before doing anything dangerous._\n  - _If a flag can accept an optional value, allow a special word like \"none.\"_\n  - _If possible, make arguments, flags and subcommands order-independent._\n  - ‚ùó _Do not read secrets directly from flags._\n  - _If input or output is a file, support `-` to read from `stdin` or write to `stdout`._\n\n```bash\ncurl https://example.com/something.tar.gz | tar xvf -\n```\n\n- **Interactivity**\n  - _Only use prompts or interactive elements if stdin is an interactive terminal (a TTY)._\n  - _If `--no-input` is passed, don‚Äôt prompt or do anything interactive._\n  - _If you‚Äôre prompting for a password, don‚Äôt print it as the user types._\n  - _Let the user escape._\n- **Subcommands**\n  - _Be consistent across subcommands._\n  - _Use consistent names for multiple levels of subcommand._\n  - _Don‚Äôt have ambiguous or similarly-named commands._\n- **Robustness**\n  - _Validate user input._\n  - _Responsive is more important than fast._\n  - _Show progress if something takes a long time._\n  - _Do stuff in parallel where you can, but be thoughtful about it._\n  - _Make things time out._\n  - _Make it idempotent._\n  - _Make it crash-only._\n  - _People are going to misuse your program._\n- **Future-proofing**\n  - _Keep changes additive where you can._\n  - _Warn before you make a non-additive change._\n  - _Changing output for humans is usually OK._\n  - _Don‚Äôt have a catch-all subcommand._\n  - _Don‚Äôt allow arbitrary abbreviations of subcommands._\n  - _Don‚Äôt create a \"time bomb.\"_\n- **Signals and control characters**\n  - _If a user hits Ctrl-C (the INT signal), exit as soon as possible._\n  - _If a user hits Ctrl-C during clean-up operations that might take a long time, skip them._\n- **Configuration**\n  - Command-line tools have lots of different types of configuration, and lots of different ways to supply it (flags, environment variables, project-level config files). The best way to supply each piece of configuration depends on a few factors, chief among them specificity, stability and complexity.\n    - Configuration generally falls into a few categories:\n      - **Likely to vary from one invocation of the command to the next.**\n        - Examples:\n          - Setting the level of debugging output\n            Enabling a safe mode or dry run of a program\n          - `Recommendation`: Use flags. Environment variables may or may not be useful as well.\n      - **Generally stable from one invocation to the next, but not always. Might vary between projects. Definitely varies between different users working on the same project.**\n        - This type of configuration is often specific to an individual computer.\n        - Examples:\n          - Providing a non-default path to items needed for a program to start\n            Specifying how or whether color should appear in output\n            Specifying an HTTP proxy server to route all requests through\n          - `Recommendation`: Use flags and probably environment variables too. Users may want to set the variables in their shell profile so they apply globally, or in .env for a particular project.\n          - If this configuration is sufficiently complex, it may warrant a configuration file of its own, but environment variables are usually good enough.\n      - **Stable within a project, for all users.**\n        - This is the type of configuration that belongs in version control. Files like Makefile, package.json and docker-compose.yml are all examples of this.\n        - `Recommendation`: Use a command-specific, version-controlled file.\n  - _Follow the XDG-spec._\n  - _If you automatically modify configuration that is not your program‚Äôs, ask the user for consent and tell them exactly what you‚Äôre doing._\n  - _Apply configuration parameters in order of precedence._\n    - Here is the precedence for config parameters, from highest to lowest:\n      - Flags\n        - The running shell‚Äôs environment variables\n        - Project-level configuration (eg. `.env`)\n        - User-level configuration\n        - System wide configuration\n- **Environment variables**\n  - _Environment variables are for behavior that varies with the context in which a command is run._\n  - _For maximum portability, environment variable names must only contain uppercase letters, numbers, and underscores (and mustn‚Äôt start with a number)._\n  - _Aim for single-line environment variable values._\n  - _Avoid commandeering widely used names._\n    - <https://pubs.opengroup.org/onlinepubs/009695399/basedefs/xbd_chap08.html>\n  - _Check general-purpose environment variables for configuration values when possible:_\n    - `NO_COLOR`, to disable color (see Output)\n      - `DEBUG`, to enable more verbose output\n      - `EDITOR`, if you need to prompt the user to edit a file or input more than a single line\n      - `HTTP_PROXY`, `HTTPS_PROXY`, `ALL_PROXY` and `NO_PROXY`, if you‚Äôre going to perform network operations (The HTTP library you‚Äôre using might already check for these.)\n      - `SHELL`, if you need to open up an interactive session of the user‚Äôs preferred shell (If you need to execute a shell script, use a specific interpreter like `/bin/sh`)\n      - `TERM`, `TERMINFO` and `TERMCAP`, if you‚Äôre going to use terminal-specific escape sequences\n      - `TMPDIR`, if you‚Äôre going to create temporary files\n      - `HOME`, for locating configuration files\n      - `PAGER`, if you want to automatically page output\n      - `LINES` and `COLUMNS`, for output that‚Äôs dependent on screen size (e.g. tables)\n  - _Read environment variables from .env where appropriate._\n  - _Don‚Äôt use .env as a substitute for a proper configuration file._\n    - A `.env` file is not commonly stored in source control\n    - (Therefore, any configuration stored in it has no history)\n    - It has only one data type: string\n    - It lends itself to being poorly organized\n    - It makes encoding issues easy to introduce\n    - It often contains sensitive credentials & key material that would be better stored more securely\n  - _Do not read secrets from environment variables._\n    - While environment variables may be convenient for storing secrets, they have proven too prone to leakage:\n    - Exported environment variables are sent to every process, and from there can easily leak into logs or be exfiltrated\n      - Shell substitutions like `curl -H \"Authorization: Bearer $BEARER_TOKEN\"` will leak into globally-readable process state. (cURL offers the `-H @filename` alternative for reading sensitive headers from a file.)\n      - [[Docker|s.containers.docker]] container environment variables can be viewed by anyone with Docker daemon access via docker inspect\n      - Environment variables in [[linux.systemd]] units are globally readable via `systemctl show`\n      - Secrets should only be accepted via credential files, pipes, `AF_UNIX` sockets, secret management services, or another IPC mechanism.\n- **Naming**\n  - _Make it a simple, memorable word._\n  - _Use only lowercase letters, and dashes if you really need to_\n  - _Keep it short._\n  - _Make it easy to type._\n- **Distribution**\n  - _If possible, distribute as a single binary._\n  - _Make it easy to uninstall._\n- **Analytics**\n  - _Do not phone home usage or crash data without consent._\n","n":0.023}}},{"i":1669,"$":{"0":{"v":"Cmd","n":1}}},{"i":1670,"$":{"0":{"v":"Youtube Dl","n":0.707},"1":{"v":"\n\n- <https://ostechnix.com/youtube-dl-tutorial-with-examples-for-beginners/>\n\n---\n\n- Can be used to download videos from webpages with minimal arguments if i go to any directory and run:\n  - `youtube-dl www.exampleURL.com`\n- It will download the YouTube video. plenty of other options available in the man pages\n- **DOWNLOAD CAPABILITIES**\n  - Single video URL\n  - Playlist URL (downloads all individual videos)\n  - Channel URL (downloads all videos on the entire YouTube channel)\n- **DOWNLOAD OPTIONS**\n  - `-F` shows all the formats available for the video download\n  - `-f` followed by a number picks that download options for video quality\n  - `-f bestaudio` will download only the best audio for the video (GREAT FOR MUSIC DOWNLOADS)\n  - `-f140` Downloads the highest quality mp4 files with no errors\n  - `--write-thumbnail` will download the thumbnail(s) of the video(s)\n  - `--skip-download` will skip the download of the actual video but with other options might do something like still download the thumbnails\n","n":0.082}}},{"i":1671,"$":{"0":{"v":"Cmd","n":1}}},{"i":1672,"$":{"0":{"v":"Formatting File Names","n":0.577},"1":{"v":"\n\n## Formatting filenames of downloaded playlist:\n\n```bash\nyoutube-dl --format mp4 -o \"%(upload_date)s %(title)s by %(uploader)s.%(ext)s\" <URL>\n```\n","n":0.267}}},{"i":1673,"$":{"0":{"v":"Download Video English Subs Burned In","n":0.408},"1":{"v":"\n\n## Download video with english subs written to the video file\n\nMight have to change `en` to the desired language such as when the language is listed as `english` for subtitles\n\n```bash\nyoutube-dl --write-sub --sub-lang en <URL>\n# Combine the video file and subtitles with ffmpeg:\nffmpeg -i input_video_file.mp4 -vf subtitles=subtitled_file.english.srt output_file_name.mp4\n```\n","n":0.146}}},{"i":1674,"$":{"0":{"v":"Download Transcripts","n":0.707},"1":{"v":"\n\n## Download transcripts\n\nMight have to change `en` to the desired language such as when the language is listed as `english` for subtitles\n\n```bash\nyoutube-dl --sub-lang en --write-auto-sub --sub-format vtt --skip-download <URL>\n```\n\n- Combine with [THIS](https://gist.github.com/glasslion/b2fcad16bc8a9630dbd7a945ab5ebf5e) to clean the output to `.txt`\n","n":0.162}}},{"i":1675,"$":{"0":{"v":"Download Only Thumbnails","n":0.577},"1":{"v":"\n\n## Download just thumbnails\n\n```bash\nyoutube-dl --write-thumbnail --skip-download <URL>\n```\n","n":0.378}}},{"i":1676,"$":{"0":{"v":"Vim","n":1},"1":{"v":"\n---\nid: zx3p8fyq31yor0hdghamk6a\ntitle: Vim\ndesc: ''\nupdated: 1641202026932\ncreated: 1641202026932\n---\n\n\n","n":0.408}}},{"i":1677,"$":{"0":{"v":"Tips and Tricks","n":0.577}}},{"i":1678,"$":{"0":{"v":"Run Background Shellscript Paste Output","n":0.447},"1":{"v":"\nvim or vim mode in vscode `!!` will start a buffer for running a shell script from PATH and put output where cursor is\n","n":0.204}}},{"i":1679,"$":{"0":{"v":"Automated Documentation","n":0.707},"1":{"v":"\n![[r.(.2022.03.03.shift-k-in-vim]]\n","n":1}}},{"i":1680,"$":{"0":{"v":"Plugins","n":1}}},{"i":1681,"$":{"0":{"v":"Vimwiki","n":1},"1":{"v":"\n\n- [Getting started with vimwiki](https://blog.mague.com/?p=602)\n- [vimwiki cheatsheet](http://thedarnedestthing.com/vimwiki%20cheatsheet)\n","n":0.378}}},{"i":1682,"$":{"0":{"v":"Ultisnips","n":1},"1":{"v":"\n\n## Snippets look like this:\n\n```\nsnippet s \"my snippet\"\n\"Hello There\"$0\nendsnippet\n```\n\n## Global Snippets\n\n_This makes The snippet apply the code to all python code blocks used_\n_in snippets. This is useful for modular code and defining methods_\n_outside of the snippet to be used across many._\n\n_!p for python, !v for Vim script and \\`\\` for bash_\n\n```\nglobal !p\ncode...\nendglobal\n```\n\nTab stops\nmirrors\nvisual tokens\ndefault text\nshell commands\nVim Script commands\npython commands\n","n":0.13}}},{"i":1683,"$":{"0":{"v":"Taskwarrior","n":1},"1":{"v":"\n\n- Mac install brew\n- Install task warrior (its task on most systems)\n- Talk about functionality\n  ```\n  + Contexts defined in RC file\n  + Make projects & tags through tasks\n  + Scripting on it with the unique modifiers (reference my tadd video)\n  ```\n- Annotations, sure , but taskopen though\n  ```\n  + Docs on file system\n  + URL‚Äôs\n  + Notes open with $EDITOR\n  ```\n- VIT\n  ```\n  + Pip install vit\n  + Needs at least 1 task to open vit\n  + Better graphical front end for taskwarrior\n  ```\n- inTheAM\n  ```\n  + setup with token\n  + cron job for refresh (though mac seems to use something other than cron)\n  ```\n- time warrior\n  ```\n  + latest addition\n  + show some uses\n  + talk about use case as contractors or tracking\n  ```\n- RESOURCES:\n\n  ```\n  + Sites for the tools\n  ```\n\n  - Taskwarrior\n  - Vit\n  - Taskopen\n  - intheAM\n  - timewarrior\n\n  Been playing around with other means of getting work done with ADHD and task warrior helped me get a lot more done that things like trello or taskell were but still i was procrastinating. now im using time blocking on icalendar `and explain it and why and how` could also use calcurse if you're one of the linux peeps or any calendar app. i like the ease of using icalendar. and siri for reminders and scheduling tasks. ive gotten things done in the first week that i was sitting on for months.\n","n":0.065}}},{"i":1684,"$":{"0":{"v":"Shred","n":1},"1":{"v":"\n\n- Shred command on linux\n- Privacy\n- File Confidentiality\n- Overwrite and optionally delete file\n- `shred -v --iterations=30 -u [file]`\n- `-u` Deallocate and remove file after overwriting\n- `--iterations=N` Number of times to overwrite the file (default is 3)\n- `-v` 'verbose'\n","n":0.162}}},{"i":1685,"$":{"0":{"v":"Rsync","n":1},"1":{"v":"\n\n## rsync for system backups\n\n### General syntax for dummies\n\n> rsync [options] from [to]\n\n### Tags im using and what they do\n\n- **-a** _Archive mode_\n- **-A** _Preserved Active control Lists (ACL's)_\n- **-X** _Preserves extended attributes_\n- **-v** _Verbose output of actions_\n- **-z** _Compress files in transit_\n\n### Extended Flags\n\n- **--delete** _Files deleted from FROM removed from TO without being explicitly cited_\n- **--exclude={/home/bryan/example/\\*}** _Exclude files from specific directories_\n\n### My 'FROM' Directory\n\n`/home/bryan`\n\n### My 'TO' Location\n\n> _Must mount the backup storage device for external backup_\n\n`/mnt/`\n","n":0.113}}},{"i":1686,"$":{"0":{"v":"Ping","n":1}}},{"i":1687,"$":{"0":{"v":"Nslookup","n":1},"1":{"v":"\n\n\n## Details\n\nIn a Windows environment, you can troubleshoot [[n.protocol.dns]] with the `nslookup` command, either interactively or from the command prompt.\n\n```powershell\nnslookup -Option Host Server\n```\n\n## Usage\n\n```powershell\nnslookup -type=mx widget.com 8.8.8.8\n```\n\n## Powershell DNS resolution\n\n### Resolve Host\n\n```powershell\nResolve-DnsName host\n```\n\n### Resolve host using the same method as the Windows client\n\n```powershell\nResolve-DnsName host -NoHostsFile\n```\n\n### Resolve host but without using any entries from the HOSTS file in the local cache\n\n```powershell\nResolve-DnsName host -DnsOnly\n```\n\n### Resolve host using only the DNS server \n\n```powershell\n-Server IPofDNSserver\n```\n\n## Additional\n\nIt is also possible to search DNS for records other than [[n.protocol.dns.resource-records.a]] or [[n.protocol.dns.resource-records.aaaa]] records. For example, to show only Mail Exchange records in a specific domain, use the cmdlet:\n\n```powershell\nResolve-DnsName domain-Type MX\n```\n\n\n","n":0.099}}},{"i":1688,"$":{"0":{"v":"Nmap","n":1},"1":{"v":"\n\n## Details\n\n<https://nmap.org/>\n\nPort scanning tool\n\n![nmap](/assets/images/2022-01-10-22-18-19.png)\n\n## Usage\n\n```\nnmap <IP subnet / address> [switches]\n```\n\nWith no switches like this the default behavior of [[cli.cmd.nmap]] is to [[cli.cmd.ping]] and send a [[n.protocol.tcp]] [[terms.ack]] packet to ports [[n.port.80]] and [[n.port.443]] to determine whether a host is present.\n\nIf you want to perform only host discovery, you can use `nmap -sn` (or `-sP` in earlier versions) to suppress the port scan.\n\n## Port scanning\n\n- [[n.protocol.tcp]] [[terms.syn]] (`-sS`)\n    - This is a fast technique (also referred to as half-open scanning) as the scanning host requests a connection without acknowledging it. \n    - The target's response to the scan's [[terms.syn]] packet identifies the port state.\n- [[n.protocol.tcp]] connect (`-sT`)\n    - A half-open scan requires [[cli.cmd.nmap]] to have privileged access to the network driver so that it can craft packets. \n    - If privileged access is not available, [[cli.cmd.nmap]] must use the OS to attempt a full [[n.protocol.tcp]] connection. \n    - This type of scan is less stealthy.\n- [[n.protocol.udp]] scans (`-sU`)\n    - Scan [[n.protocol.udp]] ports. \n    - As these do not use [[terms.ack]]s, [[cli.cmd.nmap]] needs to wait for a response or timeout to determine the port state, so [[n.protocol.udp]] scanning can take a long time. \n    - A [[n.protocol.udp]] scan can be combined with a [[n.protocol.tcp]] scan.\n- Port range (`-p`)\n    - By default, [[cli.cmd.nmap]] scans 1,000 commonly used ports. \n    - Use the `-p` argument to specify a port range. \n    - You can also use `--top-ports` n, where n is the number of commonly used ports to scan. \n    - The frequency statistics for determining how commonly a port is used are stored in the [[cli.cmd.nmap]]-services configuration file.\n","n":0.061}}},{"i":1689,"$":{"0":{"v":"Netstat","n":1},"1":{"v":"\n\nallows you to check the state of ports on the local host.\n\n## On Windows\n\n- `-a` displays all connections (active [[n.protocol.tcp]] and [[n.protocol.udp]] connections plus ports in the listening state).\n- `-o` shows the Process ID (PID) number that has opened the port.\n- `-b` shows the process name that has opened the port.\n- `-n` displays ports and addresses in numerical format. Skipping name resolution speeds up each query.\n- `-s` shows per protocol statistics (such as packets received, errors, discards, unknown requests, port requests, failed connections, and so on).\n- `-p` proto displays connections by protocol ([[n.protocol.tcp]] or [[n.protocol.udp]] or TCPv6/UDPv6). When used with `-s`, this switch can also filter the statistics shown by IP, IPv6, [[n.protocol.icmp]], and ICMPv6.\n- `-r` shows the routing table.\n- `-e` displays Ethernet statistics.\n\n---\n\n## On Linux\n\n- `‚Äët` for [[n.protocol.tcp]] Internet connections\n- `‚Äëu` for [[n.protocol.udp]] Internet connections\n- `‚Äëw` for raw connections\n- `‚Äëx` UNIX sockets/local server ports \n- `-a` includes ports in the listening state in the output. `-l` shows only ports in the listening state (omits established connections).\n- `-p` shows the Process ID (PID) number that has opened the port (similar to `-o` on Windows).\n- `-r` shows the routing table.\n- `-s` displays protocol statistics (as in Windows).\n- `-i` displays interface statistics (similar to `-e` on Windows).\n- `-e` displays extra information.\n- `-c` sets output to update continuously.\n### example\n\nFor example, the following command shows Internet connections ([[n.protocol.tcp]] and [[n.protocol.udp]]) only: `netstat ‚Äëtu`\n","n":0.066}}},{"i":1690,"$":{"0":{"v":"Ledger CLI","n":0.707},"1":{"v":"\n- cli tool for managing finances.\n- Combine with [[cli.cmd.fzf]] and some [[Bash|s.l.bash]] scripting to really power automate finances\n","n":0.236}}},{"i":1691,"$":{"0":{"v":"Grep","n":1}}},{"i":1692,"$":{"0":{"v":"Gource","n":1},"1":{"v":"\n\n## Fullscreen history of current directory\n\n```bash\ngource -f .\n```\n","n":0.354}}},{"i":1693,"$":{"0":{"v":"Git","n":1},"1":{"v":"\n\n## General Info\n\n- The `git checkout` command was replaced by `git switch` in git v2.23 as `git checkout` was apparently too overloaded.\n- **Rebasing:** essentially takes a set of commits, \"copies\" them, and plops them down somewhere else.\n  - if you have 2 parallel branches and you rebase 1 onto the other it essentially looks for their common origin point (commit), takes the \"base\" of that branch and places the base at the end and right on top of branch you're Rebasing.\n  - Then the branch that was the recipient of the rebasing needs to be updated so you rebase that onto the branch that was just rebased. This just moves the pointer to the tip of the merged branches\n  - Interactive Rebasing with `git rebase -i <commit hash>` make it a more interactive way to move around and reorder commits\n- **HEAD** is simply the name of the currently checked out commit hash\n  - each commit is a pointer to the repo at a point in time\n    - each branch is a named pointer to a particular commit\n- **Relative References** using `^` and `~` to traverse commits in the `git log` so that you don't need to type even the minimum 6 characters of the commit hash.\n  - `^` when given the name of a commit hash/branch name it will refer to the parent commit: `main^`\n    - These can be stacked too so you can refer to grandparent commit with `main==`\n    - can also use with **HEAD** to traverse from current point: `git checkout HEAD^`\n  - `~` will let you specify a number of commits to travel back instead of `git checkout HEAD====` you can use `git checkout HEAD~4` to traverse 4 commits backward\n- **Forcing Branches** You can move what commit a branch is referencing with something like:\n  - `git branch -f myBranch locationToMoveItTo`\n- **Reversing Commits** There are at least 2 ways to do this `git reset` and `git revert`\n  - `git reset` move the branch backwards in time\n  - `git revert` move the branch backwards in time and acts like the commit never even happened\n- `git cherry-pick <commit hash> <commmit hash> ...`\n  - `git cherry-pick c2 c4`\n- **Tagging** To tag commits as a project milestone or something the commands are very simple\n  - `git tag v1 <commit hash>` will tag what ever referenced commit hash with the tag _\"v1\"_\n  - `git tag v1` will tag what ever commit hash **HEAD** is on with the tag _\"v1\"_\n- `git describe <ref>` If no ref is provided it will just look at wherever HEAD is. This can, however, be used on Tags.\n  - If you have a tag on the first commit of the repo such as `0.1` with a message of `initialized repository` and then ran the command `git describe` all it would tell you is something like:\n    - _\"0.1-62-g07f34f4\"_\n      - _0.1_ for the tag\n      - _62_ for the commits since that tag\n      - _g07f34f4_ is the hash being described (your current one that hasn't been committed yet)\n","n":0.045}}},{"i":1694,"$":{"0":{"v":"Workflow","n":1}}},{"i":1695,"$":{"0":{"v":"Existing Directory","n":0.707},"1":{"v":"\n\n## Start Repository from existing directory then push to GitHub\n\n```bash\ngit init\ngit add .\ngit commit -m 'message'\ngit remote add origin <url.git>\ngit push -u origin master\n```\n","n":0.204}}},{"i":1696,"$":{"0":{"v":"Troubleshooting","n":1},"1":{"v":"\n\n## Troubleshooting\n\n- Removing a file from git history from [this SO article](https://stackoverflow.com/questions/307828/how-do-you-fix-a-bad-merge-and-replay-your-good-commits-onto-a-fixed-merge/15729420#15729420)\n","n":0.289}}},{"i":1697,"$":{"0":{"v":"Tools","n":1}}},{"i":1698,"$":{"0":{"v":"GitHub","n":1},"1":{"v":"\n\n## GitHub README Things\n\n- [Metrics](https://metrics.lecoq.io/)\n\n## Other Things\n\n- Github code art\n  - <https://codeprints.dev/>\n","n":0.289}}},{"i":1699,"$":{"0":{"v":"Tricks","n":1},"1":{"v":"\n\n## Tricks\n\n- [5 Markdown Tricks](https://grantwinney.com/cool-markdown-tricks-for-github/)\n\n```\ntesting this [feature][//]\n\n[//]: # (This comment won't be rendered to the visitor!)\n```\n\n- [open code spaces with a webpage hotkey](https://twitter.com/github/status/1425505817827151872) `.`\n\n### Open any repo in VSCode spaces\n\n- take any [[devlog.notes.processed.github]] repo URL and add `1s` before the `.com`\n\n  | This                                       | Becomes this                                 |\n  | ------------------------------------------ | -------------------------------------------- |\n  | <https://github.com/tallguyjenks/gruvboxr> | <https://github1s.com/tallguyjenks/gruvboxr> |\n\n### Open a new repo with a simple url\n\n- `repo.new` in your browser URL bar\n","n":0.119}}},{"i":1700,"$":{"0":{"v":"Tools","n":1},"1":{"v":"\n\n## Tools\n\n- [octotree](https://www.octotree.io/)\n","n":0.577}}},{"i":1701,"$":{"0":{"v":"Deep Source","n":0.707},"1":{"v":"\n<https://deepsource.io/gh/tallguyjenks/PyRM/metrics>\n","n":1}}},{"i":1702,"$":{"0":{"v":"GitHub Actions","n":0.707},"1":{"v":"\n\n- [Docs](https://docs.github.com/en/actions/quickstart)\n","n":0.707}}},{"i":1703,"$":{"0":{"v":"Setup","n":1},"1":{"v":"\n\n## Configuration\n\n- Great bash config for using git from [this thoughtbot article](https://thoughtbot.com/upcase/videos/git-customizing)\n\n```bash\n# No arguments: `git status`\n# With arguments: acts like `git`\ng() {\n\tif [[ $# > 0 ]]; then\n\t  git $@\n\telse\n\t  git status\n\tfi\n}\n\n# Complete g like git\ncompdef g=git\n```\n\n- A great tip to update your master branch return to the original branch you left and then merge changes. this is made as a git alias.\n  - `!git checkout master && git pull && git fetch --prune && git checkout - && git merge master`\n  - Aliased as `mup` for _\"Master Up\"_\n  - The `!` is running it as a shell command as git aliases can only run 1 command. So this way we're still chaining commands\n","n":0.094}}},{"i":1704,"$":{"0":{"v":"Global Configs","n":0.707},"1":{"v":"\n\n## Set Global Configs\n\n```bash\ngit config --global user.name \"John Doe\"\ngit config --global user.email johndoe@example.com\n```\n","n":0.277}}},{"i":1705,"$":{"0":{"v":"Resources","n":1},"1":{"v":"\n\n## Resources\n\n- [Official Git Docs command shorthand](https://git-scm.com/docs)\n- [GREAT graphical walkthrough tool for learning git](https://learngitbranching.js.org/)\n- [Git Alias Tips](https://www.atlassian.com/blog/git/advanced-git-aliases)\n- [.gitignore Templates](https://github.com/github/gitignore)\n- [Git Cheatsheet](https://ndpsoftware.com/git-cheatsheet.html)\n- [Git Book](https://git-scm.com/docs)\n","n":0.209}}},{"i":1706,"$":{"0":{"v":"Git Lfs","n":0.707},"1":{"v":"\n\n- [[cli.cmd.git]] [[cli.cmd.git.git-lfs]] [git-lfs wiki tutorial](https://github.com/git-lfs/git-lfs/wiki/Tutorial)\n- [[cli.cmd.git]] [[cli.cmd.git.git-lfs]] [Git Large File Storage - How to Work with Big Files](https://youtu.be/uLR1RNqJ1Mw)\n","n":0.229}}},{"i":1707,"$":{"0":{"v":"Cmd","n":1}}},{"i":1708,"$":{"0":{"v":"Worktree","n":1},"1":{"v":"\n\n### git worktree\n\n```bash\ngit worktree add master\n```\n\n- Create a bare repo and start making new worktrees [[import.git#^faf0c6]]\n  - This means that a copy of the repo files is made for each worktree at the source commit that the bare repo was made from\n  - Worktrees make it easier to open multiple repo branches at once under a unified workspace for easy switching of work between multiple features\n  - Doesn't lend itself to easy updating.\n    - The bare repo doesn't `git pull` itself but the worktrees after creation can use `git pull` but this is not ideal. The bare repo is basically frozen at a single commit for all new worktrees made.\n\n## Making work-trees\n\n- [ThePrimeagen](https://youtu.be/2uEqYw-N8uE)\n\n```bash\ngit clone --bare <repo url.git> <name of the folder to create>\n# ex:\ngit clone --bare git@github.com:tallguyjenks/CV.git CV\n\n\n# makes a bare repo of my resume\n# there's nothing in it, none of the files from the repo just git stuff\n# THEN\n\ngit worktree add master\ngit worktree add test\ngit worktree add feature\n\n# it takes the current commit at the HEAD of the repo (git pull at you're at the most recent) and this way # you're working with 3 folders basically 3 branches of the same repo but simultaneously. NO SWITCHING BACK & AND FORTH ü§ØÔ∏èü§ØÔ∏èü§ØÔ∏è\n```\n","n":0.07}}},{"i":1709,"$":{"0":{"v":"Stash","n":1},"1":{"v":"\n\n## git stash\n\n```bash\ngit stash push \n```\n\n- like an array method this will create a _Box_ and put all your changes inside of it and shove that _box_ in the corner of the room and give you a clean working tree.\n- The _box_ is now portable and you can switch to another branch and open the _box_ there and take out all of the changes.\n\n```bash\ngit stash pop\n```\n\n- This opens the _box_ and applies all those stashed changes to the current working tree.\n- This is very useful for the situations where maybe you made a bunch of changes and you forgot to make a new branch and you're still on `master`/`main` and you want to move all those changes to the actual feature branch.\n\n## Saving and moving changes\n\n```bash\n# say you're on master, and you have changes to docs and you're about to make a commit, but you realize \"oh crap, I'm still on master, I needed to put this on a feature branch!\" \n# you can run \ngit stash push \n# to basically package up all those uncommitted changes into a \"box\" and shove it into a corner returning to a master branch that is a mirror of remote master (CLEAN!) \n# then make your branch, switch to it and run \ngit stash pop \n# to grab your changes and put them onto the current working branch. \n```\n\n","n":0.067}}},{"i":1710,"$":{"0":{"v":"Reset","n":1},"1":{"v":"\n\n## Open a cloned repository from a particular commit\n\n- [SO](https://stackoverflow.com/questions/3555107/git-clone-particular-version-of-remote-repository)\n\n```bash\ngit clone [remote_address_here] my_repo\ncd my_repo\ngit reset --hard [ENTER HERE THE COMMIT HASH YOU WANT]\n```\n","n":0.209}}},{"i":1711,"$":{"0":{"v":"Pretty Log Output","n":0.577},"1":{"v":"\n\n### git log\n\n- Pretty Log Output (_PLOG_)\n\n```bash\ngit config --global  alias.plog \"log --graph --format='%Cgreen%h %Cred%aN%Cblue%d%Creset %s %C(yellow)(%cr)%Creset'\"\n```\n","n":0.25}}},{"i":1712,"$":{"0":{"v":"Clone","n":1}}},{"i":1713,"$":{"0":{"v":"Bare","n":1},"1":{"v":"\n\n## BARE Repos\n\n`git clone --bare <url>` or `git init --bare` faf0c6\n","n":0.302}}},{"i":1714,"$":{"0":{"v":"Fzf","n":1}}},{"i":1715,"$":{"0":{"v":"Ffmpeg","n":1}}},{"i":1716,"$":{"0":{"v":"Write Subtitles to Video File","n":0.447},"1":{"v":"\n\n## Write Subtitles to a video file\n\n```shell\nyt-dlp <URL>\nyt-dlp --write-sub --convert-subs srt <URL>\nffmpeg -i video.webm -i subtitles.srt -c:v copy -c:s copy output.mkv\n```\n","n":0.218}}},{"i":1717,"$":{"0":{"v":"Resources","n":1},"1":{"v":"\n\n## Resources\n\n- [VERY helpful stack overflow Q/A that answered this for me](https://stackoverflow.com/questions/7333232/how-to-concatenate-two-mp4-files-using-ffmpeg)\n","n":0.289}}},{"i":1718,"$":{"0":{"v":"Make Gif from Video","n":0.5},"1":{"v":"\n\n## Making a GIF out of a video clip:\n\n```shell\nffmpeg -i <VIDEO FILE> -pix_fmt rgb8 -r 8 -vf scale=-1:640 my-gif.gif\n```\n","n":0.229}}},{"i":1719,"$":{"0":{"v":"Lossless Video Compression","n":0.577},"1":{"v":"\n\n## Compress video with no quality loss\n\n```shell\nffmpeg -i input.mkv -vcodec libx264 -crf 24 output.mp4\n```\n","n":0.267}}},{"i":1720,"$":{"0":{"v":"Flac Audio Files to Mp3","n":0.447},"1":{"v":"\n\n## Convert flac audio files to mp3\n\n```shell\nffmpeg -i input.flac -ab 320k -map_metadata 0 -id3v2_version 3 output.mp3\n```\n","n":0.25}}},{"i":1721,"$":{"0":{"v":"Cut Clips from Video","n":0.5},"1":{"v":"\n\n## Cut clips of a video\n\n```bash\nffmpeg -ss 0 -t 608 -i input.mkv output.mkv\n```\n\n`-ss` which are the start seconds of the clip\n`-t` is how long the clip is to cut out so if we start at 0 and go until 608 seconds then it clips out a 10min8sec video out of what ever video we have. \n`-i` flags the next argument as an input file, there can be multiple.\n\n_Alternative:_\n\n```bash\nffmpeg -i input.mkv -ss 0 -t 10:08 -c copy output.mkv\n```\n\nIn this alternative examples, \n`-i` the input file \n`-ss` start stream at 0 seconds and \n`-t` says the amount of time to go is 10min8sec then \n`-c` is codec its a copy this way it doesnt need to reencode it saving time, and then the output file.\n","n":0.09}}},{"i":1722,"$":{"0":{"v":"Convert Video Formats","n":0.577},"1":{"v":"\n```bash\nffmpeg -i input.mkv -c copy output.m4v\n```\n\n## loop through a directory and convert all files of one type to the other\n\n```bash\nfor file in *.mkv; do ffmpeg -i \"${file}\" -c copy \"${file//.mkv/.mp4}\"; done\n```\n","n":0.18}}},{"i":1723,"$":{"0":{"v":"Concatenate Files","n":0.707},"1":{"v":"\n\n## File Concatenation\n\nThis is what i used to concatenate multiple files together:\n\n```bash\nffmpeg -f concat -i files.txt -c copy rsyncFullVideo.mkv\n```\n\nthe `files.txt` portion is a list of all the files in their relevant directories wrapped in single quotes with the word \"file\" preceding each line like this:\n\n```\nfile '~/Movie1.mkv'\nfile '~/Movie2.mkv'\nfile '~/Movie3.mkv'\n```\n\nafter the `copy` command you list the output file/path/extension all of that and it works!\n\n```bash\n$ cat mylist.txt\nfile '/path/to/file1'\nfile '/path/to/file2'\nfile '/path/to/file3'\n\n$ ffmpeg -f concat -i mylist.txt -c copy output.mp4\n```\n","n":0.115}}},{"i":1724,"$":{"0":{"v":"Dig","n":1},"1":{"v":"\n\n`D`omain `I`nternet `G`roper\n\nUseful with [[n.protocol.dns]]\n\n## Usage\n\n```bash\ndig www.google.com\n```\n\n### Specify a DNS server manually\n\nThis is useful for troubleshooting local DNS\n\n```bash\ndig @8.8.4.4 www.google.com\n```\n\n\n\n\n","n":0.224}}},{"i":1725,"$":{"0":{"v":"Diff","n":1}}},{"i":1726,"$":{"0":{"v":"Show Color Side by Side Diff","n":0.408},"1":{"v":"\n\n```bash\ndiff --color=always --minimal --side-by-side file1 file2\n```\n\n- Shows **red**/_green_ diff of 2 files side by side\n- `file1` is the first arg and so it is on the left\n- `file2` therefore is on the right\n\nWrite diff output to a file\n\n```bash\ndiff --color=always --minimal --side-by-side file1 file2 > output_file.diff\n```\n","n":0.149}}}]}
