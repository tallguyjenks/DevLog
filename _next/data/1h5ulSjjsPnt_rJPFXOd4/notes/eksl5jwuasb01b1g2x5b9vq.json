{"pageProps":{"note":{"id":"eksl5jwuasb01b1g2x5b9vq","title":"Excel Files","desc":"","updated":1642545803264,"created":1642545529938,"custom":{},"fname":"s.l.python.libs.pandas.excel-files","type":"note","vault":{"fsPath":"DevLog"},"contentHash":"b8c6baaa68ee8216b2942f308cbbb03a","links":[],"anchors":{"pdexcelfile":{"type":"header","text":"pd.ExcelFile","value":"pdexcelfile","line":8,"column":0,"depth":2},"pdread_excel":{"type":"header","text":"pd.read_excel","value":"pdread_excel","line":38,"column":0,"depth":2}},"children":[],"parent":"pt6olz4xmnsfaf16lebsbid","data":{}},"body":"<h1 id=\"excel-files\"><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#excel-files\"></a>Excel Files</h1>\n<h2 id=\"pdexcelfile\"><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#pdexcelfile\"></a>pd.ExcelFile</h2>\n<p><a href=\"https://stackoverflow.com/a/17977609/12339658\">https://stackoverflow.com/a/17977609/12339658</a></p>\n<pre class=\"language-python\"><code class=\"language-python\">xl <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>ExcelFile<span class=\"token punctuation\">(</span><span class=\"token string\">'foo.xls'</span><span class=\"token punctuation\">)</span>\n\nxl<span class=\"token punctuation\">.</span>sheet_names  <span class=\"token comment\"># see all sheet names</span>\n\nxl<span class=\"token punctuation\">.</span>parse<span class=\"token punctuation\">(</span>sheet_name<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># read a specific sheet to DataFrame</span>\n</code></pre>\n<p><a href=\"https://pythoninoffice.com/read-multiple-excel-sheets-with-python-pandas/#:~:text=00%3A00%3A00-,pd.ExcelFile(),-With%20this%20approach\">https://pythoninoffice.com/read-multiple-excel-sheets-with-python-pandas/#:~:text=00%3A00%3A00-,pd.ExcelFile(),-With%20this%20approach</a></p>\n<pre class=\"language-python\"><code class=\"language-python\">f <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>ExcelFile<span class=\"token punctuation\">(</span><span class=\"token string\">'users.xlsx'</span><span class=\"token punctuation\">)</span>\nf\n<span class=\"token comment\"># >>> &#x3C;pandas.io.excel._base.ExcelFile object at 0x00000138DAE66670></span>\nf<span class=\"token punctuation\">.</span>sheet_names\n<span class=\"token comment\"># >>> ['User_info', 'purchase', 'compound', 'header_row5']</span>\n<span class=\"token comment\"># To get data from a sheet, we can use the parse() method, and provide the sheet name.</span>\nf<span class=\"token punctuation\">.</span>parse<span class=\"token punctuation\">(</span>sheet_name <span class=\"token operator\">=</span> <span class=\"token string\">'User_info'</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># >>>       User Name Country      City Gender  Age</span>\n<span class=\"token comment\"># >>> 0  Forrest Gump     USA  New York      M   50</span>\n<span class=\"token comment\"># >>> 1     Mary Jane  CANADA   Tornoto      F   30</span>\n<span class=\"token comment\"># >>> 2  Harry Porter      UK    London      M   20</span>\n<span class=\"token comment\"># >>> 3     Jean Grey   CHINA  Shanghai      F   30</span>\n\n</code></pre>\n<h2 id=\"pdread_excel\"><a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#pdread_excel\"></a>pd.read_excel</h2>\n<p><a href=\"https://pythoninoffice.com/read-multiple-excel-sheets-with-python-pandas/\">https://pythoninoffice.com/read-multiple-excel-sheets-with-python-pandas/</a></p>\n<pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># Select sheets to read by index: sheet_name = [0,1,2] means the first three sheets.</span>\n<span class=\"token comment\"># Select sheets to read by name: sheet_name = ['User_info', 'compound']. This method requires you to know the sheet names in advance.</span>\n<span class=\"token comment\"># Select all sheets: sheet_name = None.</span>\n\n<span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd\ndf <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>read_excel<span class=\"token punctuation\">(</span><span class=\"token string\">'users.xlsx'</span><span class=\"token punctuation\">,</span> sheet_name <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\ndf <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>read_excel<span class=\"token punctuation\">(</span><span class=\"token string\">'users.xlsx'</span><span class=\"token punctuation\">,</span> sheet_name <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'User_info'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'compound'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\ndf <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>read_excel<span class=\"token punctuation\">(</span><span class=\"token string\">'users.xlsx'</span><span class=\"token punctuation\">,</span> sheet_name <span class=\"token operator\">=</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># read all sheets</span>\n\n<span class=\"token comment\"># We will read all sheets from the sample Excel file, then use that dataframe for the examples going forward.</span>\n\n<span class=\"token comment\"># The df returns a dictionary of dataframes. The keys of the dictionary contain sheet names, and values of the dictionary contain sheet content.</span>\ndf<span class=\"token punctuation\">.</span>keys<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># >>> dict_keys(['User_info', 'purchase', 'compound', 'header_row5'])</span>\n\ndf<span class=\"token punctuation\">.</span>values<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># >>> dict_values([      User Name Country      City Gender  Age</span>\n<span class=\"token comment\"># >>> 0  Forrest Gump     USA  New York      M   50</span>\n<span class=\"token comment\"># >>> 1     Mary Jane  CANADA   Tornoto      F   30</span>\n<span class=\"token comment\"># >>> 2  Harry Porter      UK    London      M   20</span>\n<span class=\"token comment\"># >>> 3     Jean Grey   CHINA  Shanghai      F   30,</span>\n\n<span class=\"token comment\"># >>> ID      Customer            purchase       Date</span>\n<span class=\"token comment\"># >>> 0  101  Forrest Gump        Dragon Ball  2020-08-12</span>\n<span class=\"token comment\"># >>> 1  102     Mary Jane          Evangelion 2020-01-01</span>\n<span class=\"token comment\"># >>> 2  103  Harry Porter        Kill la Kill 2020-08-01</span>\n<span class=\"token comment\"># >>> 3  104     Jean Grey        Dragon Ball  1999-01-01</span>\n<span class=\"token comment\"># >>> 4  105     Mary Jane          Evangelion 2019-12-31</span>\n<span class=\"token comment\"># >>> 5  106  Harry Porter  Ghost in the Shell 2020-01-01</span>\n<span class=\"token comment\"># >>> 6  107     Jean Grey          Evangelion 2018-04-01,</span>\n<span class=\"token comment\"># >>> ])</span>\n\n<span class=\"token comment\"># To obtain data from a specific sheet, simply reference the key in the dictionary. For example, df['header_row5'] returns the sheet in which data starts from row 5.</span>\ndf<span class=\"token punctuation\">[</span><span class=\"token string\">'header_row5'</span><span class=\"token punctuation\">]</span>\n\n<span class=\"token comment\"># >>>    Unnamed: 0    Unnamed: 1          Unnamed: 2           Unnamed: 3</span>\n<span class=\"token comment\"># >>> 0         NaN           NaN                 NaN                  NaN</span>\n<span class=\"token comment\"># >>> 1         NaN           NaN                 NaN                  NaN</span>\n<span class=\"token comment\"># >>> 2         NaN           NaN                 NaN                  NaN</span>\n<span class=\"token comment\"># >>> 3          ID      Customer            purchase                 Date</span>\n<span class=\"token comment\"># >>> 4         101  Forrest Gump        Dragon Ball   2020-08-12 00:00:00</span>\n<span class=\"token comment\"># >>> 5         102     Mary Jane          Evangelion  2020-01-01 00:00:00</span>\n<span class=\"token comment\"># >>> 6         103  Harry Porter        Kill la Kill  2020-08-01 00:00:00</span>\n<span class=\"token comment\"># >>> 7         104     Jean Grey        Dragon Ball   1999-01-01 00:00:00</span>\n<span class=\"token comment\"># >>> 8         105     Mary Jane          Evangelion  2019-12-31 00:00:00</span>\n<span class=\"token comment\"># >>> 9         106  Harry Porter  Ghost in the Shell  2020-01-01 00:00:00</span>\n<span class=\"token comment\"># >>> 10        107     Jean Grey          Evangelion  2018-04-01 00:00:00</span>\n\n</code></pre>","noteIndex":{"id":"root","title":"root","desc":"","updated":1641013093667,"created":1595961348801,"stub":false,"custom":{"stub":false,"nav_order":0,"permalink":"/"},"fname":"root","type":"note","vault":{"fsPath":"DevLog"},"contentHash":"b0b26527a2962dbb8bd5fb9a53ad702f","links":[],"anchors":{},"children":["rzqe5mjn3q2zfscw1roxr20","Bl9NeJmftBQJyJA3X4a6u","inm1S24v2GcN3Quf7gzDb","fmx7cfcdzale0ezna61yq5z","q6tr8q7gahfijix2ktlhcu3","yah6spesmpstech2ue2k3lq","6pxwlugphnw6vm4t8kn0j5p","i17wi8y2hgivywe08h6q6it","1st35wikvph2aew8aana21u","mijr0wvj3qz0mt9pv9xo1jv","qaf8v120h0ffvbowysjxw50","sh4851li2rsrhx47wwsirgv","fwqjigvqyfxiyl3pbpjvgdw","pxdvvln974xhe8w0alh0hoy","n6yddb1smrac5ll3l1y6wbd","g5dllyqoqkenoiz3opalzu6","kbwt8ucy0yh6bo8fl0kv9iw","beykavbe22agsufmm03hu0c","2uvuqa3c15o5r4j7sqadqvr","yr6gzhx0bhzyec6f52y66vf","4no90tcdswtuwmjm0bxnetx"],"parent":null,"data":{},"body":"\nThe hyperfixated rabbit hole diving knowledge base that is my brain looking at technology.\n"},"collectionChildren":null,"customHeadContent":null,"config":{"version":5,"dev":{"enablePreviewV2":true},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":true,"leaveTrace":false,"bubbleUpCreateNew":true,"fuzzThreshold":0.2,"vaultSelectionModeOnCreate":"smart"}},"randomNote":{},"insertNote":{"initialValue":"templates"},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"copyNoteLink":{},"templateHierarchy":"template"},"workspace":{"vaults":[{"fsPath":"sterkere","visibility":"private"},{"fsPath":"Norsk","visibility":"private"},{"fsPath":"DevLog"}],"journal":{"dailyDomain":"log","name":"daily","dateFormat":"yyyy.MM.dd","addBehavior":"childOfCurrent"},"scratch":{"name":"scratch","dateFormat":"yyyy.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"task":{"todoIntegration":true,"name":"task","dateFormat":"yyyy.MM.dd","addBehavior":"asOwnDomain","statusSymbols":{"":" ","wip":"wip","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"prioritySymbols":{"H":"high","M":"medium","L":"low"},"createTaskSelectionType":"selection2link","taskCompleteStatus":["done","x"]},"graph":{"zoomSpeed":1,"createStub":false},"enableAutoCreateOnDefinition":false,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"enableUserTags":true,"enableHashTags":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":false,"enableEditorDecorations":true,"maxPreviewsCached":10,"maxNoteLength":204800,"dendronVersion":"0.95.1","enableFullHierarchyNoteTitle":false,"enableHandlebarTemplates":false,"templateHierarchy":"template","enableSmartRefs":false},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableMermaid":true,"enablePrettyRefs":true,"enableKatex":true,"automaticallyShowPreview":false,"enableFrontmatterTags":true,"enableHashesForFMTags":false},"publishing":{"theme":"custom","enableFMTitle":true,"enableNoteTitleForLink":true,"enableMermaid":true,"enablePrettyRefs":true,"enableKatex":true,"assetsPrefix":"/DevLog","copyAssets":true,"siteHierarchies":["root"],"enableSiteLastModified":true,"siteRootDir":"docs","siteUrl":"https://{GITHUB_USERNAME}.github.io","enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableRandomlyColoredTags":true,"duplicateNoteBehavior":{"action":"useVault","payload":["DevLog"]},"writeStubs":false,"seo":{"title":"Dendron","description":"Personal knowledge space"},"github":{"enableEditLink":true,"editLinkText":"Edit this page on GitHub","editBranch":"master","editViewMode":"tree"},"enablePrettyLinks":true,"enableTaskNotes":true,"siteFaviconPath":"favicon.ico","siteIndex":"root"}}},"__N_SSG":true}