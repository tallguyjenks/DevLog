<!DOCTYPE html><html><head><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><link rel="icon" href="/favicon.ico"/><title>Sklearn</title><meta name="robots" content="index,follow"/><meta name="googlebot" content="index,follow"/><meta name="description" content="Personal knowledge space"/><meta property="og:title" content="Sklearn"/><meta property="og:description" content="Personal knowledge space"/><meta property="og:url" content="https://{GITHUB_USERNAME}.github.io/DevLog/notes/kurgn324lwx7qqs0ef1ffxj/"/><meta property="og:type" content="article"/><meta property="article:published_time" content="1/2/2022"/><meta property="article:modified_time" content="1/5/2022"/><link rel="canonical" href="https://{GITHUB_USERNAME}.github.io/DevLog/notes/kurgn324lwx7qqs0ef1ffxj/"/><meta name="next-head-count" content="14"/><link rel="preload" href="/DevLog/_next/static/css/477fdc912058141b.css" as="style"/><link rel="stylesheet" href="/DevLog/_next/static/css/477fdc912058141b.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/DevLog/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/DevLog/_next/static/chunks/webpack-193abd745db5a977.js" defer=""></script><script src="/DevLog/_next/static/chunks/framework-bb5c596eafb42b22.js" defer=""></script><script src="/DevLog/_next/static/chunks/main-e26c16bc784f9179.js" defer=""></script><script src="/DevLog/_next/static/chunks/pages/_app-fbacaa7678b5d585.js" defer=""></script><script src="/DevLog/_next/static/chunks/78-13ae6acd5ce7ca5b.js" defer=""></script><script src="/DevLog/_next/static/chunks/373-2f3879190a46a3d9.js" defer=""></script><script src="/DevLog/_next/static/chunks/pages/notes/%5Bid%5D-69449972c2a725d8.js" defer=""></script><script src="/DevLog/_next/static/1h5ulSjjsPnt_rJPFXOd4/_buildManifest.js" defer=""></script><script src="/DevLog/_next/static/1h5ulSjjsPnt_rJPFXOd4/_ssgManifest.js" defer=""></script><script src="/DevLog/_next/static/1h5ulSjjsPnt_rJPFXOd4/_middlewareManifest.js" defer=""></script></head><body><div id="__next" data-reactroot=""><section class="ant-layout" style="width:100%;min-height:100%"><header class="ant-layout-header" style="position:fixed;isolation:isolate;z-index:1;width:100%;border-bottom:1px solid #d4dadf;height:64px;padding:0 24px 0 2px"><div class="ant-row ant-row-center" style="max-width:992px;justify-content:space-between;margin:0 auto"><div style="display:flex" class="ant-col ant-col-xs-20 ant-col-sm-4"></div><div class="ant-col gutter-row ant-col-xs-0 ant-col-sm-20 ant-col-md-20 ant-col-lg-19"><div class="ant-select ant-select-lg ant-select-auto-complete ant-select-single ant-select-allow-clear ant-select-show-search" style="width:100%"><div class="ant-select-selector"><span class="ant-select-selection-search"><input type="search" autoComplete="off" class="ant-select-selection-search-input" role="combobox" aria-haspopup="listbox" aria-owns="undefined_list" aria-autocomplete="list" aria-controls="undefined_list" aria-activedescendant="undefined_list_0" value=""/></span><span class="ant-select-selection-placeholder">For full text search please use the &#x27;?&#x27; prefix. e.g. ? Onboarding</span></div></div></div><div style="display:none;align-items:center;justify-content:center" class="ant-col ant-col-xs-4 ant-col-sm-4 ant-col-md-0 ant-col-lg-0"><span role="img" aria-label="menu" style="font-size:24px" tabindex="-1" class="anticon anticon-menu"><svg viewBox="64 64 896 896" focusable="false" data-icon="menu" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M904 160H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0 624H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0-312H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8z"></path></svg></span></div></div></header><section class="ant-layout site-layout" style="margin-top:64px"><section class="ant-layout site-layout"><div class="site-layout-sidebar" style="flex:0 0 auto;width:calc(max((100% - 992px) / 2, 0px) + 200px);min-width:200px;padding-left:calc((100% - 992px) / 2)"><aside class="ant-layout-sider ant-layout-sider-dark" style="position:fixed;overflow:auto;height:calc(100vh - 64px);background-color:transparent;flex:0 0 200px;max-width:200px;min-width:200px;width:200px"><div class="ant-layout-sider-children"></div></aside></div><section class="ant-layout side-layout-main" style="max-width:1200px;display:initial"><main class="ant-layout-content main-content" role="main" style="padding:0 24px"><div class="ant-row"><div class="ant-col ant-col-24"><div class="ant-row" style="margin-left:-10px;margin-right:-10px"><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-24 ant-col-md-18"><div><h1 id="sklearn"><a aria-hidden="true" class="anchor-heading icon-link" href="#sklearn"></a>Sklearn</h1>
<h2 id="kaggle-ml-course"><a aria-hidden="true" class="anchor-heading icon-link" href="#kaggle-ml-course"></a>Kaggle ML Course</h2>
<h3 id="reading-and-looking-at-the-shape-of-the-data"><a aria-hidden="true" class="anchor-heading icon-link" href="#reading-and-looking-at-the-shape-of-the-data"></a>Reading and looking at the shape of the data</h3>
<pre class="language-python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd

melbourne_file_path <span class="token operator">=</span> <span class="token string">'../input/melbourne-housing-snapshot/melb_data.csv'</span>
melbourne_data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>melbourne_file_path<span class="token punctuation">)</span> 
melbourne_data<span class="token punctuation">.</span>columns
<span class="token comment"># The Melbourne data has some missing values (some houses for which some variables weren't recorded.)</span>
<span class="token comment"># We'll learn to handle missing values in a later tutorial.  </span>
<span class="token comment"># Your Iowa data doesn't have missing values in the columns you use. </span>
<span class="token comment"># So we will take the simplest option for now, and drop houses from our data. </span>
<span class="token comment"># Don't worry about this much for now, though the code is:</span>

<span class="token comment"># dropna drops missing values (think of na as "not available")</span>
melbourne_data <span class="token operator">=</span> melbourne_data<span class="token punctuation">.</span>dropna<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
<span class="token comment"># Seleting the target prediction</span>
y <span class="token operator">=</span> melbourne_data<span class="token punctuation">.</span>Price
<span class="token comment"># Choosing features to help you predict the target</span>
melbourne_features <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'Rooms'</span><span class="token punctuation">,</span> <span class="token string">'Bathroom'</span><span class="token punctuation">,</span> <span class="token string">'Landsize'</span><span class="token punctuation">,</span> <span class="token string">'Lattitude'</span><span class="token punctuation">,</span> <span class="token string">'Longtitude'</span><span class="token punctuation">]</span>
<span class="token comment"># Concention is that the data is called X</span>
X <span class="token operator">=</span> melbourne_data<span class="token punctuation">[</span>melbourne_features<span class="token punctuation">]</span>
X<span class="token punctuation">.</span>describe<span class="token punctuation">(</span><span class="token punctuation">)</span>
X<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span>

</code></pre>
<h3 id="define-the-model"><a aria-hidden="true" class="anchor-heading icon-link" href="#define-the-model"></a>Define the Model</h3>
<pre class="language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>tree <span class="token keyword">import</span> DecisionTreeRegressor

<span class="token comment"># Define model. Specify a number for random_state to ensure same results each run</span>
melbourne_model <span class="token operator">=</span> DecisionTreeRegressor<span class="token punctuation">(</span>random_state<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

<span class="token comment"># Fit model</span>
melbourne_model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Making predictions for the following 5 houses:"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>X<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"The predictions are"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>melbourne_model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

</code></pre>
<h3 id="mean-absolute-error"><a aria-hidden="true" class="anchor-heading icon-link" href="#mean-absolute-error"></a>Mean Absolute Error</h3>
<pre class="language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> mean_absolute_error

predicted_home_prices <span class="token operator">=</span> melbourne_model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
mean_absolute_error<span class="token punctuation">(</span>y<span class="token punctuation">,</span> predicted_home_prices<span class="token punctuation">)</span>
</code></pre>
<h3 id="split-data-into-test-and-validation-sets"><a aria-hidden="true" class="anchor-heading icon-link" href="#split-data-into-test-and-validation-sets"></a>Split data into test and validation sets</h3>
<pre class="language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split

<span class="token comment"># split data into training and validation data, for both features and target</span>
<span class="token comment"># The split is based on a random number generator. Supplying a numeric value to</span>
<span class="token comment"># the random_state argument guarantees we get the same split every time we</span>
<span class="token comment"># run this script.</span>
train_X<span class="token punctuation">,</span> val_X<span class="token punctuation">,</span> train_y<span class="token punctuation">,</span> val_y <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> random_state <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span>
<span class="token comment"># Define model</span>
melbourne_model <span class="token operator">=</span> DecisionTreeRegressor<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># Fit model</span>
melbourne_model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>train_X<span class="token punctuation">,</span> train_y<span class="token punctuation">)</span>

<span class="token comment"># get predicted prices on validation data</span>
val_predictions <span class="token operator">=</span> melbourne_model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>val_X<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>mean_absolute_error<span class="token punctuation">(</span>val_y<span class="token punctuation">,</span> val_predictions<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<h3 id="be-careful-and-consider-the-effects-of-both-overunderfitting"><a aria-hidden="true" class="anchor-heading icon-link" href="#be-careful-and-consider-the-effects-of-both-overunderfitting"></a>Be careful and consider the effects of both over/underfitting</h3>
<pre class="language-python"><code class="language-python"><span class="token comment"># Code you have previously used to load data</span>
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> mean_absolute_error
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>tree <span class="token keyword">import</span> DecisionTreeRegressor


<span class="token comment"># Path of the file to read</span>
iowa_file_path <span class="token operator">=</span> <span class="token string">'../input/home-data-for-ml-course/train.csv'</span>

home_data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>iowa_file_path<span class="token punctuation">)</span>
<span class="token comment"># Create target object and call it y</span>
y <span class="token operator">=</span> home_data<span class="token punctuation">.</span>SalePrice
<span class="token comment"># Create X</span>
features <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'LotArea'</span><span class="token punctuation">,</span> <span class="token string">'YearBuilt'</span><span class="token punctuation">,</span> <span class="token string">'1stFlrSF'</span><span class="token punctuation">,</span> <span class="token string">'2ndFlrSF'</span><span class="token punctuation">,</span> <span class="token string">'FullBath'</span><span class="token punctuation">,</span> <span class="token string">'BedroomAbvGr'</span><span class="token punctuation">,</span> <span class="token string">'TotRmsAbvGrd'</span><span class="token punctuation">]</span>
X <span class="token operator">=</span> home_data<span class="token punctuation">[</span>features<span class="token punctuation">]</span>

<span class="token comment"># Split into validation and training data</span>
train_X<span class="token punctuation">,</span> val_X<span class="token punctuation">,</span> train_y<span class="token punctuation">,</span> val_y <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

<span class="token comment"># Specify Model</span>
iowa_model <span class="token operator">=</span> DecisionTreeRegressor<span class="token punctuation">(</span>random_state<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token comment"># Fit Model</span>
iowa_model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>train_X<span class="token punctuation">,</span> train_y<span class="token punctuation">)</span>

<span class="token comment"># Make validation predictions and calculate mean absolute error</span>
val_predictions <span class="token operator">=</span> iowa_model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>val_X<span class="token punctuation">)</span>
val_mae <span class="token operator">=</span> mean_absolute_error<span class="token punctuation">(</span>val_predictions<span class="token punctuation">,</span> val_y<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Validation MAE: {:,.0f}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>val_mae<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># Set up code checking</span>
<span class="token keyword">from</span> learntools<span class="token punctuation">.</span>core <span class="token keyword">import</span> binder
binder<span class="token punctuation">.</span>bind<span class="token punctuation">(</span><span class="token builtin">globals</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">from</span> learntools<span class="token punctuation">.</span>machine_learning<span class="token punctuation">.</span>ex5 <span class="token keyword">import</span> <span class="token operator">*</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\nSetup complete"</span><span class="token punctuation">)</span>
</code></pre>
<pre class="language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">get_mae</span><span class="token punctuation">(</span>max_leaf_nodes<span class="token punctuation">,</span> train_X<span class="token punctuation">,</span> val_X<span class="token punctuation">,</span> train_y<span class="token punctuation">,</span> val_y<span class="token punctuation">)</span><span class="token punctuation">:</span>
  model <span class="token operator">=</span> DecisionTreeRegressor<span class="token punctuation">(</span>max_leaf_nodes<span class="token operator">=</span>max_leaf_nodes<span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
	model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>train_X<span class="token punctuation">,</span> train_y<span class="token punctuation">)</span>
	preds_val <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>val_X<span class="token punctuation">)</span>
	mae <span class="token operator">=</span> mean_absolute_error<span class="token punctuation">(</span>val_y<span class="token punctuation">,</span> preds_val<span class="token punctuation">)</span>
	<span class="token keyword">return</span><span class="token punctuation">(</span>mae<span class="token punctuation">)</span>
</code></pre>
<pre class="language-python"><code class="language-python"><span class="token comment"># Here is a short solution with a dict comprehension.</span>
<span class="token comment"># The lesson gives an example of how to do this with an explicit loop.</span>
scores <span class="token operator">=</span> <span class="token punctuation">{</span>leaf_size<span class="token punctuation">:</span> get_mae<span class="token punctuation">(</span>leaf_size<span class="token punctuation">,</span> train_X<span class="token punctuation">,</span> val_X<span class="token punctuation">,</span> train_y<span class="token punctuation">,</span> val_y<span class="token punctuation">)</span> <span class="token keyword">for</span> leaf_size <span class="token keyword">in</span> candidate_max_leaf_nodes<span class="token punctuation">}</span>
best_tree_size <span class="token operator">=</span> <span class="token builtin">min</span><span class="token punctuation">(</span>scores<span class="token punctuation">,</span> key<span class="token operator">=</span>scores<span class="token punctuation">.</span>get<span class="token punctuation">)</span>
</code></pre>
<h3 id="fit-model-using-all-data"><a aria-hidden="true" class="anchor-heading icon-link" href="#fit-model-using-all-data"></a>Fit Model Using All Data</h3>
<pre class="language-python"><code class="language-python"><span class="token comment"># Fit the model with best_tree_size. Fill in argument to make optimal size</span>
final_model <span class="token operator">=</span> DecisionTreeRegressor<span class="token punctuation">(</span>max_leaf_nodes<span class="token operator">=</span>best_tree_size<span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

<span class="token comment"># fit the final model</span>
final_model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
</code></pre>
<ul>
<li><code>sklearn.metrics.mean_absolute_error</code></li>
<li><code>sklearn.tree.DecisionTreeRegressor</code>
<ul>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html">https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html</a></li>
</ul>
</li>
<li><code>sklearn.ensemble.RandomForestRegressor</code></li>
</ul>
<pre class="language-python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd

<span class="token comment"># Load data</span>
melbourne_file_path <span class="token operator">=</span> <span class="token string">'../input/melbourne-housing-snapshot/melb_data.csv'</span>
melbourne_data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>melbourne_file_path<span class="token punctuation">)</span> 
<span class="token comment"># Filter rows with missing values</span>
melbourne_data <span class="token operator">=</span> melbourne_data<span class="token punctuation">.</span>dropna<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
<span class="token comment"># Choose target and features</span>
y <span class="token operator">=</span> melbourne_data<span class="token punctuation">.</span>Price
melbourne_features <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'Rooms'</span><span class="token punctuation">,</span> <span class="token string">'Bathroom'</span><span class="token punctuation">,</span> <span class="token string">'Landsize'</span><span class="token punctuation">,</span> <span class="token string">'BuildingArea'</span><span class="token punctuation">,</span> 
					  <span class="token string">'YearBuilt'</span><span class="token punctuation">,</span> <span class="token string">'Lattitude'</span><span class="token punctuation">,</span> <span class="token string">'Longtitude'</span><span class="token punctuation">]</span>
X <span class="token operator">=</span> melbourne_data<span class="token punctuation">[</span>melbourne_features<span class="token punctuation">]</span>

<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split

<span class="token comment"># split data into training and validation data, for both features and target</span>
<span class="token comment"># The split is based on a random number generator. Supplying a numeric value to</span>
<span class="token comment"># the random_state argument guarantees we get the same split every time we</span>
<span class="token comment"># run this script.</span>
train_X<span class="token punctuation">,</span> val_X<span class="token punctuation">,</span> train_y<span class="token punctuation">,</span> val_y <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span>random_state <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span>
</code></pre>
<pre class="language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>ensemble <span class="token keyword">import</span> RandomForestRegressor
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> mean_absolute_error

forest_model <span class="token operator">=</span> RandomForestRegressor<span class="token punctuation">(</span>random_state<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
forest_model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>train_X<span class="token punctuation">,</span> train_y<span class="token punctuation">)</span>
melb_preds <span class="token operator">=</span> forest_model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>val_X<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>mean_absolute_error<span class="token punctuation">(</span>val_y<span class="token punctuation">,</span> melb_preds<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<ul>
<li><code>sklearn.impute.SimpleImputer</code>
<ul>
<li>Inserting the mean value of the column into the <code>NA</code> values so that it can lend itself to modeling purposes still without generating outliers or skewing the probability curve with anything other than the mean</li>
</ul>
</li>
</ul>
<pre class="language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>impute <span class="token keyword">import</span> SimpleImputer

<span class="token comment"># Imputation</span>
my_imputer <span class="token operator">=</span> SimpleImputer<span class="token punctuation">(</span><span class="token punctuation">)</span>
imputed_X_train <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>my_imputer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X_train<span class="token punctuation">)</span><span class="token punctuation">)</span>
imputed_X_valid <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>my_imputer<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>X_valid<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># Imputation removed column names; put them back</span>
imputed_X_train<span class="token punctuation">.</span>columns <span class="token operator">=</span> X_train<span class="token punctuation">.</span>columns
imputed_X_valid<span class="token punctuation">.</span>columns <span class="token operator">=</span> X_valid<span class="token punctuation">.</span>columns

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"MAE from Approach 2 (Imputation):"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>score_dataset<span class="token punctuation">(</span>imputed_X_train<span class="token punctuation">,</span> imputed_X_valid<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_valid<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<ul>
<li>Better yet than just imputing is to track which values were imputed by row/column reference so that you can see the model differences by including and excluding those values</li>
</ul>
<pre class="language-python"><code class="language-python"><span class="token comment"># Make copy to avoid changing original data (when imputing)</span>
X_train_plus <span class="token operator">=</span> X_train<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
X_valid_plus <span class="token operator">=</span> X_valid<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># Make new columns indicating what will be imputed</span>
<span class="token keyword">for</span> col <span class="token keyword">in</span> cols_with_missing<span class="token punctuation">:</span>
	X_train_plus<span class="token punctuation">[</span>col <span class="token operator">+</span> <span class="token string">'_was_missing'</span><span class="token punctuation">]</span> <span class="token operator">=</span> X_train_plus<span class="token punctuation">[</span>col<span class="token punctuation">]</span><span class="token punctuation">.</span>isnull<span class="token punctuation">(</span><span class="token punctuation">)</span>
	X_valid_plus<span class="token punctuation">[</span>col <span class="token operator">+</span> <span class="token string">'_was_missing'</span><span class="token punctuation">]</span> <span class="token operator">=</span> X_valid_plus<span class="token punctuation">[</span>col<span class="token punctuation">]</span><span class="token punctuation">.</span>isnull<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># Imputation</span>
my_imputer <span class="token operator">=</span> SimpleImputer<span class="token punctuation">(</span><span class="token punctuation">)</span>
imputed_X_train_plus <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>my_imputer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X_train_plus<span class="token punctuation">)</span><span class="token punctuation">)</span>
imputed_X_valid_plus <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>my_imputer<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>X_valid_plus<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># Imputation removed column names; put them back</span>
imputed_X_train_plus<span class="token punctuation">.</span>columns <span class="token operator">=</span> X_train_plus<span class="token punctuation">.</span>columns
imputed_X_valid_plus<span class="token punctuation">.</span>columns <span class="token operator">=</span> X_valid_plus<span class="token punctuation">.</span>columns

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"MAE from Approach 3 (An Extension to Imputation):"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>score_dataset<span class="token punctuation">(</span>imputed_X_train_plus<span class="token punctuation">,</span> imputed_X_valid_plus<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_valid<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<pre class="language-python"><code class="language-python"><span class="token comment"># Shape of training data (num_rows, num_columns)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>X_train<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

<span class="token comment"># Number of missing values in each column of training data</span>
missing_val_count_by_column <span class="token operator">=</span> <span class="token punctuation">(</span>X_train<span class="token punctuation">.</span>isnull<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>missing_val_count_by_column<span class="token punctuation">[</span>missing_val_count_by_column <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div></div><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-0 ant-col-md-6"><div><div class=""><div class="ant-anchor-wrapper dendron-toc" style="max-height:calc(100vh - 64px);z-index:1"><div class="ant-anchor"><div class="ant-anchor-ink"><span class="ant-anchor-ink-ball"></span></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#kaggle-ml-course" title="Kaggle ML Course">Kaggle ML Course</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#reading-and-looking-at-the-shape-of-the-data" title="Reading and looking at the shape of the data">Reading and looking at the shape of the data</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#define-the-model" title="Define the Model">Define the Model</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#mean-absolute-error" title="Mean Absolute Error">Mean Absolute Error</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#split-data-into-test-and-validation-sets" title="Split data into test and validation sets">Split data into test and validation sets</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#be-careful-and-consider-the-effects-of-both-overunderfitting" title="Be careful and consider the effects of both over/underfitting">Be careful and consider the effects of both over/underfitting</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#fit-model-using-all-data" title="Fit Model Using All Data">Fit Model Using All Data</a></div></div></div></div></div></div></div></div></div></main><div class="ant-divider ant-divider-horizontal" role="separator"></div><footer class="ant-layout-footer" style="padding:0 24px 24px"></footer></section></section></section></section></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"note":{"id":"kurgn324lwx7qqs0ef1ffxj","title":"Sklearn","desc":"","updated":1641417314286,"created":1641105063867,"stub":false,"isDir":false,"custom":{"stub":false,"isDir":false},"fname":"s.l.python.libs.sklearn","type":"note","vault":{"fsPath":"DevLog"},"contentHash":"9404c7dec3f56820fa7edd36b4550402","links":[],"anchors":{"kaggle-ml-course":{"type":"header","text":"Kaggle ML Course","value":"kaggle-ml-course","line":11,"column":0,"depth":2},"reading-and-looking-at-the-shape-of-the-data":{"type":"header","text":"Reading and looking at the shape of the data","value":"reading-and-looking-at-the-shape-of-the-data","line":13,"column":0,"depth":3},"define-the-model":{"type":"header","text":"Define the Model","value":"define-the-model","line":40,"column":0,"depth":3},"mean-absolute-error":{"type":"header","text":"Mean Absolute Error","value":"mean-absolute-error","line":57,"column":0,"depth":3},"split-data-into-test-and-validation-sets":{"type":"header","text":"Split data into test and validation sets","value":"split-data-into-test-and-validation-sets","line":66,"column":0,"depth":3},"be-careful-and-consider-the-effects-of-both-overunderfitting":{"type":"header","text":"Be careful and consider the effects of both over/underfitting","value":"be-careful-and-consider-the-effects-of-both-overunderfitting","line":86,"column":0,"depth":3},"fit-model-using-all-data":{"type":"header","text":"Fit Model Using All Data","value":"fit-model-using-all-data","line":142,"column":0,"depth":3}},"children":[],"parent":"uf16h268w8q6iuscgzf5xuw","data":{}},"body":"\u003ch1 id=\"sklearn\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#sklearn\"\u003e\u003c/a\u003eSklearn\u003c/h1\u003e\n\u003ch2 id=\"kaggle-ml-course\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#kaggle-ml-course\"\u003e\u003c/a\u003eKaggle ML Course\u003c/h2\u003e\n\u003ch3 id=\"reading-and-looking-at-the-shape-of-the-data\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#reading-and-looking-at-the-shape-of-the-data\"\u003e\u003c/a\u003eReading and looking at the shape of the data\u003c/h3\u003e\n\u003cpre class=\"language-python\"\u003e\u003ccode class=\"language-python\"\u003e\u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e pandas \u003cspan class=\"token keyword\"\u003eas\u003c/span\u003e pd\n\nmelbourne_file_path \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e \u003cspan class=\"token string\"\u003e'../input/melbourne-housing-snapshot/melb_data.csv'\u003c/span\u003e\nmelbourne_data \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e pd\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eread_csv\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003emelbourne_file_path\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e \nmelbourne_data\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ecolumns\n\u003cspan class=\"token comment\"\u003e# The Melbourne data has some missing values (some houses for which some variables weren't recorded.)\u003c/span\u003e\n\u003cspan class=\"token comment\"\u003e# We'll learn to handle missing values in a later tutorial.  \u003c/span\u003e\n\u003cspan class=\"token comment\"\u003e# Your Iowa data doesn't have missing values in the columns you use. \u003c/span\u003e\n\u003cspan class=\"token comment\"\u003e# So we will take the simplest option for now, and drop houses from our data. \u003c/span\u003e\n\u003cspan class=\"token comment\"\u003e# Don't worry about this much for now, though the code is:\u003c/span\u003e\n\n\u003cspan class=\"token comment\"\u003e# dropna drops missing values (think of na as \"not available\")\u003c/span\u003e\nmelbourne_data \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e melbourne_data\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003edropna\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eaxis\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token number\"\u003e0\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003cspan class=\"token comment\"\u003e# Seleting the target prediction\u003c/span\u003e\ny \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e melbourne_data\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ePrice\n\u003cspan class=\"token comment\"\u003e# Choosing features to help you predict the target\u003c/span\u003e\nmelbourne_features \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e \u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e\u003cspan class=\"token string\"\u003e'Rooms'\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e \u003cspan class=\"token string\"\u003e'Bathroom'\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e \u003cspan class=\"token string\"\u003e'Landsize'\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e \u003cspan class=\"token string\"\u003e'Lattitude'\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e \u003cspan class=\"token string\"\u003e'Longtitude'\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\n\u003cspan class=\"token comment\"\u003e# Concention is that the data is called X\u003c/span\u003e\nX \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e melbourne_data\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003emelbourne_features\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\nX\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003edescribe\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\nX\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ehead\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id=\"define-the-model\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#define-the-model\"\u003e\u003c/a\u003eDefine the Model\u003c/h3\u003e\n\u003cpre class=\"language-python\"\u003e\u003ccode class=\"language-python\"\u003e\u003cspan class=\"token keyword\"\u003efrom\u003c/span\u003e sklearn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003etree \u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e DecisionTreeRegressor\n\n\u003cspan class=\"token comment\"\u003e# Define model. Specify a number for random_state to ensure same results each run\u003c/span\u003e\nmelbourne_model \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e DecisionTreeRegressor\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003erandom_state\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"token comment\"\u003e# Fit model\u003c/span\u003e\nmelbourne_model\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003efit\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eX\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e y\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003cspan class=\"token keyword\"\u003eprint\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"Making predictions for the following 5 houses:\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003cspan class=\"token keyword\"\u003eprint\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eX\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ehead\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003cspan class=\"token keyword\"\u003eprint\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"The predictions are\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003cspan class=\"token keyword\"\u003eprint\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003emelbourne_model\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003epredict\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eX\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ehead\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id=\"mean-absolute-error\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#mean-absolute-error\"\u003e\u003c/a\u003eMean Absolute Error\u003c/h3\u003e\n\u003cpre class=\"language-python\"\u003e\u003ccode class=\"language-python\"\u003e\u003cspan class=\"token keyword\"\u003efrom\u003c/span\u003e sklearn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003emetrics \u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e mean_absolute_error\n\npredicted_home_prices \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e melbourne_model\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003epredict\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eX\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\nmean_absolute_error\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ey\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e predicted_home_prices\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id=\"split-data-into-test-and-validation-sets\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#split-data-into-test-and-validation-sets\"\u003e\u003c/a\u003eSplit data into test and validation sets\u003c/h3\u003e\n\u003cpre class=\"language-python\"\u003e\u003ccode class=\"language-python\"\u003e\u003cspan class=\"token keyword\"\u003efrom\u003c/span\u003e sklearn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003emodel_selection \u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e train_test_split\n\n\u003cspan class=\"token comment\"\u003e# split data into training and validation data, for both features and target\u003c/span\u003e\n\u003cspan class=\"token comment\"\u003e# The split is based on a random number generator. Supplying a numeric value to\u003c/span\u003e\n\u003cspan class=\"token comment\"\u003e# the random_state argument guarantees we get the same split every time we\u003c/span\u003e\n\u003cspan class=\"token comment\"\u003e# run this script.\u003c/span\u003e\ntrain_X\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e val_X\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e train_y\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e val_y \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e train_test_split\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eX\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e y\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e random_state \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e \u003cspan class=\"token number\"\u003e0\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003cspan class=\"token comment\"\u003e# Define model\u003c/span\u003e\nmelbourne_model \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e DecisionTreeRegressor\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003cspan class=\"token comment\"\u003e# Fit model\u003c/span\u003e\nmelbourne_model\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003efit\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etrain_X\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e train_y\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"token comment\"\u003e# get predicted prices on validation data\u003c/span\u003e\nval_predictions \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e melbourne_model\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003epredict\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eval_X\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003cspan class=\"token keyword\"\u003eprint\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003emean_absolute_error\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eval_y\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e val_predictions\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id=\"be-careful-and-consider-the-effects-of-both-overunderfitting\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#be-careful-and-consider-the-effects-of-both-overunderfitting\"\u003e\u003c/a\u003eBe careful and consider the effects of both over/underfitting\u003c/h3\u003e\n\u003cpre class=\"language-python\"\u003e\u003ccode class=\"language-python\"\u003e\u003cspan class=\"token comment\"\u003e# Code you have previously used to load data\u003c/span\u003e\n\u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e pandas \u003cspan class=\"token keyword\"\u003eas\u003c/span\u003e pd\n\u003cspan class=\"token keyword\"\u003efrom\u003c/span\u003e sklearn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003emetrics \u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e mean_absolute_error\n\u003cspan class=\"token keyword\"\u003efrom\u003c/span\u003e sklearn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003emodel_selection \u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e train_test_split\n\u003cspan class=\"token keyword\"\u003efrom\u003c/span\u003e sklearn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003etree \u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e DecisionTreeRegressor\n\n\n\u003cspan class=\"token comment\"\u003e# Path of the file to read\u003c/span\u003e\niowa_file_path \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e \u003cspan class=\"token string\"\u003e'../input/home-data-for-ml-course/train.csv'\u003c/span\u003e\n\nhome_data \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e pd\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eread_csv\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eiowa_file_path\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003cspan class=\"token comment\"\u003e# Create target object and call it y\u003c/span\u003e\ny \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e home_data\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eSalePrice\n\u003cspan class=\"token comment\"\u003e# Create X\u003c/span\u003e\nfeatures \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e \u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e\u003cspan class=\"token string\"\u003e'LotArea'\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e \u003cspan class=\"token string\"\u003e'YearBuilt'\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e \u003cspan class=\"token string\"\u003e'1stFlrSF'\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e \u003cspan class=\"token string\"\u003e'2ndFlrSF'\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e \u003cspan class=\"token string\"\u003e'FullBath'\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e \u003cspan class=\"token string\"\u003e'BedroomAbvGr'\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e \u003cspan class=\"token string\"\u003e'TotRmsAbvGrd'\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\nX \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e home_data\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003efeatures\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\n\n\u003cspan class=\"token comment\"\u003e# Split into validation and training data\u003c/span\u003e\ntrain_X\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e val_X\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e train_y\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e val_y \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e train_test_split\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eX\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e y\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e random_state\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"token comment\"\u003e# Specify Model\u003c/span\u003e\niowa_model \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e DecisionTreeRegressor\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003erandom_state\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003cspan class=\"token comment\"\u003e# Fit Model\u003c/span\u003e\niowa_model\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003efit\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etrain_X\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e train_y\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"token comment\"\u003e# Make validation predictions and calculate mean absolute error\u003c/span\u003e\nval_predictions \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e iowa_model\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003epredict\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eval_X\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\nval_mae \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e mean_absolute_error\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eval_predictions\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e val_y\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003cspan class=\"token keyword\"\u003eprint\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"Validation MAE: {:,.0f}\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003e\u003cspan class=\"token builtin\"\u003eformat\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eval_mae\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"token comment\"\u003e# Set up code checking\u003c/span\u003e\n\u003cspan class=\"token keyword\"\u003efrom\u003c/span\u003e learntools\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ecore \u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e binder\nbinder\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ebind\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token builtin\"\u003eglobals\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003cspan class=\"token keyword\"\u003efrom\u003c/span\u003e learntools\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003emachine_learning\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eex5 \u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"token operator\"\u003e*\u003c/span\u003e\n\u003cspan class=\"token keyword\"\u003eprint\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"\\nSetup complete\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre class=\"language-python\"\u003e\u003ccode class=\"language-python\"\u003e\u003cspan class=\"token keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"token function\"\u003eget_mae\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003emax_leaf_nodes\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e train_X\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e val_X\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e train_y\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e val_y\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n  model \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e DecisionTreeRegressor\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003emax_leaf_nodes\u003cspan class=\"token operator\"\u003e=\u003c/span\u003emax_leaf_nodes\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e random_state\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token number\"\u003e0\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\tmodel\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003efit\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etrain_X\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e train_y\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\tpreds_val \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e model\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003epredict\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eval_X\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\tmae \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e mean_absolute_error\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eval_y\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e preds_val\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\t\u003cspan class=\"token keyword\"\u003ereturn\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003emae\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre class=\"language-python\"\u003e\u003ccode class=\"language-python\"\u003e\u003cspan class=\"token comment\"\u003e# Here is a short solution with a dict comprehension.\u003c/span\u003e\n\u003cspan class=\"token comment\"\u003e# The lesson gives an example of how to do this with an explicit loop.\u003c/span\u003e\nscores \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e \u003cspan class=\"token punctuation\"\u003e{\u003c/span\u003eleaf_size\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e get_mae\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eleaf_size\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e train_X\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e val_X\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e train_y\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e val_y\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e \u003cspan class=\"token keyword\"\u003efor\u003c/span\u003e leaf_size \u003cspan class=\"token keyword\"\u003ein\u003c/span\u003e candidate_max_leaf_nodes\u003cspan class=\"token punctuation\"\u003e}\u003c/span\u003e\nbest_tree_size \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e \u003cspan class=\"token builtin\"\u003emin\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003escores\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e key\u003cspan class=\"token operator\"\u003e=\u003c/span\u003escores\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eget\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id=\"fit-model-using-all-data\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#fit-model-using-all-data\"\u003e\u003c/a\u003eFit Model Using All Data\u003c/h3\u003e\n\u003cpre class=\"language-python\"\u003e\u003ccode class=\"language-python\"\u003e\u003cspan class=\"token comment\"\u003e# Fit the model with best_tree_size. Fill in argument to make optimal size\u003c/span\u003e\nfinal_model \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e DecisionTreeRegressor\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003emax_leaf_nodes\u003cspan class=\"token operator\"\u003e=\u003c/span\u003ebest_tree_size\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e random_state\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"token comment\"\u003e# fit the final model\u003c/span\u003e\nfinal_model\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003efit\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eX\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e y\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003esklearn.metrics.mean_absolute_error\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003esklearn.tree.DecisionTreeRegressor\u003c/code\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html\"\u003ehttps://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003esklearn.ensemble.RandomForestRegressor\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre class=\"language-python\"\u003e\u003ccode class=\"language-python\"\u003e\u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e pandas \u003cspan class=\"token keyword\"\u003eas\u003c/span\u003e pd\n\n\u003cspan class=\"token comment\"\u003e# Load data\u003c/span\u003e\nmelbourne_file_path \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e \u003cspan class=\"token string\"\u003e'../input/melbourne-housing-snapshot/melb_data.csv'\u003c/span\u003e\nmelbourne_data \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e pd\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eread_csv\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003emelbourne_file_path\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e \n\u003cspan class=\"token comment\"\u003e# Filter rows with missing values\u003c/span\u003e\nmelbourne_data \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e melbourne_data\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003edropna\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eaxis\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token number\"\u003e0\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003cspan class=\"token comment\"\u003e# Choose target and features\u003c/span\u003e\ny \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e melbourne_data\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ePrice\nmelbourne_features \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e \u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e\u003cspan class=\"token string\"\u003e'Rooms'\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e \u003cspan class=\"token string\"\u003e'Bathroom'\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e \u003cspan class=\"token string\"\u003e'Landsize'\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e \u003cspan class=\"token string\"\u003e'BuildingArea'\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e \n\t\t\t\t\t  \u003cspan class=\"token string\"\u003e'YearBuilt'\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e \u003cspan class=\"token string\"\u003e'Lattitude'\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e \u003cspan class=\"token string\"\u003e'Longtitude'\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\nX \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e melbourne_data\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003emelbourne_features\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\n\n\u003cspan class=\"token keyword\"\u003efrom\u003c/span\u003e sklearn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003emodel_selection \u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e train_test_split\n\n\u003cspan class=\"token comment\"\u003e# split data into training and validation data, for both features and target\u003c/span\u003e\n\u003cspan class=\"token comment\"\u003e# The split is based on a random number generator. Supplying a numeric value to\u003c/span\u003e\n\u003cspan class=\"token comment\"\u003e# the random_state argument guarantees we get the same split every time we\u003c/span\u003e\n\u003cspan class=\"token comment\"\u003e# run this script.\u003c/span\u003e\ntrain_X\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e val_X\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e train_y\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e val_y \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e train_test_split\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eX\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e y\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003erandom_state \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e \u003cspan class=\"token number\"\u003e0\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre class=\"language-python\"\u003e\u003ccode class=\"language-python\"\u003e\u003cspan class=\"token keyword\"\u003efrom\u003c/span\u003e sklearn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eensemble \u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e RandomForestRegressor\n\u003cspan class=\"token keyword\"\u003efrom\u003c/span\u003e sklearn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003emetrics \u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e mean_absolute_error\n\nforest_model \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e RandomForestRegressor\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003erandom_state\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\nforest_model\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003efit\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etrain_X\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e train_y\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\nmelb_preds \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e forest_model\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003epredict\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eval_X\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003cspan class=\"token keyword\"\u003eprint\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003emean_absolute_error\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eval_y\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e melb_preds\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003esklearn.impute.SimpleImputer\u003c/code\u003e\n\u003cul\u003e\n\u003cli\u003eInserting the mean value of the column into the \u003ccode\u003eNA\u003c/code\u003e values so that it can lend itself to modeling purposes still without generating outliers or skewing the probability curve with anything other than the mean\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre class=\"language-python\"\u003e\u003ccode class=\"language-python\"\u003e\u003cspan class=\"token keyword\"\u003efrom\u003c/span\u003e sklearn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eimpute \u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e SimpleImputer\n\n\u003cspan class=\"token comment\"\u003e# Imputation\u003c/span\u003e\nmy_imputer \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e SimpleImputer\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\nimputed_X_train \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e pd\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eDataFrame\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003emy_imputer\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003efit_transform\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eX_train\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\nimputed_X_valid \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e pd\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eDataFrame\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003emy_imputer\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003etransform\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eX_valid\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"token comment\"\u003e# Imputation removed column names; put them back\u003c/span\u003e\nimputed_X_train\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ecolumns \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e X_train\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ecolumns\nimputed_X_valid\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ecolumns \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e X_valid\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ecolumns\n\n\u003cspan class=\"token keyword\"\u003eprint\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"MAE from Approach 2 (Imputation):\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003cspan class=\"token keyword\"\u003eprint\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003escore_dataset\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eimputed_X_train\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e imputed_X_valid\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e y_train\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e y_valid\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003eBetter yet than just imputing is to track which values were imputed by row/column reference so that you can see the model differences by including and excluding those values\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre class=\"language-python\"\u003e\u003ccode class=\"language-python\"\u003e\u003cspan class=\"token comment\"\u003e# Make copy to avoid changing original data (when imputing)\u003c/span\u003e\nX_train_plus \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e X_train\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ecopy\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\nX_valid_plus \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e X_valid\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ecopy\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"token comment\"\u003e# Make new columns indicating what will be imputed\u003c/span\u003e\n\u003cspan class=\"token keyword\"\u003efor\u003c/span\u003e col \u003cspan class=\"token keyword\"\u003ein\u003c/span\u003e cols_with_missing\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n\tX_train_plus\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003ecol \u003cspan class=\"token operator\"\u003e+\u003c/span\u003e \u003cspan class=\"token string\"\u003e'_was_missing'\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e X_train_plus\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003ecol\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eisnull\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\tX_valid_plus\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003ecol \u003cspan class=\"token operator\"\u003e+\u003c/span\u003e \u003cspan class=\"token string\"\u003e'_was_missing'\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e X_valid_plus\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003ecol\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eisnull\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"token comment\"\u003e# Imputation\u003c/span\u003e\nmy_imputer \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e SimpleImputer\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\nimputed_X_train_plus \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e pd\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eDataFrame\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003emy_imputer\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003efit_transform\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eX_train_plus\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\nimputed_X_valid_plus \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e pd\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eDataFrame\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003emy_imputer\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003etransform\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eX_valid_plus\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"token comment\"\u003e# Imputation removed column names; put them back\u003c/span\u003e\nimputed_X_train_plus\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ecolumns \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e X_train_plus\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ecolumns\nimputed_X_valid_plus\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ecolumns \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e X_valid_plus\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ecolumns\n\n\u003cspan class=\"token keyword\"\u003eprint\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"MAE from Approach 3 (An Extension to Imputation):\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003cspan class=\"token keyword\"\u003eprint\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003escore_dataset\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eimputed_X_train_plus\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e imputed_X_valid_plus\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e y_train\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e y_valid\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre class=\"language-python\"\u003e\u003ccode class=\"language-python\"\u003e\u003cspan class=\"token comment\"\u003e# Shape of training data (num_rows, num_columns)\u003c/span\u003e\n\u003cspan class=\"token keyword\"\u003eprint\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eX_train\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eshape\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"token comment\"\u003e# Number of missing values in each column of training data\u003c/span\u003e\nmissing_val_count_by_column \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e \u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eX_train\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eisnull\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003e\u003cspan class=\"token builtin\"\u003esum\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003cspan class=\"token keyword\"\u003eprint\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003emissing_val_count_by_column\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003emissing_val_count_by_column \u003cspan class=\"token operator\"\u003e\u003e\u003c/span\u003e \u003cspan class=\"token number\"\u003e0\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e","noteIndex":{"id":"root","title":"root","desc":"","updated":1641013093667,"created":1595961348801,"stub":false,"custom":{"stub":false,"nav_order":0,"permalink":"/"},"fname":"root","type":"note","vault":{"fsPath":"DevLog"},"contentHash":"b0b26527a2962dbb8bd5fb9a53ad702f","links":[],"anchors":{},"children":["rzqe5mjn3q2zfscw1roxr20","Bl9NeJmftBQJyJA3X4a6u","inm1S24v2GcN3Quf7gzDb","fmx7cfcdzale0ezna61yq5z","q6tr8q7gahfijix2ktlhcu3","yah6spesmpstech2ue2k3lq","6pxwlugphnw6vm4t8kn0j5p","i17wi8y2hgivywe08h6q6it","1st35wikvph2aew8aana21u","mijr0wvj3qz0mt9pv9xo1jv","qaf8v120h0ffvbowysjxw50","sh4851li2rsrhx47wwsirgv","fwqjigvqyfxiyl3pbpjvgdw","pxdvvln974xhe8w0alh0hoy","n6yddb1smrac5ll3l1y6wbd","g5dllyqoqkenoiz3opalzu6","kbwt8ucy0yh6bo8fl0kv9iw","beykavbe22agsufmm03hu0c","2uvuqa3c15o5r4j7sqadqvr","yr6gzhx0bhzyec6f52y66vf","4no90tcdswtuwmjm0bxnetx"],"parent":null,"data":{},"body":"\nThe hyperfixated rabbit hole diving knowledge base that is my brain looking at technology.\n"},"collectionChildren":null,"customHeadContent":null,"config":{"version":5,"dev":{"enablePreviewV2":true},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":true,"leaveTrace":false,"bubbleUpCreateNew":true,"fuzzThreshold":0.2,"vaultSelectionModeOnCreate":"smart"}},"randomNote":{},"insertNote":{"initialValue":"templates"},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"copyNoteLink":{},"templateHierarchy":"template"},"workspace":{"vaults":[{"fsPath":"sterkere","visibility":"private"},{"fsPath":"Norsk","visibility":"private"},{"fsPath":"DevLog"}],"journal":{"dailyDomain":"log","name":"daily","dateFormat":"yyyy.MM.dd","addBehavior":"childOfCurrent"},"scratch":{"name":"scratch","dateFormat":"yyyy.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"task":{"todoIntegration":true,"name":"task","dateFormat":"yyyy.MM.dd","addBehavior":"asOwnDomain","statusSymbols":{"":" ","wip":"wip","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"prioritySymbols":{"H":"high","M":"medium","L":"low"},"createTaskSelectionType":"selection2link","taskCompleteStatus":["done","x"]},"graph":{"zoomSpeed":1,"createStub":false},"enableAutoCreateOnDefinition":false,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"enableUserTags":true,"enableHashTags":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":false,"enableEditorDecorations":true,"maxPreviewsCached":10,"maxNoteLength":204800,"dendronVersion":"0.95.1","enableFullHierarchyNoteTitle":false,"enableHandlebarTemplates":false,"templateHierarchy":"template","enableSmartRefs":false},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableMermaid":true,"enablePrettyRefs":true,"enableKatex":true,"automaticallyShowPreview":false,"enableFrontmatterTags":true,"enableHashesForFMTags":false},"publishing":{"theme":"custom","enableFMTitle":true,"enableNoteTitleForLink":true,"enableMermaid":true,"enablePrettyRefs":true,"enableKatex":true,"assetsPrefix":"/DevLog","copyAssets":true,"siteHierarchies":["root"],"enableSiteLastModified":true,"siteRootDir":"docs","siteUrl":"https://{GITHUB_USERNAME}.github.io","enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableRandomlyColoredTags":true,"duplicateNoteBehavior":{"action":"useVault","payload":["DevLog"]},"writeStubs":false,"seo":{"title":"Dendron","description":"Personal knowledge space"},"github":{"enableEditLink":true,"editLinkText":"Edit this page on GitHub","editBranch":"master","editViewMode":"tree"},"enablePrettyLinks":true,"enableTaskNotes":true,"siteFaviconPath":"favicon.ico","siteIndex":"root"}}},"__N_SSG":true},"page":"/notes/[id]","query":{"id":"kurgn324lwx7qqs0ef1ffxj"},"buildId":"1h5ulSjjsPnt_rJPFXOd4","assetPrefix":"/DevLog","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>